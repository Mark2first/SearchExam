{"read":"125","createTime":"2021-12-31 09:44","comment":"0","id":"15751705","title":"光速从0到1掌握Prometheus和Grafana，腾讯云专家5万字精华教程免费送","url":"https://www.cnblogs.com/tencent-cloud-native/p/15751705.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>黄雷，腾讯云高级工程师，曾负责构建腾讯云云监控新一代多维业务监控系统，擅长大规模分布式监控系统设计，对 golang 后台项目架构设计有较深理解，后加入TKE团队，致力于研究 Kubernetes 相关运维技术，拥有多年 Kubernetes 集群联邦运维管理经验，目前在团队主要负责大规模集群联邦可观测性提升，主导研发了腾讯云万级 Kubernetes 集群监控告警系统，智能巡检与风险探测系统。</p> \n <h2 id=\"摘要\">摘要</h2> \n <p>如果问笔者，在管理 Kubernetes 集群的时候，有什么开源组件是一定会用的，那笔者觉得 Prometheus 一定会是其中之一。Prometheus 拥有强劲的性能，活跃的生态，便捷的部署方式，还有灵活的 PromQL，特别适合用于 Kubernetes 场景下的 master，节点，应用等各个层级的监控数据采集和聚合，再配合炫丽的 Grafana 面板（如下图），可谓是云原生监控的最佳方案。<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211231094421038-2126516419.png\" alt=\"\" loading=\"lazy\"><br> <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211231094421608-1865426779.png\" alt=\"\" loading=\"lazy\"></p> \n <p>固然 Prometheus 和 Grafana 十分强大，但是刚接触的时候，还是有一定的学习成本，不易上手，这点笔者特别有感触。记得几年前笔者还未负责团队云原生可观测性提升的时候，就经常听到边上一刚接触 Prometheus 的哥们成天和笔者吐槽，“哎，Prometheus 的语法怎么这么复杂”，“这东西太恶心了，这怎么写啊”。当时笔者还嘲笑他夸张，但当我也开始学习 Prometheus，开始配 Grafana 面板的时候，也发出过一样的吐槽声，例如下边的语句。</p> \n <pre><code class=\"language-javascript\"> max(label_replace(\n label_replace(\n label_replace(\n kube_deployment_status_replicas_unavailable,\n \"workload_kind\",\"Deployment\",\"\",\"\")\n ,\"workload_name\",\"$1\",\"deployment\",\"(.*)\"),\n \"__name__\", \"k8s_workload_abnormal\", \"__name__\",\"(.*)\")\n )\n by (namespace, workload_name, workload_kind,__name__)\n or on (namespace,workload_name,workload_kind, __name__) max(label_replace(\n label_replace(\n label_replace(\n kube_daemonset_status_number_unavailable,\n \"workload_kind\",\"DaemonSet\",\"\",\"\")\n ,\"workload_name\",\"$1\",\"daemonset\",\"(.*)\"),\n \"__name__\", \"k8s_workload_abnormal\", \"__name__\",\"(.*)\") ) by (namespace, workload_name, workload_kind,__name__)\n or on (namespace,workload_name,workload_kind, __name__)\n max(label_replace(\n label_replace(\n label_replace(\n (kube_statefulset_replicas - kube_statefulset_status_replicas_ready),\n \"workload_kind\",\"StatefulSet\",\"\",\"\")\n ,\"workload_name\",\"$1\",\"statefulset\",\"(.*)\"),\n \"__name__\", \"k8s_workload_abnormal\", \"__name__\",\"(.*)\") ) by (namespace, workload_name, workload_kind,__name__)\n or on (namespace,workload_name,workload_kind, __name__)\n max(label_replace(\n label_replace(\n label_replace(\n (kube_job_status_failed),\n \"workload_kind\",\"Job\",\"\",\"\")\n ,\"workload_name\",\"$1\",\"job_name\",\"(.*)\"),\n \"__name__\", \"k8s_workload_abnormal\", \"__name__\",\"(.*)\") ) by (namespace, workload_name, workload_kind,__name__)\n or on (namespace,workload_name,workload_kind, __name__)\n max(label_replace(\n label_replace(\n label_replace(\n (kube_cronjob_info * 0),\n \"workload_kind\",\"CronJob\",\"\",\"\")\n ,\"workload_name\",\"\",\"cronjob\",\"(.*)\"),\n \"__name__\", \"k8s_workload_abnormal\", \"__name__\",\"(.*)\") ) by (namespace, workload_name, workload_kind,__name__)\n</code></pre> \n <p>笔者这几年在使用 Prometheus 的过程中积累了一定实践经验，也踩了不少坑。</p> \n <p>为了让想要学习 Prometheus 的读者朋友更加快速的入门，少走弯路，提升云原生时代业务监控技能。</p> \n <p>笔者整理并总结了一版教程，包括一些最基本，最核心的概念，技巧以及最佳实践分享给大家，让大家用 20% 的时间掌握 80% 最常用的部分。</p> \n <p>学会如何从零开始给自己的业务暴露监控指标，如何正确配置服务发现，以及如何配出实用的 Grafana 面板，带领读者光速入门 Prometheus+Grafana，掌握云原生监控的正确姿势。图片</p> \n <p>「腾讯云原生」公众号后台回复“ Prometheus”或“光速入门”即可获取教程！一起学起来吧！</p> \n <p>小Tips：教材目前有网站版本（需在浏览器中打开）和PDF版本，童鞋们可根据自身需求进行查看。本教材网站版本会持续进行更新，大家可以持续关注~</p> \n <p>同时欢迎大家给教程提issue, 此教程会根据大家的反馈不定时更新，扩展，修订！</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211231094421904-743560077.png\" alt=\"\" loading=\"lazy\"></p> \n <p>（提issue的GitHub地址）</p> \n <h2 id=\"教材目录如下\">教材目录如下</h2> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211231094422193-901948293.png\" alt=\"\" loading=\"lazy\"></p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211231094422421-889641616.png\" alt=\"\" loading=\"lazy\"></p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211231094422760-579736134.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"397","createTime":"2021-06-21 15:01","comment":"0","id":"14913423","title":"腾讯云TKE-基于 Cilium 统一混合云容器网络（上）","url":"https://www.cnblogs.com/tencent-cloud-native/p/14913423.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>魏后民，腾讯云后台开发工程师，关注容器、Kubernetes、Cilium等开源社区，负责腾讯云 TKE 混合云容器网络等相关工作。</p> \n <p>赵奇圆，腾讯云高级工程师，主要负责腾讯云容器网络设计和研发工作。</p> \n <h2 id=\"前言\">前言</h2> \n <p><a href=\"https://blogs.gartner.com/thomas_bittman/2012/09/24/mind-the-gap-here-comes-hybrid-cloud/\" target=\"_blank\" rel=\"noopener\">混合云</a> 并不是一个新鲜的概念，但随着容器技术的发展，混合云与容器的结合正在得到越来越多的关注。通过容器等云原生技术，可以屏蔽混合云异构集群底层计算资源基础设施的差异，实现多云场景、IDC 场景乃至边缘等场景的统一。混合云将不再是公有云和私有云的简单结合，而是计算负载无处不在的分布式云，可以充分发挥其在资源扩容、多活容灾、多集群混合部署等场景的优势。</p> \n <p>腾讯云 TKE 容器服务推出公有云集群添加第三方 IDC 计算节点服务，该服务可以让客户复用 IDC 计算资源，免去在本地搭建、运维 Kubernetes 集群的成本，最大化提高计算资源使用率。</p> \n <p><img src=\"https://main.qcloudimg.com/raw/4ecacbff0eedf943c167334c3a8e858f.png\" alt=\"\" loading=\"lazy\"></p> \n <p>在这个方案的底层实现中，打通 IDC 和公有云之间的网络是重要的一环。一个 Kubernetes 集群中可能包含众多不同网络环境的计算节点，比如 IDC 网络环境和公有云 VPC 网络环境的计算节点。为了屏蔽底层不同网络环境的差异，TKE 提出了混合云容器网络方案，在容器层面看到的是统一的网络平面，使得 Pod 无需感知其是运行在 IDC 的计算节点还是公有云的计算节点。</p> \n <p>TKE 混合云容器网络同时支持基于 VxLAN 隧道模式的 Overlay 网络和基于直接路由的 Underlay 网络。当客户不希望改变其 IDC 基础网络设施时，可以使用 Overlay 网络；当客户对于混合云容器网络的性能有很高的要求时，可以使用基于直接路由的 Underlay 网络。本文将详述混合云中容器网络面临的挑战与解决方案，并介绍 TKE 混合云容器 Overlay 网络的实现。接下来还会有文章单独介绍 TKE 混合云容器 Underlay 网络的实现，敬请期待。</p> \n <h2 id=\"混合云容器网络面临的挑战\">混合云容器网络面临的挑战</h2> \n <p>在混合云场景下，一个 Kubernetes 集群的各个组件可能分布在不同的网络平面：</p> \n <ul> \n  <li>Master Network：运行着 ApiServer 等控制面组件的网络平面</li> \n  <li>VPC Network：包含有 TKE 公有云集群计算节点的网络平面</li> \n  <li>IDC Network：包含有客户 IDC 计算节点的网络平面</li> \n </ul> \n <p>混合云复杂的场景下，如何打通不同网络平面的链路，对容器网络设计提出了挑战：</p> \n <h4 id=\"vpc-network-和-idc-network-互相访问\">VPC Network 和 IDC Network 互相访问</h4> \n <p>混合云场景下，一个 Kubernetes 集群可能既包含 VPC Network 下的公有云计算节点，也包含 IDC Network 下的计算节点。打通这些处于不同网络环境下的节点网络，是上层容器网络互通的基础。</p> \n <h4 id=\"idc-network-主动访问-master-network\">IDC Network 主动访问 Master Network</h4> \n <p>Kubernetes 环境下最常见的一个场景是计算节点的 Kubelet 会连接处于 Master Network 的 ApiServer，用于获取集群相关的状态和上报节点信息，这就要求 IDC Network 能够主动访问 Master Network。</p> \n <h4 id=\"master-network-主动访问-idc-network\">Master Network 主动访问 IDC Network</h4> \n <p>Kubernetes 环境下为了调试，我们常常使用 <code>kubectl logs</code> 和 <code>kubectl exec</code> 等命令实现获取应用 Pod 的日志和直接登陆到应用 Pod 的运行环境。以 <code>kubectl exec</code> 为例，下图展示了这类命令的实现原理：执行 kubectl exec 时首先会向 ApiServer 发起请求，由 ApiServer 转发给 Pod 所在节点上的 kubelet 进程，然后再转发给 runtime 的 exec 接口。</p> \n <p><img src=\"https://main.qcloudimg.com/raw/63ad61666e99f11c10c553fbc6d41516.png\" alt=\"\" loading=\"lazy\"></p> \n <p>上述机制如果想要成功运行，要求处于 Master Network 的 ApiServer 与计算节点上的 kubelet 之间存在一条网络通路，允许 ApiServer 能够主动访问 kubelet。除了 <code>kubectl exec</code> 和 <code>kubectl log</code> 等命令，<code>kube-scheduler</code> 的 <a href=\"https://github.com/kubernetes/community/blob/master/contributors/design-proposals/scheduling/scheduler_extender.md\" target=\"_blank\" rel=\"noopener\">extender 机制</a> 和 <code>ApiServer</code> 的 <a href=\"https://kubernetes.io/zh/docs/reference/access-authn-authz/extensible-admission-controllers/\" target=\"_blank\" rel=\"noopener\">Admission Webhook 机制</a> 都依赖于 Master Network 与计算节点的网络打通。</p> \n <h4 id=\"如何屏蔽底层网络差异统一容器网络\">如何屏蔽底层网络差异，统一容器网络</h4> \n <p>混合云场景下，一个 Kubernetes 集群可能既包含 VPC Network 下的公有云节点，也包含 IDC Network 下的 IDC 节点，甚至是其他云厂商的公有云节点，乃至环境场景的边缘节点。客户有时候并不想改变自己 IDC 环境的基础网络设置，却希望能有一套统一的容器网络。</p> \n <h2 id=\"tke-混合云网络方案\">TKE 混合云网络方案</h2> \n <p>为了解决混合云场景下容器网络所面临的挑战，腾讯云容器团队设计了以 Cilium 作为集群网络底座的 TKE 混合云容器网络方案。Cilium 基于 eBPF 技术为云原生网络重新设计，绕开 iptables，提供了网络、可观测性和安全等方面的一整套解决方案。Cilium 能够支持基于隧道的 Overlay 网络和基于直接路由的 Underlay 网络，并且在大规模扩展 Service 等性能上有<a href=\"https://cilium.io/blog/2021/05/11/cni-benchmark\" target=\"_blank\" rel=\"noopener\">优越的表现 </a>。腾讯云容器团队很早即开始<a href=\"https://cloud.tencent.com/developer/article/1687922\" target=\"_blank\" rel=\"noopener\">基于 eBPF 技术对 Kubernetes 网络进行优化</a>，本次将混合云网络与 Cilium 结合也是对 eBPF 技术的进一步探索。</p> \n <p><img src=\"https://main.qcloudimg.com/raw/a5dbbe874363e8f6761b21bf894a7750.png\" alt=\"\" loading=\"lazy\"></p> \n <p>TKE 混合云容器网络主要特点如下：</p> \n <ul> \n  <li>实现全链路容器网络的打通，屏蔽底层网络差异</li> \n  <li>同时支持基于 VxLAN 隧道模式的 Overlay 网络和基于直接路由的 Underlay 网络</li> \n  <li>基于 eBPF 技术实现 Service 和 NetworkPolicy，优化 Kubernetes 网络性能</li> \n  <li>支持自定义容器 IPAM，可实现节点多段 PodCIDR 和 PodCIDR 按需动态分配</li> \n  <li>支持网络链路的可观测性</li> \n </ul> \n <h2 id=\"tke-混合云容器网络使用方法\">TKE 混合云容器网络使用方法</h2> \n <p>在 TKE 集群基本信息页面，点击开启「支持导入第三方节点」后，需要选择混合云容器网络模式。这里我们可以选择 Cilium VxLAN 来使用混合云 Overlay 容器网络，也可以选择 Cilium BGP 来混合云 Underlay 容器网络：</p> \n <p><img src=\"https://main.qcloudimg.com/raw/b70513356878c0ea7cbd6ffe483c7ae5.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"tke-混合云网络互通方案\">TKE 混合云网络互通方案</h2> \n <h3 id=\"vpc-network-和-idc-network-互相访问-1\">VPC Network 和 IDC Network 互相访问</h3> \n <p>为了打通 VPC Network 和 IDC Network，我们推荐使用腾讯云的<a href=\"https://cloud.tencent.com/document/product/877\" target=\"_blank\" rel=\"noopener\">云联网服务</a>，云联网服务能够实现云上 VPC 之间、VPC 与 IDC 网络的互通，具备全网多点互联、路由自学习、链路选优及故障快速收敛等能力。</p> \n <h3 id=\"idc-network-主动访问-master-network-1\">IDC Network 主动访问 Master Network</h3> \n <p>为了打通 IDC Network 主动访问 Master Network 的网络链路，我们基于腾讯云 PrivateLink，实现 IDC Network 中的 Kubelet 主动访问处于 Master Network 的 ApiServer。</p> \n <p><img src=\"https://main.qcloudimg.com/raw/fe69d04f47993af8fdeba097c41fc54c.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"master-network-主动访问-idc-network-1\">Master Network 主动访问 IDC Network</h3> \n <p>为了打通 Master Network 主动访问 IDC Network 的网络链路，我们选择了基于社区的 <a href=\"https://github.com/kubernetes-sigs/apiserver-network-proxy\" target=\"_blank\" rel=\"noopener\"><code>apiserver-network-proxy</code> 项目</a> 来实现。具体的原理实现如下：</p> \n <ul> \n  <li>在 Master Network 创建 <code>Konnectivity Server</code>，作为代理服务器</li> \n  <li>在 IDC Network 创建 <code>Konnectivity Agent</code>，通过 PrivateLink 与 Master Network 中的代理服务器创建长连接</li> \n  <li>当 Master Network 中的 ApiServer 主动访问 IDC Network 的 Kubelet 时，会复用 Agent 与 Server 之间的长连接</li> \n </ul> \n <p><img src=\"https://main.qcloudimg.com/raw/7e4df9b47063d7b74421647f7210b46c.png\" alt=\"\" loading=\"lazy\"></p> \n <p>至此，Master Network 主动访问 IDC Network 的网络打通需求也得到了解决。进一步地，基于相同的方案，我们可以将多云 VPC 的计算节点和边缘场景的边缘节点纳管到同一控制平面，实现真正的分布式云。</p> \n <h2 id=\"tke-混合云-overlay-容器网络方案\">TKE 混合云 Overlay 容器网络方案</h2> \n <p>Master Network 与 IDC Network 网络打通之后，我们即可在此基础上通过隧道模式来构建 Overlay 网络。<a href=\"https://datatracker.ietf.org/doc/html/rfc7348\" target=\"_blank\" rel=\"noopener\">VxLAN</a> 是在数据中心网络中获得广泛使用的隧道封装协议，它通过 MAC in UDP 对数据包进行封装，在对端解封。Cilium 的隧道封装协议支持 VxLAN 和 Geneve，默认采用 VxLAN。基于 VxLAN 的高度可扩展性，只需要打通节点之间的网络，就可在此之上实现统一的容器网络。</p> \n <h4 id=\"跨节点-pod-互相访问\">跨节点 Pod 互相访问</h4> \n <p>当数据包从 Pod 的网口发出时，经过 veth pair 到达 <code>lxc00aa</code> 网口。在 <code>lxc00aa</code> 网口上挂载的 eBPF 程序发现数据包目的地址为远端 endpoint，转发给 <code>cilium_vxlan</code> 进行封包。封包之后，外层地址为节点的 IP，内层地址为 Pod IP，经过节点上物理网口转发给对端节点。到达对端节点后，同样经过 <code>cilium_vxlan</code> 解封包，并将数据包转发给对端 Pod。</p> \n <p><img src=\"https://main.qcloudimg.com/raw/b110a8563791c9dbd9ecccb2ea04d5cf.png\" alt=\"\" loading=\"lazy\"></p> \n <h4 id=\"节点访问远端-pod\">节点访问远端 Pod</h4> \n <p>对于从本地节点访问远端节点的 Pod，在本机上会通过节点路由转发给 <code>cilium_host</code> 网口，在 <code>cilium_host</code> 上挂载的 eBPF 程序会将数据包转发到 <code>cilium_vxlan</code> 进行隧道封包，然后转发到对端。可以看到，封包之后，外层地址为节点的 IP，内层源 IP 地址为 CiliumHostIP，目的 IP 地址为目标Pod IP 地址。后面链路与前面一致，不再赘述。</p> \n <p><img src=\"https://main.qcloudimg.com/raw/a05ae7c24f09db5631a4094e7215786e.png\" alt=\"\" loading=\"lazy\"></p> \n <h4 id=\"pod访问非-clustercidr-的网络\">Pod访问非 ClusterCIDR 的网络</h4> \n <p>对于计算节点上的 Pod 访问非容器 ClusterCIDR 的网络地址时，数据包从 Pod 网口到达 <code>lxc00aa</code> 网口后，eBPF 程序发现目标地址不是容器网络的 ClusterCIDR，则不会进行 Overlay 封包，而是转给协议栈走节点路由。通过设置 cilium 的 masquerade 参数，数据包到达节点物理网口后，对于这种目的地址的数据包会执行 masquerade，替换数据包的源地址为节点 IP，从而之后数据包能够返回到节点，并最终返回给 Pod。</p> \n <p><img src=\"https://main.qcloudimg.com/raw/a480289bdad93b35e62b9d27d814e276.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"总结与展望\">总结与展望</h2> \n <p>本文介绍了 TKE 混合云场景下公有云集群添加第三方 IDC 节点服务下，混合云容器网络所面临的复杂场景和性能的挑战，并提出了基于 Cilium 的 Overlay 的容器网络解决方案。可以看到，这套方案不仅适用于添加IDC节点，对于混合云下的异构集群（多云、边缘场景）都适用，可以解决混合云下集群网络插件不一带来的管理问题和体验问题。由此，混合云与容器的结合已经不再仅仅是混合云，而是可以实现多云场景、IDC 场景以及边缘场景的统一，是实实在在、无处不在的分布式云。</p> \n <p>Overlay 的混合云容器网络可以通过隧道模式屏蔽底层不同网络环境的差异，实现容器层面看到的是统一的网络层面。对于另一部分客户来说，他们对于混合云容器网络的性能有很高的要求，不希望引入因为 Overlay 的封解包过程带来的性能折损。这种情况下，客户希望直接基于 Underlay 网络，通过直接路由来打通容器网络。接下来还会介绍 TKE 混合云容器网络基于 BGP 直接路由的 Underlay 网络的方案实现，敬请期待。</p> \n <h2 id=\"参考资料\">参考资料</h2> \n <ol> \n  <li><a href=\"https://blogs.gartner.com/thomas_bittman/2012/09/24/mind-the-gap-here-comes-hybrid-cloud/\" target=\"_blank\" rel=\"noopener\">Mind the Gap: Here Comes Hybrid Cloud</a></li> \n  <li><a href=\"https://github.com/kubernetes/community/blob/master/contributors/design-proposals/scheduling/scheduler_extender.md\" target=\"_blank\" rel=\"noopener\">Kubernetes scheduler extender</a></li> \n  <li><a href=\"https://kubernetes.io/zh/docs/reference/access-authn-authz/extensible-admission-controllers/\" target=\"_blank\" rel=\"noopener\">Kubernetes addmision controllers</a></li> \n  <li><a href=\"https://cilium.io/blog/2021/05/11/cni-benchmark\" target=\"_blank\" rel=\"noopener\">CNI Benchmark: Understanding Cilium Network Performance</a></li> \n  <li><a href=\"https://cloud.tencent.com/developer/article/1687922\" target=\"_blank\" rel=\"noopener\">腾讯云绕过 conntrack，使用 eBPF 增强 IPVS 优化 K8s 网络性能</a></li> \n  <li><a href=\"https://cloud.tencent.com/document/product/877\" target=\"_blank\" rel=\"noopener\">腾讯云云联网服务 CCN</a></li> \n  <li><a href=\"https://github.com/kubernetes-sigs/apiserver-network-proxy\" target=\"_blank\" rel=\"noopener\">Kubernetes apiserver-network-proxy</a></li> \n  <li><a href=\"https://datatracker.ietf.org/doc/html/rfc7348\" target=\"_blank\" rel=\"noopener\">RFC 7348: Virtual eXtensible Local Area Network (VXLAN)</a></li> \n </ol> \n <blockquote> \n  <p>容器服务 TKE：无需自建，即可在腾讯云上使用稳定， 安全，高效，灵活扩展的 Kubernetes 容器平台。</p> \n </blockquote> \n</div>"}
{"read":"656","createTime":"2021-05-10 10:22","comment":"0","id":"14749994","title":"内存回收导致关键业务抖动案例分析-论云原生OS内存QoS保障","url":"https://www.cnblogs.com/tencent-cloud-native/p/14749994.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <p>蒋彪，腾讯云高级工程师，10+年专注于操作系统相关技术，Linux内核资深发烧友。目前负责腾讯云原生OS的研发，以及OS/虚拟化的性能优化工作。</p> \n <h2 id=\"导语\">导语</h2> \n <p>云原生场景，相比于传统的IDC场景，业务更加复杂多样，而原生 Linux kernel 在面对云原生的各种复杂场景时，时常显得有些力不从心。本文基于一个腾讯云原生场景中的一个实际案例，展现针对类似问题的一些排查思路，并希望借此透视Linux kernel的相关底层逻辑以及可能的优化方向。</p> \n <h2 id=\"背景\">背景</h2> \n <p>腾讯云客户某关键业务容器所在节点，偶发CPU sys(内核态CPU占用)冲高的问题，导致业务抖动，复现无规律。节点使用内核为upstream 3.x版本。</p> \n <h2 id=\"现象\">现象</h2> \n <p>在业务负载正常的情况下，监控可见明显的CPU占用率毛刺，最高可达100%，同时节点load飙升，此时业务会随之出现抖动。</p> \n <p><img src=\"https://main.qcloudimg.com/raw/3b77e017c01469f86363f1883f00dcdb.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"捕获数据\">捕获数据</h2> \n <h3 id=\"思路\">思路</h3> \n <p>故障现象为CPU sys冲高，即CPU在内核态持续运行导致，分析思路很简单，需要确认sys冲高时，具体的执行上下文信息，可以是堆栈，也可以是热点。</p> \n <p><strong>难点：</strong><br> 由于故障出现随机，持续时间比较短(秒级)，而且由于是内核态CPU冲高，当故障复现时，常规排查工具无法得到调度运行，登录终端也会hung住(由于无法正常调度)，所以常规监控(通常粒度为分钟级)和排查工具均无法及时抓到现场数据。</p> \n <h3 id=\"具体操作\">具体操作</h3> \n <h4 id=\"秒级监控\">秒级监控</h4> \n <p>通过部署秒级监控(基于atop)，在故障复现时能抓到故障发生时的系统级别的上下文信息，示例如下：<br> <img src=\"https://main.qcloudimg.com/raw/ff5d0054f633b2ce910c7fafe601db12.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>从图中我们可以看到如下现象：</p> \n <ol> \n  <li>sys很高，usr比较低</li> \n  <li>触发了页面回收（PAG行），且非常频繁</li> \n  <li>比如ps之类的进程普遍内核态CPU使用率较高，而用户态CPU使用率较低，且处于退出状态</li> \n </ol> \n <p>至此，抓到了系统级别的上下文信息，可以看到故障当时，系统中正在运行的、CPU占用较高的进程和状态，也有一些系统级别的统计信息，但仍无从知晓故障当时，sys具体消耗在了什么地方，需要通过其他方法/工具继续抓现场。</p> \n <h4 id=\"故障现场\">故障现场</h4> \n <p>如前面所说，这里说的<strong>现场</strong>，可以是故障当时的瞬时堆栈信息，也可以是热点信息。<br> 对于堆栈的采集，直接能想到的简单方式：</p> \n <ol> \n  <li>pstack</li> \n  <li>cat /proc/<pid>\n    /stack\n   </pid></li> \n </ol> \n <p>当然这两种方式都依赖：</p> \n <ol> \n  <li>故障当时CPU占用高的进程的pid</li> \n  <li>故障时采集进程能及时执行，并得到及时调度、处理</li> \n </ol> \n <p>显然这些对于当前的问题来说，都是难以操作的。</p> \n <p>对于热点的采集，最直接的方式就是perf工具，简单、直接、易用。但也存在问题：</p> \n <ol> \n  <li>开销较大，难以常态化部署；如果常态化部署，采集数据量巨大，解析困难</li> \n  <li>故障时不能保证能及时触发执行</li> \n </ol> \n <p>perf本质上是通过pmu硬件进行周期性采样，实现时采用NMI(x86)进行采样，所以，一旦触发采集，就不会受到调度、中断、软中断等因素的干扰。但由于执行perf命令的动作本身必须是在进程上下文中触发(通过命令行、程序等)，所以在故障发生时，由于内核态CPU使用率较高，并不能保证perf命令执行的进程能得到正常调度，从而及时采样。</p> \n <p>因此针对此问题的热点采集，必须提前部署(常态化部署)。通过两种方式可解决(缓解)前面提到的开销大和数据解析困难的问题：</p> \n <ol> \n  <li>降低perf采样频率，通常降低到99次/s，实测对真实业务影响可控</li> \n  <li>Perf数据切片。通过对perf采集的数据按时间段进行切片，结合云监控中的故障时间点(段)，可以准确定位到相应的数据片，然后做针对性的统计分析。</li> \n </ol> \n <p>具体方法：<br> 采集：</p> \n <pre><code>`.``/perf` `record -F99 -g -a`\n</code></pre> \n <p>分析：</p> \n <pre><code>#查看header里面的captured on时间，应该表示结束时间，time of last sample最后采集时间戳，单位是秒，可往前追溯现场时间\n./perf report --header-only\n#根据时间戳索引\n./perf report --time start_tsc,end_tsc\n</code></pre> \n <p>按此思路，通过提前部署perf工具采集到了一个<strong>现场</strong>，热点分析如下：</p> \n <p><img src=\"https://main.qcloudimg.com/raw/1b0d43937b70cf3058b596ffa6b3e8bc.png\" alt=\"\" loading=\"lazy\"></p> \n <p>可以看到，主要的热点在于 shrink_dentry_list 中的一把 spinlock。</p> \n <h2 id=\"分析\">分析</h2> \n <h3 id=\"现场分析\">现场分析</h3> \n <p>根据 perf 的结果，我们找到内核中的热点函数 dentry_lru_del，简单看下代码：</p> \n <pre><code>// dentry_lru_del()函数：\nstatic void dentry_lru_del(struct dentry *dentry) {\n    if (!list_empty(&amp;dentry-&gt;d_lru)) {\n    \tspin_lock(&amp;dcache_lru_lock);\n        __dentry_lru_del(dentry);\n        spin_unlock(&amp;dcache_lru_lock);\n    }\n}\n</code></pre> \n <p>函数中使用到的 spinlock 为 dentry_lru_lock，在3.x内核代码中，这是一把超大锁(全局锁)。单个文件系统的所有的 dentry 都放入同一个lru链表(位于superblock)中，对该链表的几乎所有操作(dentry_lru_(add|del|prune|move_tail))都需要拿这把锁，而且所有的文件系统共用了同一把全局锁(3.x内核代码)，参考 add 流程：</p> \n <pre><code>static void dentry_lru_add(struct dentry *dentry) {\n    if (list_empty(&amp;dentry-&gt;d_lru)) {\n        // 拿全局锁\n        spin_lock(&amp;dcache_lru_lock);\n       // 把dentry放入sb的lru链表中\n       list_add(&amp;dentry-&gt;d_lru, &amp;dentry-&gt;d_sb-&gt;s_dentry_lru);\n       dentry-&gt;d_sb-&gt;s_nr_dentry_unused++;\n       dentry_stat.nr_unused++;\n       spin_unlock(&amp;dcache_lru_lock);\n    }\n}\n</code></pre> \n <p>由于 dentry_lru_lock 是全局大锁，可以想到的一些典型场景中都会持这把锁：</p> \n <ol> \n  <li>文件系统 umount 流程</li> \n  <li>rmdir 流程</li> \n  <li>内存回收 shrink_slab 流程</li> \n  <li>进程退出清理/proc目录流程(proc_flush_task)-前面抓到的现场</li> \n </ol> \n <p>其中，文件系统 umount 时，会清理掉对应 superblock 中的所有 dentry，则会遍历整个 dentry 的lru链表，如果 dentry 数量过多，将直接导致 sys 冲高，而且其他依赖于 dentry_lru_lock 的流程也会产生严重的锁竞争，由于是 spinlock，也会导致其他上下文 sys 冲高。<br> 接下来，再回过头看之前的秒级监控日志，就会发现故障是系统的 slab 占用近60G，非常大：<br> <img src=\"https://main.qcloudimg.com/raw/79cf1ac5b6bc24552606027a720199eb.png\" alt=\"\" loading=\"lazy\"></p> \n <p>而dentry cache(位于slab中)很可能是罪魁祸首，确认slab中的对象的具体分布的最简便的方法：Slabtop，在相同业务集群其他节点找到类似环境，可见确实dentry占用率绝大部分：<br> <img src=\"https://main.qcloudimg.com/raw/443929ad4abdbaa084366101e29fdf9b.png\" alt=\"\" loading=\"lazy\"></p> \n <p>我们接下来可以使用 crash 工具在线解析对应文件系统的 superblock 的 dentry lru 链表，可见 unused entry 数量高达2亿+<br> <img src=\"https://main.qcloudimg.com/raw/11a1dbaf23c3f50d4c819343dff23fc8.png\" alt=\"\" loading=\"lazy\"></p> \n <p>另一方面，根据业务的上下文日志，可以确认其中一类故障时，业务有删除 pod 的操作，而删除pod过程中，会 umount overlayfs，然后会触发文件系统 umount 操作，然后就出现这样的现象，场景完全吻合！<br> 进一步，在有 2亿+dentry 环境中，手工drop slab并通过time计时，接近40s，阻塞时间也能吻合。</p> \n <pre><code>`time` `echo` `2 &gt; ``/proc/sys/vm/drop_caches`\n</code></pre> \n <p>至此，基本能解释：sys 冲高的直接原因为dentry数量太多。</p> \n <h3 id=\"亿级-dentry-从何而来\">亿级 Dentry 从何而来</h3> \n <p>接下来的疑问：为何会有这么多dentry？<br> 直接的解答方法，找到这些dentry的绝对路径，然后根据路径反推业务即可。那么2亿+dentry如何解析？</p> \n <p>两种办法：</p> \n <p><strong>方法1：在线解析</strong></p> \n <p>通过crash工具在线解析(手工操练)，<br> 基本思路：</p> \n <ol> \n  <li>找到sb中的dentry lru list位置</li> \n  <li>List所有的node地址，结果存档</li> \n  <li>由于entry数量过多，可以进行切片，分批保存至单独文档，后续可以批量解析。</li> \n  <li>Vim列编辑存档文件，批量插入命令(file)，保存为批量执行命令的文件</li> \n  <li>crash -i批量执行命令文件，结果存档</li> \n  <li>对批量执行结果进行文本处理，统计文件路径和数量</li> \n </ol> \n <p>结果示例：</p> \n <p><img src=\"https://main.qcloudimg.com/raw/0a8a45a2528a9cd1f050c3d23dc97a27.png\" alt=\"\" loading=\"lazy\"></p> \n <p>其中：</p> \n <ol> \n  <li>db为后面提及的类似xxxxx_dOeSnotExist_.db文件，占大部分。</li> \n  <li>session为systemd为每个session创建的临时文件</li> \n </ol> \n <p>db文件分析如下：</p> \n <p><img src=\"https://main.qcloudimg.com/raw/b0a852af73a52aafc458dfd7cf777c88.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>文件名称有几个明显特征：</p> \n <ol> \n  <li>有统一的计数，可能是某一个容器产生</li> \n  <li>名称中包含字符串“dOeSnotExist“</li> \n  <li>都拥有.db的后缀</li> \n </ol> \n <p>对应的绝对路径示例如下(用于确认所在容器)<br> <img src=\"https://main.qcloudimg.com/raw/5480fae4dbf67c960165b489a9bcdcb9.png\" alt=\"\" loading=\"lazy\"><br> <img src=\"https://main.qcloudimg.com/raw/93d1a7c0227c5b28d04b764049c15cad.png\" alt=\"\" loading=\"lazy\"></p> \n <p>如此可以通过继续通过 overlayfs id 继续查找对应的容器(docker inspect)，确认业务。</p> \n <p><strong>方法2：动态跟踪</strong></p> \n <p>通过编写 systemtap 脚本，追踪 dentry 分配请求，可抓到对应进程(在可复现的前提下)，脚本示例如下:</p> \n <pre><code>probe kernel.function(\"d_alloc\") {\n    printf(\"[%d] %s(pid:%d ppid:%d) %s %s\\n\", gettimeofday_ms(), execname(), pid(), ppid(), ppfunc(), kernel_string_n($name-&gt;name, $name-&gt;len));\n}\n</code></pre> \n <p><img src=\"https://main.qcloudimg.com/raw/b8eef85d634bebbf221bbc2a90cd1382.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>按进程维度统计：</p> \n <p><img src=\"https://main.qcloudimg.com/raw/f909aafd293b7457521b27435f117351.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"xxx_doesnotexist_db文件分析\">Xxx_dOeSnotExist_.db文件分析</h3> \n <p>通过前面抓取到的路径可以判断该文件与nss库（证书/密钥相关）相关，https 服务时，需要使用到底层nss密码库，访问web服务的工具如 curl 都使用到了这个库，而nss库存在bug：<br> <a href=\"https://bugzilla.mozilla.org/show_bug.cgi?id=956082\" target=\"_blank\" rel=\"noopener\">https://bugzilla.mozilla.org/show_bug.cgi?id=956082</a><br> <a href=\"https://bugzilla.redhat.com/show_bug.cgi?id=1779325\" target=\"_blank\" rel=\"noopener\">https://bugzilla.redhat.com/show_bug.cgi?id=1779325</a></p> \n <p>大量访问不存在的路径这个行为，是为了检测是否在网络文件系统上访问 nss db, 如果访问临时目录比访问数据库目录快很多，会开启cache。这个探测过程会尝试 33ms 内循环 stat 不存在的文件(最大1万次), 这个行为导致了大量的 negative dentry。<br> 使用curl工具可模拟这个bug，在测试机中执行如下命令：</p> \n <pre><code>`strace` `-f -e trace=access curl ``'https://baidu.com'`\n</code></pre> \n <p><img src=\"https://main.qcloudimg.com/raw/6e77696663c64566ce66aba752ed25eb.png\" alt=\"\" loading=\"lazy\"></p> \n <p>规避方法：设置环境变量 NSS_SDB_USE_CACHE=yes<br> 解决方法：升级 pod 内的 nss 服务<br> 至此，问题分析近乎完成。看起来就是一个由平平无奇的用户态组件的bug引发的血案，分析方法和手段也平平无奇，但后面的分析才是我们关注的重点。</p> \n <h3 id=\"另一种现象\">另一种现象</h3> \n <p>回想前面讲到的 dentry_lru_lock 大锁竞争的场景，仔细分析其他几例出现 sys 冲高的秒级监控现场，发现这种场景中并无删除pod动作(也就是没有 umount 动作)，也就意味着没有遍历 dentry lru 的动作，按理不应该有反复持有 dentry_lru_lock 的情况，而且同时会出现sys冲高的现象。</p> \n <p><img src=\"https://main.qcloudimg.com/raw/483dda867aca02da06d76f0e0e5e66ab.png\" alt=\"\" loading=\"lazy\"></p> \n <p>可以看到，故障前后的 cache 回收了2G+，但实际的 free 内存并没有增加，反而减少了，说明此时，业务应该正在大量分配新内存，导致内存不足，从而导致内存一直处于回收状态(scan 数量增加很多)。</p> \n <p>而在内存紧张进入直接回收后时，会(可能)shrink_slab，以至于需要持 dentry_lru_lock，这里的具体逻辑和算法不分析了：)。当回收内存压力持续时，可能会反复/并发进入直接回收流程，导致 dentry_lru_lock 锁竞争，同时，在出现问题的业务场景中，单pod进程拥有2400+线程，批量退出时调用 proc_flush_task 释放/proc目录下的进程目录项，从而也会批量/并发获取 dcache_lru_lock 锁，加剧锁竞争，从而导致sys冲高。</p> \n <p>两种现象都能基本解释了。其中，第二种现象相比于第一种，更复杂，原因在于其中涉及到了内存紧张时的并发处理逻辑。</p> \n <h2 id=\"解决--思考\">解决 &amp; 思考</h2> \n <h3 id=\"直接解决规避\">直接解决/规避</h3> \n <p>基于前面的分析，可以看出，最直接的解决方式为：<br> 升级 pod nss 服务，或者设置设置环境变量规避<br> 但如果再思考下：如果nss没有 bug，但其他组件也做了类似可能产生大量 dentry 的动作，比如执行类似这样的脚本：</p> \n <pre><code>#!/bin/bash\ni=0\nwhile (( i &lt; 1000000 )) ; do\n  if test -e ./$i; then\n    echo $i &gt; ./$i\n  fi\n  ((i++))\ndone\n</code></pre> \n <p>本质上也会不停的产生 dentry(slab)，面对这种场景该怎么办？可能的简便的解决/规避方法是：周期性 drop cache/slab，虽然可能引发偶尔的性能小波动，但基本能解决问题。</p> \n <h3 id=\"锁优化\">锁优化</h3> \n <p>前面分析指出，导致 sys 冲高的直接原因是 dcache_lru_lock 锁的竞争，那这把锁是否有优化空间呢？<br> 答案是：有<br> 看看3.x内核代码中的锁使用：</p> \n <pre><code>static void dentry_lru_add(struct dentry *dentry) {\n    if (list_empty(&amp;dentry-&gt;d_lru)) {\n        //全局锁\n        spin_lock(&amp;dcache_lru_lock);\n        list_add(&amp;dentry-&gt;d_lru, &amp;dentry-&gt;d_sb-&gt;s_dentry_lru);\n        dentry-&gt;d_sb-&gt;s_nr_dentry_unused++;\n        dentry_stat.nr_unused++;\n        spin_unlock(&amp;dcache_lru_lock);\n    }\n}\n\n</code></pre> \n <p>可以明显看出这是个全局变量，即所有文件系统公用的全局锁。而实际的 dentry_lru 是放在 superblock 中的，显然这把锁的范围跟lru是不一致的。<br> 于是，新内核版本中，果真把这把锁放入了 superblock 中：</p> \n <pre><code>static void d_lru_del(struct dentry *dentry) {\n    D_FLAG_VERIFY(dentry, DCACHE_LRU_LIST);\n    dentry-&gt;d_flags &amp;= ~DCACHE_LRU_LIST;\n    this_cpu_dec(nr_dentry_unused);\n    if (d_is_negative(dentry)) this_cpu_dec(nr_dentry_negative);\n    //不再加单独的锁，使用list_lru_del原语中自带的per list的lock\n    WARN_ON_ONCE(!list_lru_del(&amp;dentry-&gt;d_sb-&gt;s_dentry_lru, &amp;dentry-&gt;d_lru));\n }\nbool list_lru_add(struct list_lru *lru, struct list_head *item) {\n    int nid = page_to_nid(virt_to_page(item));\n    struct list_lru_node *nlru = &amp;lru-&gt;node[nid];\n    struct mem_cgroup *memcg;\n    struct list_lru_one *l;\n    //使用per lru list的lock\n    spin_lock(&amp;nlru-&gt;lock);\n    if (list_empty(item)) {\n        // …\n    }\n    spin_unlock(&amp;nlru-&gt;lock);\n    return false;\n}\n`\n\n</code></pre> \n <p>新内核中，弃用了全局锁，而改用了 list_lru 原语中自带的 lock，而由于 list_lru 自身位于 superblock 中，所以，锁变成了per list(superblock)的锁，虽然还是有点大，但相比之前减小了许多。</p> \n <p>所以，新内核中，对锁做了优化，但未必能完全解决问题。</p> \n <h3 id=\"继续思考1\">继续思考1</h3> \n <p>为什么访问不存在的文件/目录(nss cache和上述脚本)也会产生 dentry cache 呢？一个不存在的文件/目录的 dentry cache 有何用处呢？为何需要保留？表面看，看似没有必要为一个不存在的文件/目录保留 dentry cache。其实，这样的 dentry cache(后文简称dcache)在内核中有标准的定义：<strong>Negative dentry</strong></p> \n <pre><code>`A special form of dcache entry gets created ``if` `a process attempts to access a non-existent ``file``. Such an entry is known as a negative dentry.`\n\n</code></pre> \n <p>Negative dentry 具体有何用途？由于 dcache 的主要作用是：用于加快文件系统中的文件查找速度，设想如下场景：如果一个应用总是从一些预先配置好的路径列表中去查找指定文件(类似于 PATH 环境变量)，而且该文件仅存在与这些路径中的一个，这种情况下，如果存在 negative dcache，则能加速失败路径的查找，整体提升文件查找的性能。</p> \n <h3 id=\"继续思考2\">继续思考2</h3> \n <p>是否能单独限制 negative dcache 的数量呢？<br> 答案是：可以。</p> \n <p>Rhel7.8版本内核中(3.10.0-1127.el7)，合入了一个 feature：negative-dentry-limit，专门用来限制 negative dcache 的数量，关于这个 feature 的说明请参考：<br> <a href=\"https://access.redhat.com/solutions/4982351\" target=\"_blank\" rel=\"noopener\">https://access.redhat.com/solutions/4982351</a></p> \n <p>关于 feature 的具体实现，请参考：<br> <a href=\"https://lwn.net/Articles/813353/\" target=\"_blank\" rel=\"noopener\">https://lwn.net/Articles/813353/</a><br> 具体原理就不解释了:)</p> \n <p>残酷的现实是：rhel8和upstream kernel都没有合入这个feature，为啥呢？</p> \n <p>请参考：<br> Redhat 的官方解释(其实并没有解释清楚)<br> <a href=\"https://access.redhat.com/solutions/5777081\" target=\"_blank\" rel=\"noopener\">https://access.redhat.com/solutions/5777081</a></p> \n <p>再看看社区的激烈讨论：<br> <a href=\"https://lore.kernel.org/patchwork/cover/960253/\" target=\"_blank\" rel=\"noopener\">https://lore.kernel.org/patchwork/cover/960253/</a></p> \n <p>Linus 也亲自站出来反对。整体基调是：现有的 cache reclaim 机制已经够用(够复杂了),再结合 memcg 的 low 水线等保护措施(cgroup v2才有哦)，能处理好 cache reclaim 的活，如果限制的话，可能会涉及到同步回收等，引入新阻塞、问题和不必要的复杂，negative dache 相比于普通的 pagecache 没有特别之处，不应该被区别对待(被优待)，而且 negative dcache 本身回收很快，balabala。</p> \n <p>结果是，还是不能进社区，尽管这个功能看起来是如此“实用”。</p> \n <h3 id=\"继续思考3\">继续思考3</h3> \n <p>还有其他方式能限制 dcache 吗？<br> 答案是：还有<br> 文件系统层，提供了 unused_dentry_hard_limit 参数，可以控制 dcache 的整体数量，整体控制逻辑类似。具体代码原理也不赘述了，欢迎大家查阅代码。<br> 遗憾的是，该参数依赖于各文件系统自身实现，3.x内核中只看到 overlayfs 有实现，其他文件系统没有。所以，通用性有所限制，具体效果未知(未实际验证)。<br> 至此，看似真的已经分析清楚了？</p> \n <h2 id=\"think-more\">Think More</h2> \n <p><strong>能否再思考一下：为什么 dentry 数量这么多，而没有被及时回收呢？</strong><br> 当前案例表面上看似一个有应用(nss)bug引发的内核抖动问题，但如果仔细思考，你会发现这其实还是内核自身面对类似场景的能力不足，其本质问题还在于：</p> \n <ol> \n  <li>回收不及时</li> \n  <li>cache 无限制</li> \n </ol> \n <h3 id=\"回收不及时\">回收不及时</h3> \n <p>由于内核中会将访问过的所有文件(目录)对应的 dentry 都缓存起来存于slab中(除非有特性标记)，用于下次访问时提示效率，可以看到出问题的环境中，slab占用都高达60G，其中绝大部分都是 dentry 占用。<br> 而内核中，仅(绝大部分场景)当内存紧张时(到达内存水线)才会触发主动回收cache(主要包括slab和pagecache)，而问题环境中，内存通常很充足，实际使用较少，绝大部分为缓存(slab和pagecache)。<br> 当系统free内存低于low水线时，触发异步回收(kswapd)；当 free 内存低于 min 水线是触发同步回收。也就是说仅当free内存低到一定程度(水线)时才能开始回收 dentry，而由于水线通常较低，导致回收时机较晚，而当业务有突发内存申请时，可能导致短期内处于内存反复回收状态。<br> 注：水线(全局)由内核默认根据内存大小计算的，upstream内核中默认的水线比较低。在部分容器场景确实不太合理，新版本内核中有部分优化(可以设置min和low之间的距离)，但也不完美。</p> \n <p><strong>Memcg async reclaim</strong><br> 在云原生(容器)场景中，针对cache的有效、及时回收，内核提供了标准异步回收方式：到达low水线后的 kswapd 回收，但 kswapd 是per-node粒度(全局)，即使在调大 min 和 low 水线之间的 distance 之后(高版本内核支持)，仍存在如下不足：</p> \n <ol> \n  <li>distance 参数难以通用，难以控制</li> \n  <li>全局扫描开销较大，比较笨重</li> \n  <li>单线程(per-node)回收，仍可能较慢，不及时</li> \n </ol> \n <p>在实际应用中，也常见因为内存回收不及时导致水线被击穿，从而出现业务抖动的问题。针对类似场景的问题，社区在多年前有人提交了 memcg async relaim 的想法和补丁(相对原始)，基本原理为：为每个 pod (memcg)创建一个类似 kswapd 这样的内存异步回收线程，当pod级别的 async low 水线达到后，触发 per-cgroup 基本的异步内存回收。理论上也能比较好的解决/优化类似场景的问题。但最终经过长时间讨论后，社区最终没有接受，主要原因还是出于容器资源开销和 Isolation 的考虑：</p> \n <ol> \n  <li>如果为每个 cgroup 创建一个内核线程，当容器数量较多时，内存线程数量增多，开销难以控制。</li> \n  <li>后续优化版本去除了 per-cgroup 的内核回收线程，而借用于内核自带的 workqueue 来做，由于 workqueue 的池化能力，可以合并请求，减少线程线程创建数量，控制开销。但随之而来的是隔离性(Isolation)的问题，问题在于新提交的 workqueue 请求无法 account 到具体的 pod(cgroup)，破坏了容器的隔离性。</li> \n </ol> \n <p>从Maintainer的角度看，拒绝的理由很充分。但从(云原生)用户的角度看，只能是再次的失落，毕竟实际的问题并未得到真正充分解决。<br> 虽然 memcg async reclaim 功能最终未能被社区接受，但仍有少数厂商坚持在自己的版本分支中合入了相应功能，其中的典型代表如 Google，另外还包括我们的 TencentOS Server (原TLinux)，我们不仅合入/增强了原有的 memcg async reclaim 功能，还将其整体融入了我们的云原生资源 QoS 框架，整体为保证业务的内存服务质量提供底层支撑。</p> \n <h3 id=\"cache-无限制\">cache 无限制</h3> \n <p>Linux 倾向于尽可能将空闲内存利用起来，用做cache(主要是page cache和slab)，用于提升性能(主要是文件访问)。意味着系统中 cache 可以几乎不限制(只要有free内存)的增长。在现实场景中带来不少的问题，本案例中的问题就是其中一种典型。如果有 cache limit 能力，理论上能很大程度解决类似问题。</p> \n <p><strong>Cache limit</strong><br> 而关于page cache limit话题，多年前曾在 Kernel upstream 社区中持续争论了很长一段时间，但最终还是未能进入upstream，主要原因还在于违背了尽量利用内存的初衷。尽管在一些场景中确实存在一些问题，社区仍建议通过其他方式解决(业务或者其他内核手段)。<br> 虽然社区未接受，但少部分厂商还是坚持在自己的版本分支中合入了 page cache limit 功能，其中典型代表如SUSE，另外还包括我们的 TencentOS Server(原TLinux)，我们不仅合入/增强了 page cache limit 功能，支持同步/异步回收，同时还增强了 slab limit 的限制，可以同时限制 page cache 和 slab 的用量。该功能在很多场景中起到了关键作用。</p> \n <h2 id=\"结论\">结论</h2> \n <ol> \n  <li>在如下多个条件同时发生时，可能出现 dentry list 相关的锁竞争，导致sys高： \n   <ul> \n    <li>系统中存在大量dentry缓存(容器访问过的大量文件/目录，不停累积)</li> \n    <li>业务突发内存申请，导致free内存突破水线，触发内存回收(反复)</li> \n    <li>业务进程退出，退出时需要清理/proc 文件，期间依赖于 dentry list 的大锁，出现 spinlock race。</li> \n   </ul> </li> \n  <li>用户态应用 nss bug 导致 dcache 过多，是事故的直接原因。</li> \n  <li>深层次思考，可以发现，upstream kernel 为考虑通用性、架构优雅等因素，放弃了很多实用功能和设计，在云原生场景中，难以满足极致需求，要成为云原生OS的核心底座，还需要深度hack。</li> \n  <li>TencentOS Server 为云原生海量场景做了大量深度定制和优化，能自如应对复杂、极端云原生业务带来各种挑战(包括本案例中涉及的问题)。此外，TencentOS Server 还设计实现了云原生资源 QoS 保障特性(RUE)，为不同优先级的容器提供了各种关键资源的 QoS 保障能力。敬请期待相关分享。</li> \n </ol> \n <h2 id=\"结语\">结语</h2> \n <p>在云原生场景中，upstream kerne l难以满足极端场景的极致需求，要成为云原生OS的底座，还需要深度hack。而 TencentOS Server 正为之不懈努力！</p> \n <p>【注：案例素材取自腾讯云虚拟化团队和云技术运营团队】</p> \n <p><em>容器服务（Tencent Kubernetes Engine，TKE）是腾讯云提供的基于 Kubernetes，一站式云原生 PaaS 服务平台。为用户提供集成了容器集群调度、Helm 应用编排、Docker 镜像管理、Istio服务治理、自动化DevOps以及全套监控运维体系的企业级服务。</em></p> \n</div>"}
{"read":"11","createTime":"2022-05-26 10:10","comment":"0","id":"16312457","title":"TKE qGPU 通过 CRD 管理集群 GPU 卡资源","url":"https://www.cnblogs.com/tencent-cloud-native/p/16312457.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>刘旭，腾讯云高级工程师，专注容器云原生领域，有多年大规模 Kubernetes 集群管理经验，现负责腾讯云 GPU 容器的研发工作。</p> \n <h2 id=\"背景\">背景</h2> \n <p>目前 TKE 已提供基于 qGPU 的算力/显存强隔离的共享 GPU 调度隔离方案，但是部分用户反馈缺乏 GPU 资源的可观测性，例如无法获取单个 GPU 设备的剩余资源，不利于 GPU 资源的运维和管理。在这种背景下，我们希望提供一种方案，可以让用户在 Kubernetes 集群中直观的统计和查询 GPU 资源的使用情况。</p> \n <h2 id=\"目标\">目标</h2> \n <p>在目前 TKE 共享 GPU 调度方案的基础上，从以下几个方面增强 GPU 设备的可观测性：</p> \n <ul> \n  <li> <p>支持获取单个 GPU 设备的资源分配信息。</p> </li> \n  <li> <p>支持获取单个 GPU 设备的健康状态。</p> </li> \n  <li> <p>支持获取某个节点上各 GPU 设备信息。</p> </li> \n  <li> <p>支持获取 GPU 设备和 Pod / Container 关联信息。</p> </li> \n </ul> \n <h2 id=\"我们的方案\">我们的方案</h2> \n <p>我们通过 GPU CRD 扫描物理 GPU 的信息，并在 qGPU 生命周期中更新使用到的物理 GPU 资源，从而解决在共享 GPU 场景下缺少可见性的问题。</p> \n <ul> \n  <li> <p><strong>自定义 GPU CRD</strong>：每个 GPU 设备对应一个 GPU 对象，通过 GPU 对象可以获取 GPU 设备的硬件信息，健康状态以及资源分配情况。</p> </li> \n  <li> <p><strong>Elastic GPU Device Plugin</strong>：根据 GPU 设备的硬件信息创建 GPU 对象，定期更新 GPU 设备的健康状态。</p> </li> \n  <li> <p><strong>Elastic GPU Scheduler</strong>：根据 GPU 资源使用情况调度 Pod，同时将调度结果更新到 GPU 对象。</p> </li> \n </ul> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220526100938692-1866621066.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"tke-gpu-crd-设计\">TKE GPU CRD 设计</h3> \n <pre><code class=\"language-yaml\">apiVersion: elasticgpu.io/v1alpha1\nkind: GPU\nmetadata:\n  labels:\n    elasticgpu.io/node: 10.0.0.2\n  name: 192.168.2.5-00\nspec:\n  index: 0\n  memory: 34089730048\n  model: Tesla V100-SXM2-32GB\n  nodeName: 10.0.0.2\n  path: /dev/nvidia0\n  uuid: GPU-cf0f5fe7-0e15-4915-be3c-a6d976d65ad4\nstatus:\n  state: Healthy\n  allocatable:\n    tke.cloud.tencent.com/qgpu-core: \"50\"\n    tke.cloud.tencent.com/qgpu-memory: \"23\"\n  allocated:\n    0dc3c905-2955-4346-b74e-7e65e29368d2:\n      containers:\n      - container: test\n        resource:\n          tke.cloud.tencent.com/qgpu-core: \"50\"\n          tke.cloud.tencent.com/qgpu-memory: \"8\"\n      namespace: default\n      pod: test\n  capacity:\n    tke.cloud.tencent.com/qgpu-core: \"100\"\n    tke.cloud.tencent.com/qgpu-memory: \"31\"\n</code></pre> \n <p>每个 GPU 物理卡对应一个 GPU CRD，通过 GPU CRD 可以清楚了解每张卡的型号，显存等硬件信息，同时通过 <code>status</code> 可以获取每个 GPU 设备的健康状态和资源分配情况。</p> \n <h3 id=\"tke-gpu-调度过程\">TKE GPU 调度过程</h3> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220526100939635-1481093380.png\" alt=\"\" loading=\"lazy\"></p> \n <p>Kubernetes 提供了 Scheduler Extender 用于对调度器进行扩展，用于满足复杂场景下的调度需求。扩展后的调度器会在调用内置预选策略和优选策略之后通过 HTTP 协议调用扩展程序再次进行预选和优选，最后选择一个合适的 Node 进行 Pod 的调度。</p> \n <p>在 TKE Elastic GPU Scheduler（原 TKE qGPU Scheduler），我们结合了 GPU CRD 设计，在调度时首先会根据 <code>status.state</code> 过滤掉异常 GPU 设备，然后根据 <code>status.allocatable</code> 选择剩余资源满足需求的 GPU 设备，在最终完成调度时更新 <code>status.allocatable</code> 和 <code>status.allocated</code> 。</p> \n <h3 id=\"tke-gpu-分配过程\">TKE GPU 分配过程</h3> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220526100940577-2053575272.png\" alt=\"\" loading=\"lazy\"></p> \n <p>Kubernetes 提供了 Device Plugin 机制用于支持 GPU FPGA 等硬件设备，设备厂商只需要根据接口实现 Device Plugin 而不需要修改 Kubernetes 源码，Device Plugin 一般以 DaemonSet 的形式运行在节点上。</p> \n <p>我们在 TKE Elastic GPU Device Plugin（原 TKE qGPU Device Plugin）启动时会根据节点上 GPU 设备的硬件信息创建 GPU 对象，同时会定期检查 GPU 设备的健康状态并同步到 GPU 对象的 <code>status.state</code>。</p> \n <h2 id=\"总结\">总结</h2> \n <p>为了解决目前 TKE 集群内 GPU 资源可观测性缺失的问题，我们引入了 GPU CRD，用户可以直观的统计和查询集群内 GPU 资源的使用情况，目前这套方案已和 qGPU 完成整合，在 TKE 控制台安装 qGPU 插件时选择使用 CRD 即可开启。</p> \n <p>目前 TKE qGPU 已全量上线，详情请戳：<a href=\"https://cloud.tencent.com/document/product/457/61448\" target=\"_blank\" rel=\"noopener\">https://cloud.tencent.com/document/product/457/61448</a></p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <h4 id=\"福利\">福利：</h4> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <p>④公众号后台回复【光速入门】，可获得腾讯云专家5万字精华教程，光速入门Prometheus和Grafana。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220526100940933-2019752012.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"71","createTime":"2022-05-25 10:15","comment":"0","id":"16308328","title":"AMS 新闻视频广告的云原生容器化之路","url":"https://www.cnblogs.com/tencent-cloud-native/p/16308328.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p><strong>卓晓光</strong>，腾讯广告高级开发工程师，负责新闻视频广告整体后台架构设计，有十余年高性能高可用海量后台服务开发和实践经验。目前正带领团队完成云原生技术栈的全面转型。</p> \n <p><strong>吴文祺</strong>，腾讯广告开发工程师，负责新闻视频广告流量变现相关后台开发工作，熟悉云原生架构在生产实践中的应用，拥有多年高性能高可用后台服务开发经验。目前正推动团队积极拥抱云原生。</p> \n <p><strong>陈宏钊</strong>，腾讯广告高级开发工程师，负责新闻视频广告流量变现相关后台开发工作，擅长架构优化升级，有丰富的海量后台服务实践经验。目前专注于流量场景化方向的广告系统探索。</p> \n <h2 id=\"一引言\">一、引言</h2> \n <p>新闻视频广告团队主要负责腾讯新闻、腾讯视频、腾讯微视等媒体广告流量的广告变现提收工作，在媒体流量日益复杂，广告变现效率逐步提升的背景下，团队需要负责开发并维护的后台服务数量增长迅猛，服务维护成本与日俱增，传统的基于物理机的部署以及运维方案已经成为了制约团队人效进一步提高的瓶颈。</p> \n <p>自2019年开始，公司鼓励各研发团队将服务迁移上云，并对服务进行云原生改造。为了响应公司的号召，在充分调研了服务上云的收益后，我们决定将团队维护的业务分批上云，提升后台服务的部署及运维效率。</p> \n <h2 id=\"二业务上云三步走\">二、业务上云“三步走”</h2> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220525101509871-1167285130.png\" alt=\"\" loading=\"lazy\"><br> 图2-1 新闻视频广告后台整体架构图</p> \n <p>新闻视频广告主要承接来自腾讯新闻、腾讯视频、片多多以及腾讯微视的广告流量接入并负责提升流量的变现效率，具体包括流量接入、形态优化、ecpm 优化等等。如上图所示，由于接入的业务需求复杂多样，而且彼此之间有显著差异，比如内容广告、激励广告等，导致新闻视频广告的后台服务具有如下特点：</p> \n <ol> \n  <li>请求量大，线上服务需要承接来自流量方的海量请求，服务性能及稳定性要求高；</li> \n  <li>服务数量众多，不同服务之间负载差异大，同一服务不同时间段负载变化大，人力运维成本高；</li> \n  <li>依赖的外部组件多，服务发布与运维的流程都与传统的物理机模式深度绑定，历史包袱重，平滑上云挑战大。</li> \n </ol> \n <p>针对以上这些问题，我们在服务迁移上云的过程中，定制了”<strong>三步走</strong>“计划：</p> \n <ol> \n  <li>搭建上云依赖的基础组件并规范上云流程；</li> \n  <li>离线服务快速上云；</li> \n  <li>海量在线服务平滑上云；</li> \n </ol> \n <h2 id=\"三第一步搭建基础组件规范上云流程\">三、第一步——搭建基础组件&amp;规范上云流程</h2> \n <p>为了提高服务上云效率，方便各个服务负责人自行将服务迁移上云，我们首先搭建了云服务基础组件，并输出了服务上云的规范，主要包括容器化 CI/CD 和服务平滑上云两部分。</p> \n <h3 id=\"31-容器化-cicd-配置\">3.1 容器化 CI/CD 配置</h3> \n <p>想要上云，首先要考虑的问题就是如何将服务在云平台上部署。我们对物理机和云平台的部署情况做对比。</p> \n <table> \n  <thead> \n   <tr> \n    <th style=\"text-align: left\"></th> \n    <th style=\"text-align: center\">物理机</th> \n    <th style=\"text-align: right\">云平台</th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td style=\"text-align: left\">调度单位</td> \n    <td style=\"text-align: center\">服务器</td> \n    <td style=\"text-align: right\">Pod</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">单位数量</td> \n    <td style=\"text-align: center\">少</td> \n    <td style=\"text-align: right\">多</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">数量变化</td> \n    <td style=\"text-align: center\">相对固定，审批流程通过后才能增加或减小单位数量</td> \n    <td style=\"text-align: right\">弹性较大，动态缩扩容随负载随时变化</td> \n   </tr> \n  </tbody> \n </table> \n <p>表3-1 物理机和云平台的部署情况对比</p> \n <p>可以看到，物理机和云平台面临的情况完全不同。在物理机时代，我们采用织云部署服务，在织云平台手工配置服务器目标，管理二进制和部署，而转向云平台后，大量 Pod 动态变化组成的集群，与假定管理对象都是固定 ip 的服务器的织云并不契合。因此，我们转向采用蓝盾实现自动化集成与部署。</p> \n <p>蓝盾将集成与发布流程整合并统一管理，代码合入即自动触发编译、回归、审核和发布流程，无需额外人工。为了兼容已有的物理机服务的发布流程，保证混合部署服务的版本一致，二进制包仍然使用织云管理，由蓝盾流水线编译产物后推送至织云。蓝盾流水线从织云拉取二进制后和运维提供的包含必要 agent 的基础镜像打包，将环境与二进制标准化，模版化，以镜像的方式作为最终产物发布，拉起即用，便于 pod 快速部署与扩容，减少了手工标准化服务器的工作量。最终，我们达成了如下目标：</p> \n <ol> \n  <li>自动化部署，节约人力；</li> \n  <li>兼容物理机发布流程，便于混合部署；</li> \n  <li>模版化环境，方便快速扩容。</li> \n </ol> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220525101510239-116608721.jpg\" alt=\"\" loading=\"lazy\"><br> 图3-1 蓝盾实现 CI/CD 流水线</p> \n <h3 id=\"32-后台服务平滑上云\">3.2 后台服务平滑上云</h3> \n <h4 id=\"321-基础组件平滑上云\">3.2.1 基础组件平滑上云</h4> \n <p>新闻视频广告后台服务依赖北极星、智研等基础组件提供负载均衡、指标上报等基础功能，然而在将这些基础组件迁移上云后，我们发现它们并不能如期提供能力，影响了服务正常运行。经过深入排查分析，我们发现，这些组件不能正常工作的原因主要包括以下2点：</p> \n <ol> \n  <li>容器的 ip 不属于 idc 网段，这些基础组件在容器中的 agent 与它们的 server 无法连通；</li> \n  <li>容器 ip 会随着容器的升级和迁移而发生变化，组件注册的 ip 频繁失效。</li> \n </ol> \n <p>而这2个问题都是由于 TKE 平台为容器配置默认的 Overlay 网络策略导致的。为了解决上述的问题，TKE 平台方建议我们采用“浮动 ip”和“删除或缩容 APP 时回收”等高级网络策略。浮动 ip 策略不同于 overlay，分配由运维指定的 idc 网段的 ip，其他 idc 机器上的服务可以直接访问；“删除或缩容 APP 时回收”策略将 ip 与对应的 pod 绑定，即使 pod 更新与迁移，ip 也不会发生改变。</p> \n <p>我们在新增工作负载时，在高级设置中配置浮动 ip 与删除或缩容 APP 时回收的策略，保证增量负载的组件工作正常；同时修改已有负载的 yaml 配置，添加如下图的配置项，将存量负载的配置对齐增量负载。双管齐下，最终解决了网络策略对基础组件的影响，促进基础组件与云平台的协同工作。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220525101510592-1535900354.png\" alt=\"\" loading=\"lazy\"><br> 图3-2 TKE 平台新增负载策略选择</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220525101510875-548902426.png\" alt=\"\" loading=\"lazy\"></p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220525101511241-732868686.jpg\" alt=\"\" loading=\"lazy\"><br> 图3-3 TKE 平台存量配置修改</p> \n <h4 id=\"322-流量平滑迁移\">3.2.2 流量平滑迁移</h4> \n <p>将服务成功部署上云后，接下来就需要让云上集群承接外部流量，发挥职能。新闻视频流量当前都路由至物理机，若直接全量切换访问云服务，会面临如下问题：</p> \n <ol> \n  <li>云上集群服务未经过流量考验，可能导致未知的问题在线上暴露；</li> \n  <li>新集群未充分预热，可以承受的 QPS 较低。</li> \n </ol> \n <p>可以想见，这样激进的操作极其危险，容易引发事故甚至集群崩溃，因此我们需要将流量平滑的切至云平台，留下充裕的时间应对上云过程中出现的问题。</p> \n <p>针对平滑切换的目标，我们提出了两个上云指导方针：</p> \n <ol> \n  <li>小步慢跑。分多阶段迁移流量，每一次仅将少量的流量切换至云平台，切换后，观察系统监控以及业务指标监控无异常后，再进行下一次的流量迁移。</li> \n  <li>灰度验证。对标物理机的发布操作，挪出部分资源搭建灰度集群，每一次流量切换前，先在灰度集群上面实验，灰度集群验证完成后，再在正式集群上执行对应的操作。</li> \n </ol> \n <p>最终，我们在全量切换前提前发现问题并解决，保证线上服务的稳定，实现了流量平滑顺畅的迁移。</p> \n <h2 id=\"四第二步150离线服务的快速上云\">四、第二步——150+离线服务的快速上云</h2> \n <p>新闻视频广告的离线后台服务数量众多，服务总数150+；功能也很复杂多样，既有视频特征抽取等高计算量的服务，也有仅提供通知能力的低负载的服务。在上云过程中，如何为纷杂繁多的离线服务，设计与之适应的资源选取、优化与调度方案？对于这个问题，我们总结出了一套符合新闻视频广告离线业务特点的上云方案。</p> \n <h3 id=\"41-离线服务资源分配方案\">4.1 离线服务资源分配方案</h3> \n <h4 id=\"411-资源分配模板设计\">4.1.1 资源分配模板设计</h4> \n <p>为了提升 CPU 和内存的利用率，我们希望对不同种类的服务分配合适的资源，保证资源充分利用。在上云过程中，我们总结出一套分配资源的方法。离线服务的单个 pod，CPU 限制在0.25核-16核之间，内存最小不能低于512M，在满足下限的同时，最好与核数保持1：2的比例。遵循这套方法有什么好处呢？下面是我们总结的原因：</p> \n <ol> \n  <li>若 CPU 核数大于32，可能导致 TKE 平台在调度时，找不到空闲的核数足以满足要求的节点，导致 Pod 扩容失败；</li> \n  <li>若 CPU 核数大于32，可能导致 TKE 平台的资源碎片化，降低集群的整体资源利用率；</li> \n  <li>如果容器分配的 CPU 低于0.25核，或者内存低于512M，会导致北极星等公共组件的 agent 无法正常运行，容器无法正常拉起。</li> \n </ol> \n <p>在实际的使用中，我们结合上云的实战经验，总结出不同类型服务的推荐配置表格如下所示。</p> \n <table> \n  <thead> \n   <tr> \n    <th style=\"text-align: left\"></th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td style=\"text-align: left\"></td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">离线定时轮询服务</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">离线运营类服务</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">离线计算类服务</td> \n   </tr> \n  </tbody> \n </table> \n <p>表4-1 不同类型服务的推荐配置</p> \n <h4 id=\"412-基础镜像简化\">4.1.2 基础镜像简化</h4> \n <p>按照推荐配置表格的设置，我们将离线服务部署在 TKE 平台上。一开始，服务能够平稳的运行，然而，随着时间的推移，公共镜像中的 agent 越来越多，agent 占用的资源越来越大，对于通知服务等分配资源较少的服务，agent 的资源占用提升后，甚至超过服务本身使用的资源，导致 OOM 或容器无法拉起等异常表现。</p> \n <p>我们既想要优化不断增长的agent数量带来的资源消耗提升，又想要享受公共镜像的更新，有没有两全其美的办法呢？答案是肯定的。我们在 CI/CD 流水线构建业务镜像时，通过 RUN 命令新增删除多余 agent 的流程。在删除 Agent 流程的内部，我们配置标记服务依赖的必要镜像，反选其他无用的 agent，执行删除。由于RUN命令新增了一层不可变文件层，不影响该层以前的公共镜像文件层，公共镜像更新 agent 时，也会作用到业务镜像。通过这种方式，我们既节省了 agent 使用的资源，保证低资源分配的服务正常运行，又享受了公共镜像自动更新 agent 带来的便利。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220525101511506-1799552354.png\" alt=\"\" loading=\"lazy\"><br> 图4-1 镜像瘦身示意图</p> \n <h3 id=\"42-离线服务-hpa-配置方案\">4.2 离线服务 HPA 配置方案</h3> \n <p>很多离线服务的负载并不是稳定不变的，白天与夜晚的负载往往会有较大差异，如果为这些服务分配恒定的资源，可能会导致服务负载高峰期资源过载，负载低谷期资源闲置。因此，我们希望分配给容器的资源，能够随着服务负载的变化而变化。为此，我们选择使用HPA组件实现弹性缩扩容。</p> \n <h4 id=\"421-hpa配置模板设计\">4.2.1 HPA配置模板设计</h4> \n <p>想要使用 HPA，首先需要选取触发是否应该缩扩容的指标。选取衡量指标的核心思想，是尽量选取变化最大的指标，避免变化较小的指标限制 Pod 数量的变化，导致其他负载指标的变化超出资源限制。对于离线任务而言，一般来说，CPU 使用率更容易随着任务的开启和结束发生变化，而内存一般存储相对固定的上下文，比较稳定，选取 CPU 使用率作为判定标准比较合理。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220525101511838-123615533.png\" alt=\"\" loading=\"lazy\"><br> 图4-2 选取 CPU 利用率作为 HPA 的衡量指标</p> \n <p>其次，我们要指定 Pod 数量的上限和下限。上限可以避免不正确的配置造成大量 Pod 创建，空耗集群资源，影响集群稳定性。而下限有两个作用，第一，确保 Pod 数量符合 HPA 组件的最小副本不为零的限制，避免组件采集不到 metrics，无法获取缩扩容调整所依赖的指标后，失去调节副本数量的功能，从而使集群陷入 Pod 数量恒定为0，无 pod 可供服务的情况；第二，若少量 Pod 因故障陷入无法服务的状态，保证一定数量的 Pod 可以减小故障对服务的冲击。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220525101512096-1218059693.png\" alt=\"\" loading=\"lazy\"><br> 图4-3 设置 HPA 调整实例数量的上下限</p> \n <p>最后，我们需要根据具体的负载变化曲线，决定弹性缩扩容的策略。</p> \n <ol> \n  <li>如果负载曲线在每一天每一个时段下都高度一致，我们可以考虑使用 CronHPA 组件，人工指定不同时段的 Pod 数量，定期调度。</li> \n  <li>如果负载曲线每天都在发生变化，不论趋势还是数值，我们都可以使用 HPA 配置，设置 CPU 使用率参考值，要求集群在利用率超过或低于指定值时进行 Pod 数量的调整，将 Pod 的 CPU 使用率维持在容忍范围内。</li> \n  <li>如果负载曲线每天发生变化，但是存在定时发生的尖峰，为了避免集群自行调整的速度慢于负载增长的速度，导致集群被压垮，我们可以结合 CronHPA 与 HPA 使用，平时将控制权交给 HPA，在尖峰到来前使用 CronHPA 提前扩容，既保证尖峰不会冲垮集群，又能享受集群自动调整 Pod 数量带来的便利。</li> \n </ol> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220525101512342-1221762503.png\" alt=\"\" loading=\"lazy\"><br> 图4-5 结合 CronHPA 与 HPA 共同使用</p> \n <p>由此，我们完成了 HPA 的设置，通过多样的策略，实现了集群分配资源随着服务负载变化。</p> \n <h4 id=\"422-ip-白名单自动变更\">4.2.2 IP 白名单自动变更</h4> \n <p>服务 Pod 数量动态变化，会导致部分服务运行的环境中，IP 地址经常改变。而广告业务服务访问下游接口时，大多需要通过静态的 IP 白名单校验。静态的 IP 白名单不再适合云原生环境下部署的服务，我们希望推动下游的 IP 白名单支持动态添加容器 IP，拥抱云原生。为此，我们根据下游权限的敏感等级，使用不同的处理方式完成改造。</p> \n <ol> \n  <li>对于敏感等级较低的接口，我们推动接口作者提供 IP 自动上报的接口，为每一位用户下发凭证，服务启动前使用调用接口，上报当前的 IP 地址加入白名单。例如北极星为我们提供了上报脚本，我们仅需要在容器的启动脚本内调用上报脚本即可完成上报。由于服务运行期间，IP 将不再变更，因此仅需要上报 Pod 拉起时的 IP，即可保障服务的稳定运行。</li> \n  <li>对于敏感等级高的接口，作者不信赖来自用户的操作，担心用户的错误操作击穿白名单保护，例如 CDB 团队就担心广告隐私数据泄漏。我们推动这些团队与 TKE 平台方合作，开放授权给 TKE 平台，用户申请鉴权凭证后托管在 TKE 平台上，由 TKE 平台拉起容器的时候负责上报新的 IP。</li> \n </ol> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220525101512599-813929142.png\" alt=\"\" loading=\"lazy\"><br> 图4-6 TKE 平台配置授权</p> \n <p>最终，我们实现了下游接口对容器缩扩容的感知，自动化更新白名单，保障服务在弹性缩扩容生效的情况下正常工作。</p> \n <h2 id=\"五第三步海量在线服务的平滑上云\">五、第三步——海量在线服务的平滑上云</h2> \n <p>新闻视频广告系统承载百亿级别的流量，后台在线服务的QPS最高可以达到几十万的级别，在迁移上云后同样需要保证服务的高性能、高可用以及可扩展等。为了满足这个要求，我们与运维、TKE平台方共同合作，解决上云过程中所遇到的问题，保障海量在线服务顺利平滑上云。</p> \n <h3 id=\"51-计算密集型服务延时毛刺优化\">5.1 计算密集型服务延时毛刺优化</h3> \n <p>广告系统中，在线服务大多属于计算密集型，需要较高的性能保证计算按时完成。如果相关的计算逻辑在不同的 CPU 核间频繁调度，会引发 cache miss 频率的提升，程序性能降低，请求时延经常出现毛刺。因此，部署在物理机器上的服务大量使用绑核能力，手工指定服务运行的 CPU，提升局部性，提升程序性能。</p> \n <p>然而上云后，平台对 CPU 资源进行虚拟化管理，服务在容器内通过“/proc/cpuinfo”获取到的是分配隔离和重排序后的虚拟 CPU 列表，与节点实际的 CPU 列表大相径庭。使用虚拟的 CPU 列表进行绑核操作，不仅可能绑定到未分配的 CPU，性能不符合预期，甚至会绑定到不存在的 CPU，引发程序错误。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220525101512958-400073146.jpg\" alt=\"\" loading=\"lazy\"><br> 图5-1 96核机器节点上，某容器内虚拟化的 CPU 列表</p> \n <p>因此，需要找到一种在云平台上获取实际 CPU 列表的办法。我们考虑到云平台通过 cgroup 管理并隔离资源，可以尝试在 cgroup 中寻找获取实际 CPU 列表的接口。于是我们查找资料发现，cgroup 提供“/sys/fs/cgroup/cpuset/cpuset.cpus”子系统，可以获取到虚拟 CPU 列表在物理列表上的实际映射范围，符合我们的要求。我们修改绑核功能中获取 CPU 列表的代码，将读取 proc 子系统的部分改为读取 cgroup 子系统，从而成功实现云上服务的绑核功能。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220525101513454-1490735060.jpg\" alt=\"\" loading=\"lazy\"><br> 图5-2 cgroup 实际分配的 CPU 列表</p> \n <h3 id=\"52-在线服务的高可用性保障\">5.2 在线服务的高可用性保障</h3> \n <p>在线服务的生命周期分为三个阶段，服务启动，准备就绪，服务销毁。服务只有处于准备就绪阶段才对外可用。而集群的可用性，取决于加入负载均衡的服务中准备就绪的比例。因此，要想提高服务的可用性，可以从两个方向努力：</p> \n <ol> \n  <li>降低服务启动的时长，提升准备就绪状态在服务生命周期的占比。</li> \n  <li>降低访问服务的失败率，保证加载和销毁阶段的服务不加入负载均衡。</li> \n </ol> \n <h4 id=\"521-降低服务启动时长\">5.2.1 降低服务启动时长</h4> \n <p>想要服务的启动时长，需要分析服务启动过程中，有哪些耗时占比高的操作。经过分析，我们发现，广告服务在服务启动的过程中，其中有一个步骤是通过文件同步服务 byteflood，订阅同步广告、素材、广告主等数据的文件到容器本地。这个步骤非常耗时，占上下文加载阶段的耗时大头。有没有什么办法能够降低这个步骤的耗时呢？</p> \n <p>深入探索后，我们找到了优化的空间。原来，byteflood 每次都需要拉取全量的数据文件。为什么不能增量拉取呢？因为 byteflood 组件在容器中同步到本地的文件，存储在容器的可变层，一旦容器由于升级或者迁移触发重建，则数据文件全部丢失，必须重新拉取全量文件。看来，只需要持久化存储数据文件，我们就可以避免文件丢失，采用增量拉取的方式更新数据，从而降低数据订阅步骤的耗时，缩短上下文的加载时长，提高服务的可用性。</p> \n <p>我们采用挂载外部数据卷(volume)的方式存储数据文件。外部数据卷独立于容器文件系统，容器重建不会影响外部数据卷中的文件，保证了数据文件的持久化。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220525101513678-1925173835.png\" alt=\"\" loading=\"lazy\"><br> 图5-3 使用挂载点持久化订阅数据文件</p> \n <p>然而，使用 volume 挂载后，我们遇到了路径不一致的新问题。由于TKE平台规范限制，挂载的路径和物理机上不一致，为了保持云服务和物理机的服务配置一致，我们想要通过软链将配置路径指向挂载路径。但是挂载的行为发生在容器拉起时，而服务进程启动前，即需要保证配置路径包含数据文件。如果需要在pod启动后手工维护软链，不仅生效时间可能在服务进程执行读取操作后导致服务读不到数据，而且生成的软链同样面临容器重建后被丢弃的问题。为此，我们将容器的entrypoint，即容器启动时调用的命令，替换为自行实现的启动脚本，在脚本内加入生成软链的语句，服务启动语句放在软链的后面。容器启动即执行软链操作，无需手工处理，重建也能保证再次执行，解决了配置路径的问题。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220525101513976-1167893156.jpg\" alt=\"\" loading=\"lazy\"><br> 图5-4 软链指向实际挂载路径，对齐配置路径</p> \n <p>最终，我们成功的外挂了数据文件，将服务启动时长从5分钟降低到10秒钟，效果显著。</p> \n <h4 id=\"522-降低访问服务的失败率\">5.2.2 降低访问服务的失败率</h4> \n <p>容器内服务的状态若处于加载中或者已销毁，将无法处理请求，如果这些无法处理请求的容器的 IP 处于负载均衡的列表中，就会降低集群可用性。想要降低请求访问服务的失败率，必须保证负载均衡关联的服务均处于准备就绪的状态，而保证负载均衡关联的服务均处于准备就绪的状态，关键在于将负载均衡的关联状态纳入服务的生命周期管理，服务脱离加载状态前，不允许容器加入负载均衡，服务如果需要变更至销毁状态，需要在变更前将容器地址从负载均衡服务中剔除。</p> \n <p>平台侧已经将公司的负载均衡服务——北极星——纳入容器的生命周期，不将 Not Ready 的容器加入北极星，容器销毁时将容器地址从北极星剔除。然而，由于容器的生命周期不同于服务生命周期。容器进入 Ready 状态时，服务可能仍在加载上下文，被加入北极星却无法提供服务；容器销毁时，平台发起剔除的请求，但是北极星组件内部状态并非即时更新，可能在容器销毁后，依然转发流量到已销毁的容器。需要找到合适的方法，使北极星感知服务生命的周期，避免流量转发至加载或销毁状态的服务。</p> \n <p>想要禁止加载状态的服务加入负载均衡，可以借助平台方提供的就绪检查功能。就绪检查通过定期检查业务的 tcp 端口状态，判断服务是否已经加载完成，若未加载完成，则将 Pod 状态设置为 Unhealthy，同时禁止上游的北极星将流量转发到这个容器，直到加载完成。通过就绪检查，我们保证在服务加载完成前，不会有请求发送至服务所在的 Pod。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220525101514223-1031024906.png\" alt=\"\" loading=\"lazy\"><br> 图5-5 配置就绪检查</p> \n <p>想要保证服务变更至销毁状态前将服务地址踢出负载均衡，同样需要借助 TKE 平台的功能——后置脚本。平台侧允许业务方指定一段脚本，该脚本将在容器销毁前执行。我们在该脚本内执行等待一段时间的操作，保证上游的负载均衡器更新状态后，再销毁容器。通过后置脚本，我们保证容器在销毁前，负载均衡不再向该容器转发任何请求。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220525101514633-2009925315.jpg\" alt=\"\" loading=\"lazy\"><br> 图5-6 后置脚本示例</p> \n <h3 id=\"53-高并发服务连接失败优化\">5.3 高并发服务连接失败优化</h3> \n <p>新闻视频流量大部分在线服务需要承载海量请求，同时处理大量的并发，例如品效合一后台服务。在这些服务迁移到 TKE 平台的过程中，随着流量的逐步增长，系统失败量显著增加，特别的，一些使用短连接的服务出现了大量连接失败的情况。为此，我们和运维以及 TKE 平台方的同学共同合作，排查并解决了问题，顺利推进新闻视频团队业务在线服务全部上云，同时也增加了大家将海量服务迁移上云的信心。</p> \n <p>经过排查，我们发现错误率的提升主要由两点导致。</p> \n <ul> \n  <li> \n   <ol> \n    <li>内核的流量统计功能长期占用 CPU 导致网络处理延迟。 kubernetes 通过 ipvs 模块管理 NAT 规则控制流量转发容器，而 ipvs 默认开启流量统计功能，他向内核注册计时器触发统计操作。计时器触发时，通过自旋锁占用 CPU，遍历规则统计。一旦节点上 Pod 数量较多，规则数量多，则计时器长期占用 CPU，影响服务进程处理回包。</li> \n   </ol> </li> \n  <li> \n   <ol start=\"2\"> \n    <li>连接数超出 NAT 连接追踪表的上限导致新连接被丢弃。 kubernetes 通过 nf_conntrack 模块记录连接信息，而 nf_conntrack 的实际实现为固定大小的哈希表。一旦表被填满，新增的连接会被丢弃。</li> \n   </ol> </li> \n </ul> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220525101515029-1174169731.png\" alt=\"\" loading=\"lazy\"><br> 图5-7 服务日志展示的连接表容量已满的错误</p> \n <p>针对第一点，我们希望关闭内核模块 ipvs 的流量统计功能。然而集群的 tlinux 版本与外网版有区别，缺少流量统计功能的开关。平台方推动新增集群 tlinux 补丁同步机制，将外网版本的补丁应用在集群节点上，新增流量统计开关的内核参数。我们配置关闭统计功能后，错误数量下降显著。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220525101515451-1954130908.jpg\" alt=\"\" loading=\"lazy\"><br> 图5-8 安装补丁并关闭统计功能后的效果</p> \n <p>针对第二点，我们希望增大连接追踪表的大小，避免连接丢弃的问题。平台方及时响应，调整内核参数，保证追踪表大小大于当前连接数。修改配置后，服务日志不再打印“table full”，错误数量也大为降低。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220525101515905-2085271513.jpg\" alt=\"\" loading=\"lazy\"><br> 图5-9 提升 tke 流量权重后错误数飙升</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220525101516480-227985913.jpg\" alt=\"\" loading=\"lazy\"><br> 图5-10 调整哈希表大小后错误数几乎跌零</p> \n <p>在 TKE 平台方的帮助下，我们共同解决了业务上云过程中存在的高并发环境下连接失败问题，成功的将新闻视频流量的在线服务都迁移至 TKE 平台。</p> \n <h2 id=\"六成果展示\">六、成果展示</h2> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220525101516835-1461850884.png\" alt=\"\" loading=\"lazy\"><br> 图6-1 上云成果</p> \n <table> \n  <thead> \n   <tr> \n    <th style=\"text-align: left\">比较项</th> \n    <th style=\"text-align: center\">上云前</th> \n    <th style=\"text-align: right\">上云后</th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td style=\"text-align: left\">资源分配</td> \n    <td style=\"text-align: center\">人工申请，弹性低</td> \n    <td style=\"text-align: right\">灵活调整</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">资源管理</td> \n    <td style=\"text-align: center\">人工</td> \n    <td style=\"text-align: right\">平台自动分配</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">资源利用</td> \n    <td style=\"text-align: center\">经常面临浪费</td> \n    <td style=\"text-align: right\">低谷缩容，高峰扩容，充分利用</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">关注点</td> \n    <td style=\"text-align: center\">包含机器和服务</td> \n    <td style=\"text-align: right\">专注服务</td> \n   </tr> \n  </tbody> \n </table> \n <p>表6-1 上云前后情况对比</p> \n <p>新闻视频广告团队积极拥抱云原生，在 TKE 平台以及运维团队的协作与支持下，推动150+后台服务全部上云，上云负载累计核心达到6000+，大大提升了运维效率和资源利用率。资源利用率最高提升至原来的10倍，运维效率提升超过50%，上云过程中，针对服务的特点定制化改造适配云原生，沉淀了针对海量服务、离线服务等多套上云实践方案，有效提高了服务上云效率。</p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <h4 id=\"福利\">福利：</h4> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <p>④公众号后台回复【光速入门】，可获得腾讯云专家5万字精华教程，光速入门Prometheus和Grafana。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220525101517184-447370322.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"123","createTime":"2022-05-20 17:12","comment":"0","id":"16293039","title":"技术分享 | 云原生多模型 NoSQL 概述","url":"https://www.cnblogs.com/tencent-cloud-native/p/16293039.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>朱建平，TEG/云架构平台部/块与表格存储中心副总监。08年加入腾讯后，承担过对象存储、键值存储，先后负责过KV存储-TSSD、对象存储-TFS等多个存储平台。</p> \n <h2 id=\"nosql-技术和行业背景\">NoSQL 技术和行业背景</h2> \n <p>NoSQL 是对不同于传统关系型数据库的一个统称，提出 NoSQL 的初衷是针对某些场景简化关系型数据库的设计，更容易水平扩展存储和计算，更侧重于实现高并发、高可用和高伸缩性。</p> \n <h3 id=\"nosql-vs-关系型数据库\">NoSQL vs 关系型数据库</h3> \n <p>其实早几年大家看两者的区别是清晰的，关系型数据库就是用 SQL 语句操作，具有行列结构和预定义 scheme 的二维表；NoSQL 是 Key-Value 存储，它是一个分布式的 Hash Map 的存储。但最近几年却有些不清晰了？主要是出现 NoSQL 的部分产品也开始增强在SQL的接口和事务等方面的能力，比如 Cassandra 支持 CQL，DynamoDB 支持 PartiQL，InfluxDB 也支持 InfuxQL 等。这里我的看法是，NoSQL vs 关系型数据库的关键差异：关系型数据库具有强大的 ACID 事务、复杂 SQL 检索、数据完整性约束等能力，这给它带来很好的易用性，但同时也是它实现高并发、高可用和高伸缩性的束缚；NoSQL 在工程实现上做了个取舍平衡，弱化甚至舍弃了在跨分区事务、分布式JOIN等维度的能力，增强其在高并发、高可用和高伸缩性方面的能力。</p> \n <h3 id=\"多模型-nosql-的数据模型\">多模型 NoSQL 的数据模型</h3> \n <p>多模型 NoSQL 中的多模型是指这里包括多个数据模型：键值模型 Key-Value、宽表模型 Wide-column、文档模型 Document、时序模型 Time-series、图模型 Graph 和内存模型 in-memory 等。我们可以简单理解，Key-Value 是个哈希表，Wide-column 是个多维的哈希表即 Key-Key-Value 结构，文档 Document 是类似于 Json 结构的一个嵌套树结构，Graph 是以顶点和边组成的复杂图结构，Time-series 是按时间有序的一个检索表。</p> \n <p>数据模型使用和发展可以从受欢迎程度和增长速度两个指标来看。受欢迎程度反映着应用推广的累积效应，排名前三的依次为 文档&gt;键值&gt;宽表；增长速度代表着未来需求的反应，排名前三依次 时序&gt;键值&gt;图，其中时序和图得益于物联网LoT以及实时计算等方面需求目前增长较为迅速，国外 NoSQL 的一些创业公司，近期较多集中在时序和图存储相关领域。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220520171209376-694886272.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"nosql-存储领域的业界玩家\">NoSQL 存储领域的业界玩家</h3> \n <p>主要分为三类：垂直领域的开源社区、多模型 NoSQL 公司 和公有云厂商。</p> \n <p><strong>垂直领域的开源社区</strong>，包括键值存储领域的 Redis，文档存储的 MongoDB，时序存储领域的 InfluxDB、图存储的 Neo4j 等，这些公司都是从垂直开源社区多年的竞争中突围出来的赢家，掌握了垂直领域的生态和接口的标准，基于公有云开展支持多云的企业服务。</p> \n <p><strong>多模型NoSQL公司</strong>，如YugabyteDB、Aerospike等，虽然也是开源，也是基于公有云开展支持多云的企业服务，但并不掌握垂直领域生态和接口标准，更多地兼容Redis、Cassandra、PG（PostgreSQL）等接口标准去融入已有的生态。</p> \n <p><strong>公有云厂商</strong>，如微软 Azure CosmosDB、亚马逊 AWS DynamoDB 等，提供了云原生的托管存储服务，在接口上采用自定义或者直接兼容开源社区的 Redis 和 Cassandra 等垂直领域的接口。</p> \n <p>而我们的 NoSQL 属于这里的第三类玩家。</p> \n <p>据市场公开数据显示，最近几年这三类厂商都有比较好的市场增速，但也存在着垂直领域、开源社区和公有云厂商的一些矛盾和竞争。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220520171210245-1818513121.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"nosql-存储的发展方向与趋势\">NoSQL 存储的发展方向与趋势</h3> \n <p>公司内部自研的 NoSQL，源于早些年结合业务场景的定制开发。比如我们 oTeam 中的 CKV+、TSSD、PCG 的 BDB 、Grocery 等。但是面向云原生的场景下、新的软硬件基础设施升级以及新场景的扩展支持也面临着新的挑战，以及无法同时兼顾内部自用与云上外部客户的一些诉求。</p> \n <p><strong>首先，云原生场景下客户对自研提出了更高的要求</strong>。例如要求解除云厂商的绑定，就是采用业界 API 的接口标准，支持多可用区和地域的分布，弹性伸缩，按需付费容器化和分布式云等方式部署。</p> \n <p><strong>其次，持续提升的基础设施能力对底层存储提出更高要求</strong>。过去几年，公司机房、网络环境、微服务框架、系统、软件等基础设施方面的能力都得到极大的提升，如 SSD 单盘容量，以及单台存储服务器配置的磁盘数量都有了较显著的增长，新 TRPC 框架、新网络和新的磁盘 IO 通道，如 RDMA/DPDK、SPDK/IO_URING 等能力的推出，均要求底层的存储架构进行不断地适配，以获取更高的性价比。</p> \n <p><strong>最后，个性化内容推荐和物联网监控等新生场景出现</strong>。相较于以往我们在社交网络中的键值存储场景，近年来也出现了诸如个性化内容推荐中的特征存储、物联网/监控中的时序存储等新生场景，而它们在 API 接口、功能、存储引擎等方面跟以往的键值存储使用是有所差异，需要能复用平台的大部分能力，同时也需要能定制部分组件。</p> \n <p>为了应对新的机遇和挑战，我们联合了 PCG、CSIG、WXG 和 IEG 相关团队，在2021年组建了多模型 NoSQL 的 Oteam，支持新的业务场景。经过 oTeam 各方的一起努力，从零研发出多模型 NoSQL 平台(X-Stor)，目前已完成了平台技术能力和规模化运营能力的初步建设。</p> \n <h2 id=\"重新再造--多模型-nosql-系统架构\">重新再造--多模型 NoSQL 系统架构</h2> \n <h3 id=\"多模型-nosql-架构和目标\">多模型 NoSQL 架构和目标</h3> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220520171211204-2050838881.png\" alt=\"\" loading=\"lazy\"></p> \n <p>多模型 NoSQL 两个核心目标：一是要提供稳定强大的平台底座，供不同的扩展实现复用；二是提供快速适配的能力，供业务定制化开发或者是新的场景的扩展。</p> \n <p>平台底座，包括在线访问相关和管控相关。一 在线访问相关部分，提供高度可扩展的数据处理框架，具体包括支持多种数据一致性，数据分区与多 AZ/Region 的数据副本复制、数据分层以及索引和事务等方面的能力。二 管控相关的部分，提供工作流引擎 WorkFlow，并基于这个工作流引擎实现了资源管理、数据迁移、数据备份和定点回档、数据巡检等运营管控能力。</p> \n <p>快速适配，包括可扩展多模型API和存储引擎框架。可扩展多模型 API，方便协同方根据业务场景需求定制访问协议。目前的 API 接口已支持TSSD/BDB/Grocery 等存量键值存储平台的接口和功能，同时也支持了部分 Redis 的接口。存储引擎的框架，方便根据业务场景定制自己的存储引擎，在内存占用和磁盘 IO 资源方面进行取舍和平衡。目前已经支持的 LSM-Tree 的 RocksDB 存储引擎，基于Hash的 FasterKV 引擎和基于 TSM-Tree 的时序 TSDB 存储引擎。</p> \n <h3 id=\"多模型-nosql-资源概念\">多模型 NoSQL 资源概念</h3> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220520171211569-409297066.png\" alt=\"\" loading=\"lazy\"></p> \n <p>多模型 NoSQL 资源概念，我们分为用户资源和物理资源。</p> \n <p>用户资源是用户创建的逻辑资源，主要有 Account、Keyspace、Collection、Partition、Replica。这里大家比较陌生的可能是 Account 这个概念。多模型 NoSQL 的 Account 主要不是为了计费设计的，它跟腾讯云的账户或者公司内计费的 OBS 系统的账户不一样，主要目的是方便客户配置 Collection 的公共属性，以及底层根据 Collection 的相关性做资源的共享，比如接入机关联的北极星的入口，甚至同账户下的 Replica 副本将他们调度到一起，方便在资源层面进行多租户隔离和复用。</p> \n <p>物理资源是管理的服务器资源，目前我们申请的存储服务器和接入/逻辑类的TKE容器。对于存储服务器进行容器化，比如对一个配置了12块SSD 的存储服务器，我们创建了12个 TKE 的容器，让每个容器关联到一块 SSD 盘，我们称之为一个 Pod，相应地这台存储服务器我们称之为一个 Node。根据硬件的物理分布，我们给每个 PoD 的关联地域属性 Region，集群属性 Cluster，子集群的属性Subcluster Group，我们称为 SCG，子集群属性Subcluster Region、Subcluster Group 和 Subcluster 之间是逐层包含的一个关系。SCG将指定数量的Node组成一个节点组，而 Subcluster 的是加 SCG 的部分盘组成的一个盘组。通过将一个Partition多个副本分布在这些Group的内部，方便有效地管理同时多个节点或者磁盘故障带来的风险，同时也能控制我们在故障发生时的爆炸半径，影响半径。有兴趣的同学可以在网上 google 下 CopySet 的论文，对其原理做进一步的了解。</p> \n <h3 id=\"多模型-nosql-模块结构\">多模型 NoSQL 模块结构</h3> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220520171211890-222511588.png\" alt=\"\" loading=\"lazy\"></p> \n <p>多模型 NoSQL 的模块架构中，我们分为数据面和控制面。数据面主要是指业务在线增/删/改/查请求路径上的模块；控制面是业务的控制台、运维系统，或者内部的定时任务维护处理所涉及的模块。</p> \n <p><strong>数据面模块架构</strong>，为方便长尾延时的管控和成本的控制，采用两层设计，服务一个请求后端最多经过两跳，业务场景需求设计三类请求处理。</p> \n <p><strong>常规路径（标①），请求到达接入层 gateway</strong>，其查询本地缓存的元信息，并将请求转发给底层的存储模块cell，独立gateway部署方便于收敛前端网络连接数，以及业务前端不支持定制SDK的场景。</p> \n <p><strong>缓存路径（标②），请求到达接入层 cache</strong>，其查询本地的内存缓存，如果命中就直接返回，如果不命中，访问底层存储模块 cell 查询获取并通知 cache 主节点，由 cache 主节点根据预配置的缓存策略更新缓存并基于一致性协议同步更新给所有 cache 从节点。便于降低有明显热点效应的业务请求，降低访问成本。</p> \n <p><strong>定制路径（标③），通过定制的 sdk 允许客户端直连存储节点</strong>，实现一跳访问，同时也可以将部分计算功能卸载到客户端上执行，有利于降低访问延时，减少计算成本。</p> \n <p><strong>控制面模块结构</strong>，控制面对外的访问入口有两个访问网关和三个内部部分。访问网关为 userAdmin 和 sysAdmin，userAdmin 是供客户控制台API访问的网关，sysAdmin 是供运维系统访问的网关。内部三个部分分别是元数据的存储和分发、工作流 Workflow 和监控。</p> \n <p><strong>元数据存储和分发，主要是资源管理服务，包含资源管理服务(RM)和资源管理缓存服务(RMC)</strong>。元数据采用分布式的强一致存储，目前是五副本存储在 CMongo 中，未来会考虑闭环存储于自身系统里面。RMC是为了方便于元数据分发而设计的，数据面的 gateway 和 cache 服务启动后会注册到RMC，方便 RMC 做元数据的增量、推送、分发和一次性校验，通过 userAdmin 和 sysAdmin 网关访问 RM，实现元数据的更新，RMC 通过更新流感知到这个数据的变动，并推知元数据的更新给注册到自己的 gateway 和 cache 容器。</p> \n <p><strong>工作流 Workflow，以往存储管控的实践中，通常是基于微服务架构设计数据迁移服务、数据巡检服务、数据调度服务、容量采集服务、数据冷备服务、资源上下架服务等众多的独立模块上来实现存储管控</strong>。虽然实现了较好的伸缩性，但模块多会增加开发、维护、运营、管理方面的成本。在 X-Stor 中，我们设计的是 Workflow 框架，搭积木的方式配置组装处理流程，实现可重入的执行。通过 Workflow 框架，结合容器化部署，共用一个 Workflow 服务来实现上述的所有功能，同时自动伸缩和容错，对所有的 Workflow 执行、日志存档和审计等能力也非常容易实现。</p> \n <p><strong>监控，通过在每个服务器 Node 的上面本地部署 NodeAgent，实时汇集本 Node 上的各个容器的状态信息，并且推送给集群的 Monitor 服务</strong>。 Monitor 服务对接到 Prometheus 的存储、集群调度服务、监控报警组件如 TEG 智研监控宝等，可以方便地按集群实现实时调度和基于 Grafana 定制一个自己的可视化 Dashboard。</p> \n <h2 id=\"云原生能力设计与思考\">云原生能力设计与思考</h2> \n <p>可扩展和云原生是我们设计多模型 NoSQL 时考虑的两个目标。前面介绍了实现扩展性的相关的架构内容，系统助于扩展性，支持多种数据访问、API 和存储引擎来实现多模型存储。接下来我想分享下在云原生上的设计思考。</p> \n <p>云原生这个词是最近几年大家经常听到的概念，但当你百度这个概念时却发现很难比较清晰的理解。我个人的理解，云原生核心有两个概念，云原生产品和云原生技术。云原生产品是在公有云普及的大背景下，站在客户的视角，对云端提供服务的产品提出的能力和要求，比如弹性伸缩、可观测性等。云原生技术是帮助实现云原生产品的技术手段，如容器、服务网格、微服务、不可变的基础设施和声明式 api 等。多模型 NoSQL 从设计之初，我们就与相关的原生技术进行紧密结合，考虑了基于云原生的能力。我们云原生的特性重点体现在开放性、弹性伸缩、按需付费、多 AZ 和 Region 数据分布四个方面。</p> \n <h3 id=\"01-开放性\">01 开放性</h3> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220520171212913-772610675.png\" alt=\"\" loading=\"lazy\"></p> \n <p>多模型 NoSQL 的开放性主要在下面三个维度进行体现。</p> \n <p>首先，接口和功能的开放。客户出于成本、容错等方面的考虑提出了多云的诉求，要求对云端产品打破厂商绑定（Vendor Lockin），需要产品可以实现在不同的云厂商间迁移。云原生产品需要尊重这个考虑，我们放弃了锁定自定义私有协议和接口，转向全面兼容垂直社区软件接口和功能，如 Redis、InfluxDB 等，未来还会在数据迁移 DTS 能力方面进一步补齐。</p> \n <p>其次，支持扩展、开放互联的连接器（Connector）。不断丰富跟公有云上的其他的云原生产品实现互联互通，如目前我们已经支持的数据镜像、备份和更新流水存放于对象存储产品 COS 或者其他兼容 S3 接口的产品，更新流可以导入到我们 Kafka 队列中，未来可能会推出更多的连接器，能连接到相关的云端产品。</p> \n <p>最后，在资源层面，部署产品时不锁定特定的硬件资源。我们率先在公司内实现了从接入到存储完全架构在 K8S 的容器化化环境中，从能力上可以支持多云和分布式云的部署。</p> \n <h3 id=\"02-弹性伸缩\">02 弹性伸缩</h3> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220520171213311-1107261002.png\" alt=\"\" loading=\"lazy\"></p> \n <p>弹性伸缩，是云原生产品非常重要的能力，解决以往自行开发在软件架构层面或者在资源层面上面临的一些瓶颈。多模型 NoSQL 从客户资源、服务器或者容器资源方面实现了弹性伸缩。</p> \n <p>首先，通过分布式强一致存储和分发的架构，提供强大的元数据存储和访问能力，支持用户的库表数量和单个库表容量的伸缩能力；通过水平伸缩的架构和底层的调度能力，支持单个表在存储和访问容量上无限横向伸缩。</p> \n <p>其次，通过对资源的容器化和标准化，实现了从公司大的资源池中实时申请和释放容器资源，便于我们快速地满足业务在资源规格、资源数量和资源在机房分布等方面的要求。</p> \n <p>最后，在伸缩的速度和效率方面，借助前面提到的数据副本的分布策略和数据的实时采集调度，实现了极速地扩容和自动化伸缩，垂直伸缩小于10秒，4TB 水平伸缩小于5分钟。</p> \n <h3 id=\"03-按需付费\">03 按需付费</h3> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220520171213626-366844026.png\" alt=\"\" loading=\"lazy\"></p> \n <p><strong>按需付费，是云原生产品帮助客户实现低成本运营的关键能力</strong>。在这方面我们主要实现了两个方面的能力。</p> \n <p><strong>一是存储和计算的分开计费</strong>。不需要客户从几个预定规格的容器中去做选择，客户仅需要关注于存储容量和计算容量，底层通过集约化管理给各个库表预留的 Buffer Pool，通过多租户技术和装箱调度，提升资源的整体利用率，通过我们的资源池管理和资源利用率提升达到帮助客户去节省运营成本。</p> \n <p><strong>其次，灵活选择</strong>。通过在客户控制台/API 中方便灵活选择，而不是刚性地捆绑/锚定，实现贴合业务场景需求来实现最高的性价比。如我们在于数据的一致性，数据的副本数，多 Region 的分布，数据生命周期，甚至存储介质方面灵活地配置。在资源独享方面，平衡成本和性能，在存储机和接入机方面独享和混用，可以独立配置。</p> \n <h3 id=\"04-多-az-和-region-分布\">04 多 AZ 和 Region 分布</h3> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220520171214681-1589570727.png\" alt=\"\" loading=\"lazy\"></p> \n <p><strong>多 AZ 和 Region 分布，是云原生产品实现高可用性、数据高可靠性方面的基础要求</strong>。</p> \n <p>公有云中的 AZ 和 Region 跟我们常见的机房和城市的概念不完全一样。如同 Region 下的多个 AZ 要求相距30到100千米，RTT 一般在0.5到2毫秒以内。不同 Region 间的物理距离一般在100千米以上。X-Stor 通过对资源构建 AZ 和 Region 的属性，并结合集群调度、数据同步等方面的支持，实现了多 AZ 和 Region 数据分布的能力，可结合业务自身对于数据的一致性需求实现就近访问；同时也计划在多 Region 分布的基础上，支持异地多活（Multi-Master）。对于多 Region 分布的 Collection，可以在任意的 Region 中就近写入，内部我们对于 Region 间的数据进行复制，并解决并发冲突的问题，进一步优化写延时的体验。</p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <h4 id=\"福利\">福利：</h4> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <p>④公众号后台回复【光速入门】，可获得腾讯云专家5万字精华教程，光速入门Prometheus和Grafana。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220520171215126-874932365.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"47","createTime":"2022-05-19 10:34","comment":"0","id":"16287609","title":"最佳案例 | 游戏知几 AI 助手的云原生容器化之路","url":"https://www.cnblogs.com/tencent-cloud-native/p/16287609.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>张路，运营开发专家工程师，现负责游戏知几 AI 助手后台架构设计和优化工作。</p> \n <h2 id=\"游戏知几\">游戏知几</h2> \n <p>随着业务不断的拓展，游戏知几AI智能问答机器人业务已经覆盖了自研游戏、二方、海外的多款游戏。游戏知几研发团队主动拥抱云原生，推动后台业务全量上云，服务累计核心1w+。</p> \n <p>通过云上的容器化部署、自动扩缩容、健康检查、可观测性等手段，提高了知几项目的持续交付能力和稳定性，形成了一套适合游戏知几自身的上云实践方案。本文将会介绍游戏知几项目中遇到的痛点以及探索出的一套可靠的上云实践方案。</p> \n <h3 id=\"知几项目背景\">知几项目背景</h3> \n <p><a href=\"https://gbot.qq.com/#/home\" title=\"游戏知几\" target=\"_blank\" rel=\"noopener\">游戏知几</a>是一款游戏智能AI产品和运营解决方案，它基于自然语言处理、知识图谱、深度学习等前沿技术，为游戏玩家提供一站式服务，包括游戏内外实时智能问答、游戏语音陪伴、自助流水查询、游戏内外数据互通、主动关怀防流失、产品合规保护等多种能力，目前已经接入包括王者荣耀、和平精英、PUBG mobile、天刀手游等六星游戏在内的80+款游戏，为海内外数以亿计的游戏用户提供服务，获得众多游戏项目和广大用户的持续好评。</p> \n <p>同时游戏知几还提供了简便易用、性能良好的客户端 SDK 和功能完备的运营平台系统，支持模块化接入，显著降低了用户运营中的人力成本，提升了玩家的交互体验。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220519103344122-1556644955.png\" alt=\"\" loading=\"lazy\"></p> \n <p>随着知几业务的不断发展，知几的部署架构也在不断的演进，逐步从最初的 IDC 部署架构迁移到当前的云原生部署架构，实现了业务服务的全面上云。</p> \n <h2 id=\"上云前的知几\">上云前的知几</h2> \n <h3 id=\"docker-部署方案\">docker 部署方案</h3> \n <p>知几在最初采用 docker 部署的方案来部署服务，服务的 CI/CD 通过夸克平台实现，平台将编译打包好的服务推送到 docker 机进行部署。为了实现机器的水平扩容，运维同学会将 docker 环境整体打包成基准镜像，包括 IDC 的机器环境所依赖的环境，比如 CL5 agent，gse agent 等。当需要扩容时，将基准环境发布到扩容机器上进行扩容操作。</p> \n <p>知几整体的部署架构如下图所示：</p> \n <ol> \n  <li>外部请求统一通过 stgw 接入，rs 到后台服务的 vip 上，通常会区分移动、联通、电信和小流量运营商；</li> \n  <li>vip 下挂载的机器IP、端口通过tgw平台配置，请求通过一定的负载均衡策略发送到IDC机器的后台服务上；</li> \n  <li>服务的 CI/CD 通过夸克平台操作，完成服务的编译、打包、发布等操作，也支持操作回滚，进程监控等；</li> \n  <li>监控告警、日志系统接入的是mo监控平台和骏鹰。</li> \n </ol> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220519103344446-1371911757.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"服务遇到的问题\">服务遇到的问题</h3> \n <p>知几项目会对接 IEG 下的众多游戏，伴随着游戏接入的增多，流量也变得越来越大，知几项目的流量状况有以下特点：</p> \n <ol> \n  <li> <p>平时流量平稳，节假日流量随游戏流量增大，通常达到3倍以上；</p> </li> \n  <li> <p>主动关怀类的消息推送，运营活动会通过知几直接触达给玩家，带来可观的突发流量，极端情况10倍以上；</p> </li> \n </ol> \n <p>因此，知几对服务的稳定性、可观测性以及服务治理的能力有很高的要求，需保证项目在流量突发的情况下能够正常运行，故障时能及时发现。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220519103344682-1569046487.png\" alt=\"\" loading=\"lazy\"></p> \n <p>在 docker 部署的架构下，很难做到快速的自动扩缩容，主要问题有以下几个方面：</p> \n <ol> \n  <li> <p>扩容前的机器申请、环境准备很耗时，突发流量的情况下这个准备时间难以接受，提前准备好机器平时又会造成资源的浪费；</p> </li> \n  <li> <p>运维制作的基准镜像通常不是最新的版本，需要发布最新版本才能扩容；</p> </li> \n  <li> <p>依赖的权限（mysql 等）需要申请；</p> </li> \n  <li> <p>平台操作繁琐，容易出错；</p> </li> \n  <li> <p>需要人工完成运营活动后机器的缩容操作。</p> </li> \n </ol> \n <p>这些问题都会造成服务在扩容时的不及时，从而带来服务稳定性的隐患，同时也带来了业务同学的运维负担。除此之外，每年一次的机器裁撤也很痛苦，涉及机器确认、服务迁移、环境梳理等方方面面的操作。</p> \n <p>因此，我们希望通过上云迁移，利用云原生的 HPA 能力来解决服务稳定性、裁撤等问题。</p> \n <hr> \n <h2 id=\"上云迁移\">上云迁移</h2> \n <h3 id=\"知几云原生方案\">知几云原生方案</h3> \n <p>针对以上问题，当前知几实践了一套基于云原生的多机房部署方案。具体方案如下：</p> \n <ul> \n  <li> <p>引入 tapisix 统一网关，借助限流等网关插件管理南北流量，stgw 接入 tapisix 网关的 ingress；</p> </li> \n  <li> <p>服务分南京一区和南京二区进行部署，各区服务通过 ingress 暴露外网流量，tapisix网关混连接入一区、二区服务的 ingress；</p> </li> \n  <li> <p>新增上海灾备集群，极端情况下可快速接入；</p> </li> \n  <li> <p>CI/CD 方面通过蓝盾流水线实现，打包服务镜像推送到镜像仓库，在STKE上进行部署。</p> </li> \n </ul> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220519103345054-400049137.png\" alt=\"\" loading=\"lazy\"></p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220519103345277-978902948.png\" alt=\"\" loading=\"lazy\"></p> \n <p>基于上述的部署方案，利用云原生的自动扩缩容能力可以方便的解决上述问题：</p> \n <ol> \n  <li> <p>STKE 提供的定时 HPA 和动态扩缩容能力，可以很好的解决节假日、运营活动的流量突增带来的服务稳定性问题，且流量平稳后的自动缩容可以有效的节约资源；</p> </li> \n  <li> <p>STKE 提供自动鉴权流程，可以解决依赖权限申请的问题，通常鉴权流程的耗时在分钟级；</p> </li> \n  <li> <p>引入 tapsix 统一网关，接入分区流量，可以对流量进行快速切换，当一个区的服务有问题时，可以通过 tapsix 的路由快速切换到另外一个区；</p> </li> \n </ol> \n <h3 id=\"迁移方案\">迁移方案</h3> \n <p>知几服务的上云迁移设计外网和内网的众多服务，外网服务迁移的过程可通过运营商逐步对流量进行灰度：</p> \n <ol> \n  <li> <p>首先在 stke 集群新部署服务进行测试，提供移动、联通、电信 和CAP 四类公网 CLB；</p> </li> \n  <li> <p>先灰度 CAP 小运营商流量，服务稳定后再通过 gslb 逐步灰度其他运营商；</p> </li> \n  <li> <p>回滚则通过 gslb 快速切换回 IDC 服务的VIP；</p> </li> \n </ol> \n <p>内网服务的迁移则通过 STKE 支持的北极星、CL5 serivce 自动将 pod ip 注入到老服务的负载均衡当中，首先通过一个 pod 进行灰度，再逐步增加 pod 完成放量，最后摘除 IDC 的机器即可。通过这种方式，我们在三个月内完成了所有外网服务和后台服务的全量上云，并保证了迁移的平稳进行。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220519103345522-1606552310.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"上云实践\">上云实践</h2> \n <h3 id=\"标准化部署实践\">标准化部署实践</h3> \n <p>业务上云基础的点就是考虑怎么做标准化的容器部署和弹性服务。知几服务主要有三类，业务服务通常是 Go 服务，算法服务为 C++ 服务，需要考虑模型加载的问题，平台服务主要为 PHP 服务。在容器的标准化上，我们采用的是单容器模式，这样做的好处是每个 container 间互不影响，进程是作为容器的一号进程存在，一旦有问题 k8s 会自动把服务拉起，另外也便于资源的复用。富容器的模式是把所有的进程都放在一个容器内，这样看似方便，能实现业务的无缝平滑的快速上云，但无论从未来的维护效率、安全还是健康检查、服务弹性上看都有问题，是中间态，违反了容器单一功能原则，也不符合云原生的理念。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220519103345907-796570310.png\" alt=\"\" loading=\"lazy\"></p> \n <ul> \n  <li> <p>PHP 的服务将 nginx，pfp-fpm，业务代码都打成了独立的 container，代码通过文件共享的形式共享给 php-fpm 的 container 实现。</p> </li> \n  <li> <p>Go 服务较简单，采用常规的应用 container + sidecar 的标准化容器。</p> </li> \n  <li> <p>算法服务主要是模型，模型文件挂载到 cephfs 上，共享给 C++ 服务的容器使用。</p> </li> \n </ul> \n <p>知几在服务部署的过程中，积累了一些实践经验，通过云原生的对资源利用的优势，提升资源的利用率，降低运营成本。针对不同场景最小实例的配置如下：</p> \n <ul> \n  <li> <p>测试环境、预发布环境流量较少，统一0.1核0.25G，1实例。</p> </li> \n  <li> <p>生产环境，业务后台服务采用1核2G，2实例。</p> </li> \n  <li> <p>生产环境，算法后台服务采用8核16G（个别如在线推理服务会采用32核以上的机器）。</p> </li> \n </ul> \n <p>通过降低单 pod 的 CPU，MEM request，满足日常运营需求，流量高峰期则通过 stke 的 HPA 能力来满足业务的需要，使日常 CPU 利用率能达到40%。由于 HPA 会导致业务容器的扩缩容，如果流量在服务未完成启动时接入或者流量还在访问时接销毁 pod，会导致流量的损失，因此需要开启就绪检测和 prestop 配置。</p> \n <p>这里需要注意的是，就绪检查的启动延时设置不易过短，这样系统会认为 pod 启动失败而不断重启，导致服务无法正常启动。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220519103346096-1893323191.png\" alt=\"\" loading=\"lazy\"></p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220519103346270-1874279875.png\" alt=\"\" loading=\"lazy\"></p> \n <p>此外，stke提供的其他特性可以很好的满足知几的业务需求：</p> \n <ul> \n  <li> <p>提供鉴权流程，可以在 pod 拉起时，动态的申请 mysql 等依赖的权限，规避繁琐的权限申请流程。</p> </li> \n  <li> <p>configmap 可解决配置服务配置更新的问题。</p> </li> \n  <li> <p>可对内核进行调优，业务可根据服务、流量的特点针对性的对内核参数进行优化，如 net.core.somaxconn, net.ipv4.tcp_tw_reuse 等等。</p> </li> \n </ul> \n <p>当前知几在线上部署了超过 1w 核，支撑知几 Sdk，第五人等多个应用服务，整体的利用率在40%左右。</p> \n <h3 id=\"hpa\">HPA</h3> \n <p>STKE 提供的 HPA 能力能够很好的满足知几对扩缩容的需求，知几同时使用了定时 HPA 和动态 HAP 满足不同的场景：</p> \n <ul> \n  <li>针对突发流量， 知几采用 CPU request 和内存 request 作为触发扩容的条件</li> \n  <li>节假日和周五、六晚未成年人游戏上线，知几采用周定时 HPA 提前扩容</li> \n </ul> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220519103346464-579894813.png\" alt=\"\" loading=\"lazy\"></p> \n <p>这样很大程度上减少了开发、运维同学面对运营活动和突发流量时的心智负担，提高了服务稳定性。特别是定时 HPA，可以很方便的满足知几在未成年人保护方面对扩缩容的要求，系统可以在特定时间段完成系统容量的扩容和缩容，在保证系统平稳应对流量的同时也不会造成对资源的浪费。迁移上云后，知几通过这种方式保证了周末时段和线上多场运营活动的平稳进行。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220519103346701-664800334.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"可观测性\">可观测性</h3> \n <p>系统的可观测性能够让开发同学根据系统输出快速监控、定位问题。可观测性可以从 Metrics、Log、Trace 三个方面来看。</p> \n <ul> \n  <li>Metrics，知几服务大部分对接的是 Monitor 系统，通过自定义 metircs 上报实现模调信息、服务状态、业务等指标的监控，知几封装了 Monitor 的标准库实现指标模板的标准化和上报。Monitor 上报需要通过 http 请求获取上报的 ip 再将数据通过 tcp 形式发送到 Monitor 侧，这种形式的上报对业务并不友好，Monitor 当前也已不再接入新的业务，目前知几正逐步将 Metrics 迁移到智研监控系统，trpc 提供插件接入智研监控能力。</li> \n  <li>Log，早期知几上云时采用的 filebeat 采集日志，现在 stke 提供了统一的日志数据解决方案 CLS ，可以方便的进行日志采集、存储、检索，运维成本较低，体验较好。</li> \n  <li>Trace，知几接入天机阁来对请求做 traceing，记录系统的请求链路等上下文信息。通过 traceId 对请求进行标记染色很大程度上提升了问题定位的效率。在此基础上，知几同时也在尝试 <a href=\"https://github.com/dapr\" title=\"dapr\" target=\"_blank\" rel=\"noopener\">dapr</a> 这类新的分布式应用开发组件，dapr 提供的可观测性的无感知接入，相比天机阁等侵入式的接入方式，成本更低。</li> \n </ul> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220519103346971-1103662074.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"总结\">总结</h2> \n <p>知几整个上云迁移的过程随着公司云原生体系的基础设施的完善在不断的完善和优化，公司在相关领域的共建使得业务在实施过程中有了更多的选择。希望知几的实践能给更多的业务团队带来价值。未来在云原生的深入实践方面，团队还会在云原生标准化方向上（mecha 理念）做出更多的尝试。</p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <h4 id=\"福利\">福利：</h4> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <p>④公众号后台回复【光速入门】，可获得腾讯云专家5万字精华教程，光速入门Prometheus和Grafana。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220519103347422-1355611519.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"157","createTime":"2022-05-16 11:08","comment":"0","id":"16276201","title":"精彩分享 | 欢乐游戏 Istio 云原生服务网格三年实践思考","url":"https://www.cnblogs.com/tencent-cloud-native/p/16276201.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>吴连火，腾讯游戏专家开发工程师，负责欢乐游戏大规模分布式服务器架构。有十余年微服务架构经验，擅长分布式系统领域，有丰富的高性能高可用实践经验，目前正带领团队完成云原生技术栈的全面转型。</p> \n <h2 id=\"导语\">导语</h2> \n <p>欢乐游戏这边对 istio 服务网格的引进，自 2019 开始，从调研到规模化落地，至今也已近三年。本文对实践过程做了一些思考总结，期望能给对网格感兴趣的同学们以参考。</p> \n <p>在正文开始之前，先明确一下本文所说的服务网格（service mesh）概念 —— 基于 sidecar 通信代理，网状拓扑的后端架构级解决方案。目前业界最流行的开源解决方案为 istio。</p> \n <p>服务网格的架构思想，是解耦，以及加一层。通过将基础的治理能力从进程中解耦出去，以 sidecar 的形式提供，以达到更大规模的复用，一旦标准化，将会是行业级的复用！其实作为微服务领域炙手可热的解决方案，网格所做的解耦分拆进程这件事情本身就很 “微服务”，因为微服务其实也是做进程拆分，解耦并独立部署，以方便服务的复用。</p> \n <h2 id=\"现状与收益\">现状与收益</h2> \n <h3 id=\"技术栈现状\">技术栈现状</h3> \n <ul> \n  <li> <p>编程语言：go / c++ / python</p> </li> \n  <li> <p>meta 体系：protobuf（用于描述配置、存储、协议）</p> </li> \n  <li> <p>RPC 框架：gRPC</p> </li> \n  <li> <p>单元测试：gtest</p> </li> \n  <li> <p>容器化：docker + k8s</p> </li> \n  <li> <p>网格：istio，envoy 网关</p> </li> \n  <li> <p>配置：基于 pb 的 excel 转表工具，配置分发管理中心</p> </li> \n  <li> <p>监控：prometheus</p> </li> \n  <li> <p>其他：代码生成工具，蓝盾流水线，codecc 代码扫描，helm 部署等。</p> </li> \n </ul> \n <h3 id=\"核心收益\">核心收益</h3> \n <ul> \n  <li> <p>技术价值观：团队的技术价值观变得比较开放，拥抱开源生态，贴近云原生技术栈。</p> </li> \n  <li> <p>团队成长：大技术栈演进，是一项颇具挑战性的任务，团队同学在打怪升级之后自然就有了能力的提升。</p> </li> \n  <li> <p>RPC 框架：通过引入 gRPC 统一了跨语言的 RPC 框架，原自研 RPC 框架也继续在用，但底层会适配为 gRPC。</p> </li> \n  <li> <p>引入 golang：引入了 golang 做常规特性研发，提高了研发效率。</p> </li> \n  <li> <p>网格能力：无需开发，基于 istio 的 virtual service 做流量治理，按 label 聚合分版本调度流量，使用一致性 hash。</p> </li> \n  <li> <p>机器成本：这是唯一相对好量化的收益点，准确的数据还是要等后续完成 100% 上云后才好给出，初步估算的话，可能是原来的百分之六七十。</p> </li> \n </ul> \n <p>总体上，我们做的是一个大技术栈体系的演进，体现了较好的技术价值，提升了研发效能。所以对于我们而言，现在再回望，网格化是否值得实践？答案依旧是肯定的。</p> \n <p>但假如抛开技术栈演进这个大背景，单独看网格本身的话，那么坦率地讲，我们对网格能力的使用是较为初步的：</p> \n <ul> \n  <li> <p>转不转包：熔断、限流、重试（以幂等为前提），暂未实践。</p> </li> \n  <li> <p>包转给谁：名字服务，有实践，使用了 virtual service，使用了 maglev 一致性 hash。</p> </li> \n  <li> <p>调试功能：故障注入、流量镜像，暂未实践。</p> </li> \n  <li> <p>可观测性：关掉了 tracing，暂未实践。</p> </li> \n </ul> \n <p>考虑到实际开销情况，我们并没有拦截 inbound 流量，所以如果有依赖这点的功能特性，目前也无法实践。</p> \n <h2 id=\"网格的真正卖点\">网格的真正卖点</h2> \n <p>从笔者个人的观察来讲，istio 网格最具吸引力的，实际上就两点：</p> \n <ul> \n  <li> <p>开放技术栈的想象空间，随着 istio、envoy、gRPC 整个生态越来越丰富，未来可能会有更多能力提供，开箱即用，业务团队不必投入开发。</p> </li> \n  <li> <p>多语言适配，不用为每种语言开发治理 sdk，例如 C++ 编写的 envoy 可以给所有用 gRPC 的 service 使用。</p> </li> \n </ul> \n <p>至于熔断、限流、均衡、重试、镜像、注入，以及 tracing 监控之类的能力，严格来讲不能算到网格头上，用 sdk 也是一样可以实现的。在团队语言统一的时候，只用维护一种语言版本的 sdk，此时采用治理 sdk 方案也是可行的，也就是所谓的微服务框架方案。采用 sdk 方式下的版本维护问题，以及后期进一步演进网格的问题，这些都不难解决，这里不再发散。</p> \n <p>对于我们自己来讲，因为恰好有引进 golang 以及 gRPC，所以现在再看，选择 istio 作为网格方案也算合适。</p> \n <h2 id=\"网格的思考实践\">网格的思考实践</h2> \n <h3 id=\"一些前置条件\">一些前置条件</h3> \n <p>接入网格，要考虑天时地利人和。即，需要满足一些基本条件：</p> \n <ul> \n  <li>需要项目阶段允许，如果团队本身一直在做快版本内容迭代，业务需求都忙不过来，恐怕也很难有人力保障。</li> \n  <li>要有基础设施环境支持（我们使用了腾讯云的 tke mesh 服务），这样不至于所有东西都从零开始。</li> \n </ul> \n <p>此外，对于这类大的技术优化，还有必要先统一思想：</p> \n <ul> \n  <li>自上而下，获得各级管理干系人的认可，这样才好做较大人力的投入。</li> \n  <li>自下而上，发动同学们深度介入探讨，使得整体的方向、方案得到大家的认可，这样大家才有干劲。</li> \n </ul> \n <h3 id=\"行动之前的三思\">行动之前的三思</h3> \n <p>在早期的构思阶段，需要明确几个大的关键问题：</p> \n <ul> \n  <li> <p>1）想要达到什么目标？节约机器成本 / 提升研发效能 / 培养团队 / 技术栈演进？如果要达到对应的目标，有没有其他更优路径？</p> </li> \n  <li> <p>2）有没有失控风险？性能是否不可接受，k8s、istio 稳定性是否足够，有没有极端的可用性大风险？</p> </li> \n  <li> <p>3）如何平稳地过渡？服务搬迁过程，研发模式是否都可以平稳过渡？</p> </li> \n </ul> \n <p>对于第一点，不同团队要看自己的实际情况，这里不做展开。</p> \n <p>对于第二点，k8s 在业界的大规模应用非常多，所以还算是可靠的，而且它 level triggered 的设计，使其具备较好的健壮性。相对未知的是 istio，团队一开始对 istio 做了一些压测，也考虑了回退无 mesh 的情形，结论是可以尝试。istio 本质上就是一个复杂大型软件，所以其本身主要使人望而生畏的点，是其复杂的配置，版本之间的兼容性担忧，以及偏黑盒可控性不好这几点。现在想来，其实我们团队的步子迈得还是比较大的。幸运的是，后面的落地过程表明，istio 本身稳定性也还行，不至于三天两头出问题。</p> \n <p>对于第三点，我们针对性地做了引入间接层的设计，使用私有协议与 gRPC 互转的网关确保了服务平滑迁移上云，在服务内部引入 grpc 适配层确保了研发人员的开发模式基本不变。</p> \n <h3 id=\"系统整体架构\">系统整体架构</h3> \n <p>系统整体架构如下图所示，可以清晰地看到上文所说的间接层：</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220516110732164-1349248530.png\" alt=\"\" loading=\"lazy\"></p> \n <p>图示：gRPC 适配与网格内外通信代理</p> \n <h3 id=\"云原生研发体验\">云原生研发体验</h3> \n <p>对于评需求、定方案、写代码等差异不大的点，这里不做展开。下面主要罗列一些在云原生的技术栈体系下，与我们以前相比，有显著差异的一些研发体验。</p> \n <ul> \n  <li> <p><strong>helm</strong>：通过 helm 管理所有服务的内外网 yaml，在服务自身 yaml 里完整描述其所有部署依赖。</p> </li> \n  <li> <p><strong>测试环境 dev 副本</strong>：因为系统服务过多，虽然内网都是 debug version，资源消耗要远低于 release 版本，但考虑到复杂的服务间依赖，为每个人部署一套测试环境也不可取，所以目前还是选择的少数几套环境，大家复用。对于多人自测环境的冲突问题，我们借助网格的能力，做了基于 uin 的 dev 副本部署，这样当小 A 同学开发特定服务的时候，他自己的请求会落到自己的专属 deployment 上。</p> </li> \n </ul> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220516110732438-1215876091.png\" alt=\"\" loading=\"lazy\"></p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220516110732638-1472972290.png\" alt=\"\" loading=\"lazy\"><br> 图示：基于不同号码部署不同的专属 deployment</p> \n <ul> \n  <li> <p>测试环境每日全量<strong>自动构建部署</strong>：但是这也带来一个问题，pod 重建漂移后日志、coredump 等信息都不匹配，例如测试同学反馈说前一天遇到个什么问题，然后开发也不知道前一天在哪个 pod（已经被销毁）。我们通过设置 k8s 节点亲和策略 preferredDuringSchedulingIgnoredDuringExecution，结合日志路径固定化（取 deployment 名而非 pod 名），确保测试环境下 pod 重建后还在原 node，日志路径也保持一致，这样进入同服务的新 pod 便可以继续看到前一天的日志。</p> </li> \n  <li> <p><strong>外网金丝雀版本</strong>：灰度期间使用，直接通过 yaml 的 deploymentCanary 配置项打开，借助 istio virtual service 来配置灰度的流量比例。排查外网问题有时候也会启用，对于染色的号码，流量也会导入金丝雀版本。具体实现就是网关进程会读一份号码列表配置，只要是在列表里的号码请求，就给 gRPC 的 header 打上相关的 label，再基于 vs 的路由能力导入到金丝雀版本。</p> </li> \n  <li> <p><strong>hpa 实践</strong>：对于 hpa 笔者早先的态度还是有些犹豫的，因为这本质上是会将服务部署发布时机变得不可控，不像是常规人工干预的发布，出了问题好介入。线上也确实出过一些问题，例如 hpa （会依赖 hpa 关联的 metric 链路畅通）夜间失效导致业务过载；还有就是在日志采集弄好之前，hpa 导致 pod 漂移，前一天夜里某 pod 的告警信息，第二天想看就比较费劲，还得跑到之前调度到的 node 上去看；另外也出现过进程 hpa 启动不起来的问题，配置有误无法加载初始化成功，正在跑着的进程只会 reload 失败，但是停掉重启就会启动失败。不过 hpa 对于提升资源利用率，还是很有价值的，所以我们现在的做法是做区分对待，对于普通的业务，min 副本数可以较小，对于重要的服务，min 副本数则配置稍大一些。</p> </li> \n  <li> <p><strong>优雅启停</strong>：直接基于 k8s 的就绪、存活探针实现。</p> </li> \n  <li> <p><strong>外网日志收集</strong>：这块之前一直还没有用到比较好用的平台服务，业务自己有打过 rsyslog 远程日志，后面可能会用 cfs 挂网盘，也算能凑合用。</p> </li> \n  <li> <p><strong>配置体系</strong>：配置的定义用 protobuf，配置的解析基于代码生成，配置的分发基于 rainbow，配置的拉取基于 configAgent，配置的归档表达以 excel 形式放在了 svn，用工具完成 excel 到程序读取格式的转换。configAgent，是 webhook 给 pod 动态注入的容器。</p> </li> \n  <li> <p><strong>监控体系</strong>：prometheus，云监控。</p> </li> \n  <li> <p><strong>DEBUG_START 环境变量</strong>：在容器化部署的早期，我们遇到过一些进程启动失败的情况，反复拉起失败，然后 pod 到处漂移，排查很不方便，所以我们增加了 DEBUG_START 环境变量，如果设置为 true 的时候，进程启动失败时不退出容器。</p> </li> \n  <li> <p><strong>云上 perf</strong>因为一些安全的权限原因，容器内无法 perf，现在是临时申请 node 的 root 权限进行 perf，需要在 node 上也放一份二进制文件，不然 perf 无法解析 symbol 信息。对于 go 服务的话，则直接使用它自己的工具链来剖析。</p> </li> \n  <li> <p><strong>问题 pod 现场保留</strong>：由于 deployment 是基于 label 识别的，所以对于外网那种想保留故障 pod 的现场时会很简单，直接改一下 label 就好了。</p> </li> \n  <li> <p><strong>coredump 查看</strong>：段错误信号捕获后会把二进制本身也拷贝到 coredump 的文件夹，随便 attach 到 coredump node 上当前存活的任意 pod 就可以查看。</p> </li> \n  <li> <p><strong>代码生成</strong>：这个其实和是否上云关系不大，只是我们基于 protobuf 做了不少工作（例如用 .proto 定义配置文件，提供类似 xresloader 的功能），深感颇有益处，这里也列一下。后续整理相关代码并完善文档后，也会考虑开源。</p> </li> \n </ul> \n <h3 id=\"性能情况\">性能情况</h3> \n <p>讨论性能之前，这里先说一下我们的实践方式：关掉 tracing，关掉 inbound 拦截（远端流量过来的时候，并不会走 sidecar）。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220516110732955-1808194202.png\" alt=\"\" loading=\"lazy\"></p> \n <p>图示：pod1 上的业务容器调用 pod2 上的服务，仅拦截 outbound</p> \n <p>在上述背景下，结合我们的线上真实案例情况，分享一下读者可能会比较感兴趣的性能数据：</p> \n <ul> \n  <li> <p>内存开销：系统中共有几百个服务，使用一致性 hash，envoy sidecar 的内存占用约两三百兆。</p> </li> \n  <li> <p>CPU 开销：典型 cpu 开销和扇出情况相关，例如一个服务较多访问其他 gRPC 服务，那么 envoy 的 cpu 开销甚至会超过主业务进程，但当业务进程扇出较少时 envoy 的开销就比较低。</p> </li> \n </ul> \n <p>对于内存开销的问题，社区有相对明确的解决方案，采用 sidecar crd 来限定载入业务所需访问目标服务的 xds 信息，即可大幅减少内存占用。业务进程需要访问哪些目标服务，可以通过手动维护、静态注册或代码生成之类的办法明确，我们后面也会做相关的优化。</p> \n <p>接下来我们用相对大的篇幅讨论一下 cpu 开销的问题，先看一个大扇出业务的性能 top 示例：</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220516110733274-349819957.png\" alt=\"\" loading=\"lazy\"></p> \n <p>图示：大扇出业务进程与 envoy 性能对比示意</p> \n <p>看到上图中的数据，读者可能会有这样的疑问：为什么仅支持 gRPC 的转发，envoy 就需要如此高的 cpu 开销（图中 71.3%，远超业务进程的 43.7%）呢？关于这点，我们在分析火焰图之后，也没有发现显著异常的地方，它所做的主要工作，也就是在做协议的编解码与路由转发而已，无明显异常热点。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220516110733618-146261029.png\" alt=\"\" loading=\"lazy\"></p> \n <p>图示：envoy 火焰图示意</p> \n <p>现在网上大量介绍 envoy 的资料，基本都会说它性能比较好，难道...真相其实是 envoy 其实做的不够高效么？针对这个问题，笔者这里也无法给出一个明确的答案，envoy 内部确实大量使用了各种 C++ 的抽象，调用层级比较多，但这未必是问题的关键所在，因为：</p> \n <ul> \n  <li> <p>可能是 envoy 使用的 libnghttp2 协议解析库的性能拖累所致...</p> </li> \n  <li> <p>可能是 envoy 使用 libnghttp2 的“姿势”不大对，没有充分发挥其性能...</p> </li> \n  <li> <p>抑或是 http2 解析、编解码，以及收发包本来就需要消耗这么多的 cpu？</p> </li> \n </ul> \n <p>关于最后这一点，我们观测了业务主进程中的 grpc thread，它也需要做 http2 的解析和编解码，但它的 cpu 开销显然低得多。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220516110733981-1115360921.png\" alt=\"\" loading=\"lazy\"></p> \n <p>图示：业务进程中的 grpc 线程 %cpu * 2 后依然比 envoy 小很多</p> \n <p>将业务进程中的 grpc 线程（红框部分）%cpu 乘 2 后再与 envoy（蓝框部分）做对比，是因为 envoy 对 outbound 拦截的 workload 相对业务进程而言确实近似翻倍，例如就编解码而言，对于一次 req、rsp，业务进程就是 req 的编码和 rsp 的解码，但是对于 envoy，则是 req 的解码 + 编码，rsp 的解码 + 编码。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220516110734231-546780865.png\" alt=\"\" loading=\"lazy\"></p> \n <p>图示：envoy vs 业务进程的编解码开销</p> \n <p>从上面的示例来看，grpc 自己做 http2 parse + 编解码 + 收发包的性能，要远好于使用 libnghttp2 的 envoy，但 envoy 显然不可能直接采用 grpc 里面的相关代码。要想更好地回答关于 envoy 做 grpc 通信代理性能的疑问，恐怕还需要做更加细致的分析论证以及测试（欢迎感兴趣或有经验的读者来交流）。</p> \n <p>总之对于 gRPC 大扇出业务 sidecar cpu 损耗过大的这个问题，我们暂时也没想到好的优化方案。当然上面那个案例其实相对极端，因为是大扇出 + 主业务进程为 C++ 的情况，如果是小扇出则 sidecar 不会耗多少 cpu，如果是 golang 业务进程则 sidecar 占 pod 整体 cpu 开销的比例不会这么夸张（当然这也反过来说明 golang 性能和 C++ 差距还是蛮大的...）。</p> \n <p>对于我们自身来讲，网格的综合性能并没有严重到无法接受的地步：</p> \n <ul> \n  <li> <p>首先很多业务并不是大扇出型的，这类业务下的 sidecar 的开销并不大。</p> </li> \n  <li> <p>其次对于 golang 类的业务进程，sidecar 相较带来的涨幅比例也会小一些。</p> </li> \n  <li> <p>最后相对于传统 IDC 粗放的部署方式，在我们做了整体上云之后，总体上还是更省机器的。</p> </li> \n </ul> \n <h3 id=\"私有协议或私有网格\">私有协议或私有网格</h3> \n <p>如前文所述，envoy 的性能问题，在大扇出业务场景下确实难以忽视。</p> \n <p>如果真的无法接受相应的性能开销，那么可能私有协议或私有网格会是可选的替代方案。</p> \n <ul> \n  <li> <p>采用私有协议，基于 envoy 自己写 filter，解析私有协议头，然后结合 envoy xds 相关的能力来提供服务（可以参考腾讯开源的解决方案 <a href=\"https://github.com/aeraki-mesh/aeraki\" target=\"_blank\" rel=\"noopener\">https://github.com/aeraki-mesh/aeraki</a> ），不难想象在该方案下，完全无需解析 http2，性能必然会有非常显著的提升。但如果我们真的走到私有协议的老路上去，其实就等于又放弃了 gRPC 生态。（参考前文网格核心卖点 1）</p> </li> \n  <li> <p>采用私有网格，自己实现 xDS 相对应的系列能力，可以先从最核心能力做起。但采用该方案的话，就又会回到多语言支持的问题上来，需要为 C++ 和 golang 都实现对应的能力（参考前文网格核心卖点 2）。假如真的要自己实现私有网格，在设计上，应当考虑语言相关的 sdk 代码是相对简易的，路由策略等控制面功能依旧下沉在自研 sidecar/agent 里，数据面逻辑出于性能考虑则由业务进程自己处理。</p> </li> \n </ul> \n <h2 id=\"未来趋势展望\">未来趋势展望</h2> \n <h3 id=\"欢乐自己的实践\">欢乐自己的实践</h3> \n <p>对于欢乐自己的团队而言，后面会持续做更深度的实践。例如 envoy filter 开发、k8s crd，以及 istio 的更多能力的实践（上文也提到了，我们目前仅使用了一小部分网格能力，期望以后能使用熔断、限流等能力来提升业务的可用性）。</p> \n <h3 id=\"ebpf-的融合\">ebpf 的融合</h3> \n <p>ebpf 可能未来会与容器网络、网格有更好的融合，可以提升网络相关性能表现，或许还会带来其他一些可能。</p> \n <h3 id=\"proxyless-mesh\">proxyless mesh</h3> \n <p>proxyless mesh 可以看做基于前文讨论性能问题的一个延伸，和前面提及的私有网格有些类似。这类方案也会有对应的生存空间，因为始终有些团队无法接受数据面 sidecar 所带来的性能开销：</p> \n <ul> \n  <li> <p>时延，这点也有不少团队提及，但如果是普通互联网业务，笔者个人认为多几十毫秒级别的延迟影响都不大。</p> </li> \n  <li> <p>cpu 和内存开销，前文已有较多讨论。</p> </li> \n </ul> \n <p>proxyless mesh 实际上就是 sdk + 网状拓扑的方案，gRPC 现在也在持续完善对 xDS 的支持，所以也有可能借助 gRPC 的能力来实现。如果自行研发支持 xDS 的 sdk，那对于团队的投入还是有要求的，除非团队本身就是大厂的中间件类团队（网易轻舟、百度服务网格、阿里 dubbo，这一两年都有做 proxyless mesh 的实践）。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220516110734429-1039293750.png\" alt=\"\" loading=\"lazy\"></p> \n <p>图示：proxyless gRPC mesh</p> \n <h3 id=\"私有方案对标-xds\">私有方案对标 xDS</h3> \n <p>对于编程语言统一的团队，例如全 golang，那么只用维护一套服务治理相关的 sdk（控制面逻辑也可以用 agent 承载），所以可能会倾向于做一套自己私有的解决方案。据笔者了解，B 站之前就是采用的这种方案，参考 eureka 实现名字服务自己做流量调度。</p> \n <p>现在随着网格的流行（起码对应的理念已经广为人知了），私有方案也可以参考对标 xDS 的各种 feature。因为私有方案通常是自研的，所以理论上还能提供相对高效可控的实现，但是需要团队持续投入维护。</p> \n <h3 id=\"dapr-运行时\">Dapr 运行时</h3> \n <p>概念很好，故事很宏大，不过目前看来还为时过早。</p> \n <h2 id=\"参考资料\">参考资料</h2> \n <p>让 istio 支持私有协议：【<a href=\"https://github.com/aeraki-mesh/aeraki%E3%80%91\" target=\"_blank\" rel=\"noopener\">https://github.com/aeraki-mesh/aeraki】</a></p> \n <p>grpc 对 xDS 的支持：【<a href=\"https://grpc.github.io/grpc/cpp/md_doc_grpc_xds_features.html%E3%80%91\" target=\"_blank\" rel=\"noopener\">https://grpc.github.io/grpc/cpp/md_doc_grpc_xds_features.html】</a></p> \n <p>proxyless grpc：【<a href=\"https://istio.io/latest/blog/2021/proxyless-grpc/%E3%80%91\" target=\"_blank\" rel=\"noopener\">https://istio.io/latest/blog/2021/proxyless-grpc/】</a></p> \n <p>nghttp2 解析库：【<a href=\"https://nghttp2.org/%E3%80%91\" target=\"_blank\" rel=\"noopener\">https://nghttp2.org/】</a></p> \n <p>infoQ 基础软件创新大会微服务专场：【<a href=\"https://www.infoq.cn/video/7RLecjvETz3Nt7HedviF%E3%80%91\" target=\"_blank\" rel=\"noopener\">https://www.infoq.cn/video/7RLecjvETz3Nt7HedviF】</a></p> \n <p>xresloader 配置转换工具：【<a href=\"https://github.com/xresloader/xresloader%E3%80%91\" target=\"_blank\" rel=\"noopener\">https://github.com/xresloader/xresloader】</a></p> \n <p>Dapr：【<a href=\"https://dapr.io/%E3%80%91\" target=\"_blank\" rel=\"noopener\">https://dapr.io/】</a></p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <h4 id=\"福利\">福利：</h4> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <p>④公众号后台回复【光速入门】，可获得腾讯云专家5万字精华教程，光速入门Prometheus和Grafana。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220516110734785-31662523.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"74","createTime":"2022-05-06 09:50","comment":"0","id":"16227484","title":"最佳案例 | QQ 相册云原生容器化之路","url":"https://www.cnblogs.com/tencent-cloud-native/p/16227484.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <h4 id=\"福利\">福利：</h4> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <p>④公众号后台回复【光速入门】，可获得腾讯云专家5万字精华教程，光速入门Prometheus和Grafana。</p> \n <h2 id=\"作者\">作者</h2> \n <p>吕朋钊，腾讯业务运维高级工程师，曾负责 QQ 相册、小世界业务的存储接入层运维，现负责 AI 业务的运维。</p> \n <h2 id=\"背景\">背景</h2> \n <p>QQ 相册是 QQ 产品中为用户提供图片存储，分享等功能的成熟产品，自上线以来，一直为用户提供稳定快速的图片上传和下载服务。作为社交业务组内第一个上 TKE 的平台，相册在过去一年多时间里总结出了一套适合自身的 TKE 上云实践方案。</p> \n <h2 id=\"服务场景\">服务场景</h2> \n <p>自相册全面改造上云之后，新的架构如下：</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220506094924433-1996307897.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"问题\">问题</h2> \n <p>随着相册各模块已基本实现容器化，也暴露出了不少使用上的问题。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220506094925730-281230572.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"资源利用率提升与-cicd-优化\">资源利用率提升与 CICD 优化</h2> \n <h3 id=\"1-资源利用率提升\">1. 资源利用率提升</h3> \n <h4 id=\"复用集群独立集群迁移到共享集群\">复用集群、独立集群迁移到共享集群</h4> \n <p>复用集群因为是使用老旧机器搭建的 K8s 集群，在使用上会有比较多的损耗，而且经常会有资源抢占严重的情况。而独立集群因为母机规格不够高，会造成一定程度的资源浪费。基于这两点，把复用集群和独立集群的系统迁移到复用集群是较好的选择。会发现，迁移后的资源利用率和错误码次数都得到了明显的改善。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220506094926149-137284171.png\" alt=\"\" loading=\"lazy\"></p> \n <p>同时使用 HPA 弹性扩缩容，根据 CPU 利用率，让资源在业务低峰期得到释放，高峰期自动扩容，可以更好地节约成本。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220506094926511-748341951.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"2-部署策略优化\">2. 部署策略优化</h3> \n <p>因为当前基于一个可用区的命名空间建立一个 workload 的方案没有考虑到单可用区的容灾，所以我们在一个集群的多个可用区都建立了 workload，同时在其他地域也建立了容灾的 workload，当有机房或者地域级别的故障发生时，可以自动切换到其他机房或者地域。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220506094926852-1725515543.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"3-七彩石配置\">3. 七彩石配置</h3> \n <p>每个应用都使用七彩石作为配置管理，在 TKE&nbsp;场景中，配置变更会更改 workload yaml 中的 annotations 字段，而 downward api 会把 annotations 的值作为 volumn 注入到容器的七彩石目录，智研之后还会调用容器内部的&nbsp;configuration-reload.sh&nbsp;从而实现配置变更。此过程因为只涉及修改 annotations，并不会令pod和容器重建，一个 pod 的整个配置变更过程只需要几秒。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220506094927345-1884507704.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"4-clickhouse-日志查询\">4. ClickHouse 日志查询</h3> \n <p>随着相册业务日志量的增加，日志存储成本也在升高，因此我们把日志迁移到了 ClickHouse。在可接受的影响范围内，ClickHouse 所需资源只需要 ES 的30%-50%。</p> \n <h3 id=\"5-tget-拨测\">5. Tget 拨测</h3> \n <p>业务监控方面结合 Tget 拨测，对 oc 域名和源站域名都做了拨测告警，提高针对 vip 被封禁或者网络导致问题的响应速度。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220506094927871-1026039810.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"6-智研一站式接入\">6. 智研一站式接入</h3> \n <p>相册正在接入智研一站式开发，使用智研提供的从需求-开发-测试-发布上线-线上运营的研发全生命周期管理服务，让相册 CICD 可以更好地提高效率。</p> \n <h2 id=\"运营开发能力\">运营开发能力</h2> \n <h3 id=\"1-告警分析手机端自助剔除\">1. 告警分析手机端自助剔除</h3> \n <p>结合智研的告警分析回调接口，可以手动在企业微信界面上剔除某台机器在北极星的绑定。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220506094928499-595515076.png\" alt=\"\" loading=\"lazy\"></p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220506094929273-297768969.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"2-质量分分析\">2. 质量分分析</h3> \n <p>针对平常监控不到的新错误码引起的异常失败率升高，质量分分析工具可以让运维人员快速知道当前是由哪个错误码引起的质量降低。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220506094929981-522208978.png\" alt=\"\" loading=\"lazy\"></p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220506094930520-494766309.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"云原生成熟度提分\">云原生成熟度提分</h2> \n <h3 id=\"1-业务稳定是第一位\">1. 业务稳定是第一位</h3> \n <p>在云原生提分实践过程中，发现很多模块的瓶颈并不是 CPU，而是流量或者内存，但是目前云原生的计算方式只计算 CPU，所以制定 HPA 扩缩容策略时需要综合各维度去考虑。</p> \n <h3 id=\"2-降低-request-值\">2. 降低 request 值</h3> \n <p>对于某些流量型的模块如 http、preupload和 prxoy，可以把 workoad 的 request 的值适当降低，这样可以让 CPU 利用率的提升有立竿见影的效果，需要结合压力测试来确认 request 降低后 CPU 不会成为瓶颈。</p> \n <h2 id=\"小结\">小结</h2> \n <p>随着相册的 TKE 业务从其他平台转到共享集群，结合部署优化策略和运营开发能力，总结如下：</p> \n <ol> \n  <li> <p>云原生成熟度有了显著的提升。</p> </li> \n  <li> <p>相册平台累计使用 TKE 规模达5万+核。</p> </li> \n </ol> \n <p>3.&nbsp;打通智研 CICD 流程，显著提升日常开发和运维效率。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2022.cnblogs.com/other/2041406/202205/2041406-20220506094930828-1325305521.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"75","createTime":"2022-04-29 14:38","comment":"0","id":"16206606","title":"K8s 如何提供更高效稳定的编排能力？K8s Watch 实现机制浅析","url":"https://www.cnblogs.com/tencent-cloud-native/p/16206606.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <h4 id=\"福利\">福利：</h4> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <p>④公众号后台回复【光速入门】，可获得腾讯云专家5万字精华教程，光速入门Prometheus和Grafana。</p> \n <h2 id=\"作者\">作者</h2> \n <p>王成，腾讯云研发工程师，Kubernetes member，从事数据库产品容器化、资源管控等工作，关注 Kubernetes、Go、云原生领域。</p> \n <h4 id=\"目录\">目录</h4> \n <p>1.概述</p> \n <p>2.从 HTTP 说起</p> \n <p>2.1 Content-Length</p> \n <p>2.2 Chunked Transfer Encoding</p> \n <p>2.3 HTTP/2</p> \n <p>3.APIServer 启动</p> \n <p>4.ETCD 资源封装</p> \n <p>5.客户端 Watch 实现</p> \n <p>6.服务端 Watch 实现</p> \n <p>7.小结</p> \n <h2 id=\"概述\">概述</h2> \n <p>进入 K8s 的世界，会发现几乎所有对象都被抽象为了资源(Resource)，包括 K8s Core Resources(Pod, Service, Namespace 等)、CRD、APIService 扩展的资源类型。同时 K8s 底层将这些资源统一抽象为了 RESTful 的存储(Storage)，一方面服务端按目录形式(/registry/xxx) 存放在 ETCD 中，另一方面也为客户端提供了 RESTful API 接口，便于对资源的操作(get/post/put/patch/delete 等)。</p> \n <p>K8s Watch API 就是为资源提供的一种持续监听其变化的机制，当资源有任何变化的时候，都可以实时、顺序、可靠的传递给客户端，使得用户可以针对目标资源进行灵活应用与操作。</p> \n <p>那 K8s Watch 机制是怎么实现的呢？底层具体依赖了哪些技术？</p> \n <p>本文将从 HTTP 协议、APIServer 启动、ETCD Watch 封装、服务端 Watch 实现、客户端 Watch 实现等方面，对 K8s Watch 实现机制进行了解析。</p> \n <p>流程概览如下：</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220429143737600-2022287767.png\" alt=\"\" loading=\"lazy\"></p> \n <blockquote> \n  <p>本文及后续相关文章都基于 K8s v1.23</p> \n </blockquote> \n <h2 id=\"从-http-说起\">从 HTTP 说起</h2> \n <h3 id=\"content-length\">Content-Length</h3> \n <p>如下图所示，HTTP 发送请求 Request 或服务端 Response，会在 HTTP header 中携带 Content-Length，以表明此次传输的总数据长度。如果 Content-Length 长度与实际传输长度不一致，则会发生异常(大于实际值会超时, 小于实际值会截断并可能导致后续的数据解析混乱)。</p> \n <pre><code>curl baidu.com -v\n\n&gt; GET / HTTP/1.1\n&gt; User-Agent: curl/7.29.0\n&gt; Host: baidu.com\n&gt; Accept: */*\n\n&lt; HTTP/1.1 200 OK\n&lt; Date: Thu, 17 Mar 2022 04:15:25 GMT\n&lt; Server: Apache\n&lt; Last-Modified: Tue, 12 Jan 2010 13:48:00 GMT\n&lt; ETag: \"51-47cf7e6ee8400\"\n&lt; Accept-Ranges: bytes\n&lt; Content-Length: 81\n&lt; Cache-Control: max-age=86400\n&lt; Expires: Fri, 18 Mar 2022 04:15:25 GMT\n&lt; Connection: Keep-Alive\n&lt; Content-Type: text/html\n\n&lt;html&gt;\n&lt;meta http-equiv=\"refresh\" content=\"0;url=http://www.baidu.com/\"&gt;\n&lt;/html&gt;\n</code></pre> \n <p>如果服务端提前不知道要传输数据的总长度，怎么办？</p> \n <h3 id=\"chunked-transfer-encoding\">Chunked Transfer Encoding</h3> \n <p>HTTP 从 1.1 开始增加了分块传输编码（Chunked Transfer Encoding），将数据分解成一系列数据块，并以一个或多个块发送，这样服务器可以发送数据而不需要预先知道发送内容的总大小。数据块长度以十六进制的形式表示，后面紧跟着 \\r\\n，之后是分块数据本身，后面也是 \\r\\n，终止块则是一个长度为 0 的分块。</p> \n <pre><code>&gt; GET /test HTTP/1.1\n&gt; Host: baidu.com\n&gt; Accept-Encoding: gzip\n\n&lt; HTTP/1.1 200 OK\n&lt; Server: Apache\n&lt; Date: Sun, 03 May 2015 17:25:23 GMT\n&lt; Content-Type: text/html\n&lt; Transfer-Encoding: chunked\n&lt; Connection: keep-alive\n&lt; Content-Encoding: gzip\n\n4\\r\\n        (bytes to send)\nWiki\\r\\n     (data)\n6\\r\\n        (bytes to send)\npedia \\r\\n   (data)\nE\\r\\n        (bytes to send)\nin \\r\\n\n\\r\\n\nchunks.\\r\\n  (data)\n0\\r\\n        (final byte - 0)\n\\r\\n         (end message)\n</code></pre> \n <p>为了实现以流（Streaming）的方式 Watch 服务端资源变更，HTTP1.1 Server 端会在 Header 里告诉 Client 要变更 Transfer-Encoding 为 chunked，之后进行分块传输，直到 Server 端发送了大小为 0 的数据。</p> \n <h3 id=\"http2\">HTTP/2</h3> \n <p>HTTP/2 并没有使用 Chunked Transfer Encoding 进行流式传输，而是引入了以 Frame(帧) 为单位来进行传输，其数据完全改变了原来的编解码方式，整个方式类似很多 RPC协议。Frame 由二进制编码，帧头固定位置的字节描述 Body 长度，就可以读取 Body 体，直到 Flags 遇到 END_STREAM。这种方式天然支持服务端在 Stream 上发送数据，不需要通知客户端做什么改变。</p> \n <pre><code>+-----------------------------------------------+\n|                 Body Length (24)                   | ----Frame Header\n+---------------+---------------+---------------+\n|   Type (8)    |   Flags (8)   |\n+-+-------------+---------------+-------------------+\n|R|                 Stream Identifier (31)          |\n+=+=================================================+\n|                   Frame Payload (0...)        ...    ----Frame Data\n+---------------------------------------------------+\n</code></pre> \n <p>K8s 为了充分利用 HTTP/2 在 Server-Push、Multiplexing 上的高性能 Stream 特性，在实现 RESTful Watch 时，提供了 HTTP1.1/HTTP2 的协议协商(ALPN, Application-Layer Protocol Negotiation) 机制，在服务端优先选中 HTTP2，协商过程如下：</p> \n <pre><code>curl  https://{kube-apiserver}/api/v1/watch/namespaces/default/pods/mysql-0 -v\n\n* ALPN, offering h2\n* ALPN, offering http/1.1\n* SSL verify...\n* ALPN, server accepted to use h2\n* Using HTTP2, server supports multiplexing\n* Connection state changed (HTTP/2 confirmed)\n* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0\n* Using Stream ID: 1 (easy handle 0x7f2b921a6a90)\n&gt; GET /api/v1/watch/namespaces/default/pods/mysql-0 HTTP/2\n&gt; Host: 9.165.12.1\n&gt; user-agent: curl/7.79.1\n&gt; accept: */*\n&gt; authorization: Bearer xxx\n&gt; \n* TLSv1.3 (IN), TLS handshake, Newsession Ticket (4):\n* Connection state changed (MAX_CONCURRENT_STREAMS == 250)!\n\n&lt; HTTP/2 200 \n&lt; cache-control: no-cache, private\n&lt; content-type: application/json\n&lt; date: Thu, 17 Mar 2022 04:46:36 GMT\n\n{\"type\":\"ADDED\",\"object\":{\"kind\":\"Pod\",\"apiVersion\":\"v1\",\"metadata\":xxx}}\n</code></pre> \n <h2 id=\"apiserver-启动\">APIServer 启动</h2> \n <p>APIServer 启动采用 Cobra 命令行，解析相关 flags 参数，经过 Complete(填充默认值)-&gt;Validate(校验) 逻辑后，通过 Run 启动服务。启动入口如下：</p> \n <pre><code class=\"language-go\">// kubernetes/cmd/kube-apiserver/app/server.go\n// NewAPIServerCommand creates a *cobra.Command object with default parameters\nfunc NewAPIServerCommand() *cobra.Command {\n   s := options.NewServerRunOptions()\n   cmd := &amp;amp;cobra.Command{\n      Use: \"kube-apiserver\",\n      ...\n      RunE: func(cmd *cobra.Command, args []string) error {\n         ...\n         // set default options\n         completedOptions, err := Complete(s)\n         if err != nil {\n            return err\n         }\n\n         // validate options\n         if errs := completedOptions.Validate(); len(errs) != 0 {\n            return utilerrors.NewAggregate(errs)\n         }\n\n         return Run(completedOptions, genericapiserver.SetupSignalHandler())\n      },\n   }\n   ...\n\n   return cmd\n}\n</code></pre> \n <p>在 Run 函数中，按序分别初始化 APIServer 链(APIExtensionsServer、KubeAPIServer、AggregatorServer)，分别服务于 CRD(用户自定义资源)、K8s API(内置资源)、API Service(API 扩展资源) 对应的资源请求。相关代码如下：</p> \n <pre><code class=\"language-go\">// kubernetes/cmd/kube-apiserver/app/server.go\n// 创建 APIServer 链(APIExtensionsServer、KubeAPIServer、AggregatorServer)，分别服务 CRD、K8s API、API Service\nfunc CreateServerChain(completedOptions completedServerRunOptions, stopCh &lt;-chan struct{}) (*aggregatorapiserver.APIAggregator, error) {\n   // 创建 APIServer 通用配置\n   kubeAPIServerConfig, serviceResolver, pluginInitializer, err := CreateKubeAPIServerConfig(completedOptions)\n   if err != nil {\n      return nil, err\n   }\n   ...\n\n   // 第一：创建 APIExtensionsServer\n   apiExtensionsServer, err := createAPIExtensionsServer(apiExtensionsConfig, genericapiserver.NewEmptyDelegateWithCustomHandler(notFoundHandler))\n   if err != nil {\n      return nil, err\n   }\n\n   // 第二：创建 KubeAPIServer\n   kubeAPIServer, err := CreateKubeAPIServer(kubeAPIServerConfig, apiExtensionsServer.GenericAPIServer)\n   if err != nil {\n      return nil, err\n   }\n   ...\n\n   // 第三：创建 AggregatorServer\n   aggregatorServer, err := createAggregatorServer(aggregatorConfig, kubeAPIServer.GenericAPIServer, apiExtensionsServer.Informers)\n   if err != nil {\n      // we don't need special handling for innerStopCh because the aggregator server doesn't create any go routines\n      return nil, err\n   }\n\n   return aggregatorServer, nil\n}\n</code></pre> \n <p>之后，经过非阻塞(NonBlockingRun) 方式启动 SecureServingInfo.Serve，并配置 HTTP2(默认开启) 相关传输选项，最后启动 Serve 监听客户端请求。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220429143738084-357147758.png\" alt=\"\" loading=\"lazy\"></p> \n <blockquote> \n  <p>K8s APIServer 为了安全考虑，只支持客户端 HTTPS 请求，不支持 HTTP。</p> \n </blockquote> \n <h2 id=\"etcd-资源封装\">ETCD 资源封装</h2> \n <p>ETCD 实现 Watch 机制，经历了从 ETCD2 到 ETCD3 实现方式的转变。ETCD2 通过长轮询 Long-Polling 的方式监听资源事件的变更；ETCD3 则通过基于 HTTP2 的 gRPC 实现 Watch stream，性能得到了很大的提升。</p> \n <blockquote> \n  <p>Polling(轮询)：由于 http1.x 没有服务端 push 的机制，为了 Watch 服务端的数据变化，最简单的办法当然是客户端去 pull：客户端每隔定长时间去服务端拉数据同步，无论服务端有没有数据变化。但是必然存在通知不及时和大量无效的轮询的问题。</p> \n  <p>Long-Polling(长轮询)：就是在这个 Polling 的基础上的优化，当客户端发起 Long-Polling 时，如果服务端没有相关数据，会 hold 住请求，直到服务端有数据要发或者超时才会返回。</p> \n </blockquote> \n <p>在上一步配置 APIServerConfig 时，封装了底层存储用的 ETCD。以 kubeAPIServerConfig 为例，说明 K8s 内置资源是如何封装 ETCD 底层存储的。</p> \n <p>首先，通过 buildGenericConfig 实例化 RESTOptionsGetter，用于封装 RESTStorage。之后通过 InstallLegacyAPI -&gt; NewLegacyRESTStorage 实例化 K8s 内置资源的 RESTStorage，包括 podStorage、nsStorage、pvStorage、serviceStorage 等，用于 APIServer 在处理客户端资源请求时，调用的后端资源存储。</p> \n <p>InstallLegacyAPI 源码如下：</p> \n <pre><code class=\"language-go\">// kubernetes/pkg/controlplane/instance.go\n// 注册 K8s 的内置资源，并封装到对应的 RESTStorage(如 podStorage/pvStorage)\nfunc (m *Instance) InstallLegacyAPI(c *completedConfig, restOptionsGetter generic.RESTOptionsGetter) error {\n   ...\n   legacyRESTStorage, apiGroupInfo, err := legacyRESTStorageProvider.NewLegacyRESTStorage(c.ExtraConfig.APIResourceConfigSource, restOptionsGetter)\n   if err != nil {\n      return fmt.Errorf(\"error building core storage: %v\", err)\n   }\n   if len(apiGroupInfo.VersionedResourcesStorageMap) == 0 { // if all core storage is disabled, return.\n      return nil\n   }\n\n   controllerName := \"bootstrap-controller\"\n   coreClient := corev1client.NewForConfigOrDie(c.GenericConfig.LoopbackClientConfig)\n   bootstrapController, err := c.NewBootstrapController(legacyRESTStorage, coreClient, coreClient, coreClient, coreClient.RESTClient())\n   if err != nil {\n      return fmt.Errorf(\"error creating bootstrap controller: %v\", err)\n   }\n   m.GenericAPIServer.AddPostStartHookOrDie(controllerName, bootstrapController.PostStartHook)\n   m.GenericAPIServer.AddPreShutdownHookOrDie(controllerName, bootstrapController.PreShutdownHook)\n\n   ...\n   return nil\n}\n</code></pre> \n <p>在实例化 ETCD 底层存储中，通过开关 EnableWatchCache 来控制是否启用 Watch 缓存。如果启用了，则会先走 StorageWithCacher 逻辑，然后才走 UndecoratedStorage 真正调用底层 ETCD3 存储。</p> \n <blockquote> \n  <p>K8s 当前只支持 ETCD3，不再支持 ETCD2。K8s 充分信任 ETCD3 的 Watch 机制，保证资源状态与 ETCD 底层存储的一致性。</p> \n </blockquote> \n <p>整个调用过程如下：</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220429143739067-1002313320.png\" alt=\"\" loading=\"lazy\"></p> \n <blockquote> \n  <p>K8s 各类资源(CRD/Core/Aggregator) 都统一以 RESTful 风格暴露 HTTP 请求接口，并支持多种类型的编解码格式，如 json/yaml/protobuf。</p> \n </blockquote> \n <h2 id=\"客户端-watch-实现\">客户端 Watch 实现</h2> \n <p>经过上面的步骤，APIServer 服务端已准备好 K8s 各类资源的 RESTStorage(底层封装了 ETCD3)，此时客户端可通过 RESTful HTTP 接口向 APIServer 发出资源请求，包括 GET/POST/PATCH/WATCH/DELETE 等操作。</p> \n <blockquote> \n  <p>客户端 Watch 包括：<br> (1). kubectl get xxx -w，获取某类资源、并持续监听资源变化；<br> (2). client-go 中 Reflector ListAndWatch APIServer 各类资源；</p> \n </blockquote> \n <p>我们以 kubectl get pod -w 为例，说明客户端是如何实现资源的 Watch 操作。</p> \n <p>首先，kubectl 也是通过 Cobra 命令行解析参数(--watch，或 --watch-only)，然后调用 Run 调用 cli-runtime 包下面的 Watch 接口，之后通过 RESTClient.Watch 向 APIServer 发起 Watch 请求，获得一个流式 watch.Interface，然后不断从其中 ResultChan 获取 watch.Event。之后，根据客户端发送的编解码类型(json/yaml/protobuf)，从 stream 中按帧(Frame) 读取并解码(Decode) 数据，输出显示到命令行终端。</p> \n <p>客户端通过 RESTClient 发起 Watch 请求，代码如下：</p> \n <pre><code class=\"language-go\">// kubernetes/staging/src/k8s.io/cli-runtime/pkg/resource/helper.go\nfunc (m *Helper) Watch(namespace, apiVersion string, options *metav1.ListOptions) (watch.Interface, error) {\n   options.Watch = true\n   return m.RESTClient.Get().\n      NamespaceIfScoped(namespace, m.NamespaceScoped).\n      Resource(m.Resource).\n      VersionedParams(options, metav1.ParameterCodec).\n      Watch(context.TODO())\n}\n</code></pre> \n <p>客户端 Watch 实现过程小结如下：</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220429143739527-666127918.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"服务端-watch-实现\">服务端 Watch 实现</h2> \n <p>服务端 APIServer 启动后，一直在持续监听着各类资源的变更事件。在接收到某类资源的 Watch 请求后，调用 RESTStorage 的 Watch 接口，通过开关 EnableWatchCache 来控制是否启用 Watch 缓存，最终通过 etcd3.Watch 封装实现了 ETCD 底层的 Event 变更事件。</p> \n <blockquote> \n  <p>RESTStorage 就是在 APIServer 启动时候，提前注册、封装的 ETCD 资源存储。</p> \n </blockquote> \n <p>etcd3.watcher 通过两个 channel(incomingEventChan、resultChan，默认容量都为 100) 实现 ETCD 底层事件到 watch.Event 的转换，然后通过 serveWatch 流式监听返回的 watch.Interface，不断从 resultChan 中取出变更事件。之后，根据客户端发送的编解码类型(json/yaml/protobuf)，编码(Encode) 数据，按帧(Frame) 组装后发送到 stream 中给客户端。</p> \n <p>服务端通过 serveWatch 流式监听返回的 watch.Interface，代码如下：</p> \n <pre><code class=\"language-go\">// kubernetes/staging/src/k8s.io/apiserver/pkg/endpoints/handlers/get.go\nfunc ListResource(r rest.Lister, rw rest.Watcher, scope *RequestScope, forceWatch bool, minRequestTimeout time.Duration) http.HandlerFunc {\n   return func(w http.ResponseWriter, req *http.Request) {\n      ...\n\n      if opts.Watch || forceWatch {\n         ...\n         watcher, err := rw.Watch(ctx, &amp;amp;opts)\n         if err != nil {\n            scope.err(err, w, req)\n            return\n         }\n         requestInfo, _ := request.RequestInfoFrom(ctx)\n         metrics.RecordLongRunning(req, requestInfo, metrics.APIServerComponent, func() {\n            serveWatch(watcher, scope, outputMediaType, req, w, timeout)\n         })\n         return\n      }\n      ...\n   }\n}\n</code></pre> \n <blockquote> \n  <p>K8s 在 v1.11 之后将 WATCH/WATCHLIST 类型的 action.Verb 废弃了，统一都交由 LIST -&gt; restfulListResource 处理。</p> \n </blockquote> \n <p>服务端 Watch 实现过程小结如下：</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220429143740398-1131384563.png\" alt=\"\" loading=\"lazy\"></p> \n <blockquote> \n  <p>APIServer 除了支持 HTTP2，也支持 WebSocket 通信。当客户端请求包含了 Upgrade: websocket，Connection: Upgrade 时，则服务端会通过 WebSocket 与客户端进行数据传输。</p> \n </blockquote> \n <p>值得注意的是，底层 ETCD 事件通过 transform 函数转换为 watch.Event，包括以下几种类型(Type)：</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220429143740760-855893240.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"小结\">小结</h2> \n <p>本文通过分析 K8s 中 APIServer 启动、ETCD watch 封装、服务端 Watch 实现、客户端 Watch 实现等核心流程，对 K8s Watch 实现机制进行了解析。通过源码、图文方式说明了相关流程逻辑，以期更好的理解 K8s Watch 实现细节。</p> \n <p>K8s 底层完全信任 ETCD(ListAndWatch)，将各类资源统一抽象为了 RESTful 的存储(Storage)，通过 Watch 机制获取各类资源的变更事件，然后通过 Informer 机制分发给下游监听的 ResourceEventHandler，最终由 Controller 实现资源的业务逻辑处理。随着 ETCD3 在 HTTP/2 基础上不断优化完善，K8s 将提供更高效、更稳定的编排能力。</p> \n <h3 id=\"参考资料\">参考资料</h3> \n <ol> \n  <li><a href=\"https://en.wikipedia.org/wiki/HTTP/2\" title=\"HTTP/2 Wikipedia\" target=\"_blank\" rel=\"noopener\">HTTP/2 Wikipedia</a></li> \n  <li><a href=\"https://en.wikipedia.org/wiki/Chunked_transfer_encoding\" title=\"Chunked Transfer Encoding\" target=\"_blank\" rel=\"noopener\">Chunked Transfer Encoding</a></li> \n  <li><a href=\"https://github.com/kubernetes/kubernetes\" title=\"Kubernetes 源码\" target=\"_blank\" rel=\"noopener\">Kubernetes 源码</a></li> \n  <li><a href=\"https://etcd.io/docs/v3.2/learning/api/#watch-api\" title=\"ETCD watch-api\" target=\"_blank\" rel=\"noopener\">ETCD watch-api</a></li> \n  <li><a href=\"https://kubernetes.io/docs/reference/using-api/api-concepts/\" title=\"K8s API Concepts\" target=\"_blank\" rel=\"noopener\">K8s API Concepts</a></li> \n  <li><a href=\"https://ninokop.github.io/2018/07/25/watch-push-or-pull/\" title=\"Server Push 与 Client Poll\" target=\"_blank\" rel=\"noopener\">Server Push 与 Client Poll</a></li> \n </ol> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220429143741652-2121467113.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"297","createTime":"2022-04-20 12:11","comment":"0","id":"16169305","title":"Effective HPA：预测未来的弹性伸缩产品","url":"https://www.cnblogs.com/tencent-cloud-native/p/16169305.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>胡启明，腾讯云专家工程师，专注 Kubernetes、降本增效等云原生领域，Crane 核心开发工程师，现负责成本优化开源项目 Crane 开源治理和弹性能力落地工作。</p> \n <p>余宇飞，腾讯云专家工程师，专注云原生可观测性、成本优化等领域，Crane 核心开发者，现负责 Crane 资源预测、推荐落地、运营平台建设等相关工作。</p> \n <p>田奇，腾讯高级工程师，专注分布式资源管理和调度，弹性，混部，Kubernetes Contributor，现负责 Crane 相关研发工作。</p> \n <h2 id=\"引言\">引言</h2> \n <p>业务的稳定性和成本之间的矛盾由来已久。在云原生时代，按需付费的成本模型催生出了自动弹性伸缩技术——通过动态申请、归还云上资源，在满足业务需求的前提下，降低成本。</p> \n <h2 id=\"什么是-hpa\">什么是 HPA</h2> \n <p>谈到云原生中的弹性，大家自然想到 Kubernetes 的各种自动伸缩（Auto Scaling）技术，其中最具代表性的当属水平 Pod 自动伸缩（HPA）。</p> \n <p>HPA 作为 Kubernetes 的内建功能，具有一系列优点：</p> \n <ol> \n  <li><strong>兼顾业务高峰稳定、低谷降本的诉求</strong>。</li> \n  <li><strong>功能稳定，社区中立</strong>：随着 kubernetes 版本的迭代，其本身的功能也在不断地丰富和完善，但 HPA 的核心机制一直保持稳定，这也说明它可以满足最通用的弹性伸缩场景。</li> \n  <li><strong>顺应 Serverless 趋势</strong>：随着各个大厂发布 Serverless 容器产品，以及虚拟节点池技术的提出，HPA 很大程度上覆盖了集群自动伸缩（CA） 的功能，使得自动伸缩更轻量、更敏捷。</li> \n  <li><strong>完善的扩展机制</strong>：提供诸如 custom_metrics、external_metric 等扩展指标，用户可以根据实际情况配置最适合业务的 HPA。</li> \n </ol> \n <h2 id=\"传统-hpa-的问题\">传统 HPA 的问题</h2> \n <p>HPA 也并不完美：</p> \n <ol> \n  <li> <p><strong>如何配置</strong>：HPA 运行的效果取决于用户资源的配置（target、minReplicas、maxReplicas 等等）。配置过于激进可能导致应用可用性、稳定性受影响，配置过于保守弹性的效果就大打折扣。如何合理的配置是用好 HPA 的关键。</p> </li> \n  <li> <p><strong>弹性不够及时</strong>：原生 HPA 是对监控数据的被动响应，此外应用本身启动、预热也需要一定时间，这使得HPA天生具有滞后性，进而可能影响业务稳定。这也是很多用户不信任、不敢用HPA的一个重要原因。</p> </li> \n  <li> <p><strong>可观测性低</strong>：HPA 没法通过类似 Dryrun 方式测试，一旦使用便会实际修改应用的实例数量，存在风险；而且弹性过程也难以观测。</p> </li> \n </ol> \n <h2 id=\"时间序列预测\">时间序列预测</h2> \n <p>HPA 通常被应用于负载具有潮汐性的业务， 如果从流量或者资源消耗等指标的时间维度来看，会发现很明显的波峰、波谷形态。进一步观察，这类具有波动性的业务往往天然地在时间序列上也有着明显周期性，尤其是那些直接或间接服务于“人”的业务。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220420121126970-1554854889.png\" alt=\"\" loading=\"lazy\"></p> \n <p>这种周期性是由人们的作息规律决定的，例如，人们习惯中午、晚上叫外卖；早晚会有出行高峰；即时是搜索这种业务时段不明显的服务，夜里的请求量也会大大低于白天。对于此类业务，一个很自然的想法，就是通过过去几天的数据预测出今天的数据。有了预测的数据（例如：未来24小时的业务 CPU 的使用情况），我们就可以对弹性伸缩做出某种“超前部署”，这也是 Effective HPA 能够克服原生 HPA 实时性不足的关键所在。</p> \n <h2 id=\"effective-hpa-是什么\">Effective HPA 是什么</h2> \n <p>Effective HPA（简称 EHPA）是开源项目 Crane 中的弹性伸缩产品，它基于社区 HPA 做底层的弹性控制，支持更丰富的弹性触发策略（预测，监控，周期），让弹性更加高效，并保障了服务的质量：</p> \n <ul> \n  <li><strong>提前扩容，保证服务质量</strong>：通过算法预测未来的流量洪峰提前扩容，避免扩容不及时导致的雪崩和服务稳定性故障。</li> \n  <li><strong>减少无效缩容</strong>：通过预测未来可减少不必要的缩容，稳定工作负载的资源使用率，消除突刺误判。</li> \n  <li><strong>支持 Cron 配置</strong>：支持 Cron-based 弹性配置，应对大促等异常流量洪峰。</li> \n  <li><strong>兼容社区</strong>：使用社区 HPA 作为弹性控制的执行层，能力完全兼容社区。</li> \n </ul> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220420121127521-1435919614.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"架构\">架构</h3> \n <p>EHPA 的主要架构如下：</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220420121127993-267437643.jpg\" alt=\"\" loading=\"lazy\"></p> \n <ul> \n  <li>EHPA Controller: 负责 EHPA 对象的控制逻辑，包括 EHPA 的增删改查和 HPA 的同步</li> \n  <li>Metric Adapter：负责预测指标以及其他相关指标的生成</li> \n  <li>Predictor：负责主要用于时序数据分析和预测</li> \n  <li>TimeSeriesPrediction：时序数据预测 CRD，主要供 EHPA 和 MetricAdapter 进行消费</li> \n  <li>HPA Controller: 社区原生 HPA 控制器，EHPA 对此完全兼容，允许用户有已经配置的 HPA</li> \n  <li>KubeApiServer：社区原生 Kubernetes ApiServer</li> \n  <li>Metric Server：社区原生 Metric Server</li> \n </ul> \n <h3 id=\"主要功能\">主要功能</h3> \n <h4 id=\"基于预测的弹性\">基于预测的弹性</h4> \n <p>EHPA 充分挖掘 Workload 的相关指标，对于资源消耗和流量有明显周期性的 Workload，预测其在未来一段时间窗口的时序指标，利用该预测窗口数据，HPA 获取到的指标会带有一定的前瞻性，当前 EHPA 会取未来窗口期内指标的最大值，作为当前 HPA 的观测指标。</p> \n <p>这样当未来流量上升超过 HPA 容忍度的时候，HPA 就可以在当下完成提前扩容，而当未来短时间内有流量降低，但是其实是短时抖动，此时由于 EHPA 取最大值，所以并不会立即缩容，从而避免无效缩容。</p> \n <p>用户可以通过配置以下指标：</p> \n <pre><code class=\"language-yaml\">apiVersion: autoscaling.crane.io/v1alpha1\nkind: EffectiveHorizontalPodAutoscaler\nspec:\n  # Metrics 定义了弹性阈值，希望 workload 的资源使用保持在一个水平线上\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 50\n  # Prediction 定义了预测配置\n  # 如果不设置，则不开启弹性预测\n  prediction:\n    predictionWindowSeconds: 3600   # PredictionWindowSeconds 定义了预测未来多久的时间窗口。\n    predictionAlgorithm:\n      algorithmType: dsp\n      dsp:\n        sampleInterval: \"60s\"\n        historyLength: \"3d\"\n</code></pre> \n <ul> \n  <li>MetricSpec: 配置和 HPA 是一致的，保持用户一致的体验</li> \n  <li>Prediction: 主要用来设置预测先关参数，包括预测窗口和算法类型，未来对于窗口时序指标的处理策略，用户可以自行定制。 \n   <ul> \n    <li>PredictionWindowSeconds: 预测未来时间窗口长度</li> \n    <li>Dsp: 该算法是基于FFT（快速傅里叶变换）的时序分析算法，针对周期性强的时序有不错的预测效果，而且无需进行模型训练，简单高效</li> \n   </ul> </li> \n </ul> \n <h4 id=\"基于-cron-的弹性\">基于 Cron 的弹性</h4> \n <p>除了基于监控指标，有时候节假日弹性和工作日会有差异，简单的预测算法可能无法比较好的工作。那么此时可以通过设置周末的 Cron 将其副本数设置更大一些，从而弥补预测的不足。</p> \n <p>针对某些非 Web 流量型应用，比如有些应用会在周末的时候无需工作，此时希望工作副本缩容为1，也可以配置 Cron 进行缩容，降低用户成本。</p> \n <p>定时 Cron 弹性 Spec 设置如下：</p> \n <pre><code class=\"language-yaml\">apiVersion: autoscaling.crane.io/v1alpha1\nkind: EffectiveHorizontalPodAutoscaler\nspec:\n  crons:\n  - name: \"cron1\"\n    description: \"scale up\"\n    start: \"0 6 ? * *\"\n    end: \"0 9 ? * *\"\n    targetReplicas: 100\n  - name: \"cron2\"\n    description: \"scale down\"\n    start: \"00 9 ? * *\"\n    end: \"00 11 ? * *\"\n    targetReplicas: 1\n</code></pre> \n <ul> \n  <li>CronSpec: 可以设置多个 Cron 弹性配置，Cron 周期可以设置周期的开始时间和结束时间，在该时间范围内可以持续保证 Workload 的副本数为设定的目标值。 \n   <ul> \n    <li>Name：Cron 标识符</li> \n    <li>TargetReplicas：本 Cron 时间范围内 Workload 的目标副本数</li> \n    <li>Start：表示 Cron 的开始时间，时间格式是标准的 linux crontab 格式</li> \n    <li>End: 表示 Cron 的结束时间，时间格式是标准的 linux crontab 格式</li> \n   </ul> </li> \n </ul> \n <p>目前一些厂商和社区的弹性 Cron 能力存在一些不足之处：</p> \n <ol> \n  <li>Cron 能力是单独提供的，弹性没有全局观，和 HPA 的兼容性差，会产生冲突</li> \n  <li>Cron 的语义和行为不是很匹配，甚至使用起来非常难以理解，容易造成用户故障</li> \n </ol> \n <p>下图是当前 EHPA 的 Cron 弹性实现和其他 Cron 能力对比：</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220420121128269-1343818051.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>针对上述问题，EHPA 实现的 Cron 弹性，是在兼容 HPA 基础上来设计的，Cron 作为 HPA 的指标，是和其他指标一样共同作用于 Workload 对象的。另外，Cron 的设置也很简单，单独配置 Cron 的时候，不在激活时间范围是不会对 Workload 进行默认伸缩的。</p> \n <h4 id=\"弹性结果预览\">弹性结果预览</h4> \n <p>EHPA 支持预览(Dry-run)水平弹性的结果。在预览模式下 EHPA 不会实际修改目标工作负载的副本数，所以你可以通过预览EHPA弹性的效果来决定是否需要真的开始自动弹性。另外一种场景是当你希望临时关闭自动弹性时，也可以通过调整到预览模式来实现。</p> \n <ul> \n  <li>ScaleStrategy: Preview 为预览模式，Auto 为自动弹性模式</li> \n  <li>SpecificReplicas: 在预览模式时，可以通过设置 SpecificReplicas 指定工作负载的副本数</li> \n </ul> \n <pre><code class=\"language-yaml\">apiVersion: autoscaling.crane.io/v1alpha1\nkind: EffectiveHorizontalPodAutoscaler\nspec:\n  scaleStrategy: Preview   # ScaleStrategy 弹性策略，支持 \"Auto\" 和 \"Preview\"。\n  specificReplicas: 5      # SpecificReplicas 在 \"Preview\" 模式下，支持指定 workload 的副本数。\nstatus:\n  expectReplicas: 4        # expectReplicas 展示了 EHPA 计算后得到的最终推荐副本数，如果指定了 spec.specificReplicas，则等于 spec.specificReplicas.\n  currentReplicas: 4       # currentReplicas 展示了 workload 实际的副本数。\n</code></pre> \n <p><strong>实现原理</strong>：当 EHPA 处于预览模式时，Ehpa-controller 会将底层的 HPA 对象指向一个 Substitute(替身) 对象，底层计算和执行弹性的 HPA 只会作用于替身，而实际的工作负载则不会被改变。</p> \n <h4 id=\"落地效果\">落地效果</h4> \n <p>目前 EHPA 已经在腾讯内部开始使用，支撑线上业务的弹性需求。这里展示一个线上应用使用 EHPA 后的落地效果。</p> \n <p><strong><img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220420121128570-1301265816.png\" alt=\"image\" loading=\"lazy\"></strong></p> \n <p>上图显示了该应用一天内的 CPU 使用。红色曲线是实际使用量，绿色曲线是算法预测出的使用量，可以看到算法可以很好的预测出使用量的趋势，并且根据参数实现一定的偏好（比如偏高）。</p> \n <p><strong><img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220420121128846-1457994424.png\" alt=\"image\" loading=\"lazy\"></strong></p> \n <p>上图显示了该应用使用弹性后在一天内副本数的变化趋势。红色曲线是通过原生的 HPA 自动调整的副本数，而绿色曲线是通过 EHPA 自动调整的副本数，可以看到 EHPA 的弹性策略更加合理：提前弹和减少无效弹性。</p> \n <h2 id=\"衍生阅读什么是-crane\">衍生阅读：什么是 Crane</h2> \n <p>为推进云原生用户在确保业务稳定性的基础上做到真正的极致降本，腾讯推出了业界第一个基于云原生技术的成本优化开源项目 Crane（ Cloud Resource Analytics and Economics ）。Crane 遵循 FinOps 标准，旨在为云原生用户提供云成本优化一站式解决方案。</p> \n <p>Crane 的智能水平弹性能力是基于 Effective HPA 实现。用户在安装 Crane 后即可直接使用 Effective HPA 开启智能弹性之旅。</p> \n <p>当前 Crane 项目主要贡献者包括有腾讯、小红书、谷歌、eBay、微软、特斯拉等知名公司的行业专家。</p> \n <h2 id=\"参考链接\">参考链接</h2> \n <ol> \n  <li>Crane 开源项目地址：【<a href=\"https://github.com/gocrane/crane/%E3%80%91\" target=\"_blank\" rel=\"noopener\">https://github.com/gocrane/crane/】</a></li> \n  <li>Crane 官网: 【<a href=\"https://docs.gocrane.io/%E3%80%91\" target=\"_blank\" rel=\"noopener\">https://docs.gocrane.io/】</a></li> \n  <li>Effective HPA 使用文档：【<a href=\"https://docs.gocrane.io/dev/zh/tutorials/using-effective-hpa-to-scaling-with-effectiveness/%E3%80%91\" target=\"_blank\" rel=\"noopener\">https://docs.gocrane.io/dev/zh/tutorials/using-effective-hpa-to-scaling-with-effectiveness/】</a></li> \n </ol> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <h4 id=\"福利\">福利：</h4> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <p>④公众号后台回复【光速入门】，可获得腾讯云专家5万字精华教程，光速入门Prometheus和Grafana。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220420121129130-1580192760.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"71","createTime":"2022-04-20 10:06","comment":"0","id":"16168666","title":"使用 Elastic GPU 管理 Kubernetes GPU 资源","url":"https://www.cnblogs.com/tencent-cloud-native/p/16168666.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <h4 id=\"福利\">福利：</h4> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <p>④公众号后台回复【光速入门】，可获得腾讯云专家5万字精华教程，光速入门Prometheus和Grafana。</p> \n <h2 id=\"作者\">作者</h2> \n <p>徐蓓，腾讯云容器技术专家，腾讯云异构计算容器负责人，多年云计算一线架构设计与研发经验，长期深耕 Kubernetes、在离线混部与 GPU 容器化领域，Kubernetes KEP Memory QoS 作者，Kubernetes 积极贡献者。</p> \n <h2 id=\"当前存在问题\">当前存在问题</h2> \n <p>GPU 具备大量核心和高速内存，擅长并行计算，非常适合训练和运行机器学习模型。由于近几年 AI 技术愈发成熟，落地场景越来越多，对 GPU 的需求呈井喷趋势。而在资源管理调度平台上，Kubernetes 已成为事实标准。所以很多客户选择在 Kubernetes 中使用 GPU 运行 AI 计算任务。</p> \n <p>Kubernetes 提供 device plugin 机制，可以让节点发现和上报设备资源，供 Pod 使用。GPU 资源也是通过该方式提供。以 nvidia GPU 为例，用户在 Kubernetes 节点部署 nvidia-device-plugin，插件扫描节点 GPU 卡，会以 extended resource 机制将 GPU 资源以类似<code>nvidia.com/gpu: 8</code>的形式注册到节点中。用户创建 Pod 时指定该资源名，经过调度器调度后，Pod 绑定到节点，最终通过 nvidia docker 提供的一系列工具，将所需 GPU 设备挂载到容器里。</p> \n <p>Kubernetes device plugin 提供了一种便捷的方式用于集成第三方设备。但应用在 GPU 场景，还是存在以下不足：</p> \n <ul> \n  <li> <p><strong>集群 GPU 资源缺少全局视角</strong>。没有直观方式可获取集群层面 GPU 信息，比如 Pod / 容器与 GPU 卡绑定关系、已使用 GPU 卡数 等</p> </li> \n  <li> <p><strong>不能很好支持多 GPU 后端</strong>。各种 GPU 技术（nvidia docker、qGPU、vCUDA、gpu share、GPU 池化）均需独立部署组件，无法统一调度和管理</p> </li> \n </ul> \n <h3 id=\"问题一缺少-gpu-资源全局视角\">问题一：缺少 GPU 资源全局视角</h3> \n <p>现有 Kubernetes 对 GPU 资源的分配调度是通过 extended resource 实现的，它是基于节点上卡数量的加减调度。用户如果想知道集群中 GPU 卡的分配情况，需要遍历节点，拿到并计算这些信息。并且由于这个资源是标量的，所以并无法拿到 Pod / 容器 与卡的绑定关系。这些问题在整卡模式下不是那么凸显，但在细粒度共享模式下，就尤为严重了。</p> \n <p>由于 GPU 卡相对昂贵，并且某些 AI 负载吃不满单张 GPU 算力，GPU Sharing 技术应运而生。在 Kubernetes 中，我们会将一些 AI 负载共享同一张 GPU 卡，通过增加业务部署密度，提升 GPU 利用率，从而节省成本。以 TKE qGPU 为例，在 GPU Sharing 方式下，扩展资源从 GPU 卡数量变为百分比的 qGPU Core 与 MB 的 qGPU Memory。也就是说，用户可通过 qGPU 容器虚拟化技术，申请小于一张卡的 qGPU 虚拟设备。这些设备是在单张物理卡上虚拟出来的，资源之间也是强隔离的。除了 qGPU，vCUDA、gpu share 等技术都支持多个 Pod / 容器 共享同一张 GPU 卡。基于现有 Kubernetes 架构，是无法知道 GPU 卡所包含切片资源（我将之定义为 GPU Core 与 Memory 的组合）的分布情况的。集群资源分布对管理员与用户都是黑盒。管理员无法知道整个集群 GPU 切片资源的分配情况，用户也不知道新部署业务有无资源可用。</p> \n <h3 id=\"问题二无法支持多-gpu-后端\">问题二：无法支持多 GPU 后端</h3> \n <p>除分配挂载整卡的方式外，TKE qGPU、vCUDA、gpu share、GPU 池化 等 GPU 共享技术越来越被用户采用。每种方案都有自己独立的一套 Kubernetes 集成实现方式。比如在 TKE qGPU 中，我们自研了 tke-qgpu-scheduler 用于 GPU 细粒度算力与显存分配调度，配套的 tke-qgpu-manager，用于节点初始化、注册上报 qGPU 资源及 qGPU 容器虚拟化。vCUDA、gpu share 也是类似架构，同样是由调度器 + device plugin 组成。这些方案相互独立，没有统一标准，无法共通。这导致用户在单个集群中很难同时使用多种 GPU 后端技术。比如用户集群有些业务是在线推理，吃不满整卡，想申请 TKE qGPU 切片资源。另一部分业务是训练，需要分配单卡。有些仿真和模型调试业务，为了成本和弹性，想要动态从远端 GPU 池申请资源。现有方案很难同时满足以上诉求，这为基于 Kubernetes 构建统一 AI 基础设施平台增加了很多难度。</p> \n <p>以上问题均是 TKE 在基于 Kubernetes 帮助客户构建 AI 计算平台时遇到的真实困扰。随着 AI 业务的不断精进，客户已不再仅满足于“能使用 Kubernetes GPU 资源”。对 GPU 成本的关注，对 GPU 资源的整体把控，对 GPU 不同后端的精准使用，都成为了客户能用好 GPU 算力的前提条件。既然现有体系无法满足，那我们就需要另辟蹊径，重新思考 GPU 在 Kubernetes 中的位置。</p> \n <h2 id=\"一种全新的-kubernetes-gpu-方案\">一种全新的 Kubernetes GPU 方案</h2> \n <h3 id=\"pv--pvc-带来的启示\">PV / PVC 带来的启示</h3> \n <p>在 Kubernetes 中，资源一般是围绕 Pod 设计和定义。从重要程度上讲，集群可用资源包含两种类型：核心资源和外部资源。核心资源指维持 Pod 正常运行的必不可少的资源，包括 CPU、内存、临时存储、网卡 等。这些会通过 kubelet 扫描节点并上报到集群中。另一部分是外部资源，多指外挂存储和其他设备等，比如数据盘、GPU、FPGA 等。这些设备可能是本地设备挂载、也可能是远端设备挂载。这类资源的存在可以使得 Pod 更好的运行。比如数据盘增加了 Pod 的存储容量、GPU / FPGA 加速了 Pod 的计算能力。从这个角度看，存储与 GPU 有相似之处。</p> \n <p>Kubernetes 在存储上抽象出了一组资源，如 PV / PVC / StorageClass，并为之提供了一组 API 和交互方式，将存储的供给管理和使用标准化和分离了出来。</p> \n <ul> \n  <li><strong>PV</strong>：PV 是集群中的一块实际存储资源，可以由管理员手动创建，或者通过 StorageClass 方式动态创建。PV 类似节点上的 CPU、内存、网卡 等资源。PV 可以有多种后端供给，如前文描述的公有云存储服务、自建共享存储或本地存储。</li> \n  <li><strong>PVC</strong>：PVC 是用户对 PV 存储资源的申领。它类似于集群中的 Pod。Pod 申请节点上的 CPU、内存、网络 等资源，PVC 申请存储资源，也就是 PV。</li> \n  <li><strong>StorageClass</strong>：StorageClass 为管理员提供了描述存储“类”的方法。比如 PV 后端创建的方法、挂载的方法 等。</li> \n </ul> \n <p>用户通过 PV 在指定后端创建实际存储，用户通过 PVC 申请已创建的 PV 存储资源，或者指定 StorageClass 动态从后端创建 PV。</p> \n <p>参照 Kubernetes 存储的设计方式，我们认为 GPU 也可定义和实现类似抽象。</p> \n <h3 id=\"elastic-gpu-crd\">Elastic GPU CRD</h3> \n <p>我们定义了三种全新的 Kubernetes CRD，用于代表 GPU 资源的不同抽象：</p> \n <ul> \n  <li><strong>ElasticGPU</strong>：ElasticGPU 是集群中一个实际可使用的 GPU 资源，可以是一块本地 GPU 物理卡、一个 GPU 切片资源（ GPU 算力 / 显存 的组合）、一个远端 GPU 设备。</li> \n  <li><strong>ElasticGPUClaim</strong>：ElasticGPUClaim 是用户对 ElasticGPU 资源的申领，可以申请整卡数量，申请 GPU 核数 / 显存，或者申请 TFLOPS 算力。</li> \n  <li><strong>EGPUClass</strong>：EGPUClass 提供了生产和挂载 ElasticGPU 的方式，可以使用 qGPU 虚拟化、vCUDA、或是 GPU 远端池化的技术。</li> \n </ul> \n <pre><code class=\"language-go\">type ElasticGPU struct {\n\tmetav1.TypeMeta   `json:\",inline\"`\n\tmetav1.ObjectMeta `json:\"metadata,omitempty\" protobuf:\"bytes,1,opt,name=metadata\"`\n\tSpec              ElasticGPUSpec   `json:\"spec,omitempty\" protobuf:\"bytes,2,opt,name=spec\"`\n\tStatus            ElasticGPUStatus `json:\"status,omitempty\" protobuf:\"bytes,3,opt,name=status\"`\n}\n\ntype ElasticGPUSpec struct {\n\tCapacity         v1.ResourceList `json:\"capacity,omitempty\" protobuf:\"bytes,1,rep,name=capacity,casttype=ResourceList,castkey=ResourceName\"`\n\tElasticGPUSource `json:\",inline\" protobuf:\"bytes,2,opt,name=elasticGPUSource\"`\n\tClaimRef         v1.ObjectReference `json:\"claimRef,omitempty\" protobuf:\"bytes,3,opt,name=claimRef\"`\n\tNodeAffinity     GPUNodeAffinity    `json:\"nodeAffinity,omitempty\" protobuf:\"bytes,4,opt,name=nodeAffinity\"`\n\tNodeName         string             `json:\"nodeName,omitempty\" protobuf:\"bytes,5,opt,name=nodeName\"`\n}\n\ntype ElasticGPUSource struct {\n\tQGPU        *QGPUElasticGPUSource        `json:\"qGPU,omitempty\" protobuf:\"bytes,1,opt,name=qGPU\"`\n\tPhysicalGPU *PhysicalGPUElasticGPUSource `json:\"physicalGPU,omitempty\" protobuf:\"bytes,2,opt,name=physicalGPU\"`\n\tGPUShare    *GPUShareElasticGPUSource    `json:\"gpuShare,omitempty\" protobuf:\"bytes,3,opt,name=gpuShare\"`\n}\n\ntype ElasticGPUClaim struct {\n\tmetav1.TypeMeta   `json:\",inline\"`\n\tmetav1.ObjectMeta `json:\"metadata,omitempty\" protobuf:\"bytes,1,opt,name=metadata\"`\n\tSpec              ElasticGPUClaimSpec   `json:\"spec,omitempty\" protobuf:\"bytes,2,opt,name=spec\"`\n\tStatus            ElasticGPUClaimStatus `json:\"status,omitempty\" protobuf:\"bytes,3,opt,name=status\"`\n}\n\ntype ElasticGPUClass struct {\n\tmetav1.TypeMeta   `json:\",inline\"`\n\tmetav1.ObjectMeta `json:\"metadata,omitempty\" protobuf:\"bytes,1,opt,name=metadata\"`\n\tProvisioner       string            `json:\"provisioner\" protobuf:\"bytes,2,opt,name=provisioner\"`\n\tParameters        map[string]string `json:\"parameters,omitempty\" protobuf:\"bytes,3,rep,name=parameters\"`\n}\n</code></pre> \n <p>下面以 TKE qGPU 为例，描述结合 Elastic GPU 方案的整个资源调度分配流程。</p> \n <h4 id=\"qgpu-资源申请\">qGPU 资源申请</h4> \n <p>用户在集群中创建 ElasticGPUClass，指定 qGPU 作为 GPU 后端。</p> \n <pre><code class=\"language-yaml\">apiVersion: elasticgpu.io/v1alpha\nkind: ElasticGPUClass\nmetadata:\n  name: qgpu-class\nprovisioner: elasticgpu.io/qgpu\nreclaimPolicy: Retain\neGPUBindingMode: Immediate\n</code></pre> \n <p>创建 ElasticGPUClaim 描述对 qGPU 资源的申领，<code>tke.cloud.tencent.com/qgpu-core</code>代表申请 10% 的 GPU 算力，<code>tke.cloud.tencent.com/qgpu-memory</code>代表申请 4GB 显存。</p> \n <pre><code class=\"language-yaml\">apiVersion: elasticgpu.io/v1alpha\nkind: ElasticGPUClaim\nmetadata:\n  name: qgpu-egpuc\nspec:\n  storageClassName: qgpu-class\n  resources:\n    requests:\n      tke.cloud.tencent.com/qgpu-core: 10\n      tke.cloud.tencent.com/qgpu-memory: 4GB\n</code></pre> \n <p>用户在创建 Pod 时指定 ElasticGPUClaim 完成 qGPU 资源申领。</p> \n <pre><code class=\"language-yaml\">apiVersion: v1\nkind: Pod\nmetadata:\n  name: qgpu-pod\n  annotations:\n    elasticgpu.io/egpuc-&lt;container-name&gt;: qgpu-egpuc\nspec:\n  containers:\n  - name: test\n</code></pre> \n <h4 id=\"qgpu-资源调度\">qGPU 资源调度</h4> \n <p>考虑到 out-tree 的设计，qGPU 资源发现、上报和调度，还是依赖原有 device plugin 与 extended resource 机制。</p> \n <p>我们通过 elastic-gpu-admission-hook 在 Pod 创建时识别 annotations <code>elasticgpu.io/egpuc-&lt;container-name&gt;</code>，将申请资源正确设置到 containers 中。</p> \n <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: qgpu-pod\n  annotations:\n    elasticgpu.io/egpuc-test: qgpu-egpuc\nspec:\n  containers:\n  - name: test\n    resources:\n      requests:\n        tke.cloud.tencent.com/qgpu-core: 10\n        tke.cloud.tencent.com/qgpu-memory: 4GB\n      limits:\n        tke.cloud.tencent.com/qgpu-core: 10\n        tke.cloud.tencent.com/qgpu-memory: 4GB\n</code></pre> \n <p>qgpu-scheduler 扩展调度器用于 qGPU 资源调度，返回符合要求的节点。当 Pod 绑定到节点上后，qgpu-provisioner 会更新<code>ElasticGPU</code> CRD 中节点、GPU 卡索引 等信息，实现 qGPU 设备的绑定。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220420100626443-2003012152.png\" alt=\"\" loading=\"lazy\"></p> \n <h4 id=\"qgpu-资源创建\">qGPU 资源创建</h4> \n <p>qgpu-manager 会 watch <code>ElastciGPU</code> CRD 变化，在绑定节点成功后，会执行创建 qGPU 设备的操作。qgpu-manager 会根据 CRD 中包含的申请算力与显存信息以及调度到的 GPU 卡索引，在底层创建 qGPU 设备。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220420100626728-665482793.png\" alt=\"\" loading=\"lazy\"></p> \n <h4 id=\"qgpu-设备挂载\">qGPU 设备挂载</h4> \n <p>qgpu-manager 是一个 device plugin 插件，kubelet 会在分配 device 时通过标准接口调用插件。在接口 <code>Allocate</code> 和 <code>PreStartContainer</code> 中，我们会挂载必要的 qGPU、nvidia 设备以及设置环境变量。最后，我们依赖 qgpu-container-runtime 进行 qGPU 设备与容器的绑定工作。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220420100627044-689638908.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"下一步发展\">下一步发展</h2> \n <p>随着 AI 业务的大规模落地，越来越多的用户在 Kubernetes 中使用 GPU 进行 AI 计算。现有的 extended resource 与 device plugin 机制很难满足客户对 GPU 资源的精细控制和分配，新的技术框架势在必行。Elastic GPU 在 Kubernetes 集群中抽象了一种 native GPU 资源，围绕三种自定义 CRD，在标准化定义了与其他 GPU 技术交互的前提下，同时提供了集群层面全局 GPU 资源视角，让用户可以更好的观察和管理 GPU 资源。</p> \n <p>Elastic GPU 第一步会聚焦在 CRD 定义以及交互流程标准化，并首先适配 TKE qGPU。在这个阶段，我们希望参照 PV / PVC / CSI 的设计理念，以 Kubernetes native 的方式提供对 GPU 资源的抽象，标准化资源分配、调度、挂载等流程，并提供灵活的接口，供其他 GPU 技术集成。通过首先在生产环境支持 TKE qGPU，我们会持续打磨框架，发布第一个 alpha 版本。接下来，我们会推动社区实现对主流 GPU 技术的集成支持，包括 nvidia docker、gpu share 以及 vCUDA，横向扩展框架的适用场景。通过标准框架，统一接口和流程，降低客户管理成本。通过 GPU Sharing、Remote GPU 等技术提升灵活性、增加利用率，降低客户用卡成本。我们希望依赖 Elastic GPU 框架，最终可以为客户提供 Kubernetes 开箱即用使用 GPU 资源的能力。</p> \n <p>TKE qGPU：<a href=\"https://cloud.tencent.com/document/product/457/61448\" target=\"_blank\" rel=\"noopener\">https://cloud.tencent.com/document/product/457/61448</a></p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220420100627366-1349727067.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"89","createTime":"2022-04-06 18:54","comment":"0","id":"16107956","title":"轻量化安装 TKEStack：让已有 K8s 集群拥有企业级容器云平台的能力","url":"https://www.cnblogs.com/tencent-cloud-native/p/16107956.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <h4 id=\"福利\">福利：</h4> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <p>④公众号后台回复【光速入门】，可获得腾讯云专家5万字精华教程，光速入门Prometheus和Grafana。</p> \n <h2 id=\"作者\">作者</h2> \n <p>王龙，腾讯云后台开发工程师，负责 TKEStack 的设计开发维护及混合云项目相关工作。</p> \n <h2 id=\"前言\">前言</h2> \n <p><a href=\"https://github.com/tkestack/tke\" title=\"TKEStack\" target=\"_blank\" rel=\"noopener\">TKEStack</a> 是一个开源的企业级容器云平台，结合最前沿的先进技术，提供高度可扩展的高性能容器管理服务，可以让您轻松地在任何地方运行 Kubernetes、满足 IT 需求并为 DevOps 团队赋能。</p> \n <p>TKEStack 提供了丰富的组件实现用户管理、访问策略管理、集群管理、业务管理、监控、日志、私有镜像库等功能，这也相应地增加了在本地安装 TKEStack 的时间。对于部分用户来说，可能只需要 TKEStack 的用户管理、集群管理、控制台访问等核心功能，但也要付出一样的时间成本。另外，TKEStack 安装过程中会在裸机上部署 global 集群，并通过 global 集群管理独立集群和导入集群的生命周期。因此对于已有的 K8s 集群，用户无法对其安装集成 TKEStack。</p> \n <p>基于上述背景，TKEStack 在最新的 v1.9.0 release 中，支持了轻量化安装场景。轻量化安装打破了需要新建 global 集群的限制，实现了在用户已有的 K8s 集群上直接集成 TKESatck 的用户管理、集群管理、控制台访问等核心功能。用户由此可以通过前端可视化页面，查看并管理集群的基本信息、工作节点、命名空间、工作负载等各种资源。除此之外，通过设置自定义访问策略，打破了”单租户“的限制，用户可以实现对集群灵活的权限控制。</p> \n <h2 id=\"前置要求\">前置要求</h2> \n <p>本文介绍的内容是建立在已有一个正常运行的 K8s 集群的基础上，并且以下的操作需要在 master 节点上进行。如果没有 K8s 集群，可以通过 <a href=\"https://kind.sigs.k8s.io/docs/user/quick-start/\" title=\"kind\" target=\"_blank\" rel=\"noopener\">kind</a> 创建本地集群并进行以下的操作。</p> \n <p>本文介绍的内容需要通过 <a href=\"https://helm.sh/zh/docs/\" title=\"helm\" target=\"_blank\" rel=\"noopener\">helm</a> 安装 TKEStack 的核心组件，可参考 <a href=\"https://helm.sh/zh/docs/intro/install/\" title=\"安装手册\" target=\"_blank\" rel=\"noopener\">安装手册</a> 安装 helm。</p> \n <h2 id=\"轻量化安装-tkestack\">轻量化安装 TKEStack</h2> \n <h3 id=\"准备安装文件\">准备安装文件</h3> \n <p>通过如下命令拉取 TKEStack 的最新代码：</p> \n <pre><code class=\"language-sh\">git clone https://github.com/tkestack/tke.git\n</code></pre> \n <h3 id=\"创建本地集群已有本地集群的可跳过该步骤\">创建本地集群（已有本地集群的可跳过该步骤）</h3> \n <p>如果用户本地没有 K8s 集群，可通过 kind 进行创建。由于 kind 创建的集群实际运行在镜像容器中，为了确保 TKEStack 核心组件的端口能够从容器外部正常访问，切换到 TKEStack 代码的 <code>hack/lightweight-install/</code> 目录，执行如下命令创建集群：</p> \n <pre><code class=\"language-sh\">kind create cluster --config kindConfig.yaml --name {your cluster name} \n</code></pre> \n <h3 id=\"创建指定-namespace\">创建指定 namespace</h3> \n <p>tke-auth、tke-platform、tke-gateway 三个核心组件需要运行在指定的 namespace 下，执行如下命令：</p> \n <pre><code class=\"language-sh\">kubectl create namespace tke\n</code></pre> \n <h3 id=\"安装-chart\">安装 chart</h3> \n <p>TKEStack 提供了 chart 文件来安装 tke-auth、tke-platform、tke-gateway 三个核心组件。</p> \n <p>切换到 TKEStack 代码的 <code>hack/lightweight-install/</code> 目录，编译二进制执行文件，用于生成安装 chart 文件所需的 <code>yaml</code> 文件：</p> \n <pre><code class=\"language-sh\">go build -o gen\n</code></pre> \n <p>在 TKEStack 代码的 <code>hack/lightweight-install/</code> 目录放置了需要填写的 yaml 文件 <code>customConfig.yaml</code>。<code>customConfig.yaml</code> 文件中一些注释“必填”的参数，需要填写，其余的参数可根据需要选填，选填部分为空时会自动填充默认值。</p> \n <p><code>customConfig.yaml</code> 内容如下：</p> \n <pre><code class=\"language-yaml\"># 必填，etcd 访问地址，形式如 https://172.19.0.2:2379\netcd:\n  host: https://172.18.0.2:2379 \n# 必填，服务器内网 IP，数组形式\nserverIPs:\n  - 172.18.0.2\n# 必填，公网可访问的 IP 地址以及要使用的域名，数组形式\ndnsNames:\n  - tke.gateway\n# 必填，集群 front-proxy-ca.crt 文件地址，默认位置为 /etc/kubernetes/pki/front-proxy-ca.crt\nfrontProxyCaCrtAbsPath: /etc/kubernetes/pki/front-proxy-ca.crt\n# 必填，集群 etcd 的 ca.crt 文件地址，默认位置为 /etc/kubernetes/pki/etcd/ca.crt\netcdCrtAbsPath: /etc/kubernetes/pki/etcd/ca.crt\n# 必填，集群 etcd 的 ca.key文件地址，默认位置为 /etc/kubernetes/pki/etcd/ca.key\netcdKeyAbsPath: /etc/kubernetes/pki/etcd/ca.key\ntke-auth:\n  api:\n    # 必填\n    replicas: 1\n    # 必填\n    image: tkestack/tke-auth-api-amd64:74592a3bceb5bebca602bea21aaebf78007a3bb2\n    # 必填，数组形式，auth 的重定向访问地址，包括集群服务器 IP 地址（必填）、tke-gateway 的域名（可选）、集群高可用的 VIP 地址（可选，有的话需要填写）和集群的公共可访问域名（可选，有的话需要填写）\n    redirectHosts: \n      - 172.18.0.2\n    enableAudit: \n    # tke-auth-api 组件在 node 上的对外暴露端口，默认31138\n    nodePort: \n    # 集群的租户 id，默认 default\n    tenantID: \n    # OIDC 认证方式的 secret，默认自动生成\n    oIDCClientSecret: \n    # authentication 用户名，默认为 admin\n    adminUsername: \n  controller:\n    # 必填\n    replicas: 1\n    # 必填\n    image: tkestack/tke-auth-controller-amd64:74592a3bceb5bebca602bea21aaebf78007a3bb2\n    # 控制台登陆的用户名，默认为 admin\n    adminUsername: \n    # 控制台登陆的密码，默认自动生成\n    adminPassword: \ntke-platform:\n  # 必填，VIP 或者公网可访问的集群 IP\n  publicIP:\n  metricsServerImage: metrics-server:v0.3.6\n  addonResizerImage: addon-resizer:1.8.11\n  api:\n    # 必填\n    replicas: 1\n    # 必填\n    image: tkestack/tke-platform-api-amd64:bc48bed59bff2022d87db5e1484481715357ee7c\n    enableAuth: true\n    enableAudit: \n    # OIDC 认证方式客户端 id，默认为 default\n    oIDCClientID: \n    # OIDC 认证方式的 issuer_url，默认为 https://tke-auth-api/oidc\n    oIDCIssuerURL: \n    # 是否开启 OIDC 认证，默认不开启，值为空\n    useOIDCCA:\n  controller:\n    # 必填\n    replicas: 1\n    # 必填\n    providerResImage: tkestack/provider-res-amd64:v1.21.4-1\n    # 必填\n    image: tkestack/tke-platform-controller-amd64:bc48bed59bff2022d87db5e1484481715357ee7c\n    # 默认为 docker.io\n    registryDomain:\n    # 默认为 tkestack\n    registryNamespace:\n    # 监控存储类型，默认为 influxdb\n    monitorStorageType: \n    # 监控存储地址，默认为集群 master IP 地址加8086端口\n    monitorStorageAddresses:\ntke-gateway:\n  # 必填\n  image: tkestack/tke-gateway-amd64:bc48bed59bff2022d87db5e1484481715357ee7c\n  # 默认为 docker.io\n  registryDomainSuffix:\n  # 集群的租户 id，默认为 default\n  tenantID:\n  # OIDC 认证方式的 secret，默认自动生成\n  oIDCClientSecret:\n  # 是否开启自签名，默认为 true\n  selfSigned: true\n  # 第三方 cert 证书，在 selfSigned 为 false 时需要填值\n  serverCrt:\n  # 第三方 certKey 密钥，在 selfSigned 为 false 时需要填值\n  serverKey:\n  enableAuth: true\n  enableBusiness:\n  enableMonitor:\n  enableRegistry:\n  enableLogagent:\n  enableAudit:\n  enableApplication:\n  enableMesh:\n\n</code></pre> \n <p><code>customConfig.yaml</code> 文件中的参数填写完毕后，在当前 <code>hack/lightweight-install/</code> 目录下执行 <code>gen</code>：</p> \n <pre><code class=\"language-sh\">./gen\n</code></pre> \n <p>会在同级目录生成 <code>auth-chart-values.yaml</code>、<code>platform-chart-values.yaml</code>、<code>gateway-chart-values.yaml</code> 三个 yaml 文件，分别对应三个 chart（tke-auth、tke-platform、tke-gateway）在安装时需要的 <code>values.yaml</code> 文件。</p> \n <p>在当前 <code>hack/lightweight-install/</code> 目录下进行三个核心组件的安装：</p> \n <pre><code class=\"language-sh\"># tke-auth 的安装\nhelm install -f auth-chart-values.yaml tke-auth tke-auth/\n</code></pre> \n <pre><code class=\"language-sh\"># tke-platform 的安装\nhelm install -f platform-chart-values.yaml tke-platform tke-platform/\n</code></pre> \n <pre><code class=\"language-sh\"># tke-gateway 的安装\nhelm install -f gateway-chart-values.yaml tke-gateway tke-gateway/\n</code></pre> \n <p>通过如下命令如果能查询到三个 chart 的安装状态均为 <code>deployed</code>，则表示核心组件安装成功：</p> \n <pre><code class=\"language-sh\">helm list\n</code></pre> \n <p>chart 安装完成后，可以查询到以下信息，如图所示：</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220406185350168-743757800.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"修改集群-apiserver-配置\">修改集群 apiserver 配置</h3> \n <p>在集群对应的目录 <code>/etc/kubernetes/pki/</code> 下新建文件 <code>tke-authz-webhook.yaml</code>，文件内容如下（其中 <code>cluster.server</code> 参数中的 IP 地址需要修改为 master 的 IP 地址）：</p> \n <pre><code class=\"language-yaml\">apiVersion: v1\nkind: Config\nclusters:\n  - name: tke\n    cluster:\n      server: https://172.19.0.2:31138/auth/authz\n      insecure-skip-tls-verify: true\nusers:\n  - name: admin-cert\n    user:\n      client-certificate: /etc/kubernetes/pki/webhook.crt\n      client-key: /etc/kubernetes/pki/webhook.key\ncurrent-context: tke\ncontexts:\n- context:\n    cluster: tke\n    user: admin-cert\n  name: tke\n</code></pre> \n <p>将二进制执行文件 <code>gen</code> 生成的 <code>webhook.crt</code> 和 <code>webhook.key</code>（位置在 TKEStack 代码下的 <code>hack/lightweight-install/data/</code> 目录）复制到集群的对应目录 <code>/etc/kubernetes/pki/</code> 下。</p> \n <p>修改 K8s 集群中 <code>/etc/kubernetes/mainfest/kube-apiserver.yaml</code> 的内容，在 <code>spec.containers.command</code> 字段增加以下两个参数：</p> \n <pre><code class=\"language-yaml\"># 如果已有这两个参数，则将其按照以下内容修改\n- --authorization-mode=Node,RBAC,Webhook\n- --authorization-webhook-config-file=/etc/kubernetes/pki/tke-authz-webhook.yaml\n</code></pre> \n <h3 id=\"创建独立集群\">创建独立集群</h3> \n <p>访问地址 <code>http://{公网可访问ip}/tkestack</code>，出现如下登陆界面，输入之前设置的用户名 <code>adminUsername</code> 和密码 <code>adminPassword</code>，如无设置，默认用户名为 <code>admin</code> ，密码为 <code>YWRtaW4=</code>。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220406185350472-855721346.png\" alt=\"\" loading=\"lazy\"></p> \n <p>登陆后，点击集群管理的新建独立集群：</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220406185350752-1952101051.png\" alt=\"\" loading=\"lazy\"></p> \n <p>具体的集群创建信息可参考文档<a href=\"https://tkestack.github.io/web/zh/docs/user-guide/platform-console/cluster-mgmt/#%E6%96%B0%E5%BB%BA%E7%8B%AC%E7%AB%8B%E9%9B%86%E7%BE%A4\" title=\"集群创建\" target=\"_blank\" rel=\"noopener\">集群创建</a>。</p> \n <p>创建集群完成后，可以在页面端看到如下状态：</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220406185351062-902364393.png\" alt=\"\" loading=\"lazy\"></p> \n <p>并且可以在 master 节点上查询到独立集群的信息：</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220406185351335-481344241.png\" alt=\"\" loading=\"lazy\"></p> \n <p>如果在创建独立集群时，Kubernetes 版本显示暂无数据，可以通过在名为 cluster-info（namespace 为 kube-public）的 configmap 中增加如下字段解决（具体字段值可参考 <code>hack/lightweight-install/</code> 目录下的 <code>patch.yaml</code> 文件）：</p> \n <pre><code class=\"language-sh\">data:\n  k8sValidVersions: '[\"1.21.4-tke.1\",\"1.20.4-tke.1\"]'\n</code></pre> \n <h2 id=\"总结\">总结</h2> \n <p>本文介绍了如何基于 TKEStack 最新的 v1.9.0 release 版本在已有的 K8s 集群上轻量化安装 TKEStack，并以此集成 TKEStack 的用户管理、集群管理、控制台访问等核心功能。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2022.cnblogs.com/other/2041406/202204/2041406-20220406185351686-479725407.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"94","createTime":"2022-03-24 11:12","comment":"0","id":"16048822","title":"技术集锦 | 云原生 AI 技术原理及最佳实践系列","url":"https://www.cnblogs.com/tencent-cloud-native/p/16048822.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <h4 id=\"福利\">福利：</h4> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <p>④公众号后台回复【光速入门】，可获得腾讯云专家5万字精华教程，光速入门Prometheus和Grafana。</p> \n <h2 id=\"摘要\">摘要</h2> \n <p>云原生已成为了云计算行业下一代的标准。目前，除了传统应用与基础架构的云原生化，AI 与大数据也开始拥抱云原生的架构。</p> \n <p>腾讯云容器服务基于在云原生领域的技术沉淀，推出模块化，低耦合、高扩展性的云原生 AI 服务，旨在利用云原生的思想和技术，为 AI 场景的数据处理、模型训练、模型上线推理等需求构建弹性可扩展的系统架构的技术，在支持更广泛、多样的用户需求的同时，提高开发、运维和设备的效率。</p> \n <p>【腾讯云原生】收集了关于云原生 AI 系列干货文8篇，帮助你更好了解“云原生 AI”，一定要收藏哦！</p> \n <h2 id=\"技术原理--实践\">技术原理 &amp; 实践</h2> \n <p><a href=\"https://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247492919&amp;idx=1&amp;sn=48491e1d55f32b69f7b5523ca171e1ff&amp;chksm=c0045eedf773d7fb8c73e1ee5a790abb79b6e786f93e771325b7ed8f533ce2aa9feae86cd09d&amp;scene=21#wechat_redirect\" title=\"云原生的弹性 AI 训练系列之一：基于 AllReduce 的弹性分布式训练实践\" target=\"_blank\" rel=\"noopener\">云原生的弹性 AI 训练系列之一：基于 AllReduce 的弹性分布式训练实践</a></p> \n <ul> \n  <li>本文主要介绍了数据并行的分布式训练任务的弹性能力在 Kubernetes 上的设计与实现。并且通过实验的方式验证了特定的场景下，在保证训练精度的同时，这一特性能够使成本降低 70%。</li> \n </ul> \n <p><a href=\"https://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247515990&amp;idx=1&amp;sn=259d3fb3be4589d02d4315e39ebf2479&amp;chksm=c004048cf7738d9a1a5be351f38e0e9ac2c8091e6ce056f5936e41b659c519704f30e9cdaa3c&amp;scene=21#wechat_redirect\" title=\"云原生的弹性 AI 训练系列之二：PyTorch 1.9.0 弹性分布式训练的设计与实现\" target=\"_blank\" rel=\"noopener\">云原生的弹性 AI 训练系列之二：PyTorch 1.9.0 弹性分布式训练的设计与实现</a></p> \n <ul> \n  <li>本文介绍了 PyTorch 1.9.0 版本中弹性训练的设计与实现。然后分析总结了实现弹性训练的方式和不同框架之间的设计差异。</li> \n </ul> \n <p><a href=\"https://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247517144&amp;idx=1&amp;sn=dc34d6550430379ed7dedf36203adeb9&amp;chksm=c0043802f773b114af1a1c111a35aabc71dd84be8de09387b48412b5994d3f7a1a5bb253b8cc&amp;scene=21#wechat_redirect\" title=\"云原生的弹性 AI 训练系列之三：借助弹性伸缩的 Jupyter Notebook，大幅提高 GPU 利用率\" target=\"_blank\" rel=\"noopener\">云原生的弹性 AI 训练系列之三：借助弹性伸缩的 Jupyter Notebook，大幅提高 GPU 利用率</a></p> \n <ul> \n  <li>这篇文章介绍了 elastic-jupyter-operator 这一开源项目的使用方式以及工作原理。</li> \n </ul> \n <p><a href=\"https://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247514143&amp;idx=1&amp;sn=58a47283e485f8db412d323d84da6061&amp;chksm=c00403c5f7738ad36a3b2c7c6dac634b719b96c78d04dee600291323f683d68715ad0d01dd91&amp;scene=21#wechat_redirect\" title=\"公有云上构建云原生 AI 平台的探索与实践\" target=\"_blank\" rel=\"noopener\">公有云上构建云原生 AI 平台的探索与实践</a></p> \n <ul> \n  <li>本文介绍了 AI 类业务在公有云上的现状以及相应的技术选型和面临的问题，同时分享了对于未来全弹性的 AI 基础设施的展望。</li> \n </ul> \n <p><a href=\"https://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247515798&amp;idx=1&amp;sn=2acd5a588a0223e12d7c9cc25c1b475e&amp;chksm=c004054cf7738c5a4833ea01280e2cf1651ad23e0b467d3d4d91133383a14d090f5004b99429&amp;scene=21#wechat_redirect\" title=\"Fluid + GooseFS 助力云原生数据编排与加速快速落地\" target=\"_blank\" rel=\"noopener\">Fluid + GooseFS 助力云原生数据编排与加速快速落地</a></p> \n <ul> \n  <li>本文介绍了 Fluid 技术的背景以及与 GooseFS 的关系，通过在 TKE 集群上的实际操练让大家体验 Fluid v0.6.0 的两大特性，让大家进一步了解云原生应用场景下的数据编排能力。</li> \n </ul> \n <p><a href=\"https://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247516415&amp;idx=1&amp;sn=6e4d873989eec94c15d9f2ac8f4ca7cd&amp;chksm=c0043b25f773b2333f0a6f741b3bc360303d9e9533723369952cf58c71f7d9587447e2d69dc6&amp;scene=21#wechat_redirect\" title=\"云原生 AI 前沿：Kubeflow Training Operator 统一云上 AI 训练\" target=\"_blank\" rel=\"noopener\">云原生 AI 前沿：Kubeflow Training Operator 统一云上 AI 训练</a></p> \n <ul> \n  <li>本文介绍了 kubeflow 社区面对多个 训练 operator 遇到的维护、性能上的问题，通过融合的方式构建统一的 training-operator。</li> \n </ul> \n <p><a href=\"https://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247517825&amp;idx=1&amp;sn=0cf53cf759614600ac196c774e3ab6a3&amp;chksm=c0043d5bf773b44d7ecbfb491e9b549a02d3ffeb4f00952d5611bc33a225e91b22391e535bd3&amp;scene=21#wechat_redirect\" title=\"Aggregated APIServer 构建云原生应用最佳实践\" target=\"_blank\" rel=\"noopener\">Aggregated APIServer 构建云原生应用最佳实践</a></p> \n <ul> \n  <li>本文从实战角度出发介绍我们开发 SKAI 平台过程中选择 Aggregated API 的原因，以及 kube-apisever 的扩展原理，演示如何构建起自己的 Aggregated API，并将它部署到 EKS 集群中。</li> \n </ul> \n <p><a href=\"https://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247518028&amp;idx=1&amp;sn=417e2f4322537335d08fe4e6c0a06a9c&amp;chksm=c0043c96f773b5801690f411e922cfe5d8b69b12b67c364e4e2de9cb879fad648ad791eb320e&amp;scene=21#wechat_redirect\" title=\"GPU 分布式 AI 训练加速引擎 TACO-Training 容器方案首发！\" target=\"_blank\" rel=\"noopener\">GPU 分布式 AI 训练加速引擎 TACO-Training 容器方案首发！</a></p> \n <p>本文介绍了 TKE 提供的云原生 AI 能力和腾讯云自研网络协议栈 HARP，并指导用户如何在 TKE 上部署实践 TACO-Training 分布式训练方案。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220324111133399-2173504.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"225","createTime":"2022-03-18 19:39","comment":"0","id":"16023311","title":"腾讯推出国内首个云原生成本优化开源项目 Crane","url":"https://www.cnblogs.com/tencent-cloud-native/p/16023311.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <h4 id=\"福利\">福利：</h4> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <p>④公众号后台回复【光速入门】，可获得腾讯云专家5万字精华教程，光速入门Prometheus和Grafana。</p> \n <h2 id=\"作者\">作者</h2> \n <p>王孝威，FinOps 认证从业者，腾讯云技术产品经理，Crane 产品负责人。</p> \n <h2 id=\"云资源管理现状\">云资源管理现状</h2> \n <p>设想你是一个应用开发人员，编写业务代码是你的主业，应用需要多少资源，往往通过压测决定，这导致非业务高峰期时段巨大的资源浪费。正好，社区和公司都在积极推动云原生，声称可以利用其强大的调度和弹性解决资源浪费问题。你兴致勃勃的拥抱云原生，但最终发现，云原生业务的资源配置，同样还是需要压测这种传统而手工的方式。</p> \n <p>又比如你是一个平台侧运维人员，你背负着提升平台资源利用率的 KPI。集群内运行着众多负载规律波动的应用，你惊喜的发现，Kubernetes 提供了自动扩容能力，你很想试试看。但真正使用了HPA，从负载上升触发阈值，到弹性控制器开始扩容，到应用启动完成，可能有数分钟甚至数十分钟的滞后，在弹性起作用之前，应用已经被压垮。于是你抛弃自动弹性能力，继续回归到锁定超量资源的老路上来。</p> \n <p>研发人员到底能否从资源配置的深渊中解脱出来，是否能让弹性能力高效实用？于是你带着问题去社区寻找答案。你发现将应用代码和基础架构彻底分离的 Serverless 技术似乎是一个选项，但是随着深入了解你发现，Serverless 只是一个概念，不是一个标准，由于完全抛弃了服务器，底层自主可控和性能优化能力完全丧失；另一类是以谷歌 Autopilot 集群为首的资源托管类集群，这类集群应该满足你的诉求，但它平台绑定并且需要付费。</p> \n <p>我们决定改变现状，我们在对腾讯内部业务做成本优化时积累了众多经验，结合资源预测、智能弹性和全构混部能力，在不牺牲稳定性的前提下，将集群峰值利用率提升到了50%以上，下图是优化的效果。我们期待与社区同道一起优化应用资源配置和弹性的共性问题，于是我们给大家一个不重造轮子的可能，选择了开源。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220318193902885-2140339085.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>图1 Crane 在大规模场景下的优化效果</p> \n <h2 id=\"crane-的诞生首款企业成本优化的开源工具\">Crane 的诞生：首款企业成本优化的开源工具</h2> \n <p>为推进云原生用户在确保业务稳定性的基础上做到真正的极致降本，腾讯推出了国内第一个基于云原生技术的成本优化开源项目 Crane（ Cloud Resource Analytics and Economics ）。Crane 遵循 FinOps 标准，旨在为云原生用户提供云成本优化一站式解决方案。</p> \n <p>当前 Crane 项目主要贡献者包括有腾讯、小红书、谷歌、eBay、微软、特斯拉等知名公司的行业专家。（Crane 开源项目地址：<a href=\"https://github.com/gocrane/crane/%EF%BC%89\" target=\"_blank\" rel=\"noopener\">https://github.com/gocrane/crane/）</a></p> \n <h2 id=\"符合-finops-标准的-crane-成本优化工具能力模型\">符合 FinOps 标准的 Crane 成本优化工具能力模型</h2> \n <p>Crane 是腾讯内部云资源优化流程方法和工具的系统性输出，同时，Crane核心能力的构建与规划均与 FinOps 基金会提出的能力模型完全契合。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220318193904518-1016347704.png\" alt=\"\" loading=\"lazy\"></p> \n <p>图2 Crane 能力模型</p> \n <h2 id=\"crane-架构与特性\">Crane 架构与特性</h2> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220318193906793-78305703.png\" alt=\"\" loading=\"lazy\"><br> 图3 Crane 架构</p> \n <p>Crane 致力于推荐资源和智能弹性配置，业务人员无需再为业务需要多少资源，自动扩缩容应该如何配置等问题而烦恼，Crane 会基于业务的时序变动数据给出最优解。</p> \n <h3 id=\"一键部署\">一键部署</h3> \n <p>Crane 保持平台独立，通过一个 Helm 包将 Crane 安装至任意 Kubernetes 集群，无论云上还是云下，即可享受一站式资源优化能力。Crane 侵入性小，核心组件包括集中控制器 craned 和节点代理 crane agent，你可以自由组合安装，通过 featureGate 选择开启哪些能力。</p> \n <h3 id=\"简单易用可视化控制台\">简单易用可视化控制台</h3> \n <p>为降低使用门槛，Crane 提供内置控制台，用户可基于控制台查看成本分配，成本走势，并通过鼠标点击实现成本优化。所有能力均提供灰度控制和预览模式，以及回滚的能力，以消除业务侧对资源变动的顾虑。</p> \n <h3 id=\"开箱即用的巡检能力\">开箱即用的巡检能力</h3> \n <p>Crane 可以全局扫描整体浪费情况，将隐藏浪费可视化的呈现出来，使运维人员免除拉取监控数据，编写查询脚本等重复性工作。</p> \n <p>优化方案包含对成本变化的展示，对利用率变化的展示，可能的风险点，甚至是优化建议的排序。因为我们相信，每个业务都是独一无二的，都有其最适合的优化方案，不能一概而论。</p> \n <h3 id=\"即时迅速的弹性-effectivepodautoscalerepa\">即时迅速的弹性 (EffectivePodAutoscaler(EPA))</h3> \n <p>传统基于事件的弹性工具会导致一个天然缺陷——当业务指标偏离正常值后才会触发弹性，这种滞后性使得云用户不敢使用弹性。EPA 支持可扩展的预测算法，以预测结果驱动横向和纵向弹性，确保业务能提前弹出来，彻底避免原生弹性能力未弹先死的尴尬。同时 Crane 将社区的 HPA 和 VPA 两种弹性能力统一起来，提出了弹性概念 EPA。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220318193908302-1998061180.png\" alt=\"\" loading=\"lazy\"></p> \n <p>图4 EPA 确保工作负载提前扩容</p> \n <h3 id=\"稳定性与资源优化的双重兼\">稳定性与资源优化的双重兼</h3> \n <p>Crane 对资源利用率的提升，绝不是以牺牲稳定性作为代价。Crane 允许用户对业务进行定级，节点代理负责周期性检查节点资源水位和系统指标，识别应用干扰，并通过调度禁止，调整 cgroup，驱逐等多种手段确保敏感业务服务等级不受损。</p> \n <h2 id=\"crane-现状与未来\">Crane 现状与未来</h2> \n <p>当前Crane已发布0.2.0版本，具备了资源推荐，弹性推荐，智能弹性和稳定性增强等核心能力，更多开发计划请参考<a href=\"https://github.com/gocrane/crane/blob/main/docs/roadmaps/roadmap-1h-2022.md\" title=\"里程碑\" target=\"_blank\" rel=\"noopener\">里程碑</a>。</p> \n <h2 id=\"延伸阅读\">延伸阅读</h2> \n <p><a href=\"https://www.finops.org/introduction/what-is-finops/\" title=\"FinOps\" target=\"_blank\" rel=\"noopener\">FinOps</a> (Financial Operations) 定义了一系列云财务管理规则和最佳实践，通过助力工程和财务团队、技术和业务团队彼此合作，进行数据驱动的成本决策，使组织能够获得最大收益。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220318193909700-945973663.png\" alt=\"\" loading=\"lazy\"></p> \n <p>秉承着用户为本，科技向善的核心价值观，腾讯云将内部云资源优化的经验、方法、工具以开源的形式分享给社区，助力云用户云成本优化视为自己的使命与责任。2021年12月，腾讯成为 FinOps 基金会顶级会员，致力于云资源优化理念的推广与技术输出。</p> \n <h2 id=\"加入我们\">加入我们</h2> \n <p>Crane 项目开源进行时，欢迎关注 <a href=\"https://github.com/gocrane/crane/\" target=\"_blank\" rel=\"noopener\">https://github.com/gocrane/crane/</a> 收藏/Star支持。</p> \n <p>我们正在限量召集 Crane 的第一批开源技术粉丝，只要你对 Crane 及相关技术感兴趣，都欢迎加入，参与方式：添加腾小云微信（TKEplatform），回复：Crane，小云会拉你进群。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220318193910422-128387385.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"200","createTime":"2022-03-15 18:14","comment":"0","id":"16009682","title":"SuperEdge: 使用WebAssembly扩展边缘计算场景","url":"https://www.cnblogs.com/tencent-cloud-native/p/16009682.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>SuperEdge 开发者团队</p> \n <h2 id=\"概要\">概要</h2> \n <p><a href=\"https://github.com/superedge/superedge\" title=\"SuperEdge\" target=\"_blank\" rel=\"noopener\">SuperEdge</a> 是 <code>一个开源的分布式边缘计算容器管理系统，用于管理多个云边区域中的计算资源和容器应用。</code> 在当前架构中，这些资源和应用能够作为一个 Kubernetes 原生的资源进行管理。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220315181330855-1031105605.png\" alt=\"\" loading=\"lazy\"></p> \n <p>然而在某些情况下，边缘设备通常需要一些更加轻量、性能更好的运行时。也需要减少以 GB 为单位的容器镜像，将容器的启动时间提升到到秒级甚至毫秒级，而基于虚拟机堆栈二进制指令格式的 WebAssembly 可以更好地处理这种情况。</p> \n <p><a href=\"https://github.com/WasmEdge/WasmEdge\" title=\"WasmEdge\" target=\"_blank\" rel=\"noopener\">WasmEdge</a> 是一个轻量级、高性能和可扩展的 WebAssembly 运行时，适用于云原生、边缘和去中心化应用程序。它是当今发展最快的 Wasm 运行时，社区活跃度也相当的高。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220315181331231-441124076.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"运行简图\">运行简图</h2> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220315181331523-1056102742.png\" alt=\"\" loading=\"lazy\"></p> \n <p>Superedge 最近支持了 Containerd，在边缘节点我们将让 Containerd 使用 crun 来支持 WasmEdge 运行时。也就是说，按照这些步骤后，你的边缘节点可以同时支持 OCI 容器和 WASM 容器。</p> \n <h2 id=\"安装-superedge-边缘-k8s-集群\">安装 SuperEdge 边缘 K8s 集群</h2> \n <ul> \n  <li>下载安装包</li> \n </ul> \n <pre><code class=\"language-bash\">arch=amd64 version=v0.7.0 &amp;&amp; rm -rf edgeadm-linux-* &amp;&amp; wget https://superedge-1253687700.cos.ap-guangzhou.myqcloud.com/$version/$arch/edgeadm-linux-containerd-$arch-$version.tgz &amp;&amp; tar -xzvf edgeadm-linux-* &amp;&amp; cd edgeadm-linux-$arch-$version &amp;&amp; ./edgeadm\n</code></pre> \n <p>注意选择机器架构对应的安装包，这个安装包默认带 Containerd 容器运行时。</p> \n <ul> \n  <li>创建边缘集群</li> \n </ul> \n <pre><code class=\"language-bash\">./edgeadm init --kubernetes-version=1.18.2 --image-repository superedge.tencentcloudcr.com/superedge --service-cidr=10.96.0.0/12 --pod-network-cidr=192.168.0.0/16 --install-pkg-path ./kube-linux-*.tar.gz --apiserver-cert-extra-sans=&lt;Master Public IP&gt; --apiserver-advertise-address=&lt;Master Intranet IP&gt; --enable-edge=true --runtime=containerd\n</code></pre> \n <p>注意带 <code>--runtime=containerd</code> 参数，表示使用 Containerd 容器运行时， <code>--runtime=dockerd</code> 表示使用 Docker容器运行时。</p> \n <ul> \n  <li>Join 边缘节点</li> \n </ul> \n <pre><code class=\"language-bash\">./edgeadm join &lt;Master Public/Intranet IP Or Domain&gt;:Port --token xxxx --discovery-token-ca-cert-hash sha256:xxxxxxxxxx --install-pkg-path ./kube-linux-*.tar.gz --enable-edge=true --runtime=containerd\n</code></pre> \n <p>详细可查看 SuperEdge 官方文档<a href=\"https://github.com/superedge/superedge/blob/main/docs/installation/install_edge_kubernetes_CN.md\" title=\"一键安装原生的k8s集群和边缘K8s集群\" target=\"_blank\" rel=\"noopener\">一键安装原生的k8s集群和边缘K8s集群</a></p> \n <h2 id=\"安装-wasmedge-运行环境\">安装 WasmEdge 运行环境</h2> \n <h3 id=\"安装-wasmedge\">安装 WasmEdge</h3> \n <p>在边缘节点上使用脚本便可很轻松安装 WasmEdge，在边缘节点执行如下脚本：</p> \n <pre><code class=\"language-bash\">curl -sSf https://raw.githubusercontent.com/WasmEdge/WasmEdge/master/utils/install.sh | bash\n</code></pre> \n <h3 id=\"安装-crun\">安装 crun</h3> \n <p><a href=\"https://github.com/containers/crun\" title=\"crun\" target=\"_blank\" rel=\"noopener\">crun</a> 项目内置了 WasmEdge 支持，但是默认的 crun release 没有把 wasmedge 模块编译进去，目前需要手动从源代码构建支持 WasmEdge 的 crun 二进制。<br> 首先，确保在您的 Ubuntu 20.04 上安装了 crun 依赖项。对于其他 Linux 发行版请参阅 crun 的 <a href=\"https://github.com/containers/crun#readme\" title=\"README\" target=\"_blank\" rel=\"noopener\">README</a>。</p> \n <pre><code class=\"language-bash\">sudo apt update\nsudo apt install -y make git gcc build-essential pkgconf libtool \\\n    libsystemd-dev libprotobuf-c-dev libcap-dev libseccomp-dev libyajl-dev \\\n    go-md2man libtool autoconf python3 automake\n</code></pre> \n <p>接下来，编译和安装 crun：</p> \n <pre><code class=\"language-bash\">git clone https://github.com/containers/crun\ncd crun\n./autogen.sh\n./configure --with-wasmedge\nmake\nsudo make install\n</code></pre> \n <h3 id=\"配置-containerd-使用-crun-运行时\">配置 Containerd 使用 crun 运行时</h3> \n <p>这里我们给出需要配置 Containerd 文件 <code>/etc/containerd/config.toml</code> 原始配置和配置之后的差异，用户可以按对比进行修改。</p> \n <pre><code class=\"language-bash\">cat &gt; config.toml.diff &lt;&lt; EOF\n--- /etc/containerd/config.toml 2022-02-14 15:05:40.061562127 +0800\n+++ /etc/containerd/config.toml.crun    2022-02-14 15:03:35.846052853 +0800\n@@ -24,17 +24,23 @@\n   max_concurrent_downloads = 10\n\n   [plugins.cri.containerd]\n-        default_runtime_name = \"runc\"\n-    [plugins.cri.containerd.runtimes.runc]\n+        default_runtime_name = \"crun\"\n+    [plugins.cri.containerd.runtimes.crun]\n       runtime_type = \"io.containerd.runc.v2\"\n-      pod_annotations = []\n+      pod_annotations = [\"*.wasm.*\", \"wasm.*\", \"module.wasm.image/*\", \"*.module.wasm.image\", \"module.wasm.image/variant.*\"]\n       container_annotations = []\n       privileged_without_host_devices = false\n-      [plugins.cri.containerd.runtimes.runc.options]\n-        BinaryName = \"runc\"\n+      [plugins.cri.containerd.runtimes.crun.options]\n+        BinaryName = \"crun\"\n   # cni\n   [plugins.cri.cni]\n     bin_dir = \"/opt/cni/bin\"\n     conf_dir = \"/etc/cni/net.d\"\n     conf_template = \"\"\n\n+  [plugins.\"io.containerd.runtime.v1.linux\"]\n+    no_shim = false\n+    runtime = \"crun\"\n+    runtime_root = \"\"\n+    shim = \"containerd-shim\"\n+    shim_debug = false\nEOF\n</code></pre> \n <p>最后重启下 Containerd 容器运行时</p> \n <pre><code class=\"language-bash\">sudo patch -d/ -p0 &lt; config.toml.diff\nsudo systemctl restart containerd\n</code></pre> \n <h2 id=\"创建-wasm-应用\">创建 WASM 应用</h2> \n <p>我们将使用已经在 dockerhub 上的一个wasm示例镜像<a href=\"https://hub.docker.com/r/hydai/wasm-wasi-example\" title=\"wasm-wasi-example\" target=\"_blank\" rel=\"noopener\">wasm-wasi-example</a>。这里 wasm 镜像需要在镜像的Manfest文件中增加一个<code>\"module.wasm.image/variant\":\"compat\"</code>的 Annotation 让运行时区分出 wasm 和操作系统运行时，因此 docker build 功能是没法满足的，可以使用<a href=\"https://wasmedge.org/book/en/kubernetes/demo/wasi.html\" title=\"buildah\" target=\"_blank\" rel=\"noopener\">buildah</a>来构建 wasm 镜像并 push 到任意 OCI 标准的镜像仓库中。</p> \n <pre><code class=\"language-bash\">cat &gt; wasmedge-app.yaml &lt;&lt; EOF\napiVersion: v1\nkind: Pod\nmetadata:\n  annotations:\n    module.wasm.image/variant: compat\n  labels:\n    run: wasi-demo\n  name: wasi-demo\nspec:\n  containers:\n  - args:\n    - /wasi_example_main.wasm\n    - \"50000000\"\n    image: hydai/wasm-wasi-example:with-wasm-annotation\n    imagePullPolicy: IfNotPresent\n    name: wasi-demo\n  hostNetwork: true\n  restartPolicy: Never\nEOF\n\nkubectl create -f wasmedge-app.yaml\n</code></pre> \n <p>可用 <code>kubectl logs wasi-demo</code> 看到这个程序输出如下内容：</p> \n <pre><code>Random number: -1643170076\nRandom bytes: [15, 223, ... 106, 51]\nPrinted from wasi: This is from a main function\nThis is from a main function\nThe env vars are as follows.\nThe args are as follows.\n/wasi_example_main.wasm\n50000000\nFile content is This is in a file\n</code></pre> \n <h2 id=\"未来\">未来</h2> \n <p>随着更广泛的边缘设备接入，更多的边缘场景覆盖的要求，SuperEdge 在边缘计算运行时不仅支持传统的 docker 和 containerd 等，现在还可以支持各种 WebAssembly 运行时（WasmEdge），也会持续为广大开发者创造充满想象力且无限可能的边缘计算和调度平台。</p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <h4 id=\"福利\">福利：</h4> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <p>④公众号后台回复【光速入门】，可获得腾讯云专家5万字精华教程，光速入门Prometheus和Grafana。</p> \n <p>⑤公众号后台回复【精选集】，可获得腾讯24位腾讯云专家精彩演讲——4万字《腾讯云技术实践精选集 2021》。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220315181331922-433870193.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"175","createTime":"2022-03-14 18:29","comment":"0","id":"16005385","title":"重磅 | 腾讯云服务网格开源项目 Aeraki Mesh 加入 CNCF 云原生全景图","url":"https://www.cnblogs.com/tencent-cloud-native/p/16005385.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>赵化冰，腾讯云工程师，Aeraki Mesh 创始人，Istio member，Envoy contributor，目前负责 Tencent Cloud Mesh 研发工作。</p> \n <h2 id=\"摘要\">摘要</h2> \n <p>近日，腾讯云开源的服务网格项目 Aeraki Mesh 正式进入 CNCF 云原生全景图，位于 Service Mesh 类别下。CNCF Landscape 在云原生实践过程中的每个环节帮助用户了解有哪些具体的软件和产品选择，Aeraki Mesh 进入 CNCF Landscape，意味着 Aeraki Mesh 正式成为了 CNCF 认可的构建云原生最佳实践中的一环。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220314182915240-446268026.png\" alt=\"\" loading=\"lazy\"><br> （Aeraki Mesh 在 CNCF 云原生全景图中的位置）</p> \n <h2 id=\"什么是-cncf-云原生全景图\">什么是 CNCF 云原生全景图？</h2> \n <p>Cloud Native Computing Foundation，云原生计算基金会（以下简称CNCF）是一个开源软件基金会，它致力于云原生（Cloud Native）技术的普及和可持续发展。云原生技术通过一系列的软件、规范和标准帮助企业和组织，在现代的动态环境（如公共云、私有云和混合云）中构建和运行敏捷的、可扩展的应用程序。</p> \n <p>CNCF 发布了云原生全景图（CNCF Landscape），旨在帮助企业和开发人员快速了解云原生体系的全貌，帮助用户选择云原生实践中的恰当的软件和工具，因此受到广大开发者和使用者的关注和重视。</p> \n <h2 id=\"aeraki-mesh-解决了云原生中的什么问题\">Aeraki Mesh 解决了云原生中的什么问题？</h2> \n <p>Aeraki Mesh 是腾讯云在 Service Mesh 领域的一个开源项目，解决目前的服务网格项目只处理 了 HTTP/gRPC 协议，不支持其他开源及私有协议的痛点。</p> \n <p>Aeraki Mesh 可以帮助你在服务网格中管理任何七层协议。目前已经支持了 Dubbo、Thrit、Redis、Kafka、ZooKeeper 等开源协议。你还可以使用 Aeraki Mesh 提供的 MetaProtocol 协议扩展框架来管理私有协议的七层流量。</p> \n <h2 id=\"aeraki-mesh-的架构及特性\">Aeraki Mesh 的架构及特性</h2> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220314182915550-1207039376.png\" alt=\"\" loading=\"lazy\"><br> （Aeraki Mesh 控制面架构）</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220314182915782-698928967.png\" alt=\"\" loading=\"lazy\"><br> （Aeraki Mesh 数据面架构）</p> \n <p><strong>Aeraki 的主要特点</strong>：</p> \n <ul> \n  <li>和 Istio 无缝集成，是 Istio Ecosystem 集成推荐项目。您可以采用 Istio + Aeraki 来构建一个可以同时管理 HTTP 和其他七层协议的全栈服务网格。</li> \n  <li>支持在 Istio 中管理 Dubbo、Thrift、Redis 等开源协议的流量。</li> \n  <li>支持在 Istio 中管理私有协议的流量，只需数百行代码，对 Istio 无任何改动。</li> \n  <li>支持请求级负载均衡，支持任意匹配条件的动态路由，全局和本地限流，流量镜像等流量管理能力。</li> \n  <li>提供丰富的请求级性能指标，包括请求时延、错误、数量等，支持分布式调用跟踪。</li> \n </ul> \n <p>目前 Aeraki 已经在央视频、腾讯音乐、王者破晓等多个大型项目中得到了应用，并经过了 2022 冬奥会线上大规模流量的实践检验。</p> \n <h2 id=\"我想使用-aeraki-mesh--加入社区贡献\">我想使用 Aeraki Mesh / 加入社区贡献？</h2> \n <p>Aeraki Mesh 是一个厂商中立的开源社区，目前社区正在大力发展中，欢迎大家加入！</p> \n <p><strong>安装试用</strong>： <a href=\"https://www.aeraki.net/zh/docs/v1.0/quickstart/\" target=\"_blank\" rel=\"noopener\">https://www.aeraki.net/zh/docs/v1.0/quickstart/</a></p> \n <p><strong>加入社区会议</strong>： <a href=\"https://www.aeraki.net/zh/community/#community-meetings\" target=\"_blank\" rel=\"noopener\">https://www.aeraki.net/zh/community/#community-meetings</a></p> \n <p><strong>Star 一下</strong>： <a href=\"https://github.com/aeraki-mesh/aeraki\" target=\"_blank\" rel=\"noopener\">https://github.com/aeraki-mesh/aeraki</a></p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <h4 id=\"福利\">福利：</h4> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <p>④公众号后台回复【光速入门】，可获得腾讯云专家5万字精华教程，光速入门Prometheus和Grafana。</p> \n <p>⑤公众号后台回复【精选集】，可获得腾讯24位腾讯云专家精彩演讲——4万字《腾讯云技术实践精选集 2021》。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220314182916169-887311254.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"285","createTime":"2022-03-11 11:49","comment":"0","id":"15993123","title":"分布式边缘容器项目 SuperEdge v0.7.0 版本来袭！","url":"https://www.cnblogs.com/tencent-cloud-native/p/15993123.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>SuperEdge 开发者团队，腾讯云容器中心TKE Edge团队</p> \n <h2 id=\"摘要\">摘要</h2> \n <p>SuperEdge是基于原生Kubernetes的分布式边缘云容器管理系统，由腾讯云牵头，联合英特尔、VMware威睿、虎牙、寒武纪、美团、首都在线等多家厂商在2020年12月共同发起的边缘计算开源项目，旨在将把Kubernetes强大的容器管理能力无缝的扩展到边缘计算和分布式资源管理的场景中，为边缘IoT，边缘AI，边缘智慧行业等赋能，推动物联网和数字化的落地。目前已成为CNCF Sandbox项目，由CNCF基金会进行托管。</p> \n <h2 id=\"superedge-v070-版本正式发布\">SuperEdge v0.7.0 版本正式发布</h2> \n <p>SuperEdge 在2022-02-09 发布了 v0.7.0版本，详情扫下方二维码了解。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220311114858153-1342449746.png\" alt=\"\" loading=\"lazy\"></p> \n <p>本次版本主要是生产落地过程中功能的提炼，有边缘站点资源的抽象和应用的抽象，进行资源和应用的灵活搭配；有实例落地过程中用户对边缘应用高可用和断网更新的实际需求；有边缘Webhook无感知访问诉求的解决；有社区强烈呼吁的K8s的1.20版本、Containerd运容器行时，云边节点混部……功能。也有WasmEdge、GPU和NANO-GPU、云边互通Fabedge的使用案例，以下是功能细节：</p> \n <h3 id=\"新的功能点\">新的功能点</h3> \n <h4 id=\"通过nodunit和nodegroup-crd去管理边缘众多的站点资源\">通过NodUnit和NodeGroup CRD去管理边缘众多的站点资源</h4> \n <ul> \n  <li>用NodeUnit的CR代表一个边缘的逻辑站点；</li> \n  <li>用NodeGroup的CR代表拥有同一属相的边缘站点，比如所有拥有GPU的边缘站点；</li> \n </ul> \n <p>NodeGroup是边缘资源的抽象，ServiceGroup是边缘应用的抽象，两者根据应用的需要进行不同资源属性的绑定，将边缘应用调度到合理的边缘节点上。</p> \n <p>该功能使用文档见：</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220311114859079-701764344.png\" alt=\"\" loading=\"lazy\"></p> \n <h4 id=\"支持云边断网边缘pod可更新\">支持云边断网边缘Pod可更新</h4> \n <p>这个功能是边缘应用高可用的初版，边缘应用不同于K8s的原生应用，硬搬K8s的原生应用并不适合边缘场景，特别是应对边缘应用的高可用和弹性扩展。</p> \n <p>本功能本次只提供在云边断网时，边缘Pod可更新，主要是通过Static Pod实现。后续还会提供更加优雅的方式，以支持边缘应用的高可用和弹性扩展。</p> \n <p>该功能使用文档见：</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220311114900317-1101051200.png\" alt=\"\" loading=\"lazy\"></p> \n <h4 id=\"支持kube-apiserver访问边缘侧的webhook\">支持kube-apiserver访问边缘侧的webhook</h4> \n <p>在边缘应用中存在webhook，那么kube-apiserver是无法直接访问到的。本次在tunnel中支持了ANP，通过kube-apiserver的EgressSelector功能把请求边侧webhook的请求通过Tunnel转发给边缘，实现了边缘集群中webhook的无感知访问。</p> \n <p>该功能使用文档见：</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220311114901361-496489914.png\" alt=\"\" loading=\"lazy\"></p> \n <h4 id=\"edge-health支持用户自定义check-插件\">edge-health支持用户自定义Check 插件</h4> \n <p>edge-health是定时Check边缘站点内节点健康状况的组件。本次借助kube-scheduler的out-of-tree插件注册思想，实现了edge-health的自定义插件功能。用户无须修改edge-health的源码，便可注册自己的Check逻辑。</p> \n <h4 id=\"支持kubernetes-v1206-版本\">支持Kubernetes v1.20.6 版本</h4> \n <p>本次支持了Kubernetes的v1.20.6 版本，目前社区提供了Kubernetes的v1.18.2和 Kubernetes的v1.20.6 eageadm的一键部署，其他版本可按<a href=\"https://mp.weixin.qq.com/s/LATtAVu6l4gUl03sJ96tBQ\" target=\"_blank\" rel=\"noopener\">用 edgeadm 一键安装边缘 K8s 集群和原生 K8s 集群</a>，SuperEdge 需要做组件代码的升级，感兴趣的同学也可来社区，为SuperEdge 做出您的贡献。</p> \n <p>用edgeadm 一键安装边缘K8s的安装包可执行如下命令下载，注意机器的体系：</p> \n <pre><code>arch=amd64 version=v0.7.0 kubernetesVersion=1.20.6 &amp;&amp; rm -rf edgeadm-linux-* &amp;&amp; wget https://attlee-1251707795.cos.ap-chengdu.myqcloud.com/superedge/$version/$arch/edgeadm-linux-$arch-$version-k8s-$kubernetesVersion.tgz &amp;&amp; tar -xzvf edgeadm-linux-* &amp;&amp; cd edgeadm-linux-$arch-$version-k8s-$kubernetesVersion &amp;&amp; ./edgeadm\n</code></pre> \n <p>详细安装请参考<a href=\"https://mp.weixin.qq.com/s/LATtAVu6l4gUl03sJ96tBQ\" target=\"_blank\" rel=\"noopener\">用 edgeadm 一键安装边缘 K8s 集群和原生 K8s 集群</a>，或者<a href=\"https://github.com/superedge/superedge\" title=\"SuperEdge的Quickstart\" target=\"_blank\" rel=\"noopener\">SuperEdge的Quickstart</a>。</p> \n <p>演示短视频：[视频链接](!video<a href=\"/download/attachments/1539578517/edegadm-init-k8s.mp4?version=1&amp;modificationDate=1646881100066&amp;api=v2\" title=\"视频链接\" target=\"_blank\" rel=\"noopener\">edegadm-init-k8s.mp4</a>)</p> \n <p>视频链接: <a href=\"https://attlee-1251707795.cos.ap-chengdu.myqcloud.com/superedge/v0.7.0/edegadm-init-k8s.mp4\" target=\"_blank\" rel=\"noopener\">https://attlee-1251707795.cos.ap-chengdu.myqcloud.com/superedge/v0.7.0/edegadm-init-k8s.mp4</a></p> \n <h4 id=\"支持-containerd-容器运行时\">支持 Containerd 容器运行时</h4> \n <p>在<a href=\"https://mp.weixin.qq.com/s/LATtAVu6l4gUl03sJ96tBQ\" target=\"_blank\" rel=\"noopener\">用 edgeadm 一键安装边缘 K8s 集群和原生 K8s 集群</a>时，可通过参数 <code>--runtime=containerd/dockerd</code>来选择你需要的容器运行时，默认<code>--runtime=dockerd</code>, dockerd 版本是<code>19.03.8</code>, cotainerd版本是<code>1.3.4</code>, 其他版本可替换安装包中的组件二进制。</p> \n <h4 id=\"支持在superedge-边缘k8s集群里面同时添加原生k8s节点和边缘k8s节点\">支持在SuperEdge 边缘K8s集群里面同时添加原生K8s节点和边缘K8s节点</h4> \n <p>在<a href=\"https://mp.weixin.qq.com/s/LATtAVu6l4gUl03sJ96tBQ\" target=\"_blank\" rel=\"noopener\">用 edgeadm 一键安装边缘 K8s 集群和原生 K8s 集群</a> 时，edgedam join 节点时可通过参数 <code>--enable-edge=true</code>来选择Join原生的K8s节点还是边缘K8s节点。默认<code>--enable-edge=true</code> Join 边缘节点，明确指定<code>--enable-edge=false</code>Join 原生的K8s节点。 Join原生K8s节点要注意 Join的节点要和Kubernetes master 二层网络互通，也就是内网互通，否则可当边缘节点处理。</p> \n <h4 id=\"lite-apiserver支持多网卡出口和使用-pebble-作为存储\">lite-apiserver支持多网卡出口和使用 Pebble 作为存储</h4> \n <p>lite-apiserver 是 SuperEdge 的边缘自治组件，本次增强的重要功能如下：</p> \n <ul> \n  <li><strong>lite-apiserver支持多网卡出口</strong>：因为生产环境机器上通常会有多网卡，网络质量并不均等，为了保证lite-apiserver和云端kube-apiserver的质量，可以通过<code>--network-interface</code>参数填入多个网卡，在多个网卡中选择好的网络质量和kube-apiserver保持连接。当然基于多网卡的功能扩展也正在进行。</li> \n  <li><strong>lite-apiserver支持使用Pebble作为缓存存储</strong>：<a href=\"https://github.com/cockroachdb/pebble\" title=\"Pebble\" target=\"_blank\" rel=\"noopener\">Pebble</a> 是受 LevelDB/RocksDB 启发的键值存储，专注于 CockroachDB 的性能。</li> \n </ul> \n <p>更多功能的详细介绍，可查看<a href=\"https://github.com/superedge/superedge/blob/0.7.7/CHANGELOG/CHANGELOG-0.7.md\" title=\"SuperEdge changelog 0.7\" target=\"_blank\" rel=\"noopener\">SuperEdge changelog 0.7</a>.</p> \n <h2 id=\"三个生态合作案例\">三个生态合作案例</h2> \n <ul> \n  <li><a href=\"https://github.com/superedge/superedge/blob/main/examples/wasmedge/wasmedge.md\" title=\"在SuperEdge中部署WasmEdge运行时，来部署WebAssembly应用；\" target=\"_blank\" rel=\"noopener\">在SuperEdge中部署WasmEdge运行时，来部署WebAssembly应用；</a></li> \n  <li><a href=\"https://mp.weixin.qq.com/s/H-xIzIIJ_-osJ3UFSDJGcA\" target=\"_blank\" rel=\"noopener\">用博云开源的Fabedge支持云边网络和边边网络的互通；</a></li> \n  <li><a href=\"https://github.com/superedge/superedge/blob/main/examples/gpu/SuperEdge_GPU_CN.md\" title=\"在SuperEdge使用gpu和nano-gpu，分别来提高计算能力和资源利用率；\" target=\"_blank\" rel=\"noopener\">在SuperEdge使用gpu和nano-gpu，分别来提高计算能力和资源利用率；</a></li> \n </ul> \n <h2 id=\"新晋member和reviwer\">新晋Member和Reviwer</h2> \n <p>SuperEdge 0.7 版本社区很多同学做出了杰出的贡献，经评审有两名同学达到Member级别，有两名同学达到了Reviwer 级别，现公布如下：</p> \n <p><strong>2名Reviwer：</strong></p> \n <ul> \n  <li><a href=\"https://github.com/JaneLiuL\" title=\"@JaneLiuL\" target=\"_blank\" rel=\"noopener\">@JaneLiuL</a></li> \n  <li><a href=\"https://github.com/malc0lm\" title=\"@malc0lm\" target=\"_blank\" rel=\"noopener\">@malc0lm</a></li> \n </ul> \n <p><strong>2名Member：</strong></p> \n <ul> \n  <li><a href=\"https://github.com/luhaopei\" title=\"@luhaopei\" target=\"_blank\" rel=\"noopener\">@luhaopei</a></li> \n  <li><a href=\"https://github.com/huweihuang\" title=\"@huweihuang\" target=\"_blank\" rel=\"noopener\">@huweihuang</a></li> \n </ul> \n <h2 id=\"携手社区\">携手社区</h2> \n <p>扫描下面的二维码加入我们的交流群，共同探讨SuperEdge、研究边缘容器技术。</p> \n <p><img src=\"/download/attachments/1111497337/image-1634109872881.png?version=1&amp;modificationDate=1634109872986&amp;api=v2\" alt=\"enter image description here\" loading=\"lazy\"></p> \n <p><a href=\"https://mp.weixin.qq.com/s/1hxDCUmzOzw4m1_kDi5bbg\" target=\"_blank\" rel=\"noopener\">【从0到N了解 SuperEdge，30+篇干货合集】</a><br> 项目链接：<a href=\"https://github.com/superedge/superedge\" target=\"_blank\" rel=\"noopener\">https://github.com/superedge/superedge</a><br> Release 链接：<a href=\"https://github.com/superedge/superedge/releases/tag/v0.7.0\" title=\"https://github.com/superedge/superedge/releases/tag/v0.7.0\" target=\"_blank\" rel=\"noopener\">https://github.com/superedge/superedge/releases/tag/v0.7.0</a><br> 变更记录：<a href=\"https://github.com/superedge/superedge/blob/main/CHANGELOG/CHANGELOG-0.7.md\" title=\"https://github.com/superedge/superedge/blob/main/CHANGELOG/CHANGELOG-0.7.md\" target=\"_blank\" rel=\"noopener\">https://github.com/superedge/superedge/blob/main/CHANGELOG/CHANGELOG-0.7.md</a><br> 项目文档：<a href=\"https://github.com/superedge/superedge/tree/main/docs\" target=\"_blank\" rel=\"noopener\">https://github.com/superedge/superedge/tree/main/docs</a></p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <h4 id=\"福利\">福利：</h4> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <p>④公众号后台回复【光速入门】，可获得腾讯云专家5万字精华教程，光速入门Prometheus和Grafana。</p> \n <p>⑤公众号后台回复【精选集】，可获得腾讯24位腾讯云专家精彩演讲——4万字《腾讯云技术实践精选集 2021》。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220311114902271-1505270576.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"239","createTime":"2022-03-09 18:13","comment":"0","id":"15986449","title":"使用 Istio CNI 支持强安全 TKE Stack 集群的服务网格流量捕获","url":"https://www.cnblogs.com/tencent-cloud-native/p/15986449.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>陈计节，企业应用云原生架构师，在腾讯企业 IT 负责云原生应用治理产品的设计与研发工作，主要研究利用容器集群和服务网格等云原生实践模式降低微服务开发与治理门槛并提升运营效率。</p> \n <h2 id=\"摘要\">摘要</h2> \n <blockquote> \n  <p>给需要快速解决问题的集群管理员：<br> 在 TKE Stack 中正确安装 Istio CNI 有两种方式：如果你的 TKE Stack 集群所使用 Galaxy 版本可以支持 cniVersion 0.3.1，请以默认的方式安装 Istio CNI；否则请使用以“网卡插件”的方式安装 Istio CNI，并在创建 Pod 时指定使用集群默认网络名称。<br> 如果你发现你的 TKE Stack 集群安装完 Istio CNI 之后，无法创建新的 Pod，请立即卸载已安装的 Istio CNI，并手动恢复各个节点上写入的 Galaxy 配置文件：将 /etc/cni/net.d/00-galaxy.conflist 文件内的 plugins 数组字段的第一个元素提取出来，并保存为单独的 conf 文件： /etc/cni/net.d/00-galaxy.conf。删除正在创建中、但无法成功的 Pod，等待其重建，Pod 的创建功能应该能自动恢复。</p> \n </blockquote> \n <p>Istio 是流行的服务网格软件，它通过向业务 Pod 注入可捕获出入口流量的代理软件 Envoy 作为 Sidecar 来完成对流量的观测与治理。</p> \n <p>Istio 为了让 Envoy 代理能够捕获来去业务容器的流量，需要向 Pod 所在网络下发如下 IPTABLES 规则：</p> \n <pre><code>*nat\n-N ISTIO_INBOUND\n-N ISTIO_REDIRECT\n-N ISTIO_IN_REDIRECT\n-N ISTIO_OUTPUT\n-A ISTIO_INBOUND -p tcp --dport 15008 -j RETURN\n-A ISTIO_REDIRECT -p tcp -j REDIRECT --to-ports 15001\n-A ISTIO_IN_REDIRECT -p tcp -j REDIRECT --to-ports 15006\n-A PREROUTING -p tcp -j ISTIO_INBOUND\n-A ISTIO_INBOUND -p tcp --dport 22 -j RETURN\n-A ISTIO_INBOUND -p tcp --dport 15090 -j RETURN\n-A ISTIO_INBOUND -p tcp --dport 15021 -j RETURN\n-A ISTIO_INBOUND -p tcp --dport 15020 -j RETURN\n-A ISTIO_INBOUND -p tcp -j ISTIO_IN_REDIRECT\n-A OUTPUT -p tcp -j ISTIO_OUTPUT\n-A ISTIO_OUTPUT -o lo -s 127.0.0.6/32 -j RETURN\n-A ISTIO_OUTPUT -o lo ! -d 127.0.0.1/32 -m owner --uid-owner 1337 -j ISTIO_IN_REDIRECT\n-A ISTIO_OUTPUT -o lo -m owner ! --uid-owner 1337 -j RETURN\n-A ISTIO_OUTPUT -m owner --uid-owner 1337 -j RETURN\n-A ISTIO_OUTPUT -o lo ! -d 127.0.0.1/32 -m owner --gid-owner 1337 -j ISTIO_IN_REDIRECT\n-A ISTIO_OUTPUT -o lo -m owner ! --gid-owner 1337 -j RETURN\n-A ISTIO_OUTPUT -m owner --gid-owner 1337 -j RETURN\n-A ISTIO_OUTPUT -d 127.0.0.1/32 -j RETURN\n-A ISTIO_OUTPUT -j ISTIO_REDIRECT\nCOMMIT\n</code></pre> \n <p>在常规安装模式下，下发 IPTABLES 规则的操作，是通过与 Envoy 代理容器一同注入的初始化容器 istio-init 完成的。向 Pod 网络下发 IPTABLES 规则要求 Pod 可以使用 <a href=\"https://man7.org/linux/man-pages/man7/capabilities.7.html\" title=\"NET_ADMIN 和 NET_RAW\" target=\"_blank\" rel=\"noopener\">NET_ADMIN 和 NET_RAW</a> 两个高权限功能（Capabilities）。Linux 将传统与超级用户 root 关联的特权划分为不同的单元，称为 Capabilites。Capabilites 每个单元都可以独立启用和禁用。这样当系统在做权限检查的时候就检查特定的 Capabilites，并决定当前用户其进程是否可以进行相应特权操作。比如如果要设置系统时间，就得具有 CAP_SYS_TIME 这个 Capabilites。</p> \n <h2 id=\"istio-流量捕获功能面临的安全挑战\">Istio 流量捕获功能面临的安全挑战</h2> \n <p>容器本质上是是宿主机上运行的进程，虽然容器运行时默认只向容器提供必要 Capabilities，但如果使用 <code>--privileded</code> 模式运行容器，或者向容器追加更多 Capabilities 时，容器就可以像其他进程一样拥有很高权限的操作能力。这样，能使用 NET_ADMIN 和 NET_RAW 权限的 Pod 理论上不光可以操作自己这个 Pod 的网络，如果处理不当，还可能影响到同一工作节点的其他 Pod 甚至是宿主机的网络配置。通常，这在一些对容器应用的权限严格限制的环境中，是不推荐使用的。</p> \n <p>从 Kubernetes 1.11 版本开始，我们可以在集群中使用 <a href=\"https://kubernetes.io/docs/concepts/policy/pod-security-policy/\" title=\"PodSecurityPolicy\" target=\"_blank\" rel=\"noopener\">PodSecurityPolicy</a> 资源（PSP）来限制集群中的 Pod 可以使用的默认权限或能力。通过编写如下 PSP 即可限制集群内的 Pod 均不得使用任何特权 Capabilities：</p> \n <pre><code class=\"language-yaml\">apiVersion: policy/v1beta1\nkind: PodSecurityPolicy\nmetadata:\n  name: pod-limited\nspec:\n  allowPrivilegeEscalation: false\n  # 不允许使用 Capabilities\n  # allowedCapabilities:\n  #   - '*'\n  fsGroup:\n    rule: RunAsAny\n  runAsUser:\n    rule: RunAsAny\n  supplementalGroups:\n    rule: RunAsAny\n  volumes:\n  - configMap\n  - downwardAPI\n  - emptyDir\n  - persistentVolumeClaim\n  - secret\n  - nfs\n</code></pre> \n <p>可想而知，在一个添加了上述限制的集群上，istio-init 容器由于无法获得相应特权，将无法完成预定工作：无法让 Envoy 代理软件捕获 Pod 中的流量。这样整个 Istio 软件的功能也就无从谈起了。此外，从 Kubernetes 1.21 版本开始， PSP 功能将逐步被弃用。新版集群上可能使用其他替代机制限制 Pod 权限。</p> \n <h3 id=\"使用-istio-cni-解决权限扩散问题\">使用 Istio CNI 解决权限扩散问题</h3> \n <p>上面谈到的安全风险来自于在所有需要注入 Sidecar 的业务 Pod 均需要同步注入高权限 istio-init 容器，而业务 Pod 可以由使用集群的任何人来创建和使用。这对于集群来说，就构成了攻击面的无限蔓延。这类问题的解决思路，通常是将攻击面集中化管理。也就是说，由少量可控的高权限 Pod 来侦听 Pod 创建的过程，在 Pod 启动前，为它们完成 IPTABLES 下发过程。</p> \n <p>这正是 <a href=\"https://istio.io/latest/docs/setup/additional-setup/cni/\" title=\"Istio CNI\" target=\"_blank\" rel=\"noopener\">Istio CNI</a> 所解决的问题。</p> \n <p>通常，如果要侦听 Pod 创建、删除的事件，使用 Imformer 机制即可很轻松地获取到集群内各类资源的创建与回收事件。这也是在 Kubernetes 中开发各类 Controller 所常见的做法。但为 Pod 下发 IPTABLES 规则的任务与普通 Controller 有所不同：它需要在 Pod 事件创建或删除时，在 Pod 所在工作节点上，进入相应容器的 Linux Namespace，并下发 IPTABLES 规则。从执行位置来说，这更像是一种 Daemonset。另一方面，对 Pod 的创建和删除事件的处理恰好与 CNI 定义的一些命令吻合，CNI 是 Kubernetes 定义的用于为 Pod、Service 提供网络的机制。正好下发 IPTABLES 也是一种网络相关的操作，所以 Istio 团队也就索性直接以 CNI 插件的方式提供这一功能。</p> \n <p>Istio CNI 的工作流程如下图：</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220309181231434-821564176.png\" alt=\" \" loading=\"lazy\"></p> \n <p>Istio CNI DaemonSet 负责将 Istio CNI 插件的可执行程序安装到工作节点上。这些程序稍后在新的业务 Pod 创建或销毁时会收到来自 k8s 的调用，接着它们完成 IPTABLES 规则的配置。由于这些程序是运行在工作节点上，因此具有较高的权限：但它们可以被集中管理，因此权限是受控的，而业务 Pod 此时不再需要高权限来配置这些 IPTABLES，只需要运行一个简单的检查程序，确保业务容器运行之前，这些规则已就绪即可。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220309181232269-609200585.png\" alt=\"\" loading=\"lazy\"></p> \n <p>上图是 Istio 自注入模板的代码片断，从中可以看出，当启用 Istio CNI 时，如果启用了 Istio CNI 功能，Istio 向 Pod 注入的容器不再需要高权限。</p> \n <h3 id=\"在-tke-stack-中安装-istio-cni-的问题\">在 TKE Stack 中安装 Istio CNI 的问题</h3> \n <p>与普通 CNI 插件不同，Istio CNI 并不提供常规的 IP 地址管理（IPAM）和联网（SDN）功能。它只在 Pod 的网络已建立之后，负责下发上述规则。因此，Istio CNI 并不会、也不能替换集群现有的 CNI 插件的功能。也就是说，在配置 Istio CNI 之外，k8s 集群还需要配置其他负责 IPAM 和 SDN 的软件，比如我们熟悉的 Flannel 或 Calico 等。</p> \n <p>为了配合不同种类的现有 CNI 插件，Istio CNI 既能以“网卡插件”（Interface Plugins）的方式运行，也能以“插件链”（Chained Plugins）的方式附加到现有网卡插件运行。根据 CNI 标准的描述，网卡插件是用于创建虚拟网卡的 CNI 插件，而插件链则允许多个插件为已创建的网卡提供附加功能。插件链模式很符合 Istio CNI 的定位，也是 Istio CNI 的默认运行方式。在这种运行方式下，Istio CNI 先会检查集群当前 CNI 插件的配置：如果它已经是一个插件链，则将自身添加到它的尾部，成为新的功能；如果当前插件是一个“网卡插件”，则先将其转换为插件链，再将自身添加到链的尾部。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220309181232538-1430469765.png\" alt=\"\" loading=\"lazy\"></p> \n <p><a href=\"https://github.com/tkestack\" title=\"TKE Stack\" target=\"_blank\" rel=\"noopener\">TKE Stack</a> 是由腾讯主导的开源 k8s 发行版，与社区版 k8s 相比，TKE Stack 主要提供了更强的网络接入能力、多集群管理能力，以及将容器资源与业务和用户等因素集成管理等丰富的功能。TKE Stack 也是腾讯云提供的容器服务的开源版本，在腾讯内部部署了超过数十万核的超大规模集群，稳定运行了数年。</p> \n <p>TKE Stack 的默认 CNI 插件是 Galaxy，它是一个能让集群接入各类网络插件的“元 CNI”框架：基于它，我们可以让集群中的 Pod 基于 Flannel 之类的插件获得普通 Overlay 网络的同时，还可以基于其他插件获得诸如 Underlay 网络等强大的能力。比如，典型的 Underlay 网络可以提供的能力有，可以让 Pod 获取到另一个子网（比如工作节点所在子网）的 IP 地址、获取固定 IP 地址等。</p> \n <p>经过测试发现，在一些集群上，Istio CNI 插件默认的插件链运行模式与 Galaxy 不能兼容。原因是，<a href=\"https://github.com/istio/istio/issues/32137\" title=\"Istio CNI 的配置转换处理过程存在瑕疵\" target=\"_blank\" rel=\"noopener\">Istio CNI 的配置转换处理过程存在瑕疵</a>：这些集群上的原有 Galaxy CNI 的配置是网卡插件（即 00-galaxy.conf）模式， 经过 Istio CNI 的处理之后，相关配置无法被 Galaxy CNI 识别和处理。</p> \n <p>具体原因是，Istio CNI 在将原有配置复制为插件链模式的过程中，会删除原配置中的 cniVersion 版本号（如果有），在新生成的插件链配置文件 00-galaxy.conflist 时，将此版本号强制改为 Galaxy CNI 尚未支持的 0.3.1。进入 Galaxy CNI 相关 daemonset 容器，并模拟执行 CNI 版本检查命令，可以发现此集群上 Galaxy CNI 支持的 cniVersion 最高为 0.2.0。相关源码可<a href=\"https://github.com/istio/istio/blob/master/cni/pkg/install/cniconfig.go#L276\" title=\"点击此处\" target=\"_blank\" rel=\"noopener\">点击此处</a>。</p> \n <pre><code class=\"language-sh\">CNI_COMMAND=VERSION /opt/cni/bin/galaxy-sdn &lt;/etc/cni/net.d/00-galaxy.conf\n</code></pre> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220309181233342-1875014628.png\" alt=\"\" loading=\"lazy\"></p> \n <p>在这样的 TKE Stack 集群中以插件链模式运行 Istio CNI 之后，将出现新 Pod 无法创建的问题。具体错误为：plugin galaxy-sdn does not support config version \"0.3.1\"。从 Pod 创建日志及 kubelet 上都可以找到这一错误信息。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220309181234082-475968873.png\" alt=\"\" loading=\"lazy\"></p> \n <p>更糟糕的是，即使此时卸载 Istio CNI，仍然不能恢复 Galaxy CNI 的功能。这是因为虽然 Istio CNI 卸载过程会尝试回退它做的修改，但是回退过程只是将 Istio CNI 相关内容从新创建的 conflist 格式配置中移除，而并未将 CNI 配置文件恢复为原始的 conf 格式，无法识别的版本号 0.3.1 被保留了下来。</p> \n <p>此时，需要管理员登录每台集群工作节点，手工将 /etc/cni/net.d/00-galaxy.conflist 文件内的 plugins 数组字段的第一个元素提取出来，并保存为单独的 conf 文件： /etc/cni/net.d/00-galaxy.conf。删除正在创建中、但无法成功的 Pod，等待其重建，Pod 的创建功能应该能自动恢复。</p> \n <h2 id=\"istio-cni-安装问题的解决思路\">Istio CNI 安装问题的解决思路</h2> \n <p>明确了问题的缘由，要解决这些问题就很直接了。在 TKE Stack 集群中安装 Istio CNI 的两个思路是：</p> \n <ol> \n  <li>使用网卡插件的方式运行 Istio CNI</li> \n  <li>升级 TKE Stack 集群中的 Galaxy CNI 版本</li> \n </ol> \n <h3 id=\"使用网卡插件的方式运行-istio-cni\">使用网卡插件的方式运行 Istio CNI</h3> \n <p>既然 Istio CNI 提供了网卡插件的运行方式，那启用它是一种比较轻松的处置方法。安装 Istio CNI 时，关闭 chained 参数即可以网卡插件的方式运行 Istio CNI。如果是为已有 Istio 集群补充安装 Istio CNI，则可能需要手工修改位于 istio-system 命名空间的 Istio 注入模板配置 configmap/istio-sidecar-injector 资源中的 values 数据。其中的 istio_cni 配置节：</p> \n <pre><code class=\"language-json\">\"istio_cni\": {\n  \"enabled\": true,\n  \"chained\": false\n}\n</code></pre> \n <p>需要注意的是，以网卡模式运行的 Istio CNI，会在 Pod 创建为其时添加 k8s.v1.cni.cncf.io/networks 注解（Annotation），以便通知集群上可以支持这个注解的 CNI 插件调用 Istio CNI 完成功能。Galaxy CNI 作为一个元 CNI 插件，是可以支持这个注解的。当 Galaxy 遇到这个注解时，将会跳过默认的 Galaxy 网络插件，而启用注解中配置的 CNI 插件。Istio CNI 并不实际提供联网功能，因此如果只运行 Istio CNI 会导致 Pod 无法获得正确的 IP，因此还是无法正确创建。以下代码片断来自 Istio 注入模板，从中可以看出其中的逻辑：</p> \n <pre><code class=\"language-go\">  {{- if and (.Values.istio_cni.enabled) (not .Values.istio_cni.chained) }}\n  {{ if isset .ObjectMeta.Annotations `k8s.v1.cni.cncf.io/networks` }}\n    k8s.v1.cni.cncf.io/networks: \"{{ index .ObjectMeta.Annotations `k8s.v1.cni.cncf.io/networks`}}, istio-cni\"\n  {{- else }}\n    k8s.v1.cni.cncf.io/networks: \"istio-cni\"\n  {{- end }}\n  {{- end }}\n</code></pre> \n <p>从上面的代码中可以看出，Istio 模板尝试读取 Pod 上已有的注解值，并将 istio-cni 追加到末尾。这样，我们只需要在创建 Pod 时将 Galaxy 默认的网络配置名称以注解的方式提前列出，即可正确创建 Pod。从 kube-system 命名空间中的 configmap/galaxy-etc 配置的 DefaultNetworks 可以找到当前 Galaxy CNI 的默认网络名称。</p> \n <pre><code class=\"language-yaml\">kind: Pod\nmetadata:\n  annotations:\n    k8s.v1.cni.cncf.io/networks: galaxy-flannel\n  name: my-pod\n</code></pre> \n <p>实际测试结果表明，以网卡插件模式运行 Istio CNI，并在 Pod 上标记原有网络模式，即可在 TKE Stack 上成功运行 Pod 并正常使用 Istio 的各项功能。</p> \n <h3 id=\"升级-tke-stack-集群中的-galaxy-cni\">升级 TKE Stack 集群中的 Galaxy CNI</h3> \n <p>虽然以独立网卡插件模式运行 Istio CNI 是可以解决 Pod 无法创建的问题的，但是由于需要向 Pod 上添加额外的注解，所以给应用开发者或者部署流水线增加了额外的复杂度，甚至有可能影响 Pod 使用 Galaxy CNI 提供的其他网络功能。比较理想的效果是，能像 Istio CNI 原生提供的那样，能透明地支持相关功能。</p> \n <p>幸运的是，在最新的 1.0.8 版本 的 Galaxy CNI 的代码中，已经支持了 0.4.0 及之前版本的各个 cniVersion。因此将 Galaxy CNI 的版本升级到最新版，就能以默认插件链模式运行 Istio CNI 了。如果你的集群中的组件经过了自己团队的定制，则需要联系这些定制组件的开发团队核实他们所使用的上游版本，并提醒他们升级 Galaxy 组件的版本。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220309181234370-414709982.png\" alt=\"\" loading=\"lazy\"></p> \n <p>升级到最新版本的 Galaxy 组件之后，再运行相应的验证脚本，可以发现新版本的 Galaxy 已支持包括 0.3.1 在内的多个 cniVersion。</p> \n <h2 id=\"总结\">总结</h2> \n <p>作为流行的服务网格软件，Istio 可以为微服务提供接近无侵入的强大流量治理能力和丰富的观测能力。而 Istio 这些能力都来源于它对来往业务容器的网络流量的完全捕获能力。</p> \n <p>虽然 Istio 本身提供了多种在指定命名空间安装的特性，但将 Istio 作为一个集群级基础平台能力是众多团队的首选。而在一些公开的多租户集群、有特殊安全策略要求等复杂的集群环境，安装和运营 Istio 会面临一些独特的挑战。</p> \n <p>本文简要介绍了在安全限制严格的集群中，要使用 Istio 流量治理功能所依赖的 IPTABLES 网络策略需要的 Istio CNI 插件的运行原理，以及要在 TKE Stack 集群中运行 Istio CNI 会遇到的问题和解决方法。运用这些方法，可以较好地使用较低的权限运行业务应用的同时，以兼容集群现有网络功能的方式，提供 Istio 的完整功能。</p> \n <h2 id=\"参考资料\">参考资料</h2> \n <ul> \n  <li><a href=\"https://istio.io/latest/docs/setup/additional-setup/cni/\" title=\"Istio CNI 的安装方法\" target=\"_blank\" rel=\"noopener\">Istio CNI 的安装方法</a></li> \n  <li><a href=\"https://github.com/containernetworking/cni/blob/master/SPEC.md#section-1-network-configuration-format\" title=\"Kubernetes CNI 插件标准\" target=\"_blank\" rel=\"noopener\">Kubernetes CNI 插件标准</a></li> \n  <li><a href=\"https://cloud.redhat.com/blog/increasing-security-of-istio-deployments-by-removing-the-need-for-privileged-containers\" title=\"在 OpenShift 上消除 Istio Pod 高权限并提高安全性\" target=\"_blank\" rel=\"noopener\">在 OpenShift 上消除 Istio Pod 高权限并提高安全性</a></li> \n  <li>[Linux 上的 Capabilities](<a href=\"https://www.qikqiak.com/post/capabilities-on-k8s/%20https://istio.io/latest/docs/setup/additional-setup/cni/\" target=\"_blank\" rel=\"noopener\">https://www.qikqiak.com/post/capabilities-on-k8s/ https://istio.io/latest/docs/setup/additional-setup/cni/</a> \"Linux 上的 Capabilities</li> \n </ul> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <h4 id=\"福利\">福利：</h4> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <p>④公众号后台回复【光速入门】，可获得腾讯云专家5万字精华教程，光速入门Prometheus和Grafana。</p> \n <p>⑤公众号后台回复【精选集】，可获得腾讯24位腾讯云专家精彩演讲——4万字《腾讯云技术实践精选集 2021》。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220309181235413-247302153.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"92","createTime":"2022-03-04 18:26","comment":"0","id":"15965627","title":"24位腾讯云专家精彩演讲，4万字《腾讯云技术实践精选集 2021》发布！（附合集下载）","url":"https://www.cnblogs.com/tencent-cloud-native/p/15965627.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"摘要\">摘要</h2> \n <p>随着创新技术的发展，数字经济也迎来了新的风口。新风口下，企业该如何进行云原生改造，实现成本优化？如何对基础架构和数据库技术进行创新，化解可用性、可靠性、高并发、性能、稳定性等难题？</p> \n <p>腾讯云近期发布的《腾讯云技术实践精选集 2021》，旨在将过往积累的成功技术和解决方案经验，向外部技术同仁赋能输出，推动产业升级，促进业务创新。</p> \n <h2 id=\"听技术专家真知灼见\">听：技术专家真知灼见</h2> \n <p>《腾讯云技术实践精选集 2021》收录24位腾讯云技术专家在 QCon、ArchSummit、GMTC 等技术大会中的演讲内容，一起帮助更多互联网行业同仁，学习腾讯云在技术演进、能力落地以及行业探索等方面的经验。</p> \n <h3 id=\"精--选--集--亮--点\">精 选 集 亮 点</h3> \n <p>· 24位腾讯云技术专家</p> \n <p>真知灼见的大会演讲内容</p> \n <p>· 创新技术解读<br> 多角度阐述技术演进和创新</p> \n <p>· 实践案例加持<br> 丰富的行业探索和落地案例</p> \n <h3 id=\"精--选--集--内--容--解--读\">精 选 集 内 容 解 读</h3> \n <p>· 云原生技术应用<br> 涵盖 Serverless、Kubernetes、容器等技术应用的落地实践，助力企业提升开发效率，实现成本优化。</p> \n <p>· 数据库与存储技术</p> \n <p>探索云原生数据库、企业级分布式数据库、存储数据湖等当下热门技术和产品，激发企业技术新活力。<br> · 前端业务架构<br> 前端业务架构解析、TRTC Web SDK 新架构设计、低代码实践、音视频跨平台应用。<br> · 架构设计<br> 解读十亿级 Node.js 网关架构、亿级 QPS 系统演进、微服务治理架构实践。</p> \n <p><strong>「腾讯云原生」公众号后台回复“精选集”或“技术实践”</strong></p> \n <p><strong>即可免费下载《腾讯云技术实践精选集 2021》</strong></p> \n <h2 id=\"学云原生成本优化创新实践\">学：云原生成本优化创新实践</h2> \n <p>上云，成为企业转型升级的必经之路。但不同企业上云后，其成本节省程度从10%到70%差异巨大。有什么组织管理手段和产品技术手段可以降低企业上云成本？</p> \n <p>在《腾讯云技术实践精选集 2021》中，腾讯云专家工程师于广游详细阐述了企业 IT 资源成本节省差异大的原因，解答了企业如何借助云原生进行更深层次的成本优化，并分享了解决路径和最佳实践。</p> \n <h3 id=\"解--决--路--径\">解 决 路 径</h3> \n <p>· 弹性伸缩<br> 腾讯云从云原生、大数据等多角度推动业务按需使用，用多少申请多少，消除浪费。<br> · 在离线混部<br> 如意 RUE 解决方案，确保业务不用动，平台方进行资源腾挪复用，提升资源利用率。</p> \n <h2 id=\"实--践--案--例\">实 践 案 例</h2> \n <p>· 外部客户<br> 通过优化资源碎片、在离线混合部署、自动扩缩容，企业整体计算成本下降了 43%。<br> · 腾讯内部<br> 在进行全面云原生改造后，平均资源利用率达到了46.5%，样板集群资源利用率达 65%。</p> \n <p><strong>「腾讯云原生」公众号后台回复“精选集”或“技术实践”</strong></p> \n <p><strong>即可免费下载《腾讯云技术实践精选集 2021》</strong></p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <h3 id=\"福利\">福利：</h3> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <p>③公众号后台回复【光速入门】，可获得腾讯腾讯云专家5万字精华教程，光速入门Prometheus和Grafana。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2022.cnblogs.com/other/2041406/202203/2041406-20220304182534578-237239887.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"99","createTime":"2022-02-11 15:49","comment":"0","id":"15883546","title":"技术集锦 | 大数据云原生技术实战及最佳实践系列","url":"https://www.cnblogs.com/tencent-cloud-native/p/15883546.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <p>随着云平台、容器等技术的不断成熟，云原生大数据解决了传统大数据平台建设和运维中的繁琐，使即时可得，按需分配的高效大数据开发平台成为可能。<br> 云原生的到来不止为大数据部署和交付带来了变革，它更是帮助大数据连接了一个生态。利用云原生生态，真正做到了为大数据赋予云的能力，使得大数据可以“生长在云端”。<br> 【腾讯云原生】收集了关于大数据云原生系列干货文8篇，帮助你更好了解”大数据云原生“，一定要收藏哦！</p> \n <h2 id=\"技术原理\">技术原理</h2> \n <p><a href=\"https://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247484206&amp;idx=1&amp;sn=8bb9ec250d38f9832113fce6bb090927&amp;chksm=c007b8f4f77031e2efab2bbc2326c9af9c44bc3494dff924eedef181f40ac06bb1771db73b01&amp;scene=21#wechat_redirect\" target=\"_blank\" rel=\"noopener\">Apache Flink on K8s：四种运行模式，我该选择哪种？</a></p> \n <ul> \n  <li>本文根据 Flink 在 Kubernetes 集群上的运行模式的趋势，依次分析了这些模式的特点，并在最后介绍了 Flink operator 方案及其优势。</li> \n </ul> \n <p><a href=\"https://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247485741&amp;idx=1&amp;sn=ef4b080884fca9e7bd5d24fc9cdfc0a8&amp;chksm=c007b2f7f7703be1eb5f09686c25d753372019ec7cee0142584f7ff3618c11dc405020222d8b&amp;scene=21#wechat_redirect\" target=\"_blank\" rel=\"noopener\">大数据平台是否更应该容器化？</a></p> \n <ul> \n  <li>随着 Kubernete 技术的成熟，使大数据容器化从设想变成了可能。通过容器化技术可以像在线业务场景一样在大数据场景进一步提升运维管理和资源使用的效率，进一步释放大数据的活力。</li> \n </ul> \n <p><a href=\"https://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247488081&amp;idx=1&amp;sn=9ebcbfa52ddb0a7b17feee58b23d3da4&amp;chksm=c007a98bf770209d92a27500c93ddf84915919a0501e0c1e04a87694c32e2cbe8020cf09df06&amp;scene=21#wechat_redirect\" target=\"_blank\" rel=\"noopener\">大数据系统云原生渐进式演进最佳实践</a></p> \n <ul> \n  <li>本文依次分析了大数据系统当前面临的主要问题、云原生如何解决这些问题、大数据系统云原生改造面临的挑战，基于这些问题和调整，重点介绍了基于 Hadoop Yarn on Kubernetes Pod 的渐进式的云原生演进方案及其最佳实践。</li> \n </ul> \n <p><a href=\"https://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247489101&amp;idx=1&amp;sn=d634dd6211ba979002d9e51e4f3b939f&amp;chksm=c007ad97f7702481298b8fb9ec39e660697de65b272836148b2b049ee3700067d65b1d43b700&amp;scene=21#wechat_redirect\" target=\"_blank\" rel=\"noopener\">使用 Iceberg on Kubernetes 打造新一代云原生</a></p> \n <ul> \n  <li>本文主要介绍如何利用 Iceberg 与 Kubernetes 打造新一代云原生数据湖。</li> \n </ul> \n <p><a href=\"https://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247489507&amp;idx=1&amp;sn=e1f4b44fbd212350359da759749367b5&amp;chksm=c007ac39f770252f65e3439d3206151f417f103ea9b3a5ca5ac17f48ccacb06949269d7786d0&amp;scene=21#wechat_redirect\" target=\"_blank\" rel=\"noopener\">基于云原生的大数据实时分析方案实践</a></p> \n <ul> \n  <li>本文主要介绍如何利用 Kubernetes 实现云原生大数据实时分析平台。</li> \n </ul> \n <h2 id=\"案例分享\">案例分享</h2> \n <p><a href=\"https://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247489473&amp;idx=1&amp;sn=ea82dd73dde466a966463e08917d94cf&amp;chksm=c007ac1bf770250d475911c8212cb3e70915935606a823dfd89c15a73257b0c3e411e622cc01&amp;scene=21#wechat_redirect\" target=\"_blank\" rel=\"noopener\">连夺双奖，腾讯云大数据云原生究竟凭什么？</a></p> \n <ul> \n  <li>由 InfoQ 发起组织的【 2020 中国技术力量年度榜单评选】中，腾讯云大数据云原生技术脱颖而出，荣获“2020年度十大云原生创新技术“”。</li> \n </ul> \n <p><a href=\"https://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247495080&amp;idx=1&amp;sn=4db219fdc316d16708292ee20e3b6705&amp;chksm=c0045672f773df64606f96687a048624c5c66e5939a5136c53b2a4e4b6a77ff09f9ae7b0efe3&amp;scene=21#wechat_redirect\" target=\"_blank\" rel=\"noopener\">微信 Flink on Kubernetes 实战总结</a></p> \n <ul> \n  <li>使用 Kubernetes，并基于腾讯云 TKE 容器平台逐步搭建我们的大数据计算平台，Flink on Kubernetes 实战之路。</li> \n </ul> \n <p><a href=\"https://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247495290&amp;idx=1&amp;sn=e460005b81edaae141f4a83031780e11&amp;chksm=c00455a0f773dcb667e2f7414404b02567fd595295ee3ba7b7fa4424783d9afa4c030265982d&amp;scene=21#wechat_redirect\" target=\"_blank\" rel=\"noopener\">吹皱一池湖水，腾讯云原生数据湖计算重磅发布</a></p> \n <ul> \n  <li>敏捷高效，开箱即用。</li> \n </ul> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <h3 id=\"福利\">福利：</h3> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <p>③公众号后台回复【光速入门】，可获得腾讯腾讯云专家5万字精华教程，光速入门Prometheus和Grafana。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2022.cnblogs.com/other/2041406/202202/2041406-20220211154832745-1754318121.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"227","createTime":"2022-01-27 16:32","comment":"0","id":"15850314","title":"从重大漏洞应急看云原生架构下的安全建设与安全运营（下）","url":"https://www.cnblogs.com/tencent-cloud-native/p/15850314.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"前言\">前言</h2> \n <p>前一篇文章中，我们简要分析了对于重大安全漏洞，在云原生架构下该如何快速进行应急和修复，以及云原生架构对于这种安全应急所带来的挑战和优势。事件过后我们需要痛定思痛，系统的来思考下，面对云原生架构如何进行有效的安全建设和安全运营，使得我们在安全事件的处置上可以做到游刃有余。</p> \n <p><strong>腾讯云容器服务TKE目前拥有国内最大规模的Kubernetes集群</strong>，运行了包括游戏、支付、直播、金融等多个应用场景。而集群的稳定运行离不开安全能力的保驾护航，腾讯云容器安全服务TCSS掌握了业内最前沿的云原生安全视角，为TKE的安全治理提供持续指导并沉淀了丰富的思考和最佳实践。</p> \n <p>本文将结合我们的安全建设和安全运营实践，系统的分享我们对于云原生架构下安全建设和安全运营的思考。</p> \n <h2 id=\"云原生架构下的安全建设与安全运营\">云原生架构下的安全建设与安全运营</h2> \n <p><strong>安全运营是目标，安全能力是手段</strong>。安全能力的建设与安全运营有着紧密的关系，安全能力建设是安全运营的基础，巧妇难为无米之炊，更好的安全能力建设可以使安全运营更加顺畅，同样安全运营也能给安全能力建设提供更好的输入和反馈，使安全检测和防护能力更加精准。</p> \n <p>云原生架构下的安全能力建设和运营，其实是一个很大的命题，限于篇幅本文不会完全覆盖。本文主要围绕log4j2漏洞这个典型场景，从安全运营的视角，分析安全能力建设的必选项。</p> \n <h3 id=\"传统的安全能力建设必不可少\">传统的安全能力建设必不可少</h3> \n <p>首先需要说明的是，不管是我们现在讲的容器安全，还是云原生安全，都是一个相对狭义的概念，通常只包含了云原生架构下特有安全风险的检测与防护。从安全风险角度来看，我们也一直强调，云原生架构下的安全风险是一个增量，因此在整体的安全建设上，一定是个纵深防御的体系，不是某个产品单打独斗所能完成的。</p> \n <p>例如南北向流量出入口的WAF、防火墙、抗D等，假如我们的云原生是建立在IaaS基础之上的，那么VPC、甚至是underlay层面的网络分级分域的隔离和入侵检测，这些都是云原生安全建设的基础。</p> \n <p>在这次log4j2漏洞的应急处置中，我们也发现，即使是容器环境，通过升级WAF规则、更新防火墙出站策略等方式，也能在第一时间实现一定程度的漏洞缓解和阻断。</p> \n <p>腾讯云在2021年11月发布的《腾讯云容器安全白皮书》中，也提出了层次化的容器安全体系框架，其中很重要的一部分就是基础安全，这里的基础安全就是包括了原有的数据中心安全以及云安全建设所覆盖的内容。</p> \n <h3 id=\"安全运营驱动安全能力建设\">安全运营驱动安全能力建设</h3> \n <p>对于体系化的安全建设和安全运营，一些技术组织以及标准化组织，也提出过相关的标准框架，这些框架对于我们在安全建设上，都有着重要的指导和参考意义，这里我们以NIST提出的网络安全框架 为例来作为我们云原生安全建设的参考。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202201/2041406-20220127163226948-1580584841.webp\" alt=\"图片\" loading=\"lazy\"></p> \n <p>参考NIST网络安全框架，我们同样将云原生安全建设划分为五个并行并且连续的步骤，分别是识别、防护、检测、响应和恢复。</p> \n <h4 id=\"安全识别\">安全识别</h4> \n <p><strong>（1）集群资产识别</strong></p> \n <p>安全识别最主要是体现在资产识别上。这里的资产既包括cluster、node、namespace、pod、service、container等Kubernetes资源层面的资产，同样还包括镜像仓库、容器镜像等维度的应用资产信息。</p> \n <p>云原生架构下，除了基本的资产识别盘点之外，还需要能够发现这些资产之间潜在的资源和业务之间的逻辑关系。这样一旦检测到某个镜像包含新的漏洞，或者检测到相应的入侵行为，需要能够快速进行所有资产和人员的自动化关联定位，发现影响范围，以及定位安全责任人，进而快速进行处置。</p> \n <p><strong>（2）自建容器识别</strong></p> \n <p>除了对于标准集群层面的资产具备上述识别能力外，对于研发系统等相对复杂的环境同样需要有一定的适配能力。例如，在研发环境中，除了标准集群层面的资产外，还会出现自建的资产，例如用户用Docker run等命令直接拉起运行的容器。</p> \n <p><strong>（3）业务风险识别</strong></p> \n <p>从安全运营角度看，安全识别还体现在业务风险识别上。我们需要对集群、应用进行清晰的安全风险级别划分，对于高风险应用，需要采用更高级别的安全策略。例如，对于核心业务系统，要有严格的网络隔离以及访问控制机制，对于直接暴露出去的服务，在容器维度要有更加严格的权限控制等。</p> \n <h4 id=\"安全防护\">安全防护</h4> \n <p>具备资产以及业务风险信息后，接下来就需要依赖基本的安全防护能力，实现对已知威胁的安全防护。这里的安全防护主要包括两个方面：</p> \n <p><strong>（1）系统加固</strong></p> \n <p><strong>• 配置检测与修复</strong></p> \n <p>系统加固可谓是个老生常谈的话题了，尤其是配置检查与安全配置加固，但是在云原生架构下，这一点是尤为重要的。因为从容器的设计理念来看，其与操作系统共享内核，给了容器用户更大的可操作空间，因此，配置的安全与否将在很大程度上影响着整个系统的安全性。</p> \n <p>从前文的容器环境主要入侵路径可以看出，通过主机攻击容器是其中重要的一种路径，例如通过Docker Remote API。因此安全能力需要包括全面的配置检查。</p> \n <p>配置加固虽然说起来是个老问题，但是在云原生环境中，真正实现完整的安全能力还是比较复杂，这既包括Kubernetes、Docker、Istio等基础平台与组件的加固，还包括镜像内应用软件的配置加固，这个做起来就更复杂一些。我们在这里就不再展开。</p> \n <p>从安全运营角度看，我们需要能够根据配置检查得到的信息，将基本的配置进行安全性加固。同时一个重要的点就是，安全配置与业务稳定运行之间的平衡，一方面需要保证充分实现了安全性，另一方面就是不会对业务的可用性和稳定性造成影响。这就需要在配置加固的同时，结合业务特性与安全配置要求，灵活对配置策略进行调整，这将会是一个持续的修正和完善的过程。</p> \n <p><strong>• 漏洞检测与修复</strong></p> \n <p>已知漏洞修复同样是个古老的话题，包括主机层面的漏洞和镜像的漏洞，对于检测出来的漏洞，需要根据漏洞的威胁等级以及利用难易程度等信息，确定是否需要修复以及修复的优先级。</p> \n <p><strong>• 镜像安全评估与修复</strong></p> \n <p>容器镜像作为云原生应用的源头，除了漏洞之外，还需要进行更多维度的安全性评估。例如至少需要包含以下几个方面：镜像内敏感信息的检测，确保不会发生敏感信息泄露；镜像中病毒木马等恶意文件检测，这主要针对不确定来源的公开镜像；镜像构建的合规性检测，比如COPY和ADD的使用区别等。</p> \n <p>除了针对上述镜像风险的检测和修复之外，在安全运营上还需要考虑对僵尸镜像清理，这既包括对镜像仓库的清理，也包括对集群node节点的清理，这对于减小攻击面有着重要的作用。</p> \n <p>同时，针对不同镜像需要支持自定义的检测规则，不同的组织用户或者不同类型业务的镜像，对安全的要求是不一样的，因此在镜像的安全评估上，除了基于一套通用的检测评价规则之外，还需要支持用户的自定义规则，这样可以结合前文的业务风险识别，针对不同的镜像，灵活采用不同的安全规则。</p> \n <p><strong>• 风险管理</strong></p> \n <p>在运营管理上，针对上述提及的配置、漏洞等风险信息，需要有一套完善的闭环风险管理流程，确保完全实现了风险的识别、修复以及确认。</p> \n <p><strong>（2）安全防护</strong></p> \n <p>除了系统加固外，在安全防护阶段，还应该在不同层面，针对已知可能发生的入侵风险，通过相关的防护能力和防护策略进行攻击的预防。</p> \n <p><strong>• 准入控制</strong></p> \n <p>准入控制顾名思义就是在云原生应用的全生命周期流程中，根据安全的要求，在不同的阶段进行控制和阻断，进而实现安全性的目标，这也是DevSecOps的一项基本要求。云原生架构凭借其灵活的资源管理与自动化的应用编排，给安全性的控制提供了充分的便利。准入控制的价值，一方面体现在安全风险的预防上，另一方面，一旦log4j等重大0day爆发后，可以通过准入控制，快速控制影响面，防止风险新增。</p> \n <p>从生命周期流程看，准入控制需要分别从研发（dev）和运行时(ops)两个阶段来实施。研发阶段的准入主要指在CI、入库等阶段，进行漏洞、敏感信息之类的安全风险的检测，只有符合安全要求后，才允许进入流水线的下一个阶段。这里的准入条件通常需要涵盖前文讲的各种加固内容。</p> \n <p>运行时的准入控制，则主要体现在应用被部署运行的阶段，只有符合安全要求的容器/pod，才允许被拉起运行，这里的准入条件通常包括对资源限制的检测、对syscall/capability等权限限制的检测等。</p> \n <p>同样，从运营的角度看，准入控制规则除了标准默认的之外，还需要能够根据应用进行灵活则调整和完善。</p> \n <p><strong>• 运行时拦截</strong></p> \n <p>云原生架构下的容器内，承载的是微服务应用，因此理论上是不应该具备高权限指令的执行，这一点我们在准入控制虽然做了一定程度的预防。这里我们基于运行时安全能力，还需要实现对容器内高危操作的拦截，例如高危命令、高危系统调用等，在不同维度实现安全的纵深防御。</p> \n <p><strong>• 网络隔离</strong></p> \n <p>横向扩展是攻击者在实现第一步攻击之后的操作，也可以称为后渗透阶段。在云原生网络的设计中，通常默认是不具备任何网络隔离能力的，因此，需要设置并实现一套完善的网络隔离机制，实现不同业务之间的网络隔离。</p> \n <p>云原生架构下的网络组织形态，区别于传统的基于主机或者虚拟机的网络，在Kubernetes中，网络的最小单位是Pod，而Pod中承载的是业务容器。因此，在实现网络隔离的时候，传统的基于IP、端口的网络策略将不再适用，我们需要基于label、service等资源，实现不同粒度的网络隔离。</p> \n <p><strong>• 防护策略管理</strong></p> \n <p>在运营过程中，如何设置准入控制、操作拦截、网络隔离等策略，这是一个令人头疼的问题，因为无论是安全管理员、运维管理员，甚至是开发人员，都很难完全讲得清楚这些规则该如何配置，才能实现相对最安全的状态。</p> \n <p>这是云原生架构下安全运营的一个挑战，同时云原生架构本身也提供应对这种挑战的优势。前文提到云原生架构的一个重要特性就是不可变的基础设施，这就意味着，我们可以通过白名单、行为模型等方式，基于业务特性以及历史运行数据，自动化的学习生成一套安全基线，这个安全基线将成为各种防护策略配置的重要参考。</p> \n <h4 id=\"安全检测\">安全检测</h4> \n <p>安全永远是一个攻防博弈的过程，而防守方往往处于相对劣势的地位，甚至可以说没有攻不破的系统。</p> \n <p>在云原生架构下，业务变得越来越开放和复杂，攻击者的手段越来越多样化，前文所述的防御拦截措施，总是难以应对所有的威胁，有些高级定向攻击或者是像针对log4j2这种0day漏洞的攻击，总是可以轻易的绕过各种防御手段，让安全威胁防不胜防。</p> \n <p>因此，在完成了上述所有的防御拦截措施之后，还需要持续的对云原生系统进行运行时监测以及安全检测。基于云原生架构的特性，这里将安全检测分为两个维度来进行。</p> \n <p><strong>1）系统维度的威胁检测</strong></p> \n <p>主要针对容器内的行为来进行，比如容器内进程异常的检测、文件异常的检测、用户异常的检测等，通过这些细粒度的异常检测，发现诸如提权、挖矿等攻击行为。</p> \n <p>网络维度的威胁检测。主要面向的是后渗透阶段的横向移动，虽然我们在防护阶段已经设置了严格的访问控制策略，但是在网络可达范围内的横向移动攻击，仍然会带来重要的安全威胁。网络威胁检测主要分为两个方面：一方面是从网络行为的角度，基于Flow实现网络流量尤其是东西向流量的异常检测，这对于端口探测、APT攻击，甚至是新型的网络威胁或者高级的网络威胁等检测将会起到重要的帮助（NDR）；另一方面就是从数据包的角度，分析容器之间网络的数据包异常，实现容器网络的入侵检测（NIDS）。</p> \n <p><strong>2）应用维度的威胁检测</strong></p> \n <p>同样面向是后渗透阶段的横向移动，云原生时代应用的微服务架构使得容器间的网络通信会存在大量的API调用，确保所有这些API之间调用都是安全的，对于云原生应用的安全有着重要的意义。例如，在已攻陷的容器中，通过API的方式获取其他服务的数据、或者是通过构造恶意的参数实现对关联服务的攻击。因此，需要在应用的维度实现对API调用异常的检测，比如调用行为、调用路径、调用参数等。</p> \n <h4 id=\"安全响应\">安全响应</h4> \n <p>安全响应主要是针对前一个步骤的安全检测告警所做出的处置措施。在云原生架构下的安全响应，尤其是网络安全层面的安全响应，我们更倾向于使用旁路检测响应处置这样的操作步骤，而不是像传统网络安全中串联接入IPS、WAF这种直接阻断式的检测响应，这样的设计主要是从业务性能的角度出发。</p> \n <p>威胁的响应主要也是包括两个方面：</p> \n <p><strong>（1）处置</strong></p> \n <p>通过网络隔离、暂停容器、停止异常进程、销毁容器等方式，实现对告警的响应处置。这里有一个前提，就是在安全能力的建设过程中，鉴于容器的短生命周期特性，需要实现完善的日志和追踪记录，以便实现处置后的溯源取证。</p> \n <p>处置的过程中，对于某些确定性异常，可以通过一键阻断、一键隔离等方式，实现处置操作的自动化，以降低运营成本。</p> \n <p><strong>（2）溯源</strong></p> \n <p>根据容器的告警、日志、追踪等数据以及数据间的关联分析，实现对告警的溯源分析，明确攻击链路，确定入侵原因。</p> \n <h4 id=\"安全修复\">安全修复</h4> \n <p>在安全修复阶段主要包括两个方面的内容：一方面就是针对入侵原因，对相关风险进行加固性修复；另一方面，就是从加固、防护、检测等步骤，分别更新相关的安全策略，实现运营反馈。</p> \n <h2 id=\"总结\">总结</h2> \n <p>Log4j2漏洞已经过去了一个多月，相信很多该打的补丁都已经修复完毕，这次突发的应急事件，是否让我们需要重新思考云原生架构下的安全建设和安全运营。漏洞或者入侵很难预测，不知道下一次什么时候还会发生，痛定思痛，到那时我们能否可以从容应对。</p> \n <p>希望本文的思考能给云原生安全建设带来一些思路和帮助，如有任何建议或疑问，欢迎文末留言。</p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>即刻关注【腾讯云原生】公众号，回复“虎虎生威”，领取腾讯定制红包封面~</p> \n <h3 id=\"福利\">福利：</h3> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <p>③公众号后台回复【光速入门】，可获得腾讯腾讯云专家5万字精华教程，光速入门Prometheus和Grafana。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2022.cnblogs.com/other/2041406/202201/2041406-20220127163228164-1442058268.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"265","createTime":"2022-01-27 14:47","comment":"0","id":"15849851","title":"从重大漏洞应急看云原生架构下的安全建设与安全运营（上）","url":"https://www.cnblogs.com/tencent-cloud-native/p/15849851.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"前言\">前言</h2> \n <p>近年来，云原生架构被广泛的部署和使用，业务容器化部署的比例逐年提高，对于突发重大漏洞等0day安全事件，往往给安全的应急带来重大的挑战。例如前段时间广受影响的重大漏洞的爆发，可以说是云原生架构下安全建设和安全运营面临的一次大考。</p> \n <p>本文将以该高危任意代码执行漏洞作为案例，分享云原生架构下的安全建设和安全运营的思考。</p> \n <h2 id=\"漏洞处置回顾\">漏洞处置回顾</h2> \n <p>漏洞爆发后，第一时间关注的一定是攻击者能否利用漏洞攻击业务系统，可以通过哪些方式实施攻击。对于容器环境，从攻击视角来看，通常可以有以下几种入侵途径。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202201/2041406-20220127144620447-1945921115.webp\" alt=\"\" loading=\"lazy\"></p> \n <p>图1</p> \n <p><strong>1）通过容器主机实施攻击</strong>。这种通常是由于主机配置问题引起，例如对公网开放并且未开启认证的Docker RemoteAPI，或者是未开启认证的Kubernetes API Server。</p> \n <p><strong>2）通过脆弱的容器实施攻击</strong>。这种类型攻击主要以容器环境中部署应用程序的脆弱性作为攻击突破口。</p> \n <p><strong>3）通过投毒的镜像实施攻击</strong>。主要通过对公共仓库中的镜像进行投毒，当镜像被拉取运行时，即可执行相关的攻击操作。</p> \n <h3 id=\"攻击者可以做什么\">攻击者可以做什么？</h3> \n <p>本次log4j2漏洞的影响，主要是体现在第二种攻击方式上，也就是攻击者会通过受影响的应用程序，利用漏洞对容器化的应用实施攻击。</p> \n <p>一旦第一步漏洞利用成功，接下来就会按照通常的渗透攻击逻辑，一方面在主机执行恶意程序；另一方面通过横向移动，扩大攻击范围，这里的横向移动既会涉及主机层面的容器逃逸，也包括东西向网络层面的移动攻击。</p> \n <h3 id=\"如何快速响应处置\">如何快速响应处置？</h3> \n <p>云原生架构下，在漏洞的应急响应上，总体思路和传统安全事件的应急是一致的。首先需要对漏洞的原理以及可能被利用的方式进行分析，确定修复和缓解方案，同时制定相关安全产品的防护规则，实现对漏洞利用的检测和拦截，最后就是有条不紊的进行漏洞的修复和处置。</p> \n <p>在容器环境中，具体可以梳理出如下的一些关键操作步骤：</p> \n <ul> \n  <li> <p>首先，需要确定现有业务的受影响范围。例如：确定仓库中所有受漏洞影响的镜像，确定受影响的线上业务；</p> </li> \n  <li> <p>其次，升级相关安全产品的防护策略。例如通过WAF规则以及防火墙规则等实现对漏洞利用的攻击进行一定程度的暂时性拦截；必要时升级运行时检测策略，一旦入侵成功，可以快速的发现并进行处置。</p> </li> \n  <li> <p>最后，就是修复漏洞，升级到官方发布的修复版本。</p> </li> \n </ul> \n <h4 id=\"为什么不容易\">为什么不容易</h4> \n <p>安全应急或者安全运营的效率，很大程度上依赖安全能力的建设。上述处置步骤，相对来说是理想情况下的一种处置流程，或者是需要在一套完善的安全能力建设基础之上才可以轻松实施的处置流程。</p> \n <p>根据腾讯云在2021年11月份发布的《腾讯云容器安全白皮书》显示，当前云原生用户在安全能力的建设上可谓是参差不齐，像镜像漏洞扫描、主机安全加固以及集群监控审计等基础安全能力，落地部署的比例也仅仅只有50%左右，甚至有7%的用户在云原生的使用时没有任何安全能力的部署。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202201/2041406-20220127144621439-548438900.webp\" alt=\"\" loading=\"lazy\"></p> \n <p>图2</p> \n <p>因此，在这样的现状下，面对log4j2这样的0day漏洞，在应急处置上，难免会出现各种捉襟见肘的问题。</p> \n <h4 id=\"控制影响范围\">控制影响范围</h4> \n <p>对于漏洞的处置，首先就是控制漏洞影响范围。因为漏洞的修复需要一定的时间周期，像log4j2这种使用范围如此之广的组件，甚至有预测，漏洞影响将会持续很长一段时间，因此控制新的影响资产增加也是十分重要的。</p> \n <p>这里主要体现在两个方面：</p> \n <p>（1）防止包含漏洞镜像的入库。CI集成以及镜像入库等阶段，需要严格进行安全检查，防止漏洞的引入。</p> \n <p>（2）防止包含漏洞镜像的运行。在新的服务启动运行时，需要检测相关镜像是否包含漏洞，对于未通过安全检测的镜像，要严格阻止其启动运行。</p> \n <h4 id=\"怎么确定受影响范围\">怎么确定受影响范围</h4> \n <p><strong>1）识别所有受到漏洞影响的镜像</strong></p> \n <p>在确定业务的受影响范围时，如果部署了容器镜像安全扫描的能力，安全厂商通常会在第一时间更新漏洞库或检测规则，用户可以直接通过对镜像仓库的所有镜像进行扫描发现受影响的镜像。</p> \n <p>如果没有部署镜像安全扫描，腾讯云容器安全服务<strong>提供7天的免费试用</strong>，用户可以通过其中的镜像扫描功能，对镜像资产进行排查。最差情况下，用户可以使用开源的镜像扫描工具（例如Clair/Anchore/Trivy等）进行问题排查，但是有一点需要注意，使用开源工具前，要确保漏洞库或者检测规则已经包含了对目标漏洞的检测。</p> \n <p><strong>2）识别受影响的运行工作负载</strong></p> \n <p>当确定了受影响的镜像后，就需要根据这个列表确定受影响的线上业务。假如我们的日常安全运营做的足够完善，理论上这个列表跟受影响的业务列表应该是一致的。或者是我们需要部署相应的安全能力，实现镜像资产到线上业务资产的映射。</p> \n <p>假如这些都没有的话，就需要逐个集群的检索当前使用的镜像，判断其是否受到影响，例如可以使用“kubectl describe pods --all-namespaces| grep image”这种最粗暴的指令获取集群运行业务所使用的所有镜像。</p> \n <p>到这里我们发现，如果仓库中镜像的数量太多，其实也可以采用另一种思路，先使用类似“kubectl describe pods --all-namespaces| grep image”这样的命令，逐个集群查询到所有线上业务使用的镜像，然后对于这些镜像定向的进行漏洞检测。</p> \n <h4 id=\"怎么修复\">怎么修复</h4> \n <p>面对漏洞的爆发，所有人都希望能充分了解这个漏洞，并在第一时间使用对应的补丁解决问题。不幸的是：一方面，软件开发和测试需要时间周期，漏洞的修复不会那么快；另一方面，在微服务架构下，受影响的镜像可能会非常多，这同样给漏洞的修复带来很大的挑战。</p> \n <p>因此，在漏洞修复的同时，我们可以通过建议的缓解措施进行缓解，例如，对于log4j2漏洞，可以添加jvm启动参数：</p> \n <p>-Dlog4j2.formatMsgNoLookups=true进行暂时的缓解。</p> \n <p>但是，在云原生架构下，应用程序的启动命令以及运行参数等信息，都是直接打包在镜像中，这样又回到前文提到的问题，如果受影响的镜像数量非常庞大的时候，这种临时的缓解措施在实施起来也将面临重大的挑战。</p> \n <p><strong>在云原生架构下，我们看到可以有几种针对漏洞的缓解性操作：</strong></p> \n <p><strong>（1）修改线上运行环境</strong></p> \n <p>我们可以通过kubectl edit pod…命令，修改线上服务Pod的运行参数，实现漏洞的缓解。针对批量的运行参数修改，我们也推出了一个开源的工具 。</p> \n <p>值得注意的是，上述处置方式在修改完参数之后，会自动重启服务，用户在使用时，需评估相应的重启风险。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202201/2041406-20220127144622415-698742809.webp\" alt=\"\" loading=\"lazy\"></p> \n <p>图3</p> \n <p><strong>（2）利用漏洞特性缓解</strong></p> \n <p>以log4j2为例，这是个远程任意代码执行的漏洞，简单来说，就是在打印日志时，如果发现日志内容中包含关键词 ${，那么这个里面包含的内容会当做变量来进行替换，导致攻击者可以任意执行命令。</p> \n <p>因此在进行漏洞缓解时，可以利用漏洞的这一特性，将缓解指令通过漏洞传进去，实现利用漏洞来缓解漏洞的效果。</p> \n <p>这种方法针对不同的漏洞，不具有普适性。</p> \n <p><strong>（3）漏洞利用的阻止</strong></p> \n <p>前面两种操作，都是从漏洞本身出发，通过缓解方式，使得漏洞不能被利用。另外一种缓解措施就是一旦前述缓解措施失效或被绕过，可以在漏洞利用的关键路径上，进行操作的拦截，从而达到漏洞缓解的效果。</p> \n <p>这种操作对安全能力有一定的依赖，一方面，安全能力需要能够检测出漏洞利用的行为，另一方面，需要能够精准的对进程行为进行阻断。尤其是对于log4j2这种任意代码执行的漏洞，漏洞利用的检测对安全能力有着较高的要求。</p> \n <p>通过上述几种临时缓解措施后，接下来我们需要做的就是，结合线上环境使用的镜像以及业务重要性和优先级等因素，有条不紊的将受影响的组件升级至官方发布的稳定修复版本。</p> \n <h3 id=\"云原生架构下安全运营的挑战和优势\">云原生架构下安全运营的挑战和优势</h3> \n <p>从上述漏洞处置的过程我们可以发现，云原生架构下在漏洞的处置修复上，容器环境既面临一定的挑战，同时也有着一定的优势。</p> \n <h4 id=\"挑战\">挑战</h4> \n <p><strong>1）镜像数量大。</strong>一方面，由于log4j2本身就是应用范围很广的组件，而且在微服务架构下，应用又会进行很多细粒度的微服务拆分，因此在仓库中会受影响的镜像会涉及到很多个Repositories；另一方面，由于DevOps等敏捷开发流程的使用，镜像仓库中的每一个镜像又会有很多个版本（每个Repository有很多个Tags）。因此，在漏洞处置的过程中会发现，扫描出来的受影响镜像数量巨大。</p> \n <p><strong>2）僵尸镜像</strong>。所谓的僵尸镜像，其实可以理解为存储在仓库中的旧版本镜像，或者过期镜像，已经几乎不会再被运行使用。如果对仓库中的镜像没有很好的管理机制，这种僵尸镜像的数量也会非常大。这种现象其实也很好理解，DevOps带来业务快速的迭代，自然就会产生大量的过期镜像。</p> \n <p>在常规的安全运营中，这些僵尸镜像原则上是应该及时被清除的（不需要考虑备份回滚的问题，代码仓库会有），这种清除操作不仅仅是需要覆盖镜像仓库，同样适用于主机上的僵尸镜像。</p> \n <p><strong>3）不可变基础设施</strong>。云原生架构的一个典型特征就是不可变的基础设施，所谓的不可变基础设施，是指一旦部署了服务之后决不允许被修改。如果需要以任何方式更新、修复或修改某些内容，则需要修改相对应的镜像，构建全新的服务镜像来替换旧的需要改变的服务镜像，经过验证后，使用新的镜像重新部署服务，而旧的则会被删除。</p> \n <p>这种特性，给我们针对线上业务在进行漏洞缓解的时候带来了很大的不便。一方面体现在修改应用的运行参数和环境变量等信息上；另一方面体现在这种缓解措施的修改，会引发运行时安全的再次告警，因为这种操作违背了不可变基础设施的要求，不是正常的业务操作流程。</p> \n <h4 id=\"优势\">优势</h4> \n <p><strong>• 资产可视化，快速定位</strong>。资产问题一直是安全建设和安全运营中重要的问题，同时也是最让人头疼的问题。云原生架构很好的解决了资产的问题，通过Kubernetes等编排平台以及镜像仓库等组件，可以让我们快速的进行资产梳理、问题定位。</p> \n <p><strong>• 流程自动化，快速生效</strong>。Kubernetes等编排平台提供了一整套的业务自动化管理方案，包括配置管理、服务编排、任务管理等。因此，对于漏洞的修复可以实现快速分发和对应的灰度升级等。</p> \n <p><strong>• 安全左移，快速控制</strong>。能够在CI/CD等多个环节进行安全左移检测，镜像入库前的检测，阻止包含漏洞镜像推送到仓库，降低增量风险；在运行时进行准入检测，对于包含漏洞风险的镜像，阻止其启动运行，减小线上环境新增暴露面。</p> \n <p><strong>• 微服务架构</strong>。在微服务架构下，应用间相对独立，这给漏洞修复带来的好处，一方面，针对某个镜像的漏洞修复，影响范围小，提高漏洞修复效率；另一方面，微服务架构下，服务功能单一，很多重复的功能会形成独立服务，这样减小了修复数量。</p> \n <p>这次漏洞的爆发，给我们在云原生安全建设和运营上敲响了警钟，以该事件作为切入点，<strong>企业在云原生架构的落地过程中，需要系统全面的考虑安全能力的建设和运营了</strong>。我们将在下一篇文章中，结合自身实践，系统的分享我们对于云原生架构下安全建设和安全运营的思考。</p> \n <p><strong>关于腾讯容器安全服务（TCSS）</strong></p> \n <p>腾讯容器安全服务（Tencent Container SecurityService, TCSS）提供容器<strong>资产管理、镜像安全、集群安全、运行时入侵检测</strong>等安全服务，保障容器从镜像构建、部署到运行时的全生命周期安全，帮助企业构建容器安全防护体系。</p> \n <p>腾讯从2018年9月30日启动全面云原生上云战略，至今已经有数千万核心规模。容器安全服务产品团队结合业内最大规模容器集群安全治理运营经验打磨产品，推动行业标准及规范的编写制定，并首发《腾讯云容器安全白皮书》，对国内容器环境安全现状进行分析总结，助力云原生安全生态的标准化和健康发展。</p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>即刻关注【腾讯云原生】公众号，回复“虎虎生威”，领取腾讯定制红包封面~</p> \n <h3 id=\"福利\">福利：</h3> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <p>③公众号后台回复【光速入门】，可获得腾讯腾讯云专家5万字精华教程，光速入门Prometheus和Grafana。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2022.cnblogs.com/other/2041406/202201/2041406-20220127144629477-253924816.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"379","createTime":"2022-01-24 09:57","comment":"0","id":"15838298","title":"Clusternet：一款开源的跨云多集群云原生管控利器！","url":"https://www.cnblogs.com/tencent-cloud-native/p/15838298.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>徐迪，Clusternet 项目发起人，腾讯云容器技术专家。</p> \n <h2 id=\"摘要\">摘要</h2> \n <p>Clusternet (Cluster Internet)是一个兼具多集群管理和跨集群应用编排的开源云原生管控平台，解决了跨云、跨地域、跨可用区的集群管理问题。 在项目规划阶段，就是面向未来混合云、分布式云和边缘计算等场景来设计的，支持海量集群的接入和管理、应用分发、流量治理（开发中）等。</p> \n <h2 id=\"如何注册一个集群\">如何注册一个集群</h2> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202201/2041406-20220124095630105-1863605997.png\" alt=\"\" loading=\"lazy\"></p> \n <p>Clusternet 在设计的时候，完全采用 <strong>add-on</strong> 的架构，支持一键部署和安装。各个模块的更多安装方式，详见<a href=\"https://github.com/clusternet/clusternet/blob/main/docs/tutorials/installing-clusternet-with-helm.md\" title=\"官方文档\" target=\"_blank\" rel=\"noopener\">官方文档</a>。</p> \n <p>在注册一个集群的时候，也非常简单，通过安装 <strong>clusternet-agent</strong> 的 Helm Chart，即可完成一个集群的注册，见如下命令，</p> \n <pre><code>helm repo add clusternet https://clusternet.github.io/charts\nhelm install clusternet-agent -n clusternet-system --create-namespace \\\n  --set parentURL=PLEASE-CHANGE-ME \\\n  --set registrationToken=PLEASE-CHANGE-ME \\\n  clusternet/clusternet-agent\n</code></pre> \n <p>这里需要将 PLEASE-CHANGE-ME 替换为对应集群的合理配置，</p> \n <ul> \n  <li>parentURL 是管控集群的 apiserver 地址</li> \n  <li>registrationToken 是一个可以访问该管控集群的 token，可以是 <a href=\"https://kubernetes.io/zh/docs/reference/access-authn-authz/bootstrap-tokens/\" title=\"bootstrap token\" target=\"_blank\" rel=\"noopener\">bootstrap token</a>，也可以是 <a href=\"https://kubernetes.io/zh/docs/reference/access-authn-authz/authentication/#service-account-tokens\" title=\"ServiceAccount token\" target=\"_blank\" rel=\"noopener\">ServiceAccount token</a>。</li> \n </ul> \n <p>这些 token 的主要作用只是用于注册集群，因此权限可以设置的很低，如下是默认的权限设置，</p> \n <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: clusternet:system:bootstrapping\nrules:\n  - apiGroups:\n      - \"clusters.clusternet.io\"\n    resources:\n      - clusterregistrationrequests\n    verbs:\n      - get\n      - create\n</code></pre> \n <p>所有 Group 为 <strong>system:bootstrappers:clusternet:register-cluster-token</strong> 的 bootstrap token 都自动拥有注册集群的权限。创建该 bootstrap token 的例子，可以参考如下例子，</p> \n <pre><code>$ # 如下命令会创建一个 bootstrap token \"07401b.f395accd246ae52d\"\n$ # 这里你可以更改 yaml 文件，创建出你设定的值\n$ kubectl apply -f manifests/samples/cluster_bootstrap_token.yaml\n</code></pre> \n <p>如果使用 ServiceAccount token 来进行注册，像 <a href=\"https://k3s.io/\" title=\"k3s\" target=\"_blank\" rel=\"noopener\">k3s</a> 就不支持使用 bootstrap token ，可以参考如下的例子创建 ServiceAccount Token 用于注册集群。</p> \n <pre><code>$ # 你可以更改如下的 yaml 文件，再进行 apply 操作\n$ # 如下命令可以创建一个 ServiceAccount token\n$ kubectl apply -f manifests/samples/cluster_serviceaccount_token.yaml\n$ # 通过如下的命令，即可拿到对应的 ServiceAccount token\n$ kubectl get secret -n clusternet-system -o=jsonpath='{.items[?(@.metadata.annotations.kubernetes\\.io/service-account\\.name==\"cluster-bootstrap-use\")].data.token}' | base64 --decode; echo\n</code></pre> \n <p>当 <strong>clusternet-agent</strong> 安装好了以后，会自动将本集群注册到上述通过 parentURL 指定的管控集群中，用对象 <strong>ClusterRegistrationRequest</strong> 来标识。每个集群都有一个独一无二的 Cluster ID，用于标识该集群。 <strong>clusternet-agent</strong> 重启或者重建，并不会更改当前注册集群的 ID。</p> \n <p>然后可以通过如下命令，查看当前已经注册的集群，</p> \n <pre><code>$ # clsrr is an alias for ClusterRegistrationRequest \n$ kubectl get clsrr\nNAME                                              CLUSTER ID                             STATUS     AGE\nclusternet-dc91021d-2361-4f6d-a404-7c33b9e01118   dc91021d-2361-4f6d-a404-7c33b9e01118   Approved   3d6h \n$ kubectl get clsrr clusternet-dc91021d-2361-4f6d-a404-7c33b9e01118 -o yaml \napiVersion: clusters.clusternet.io/v1beta1 \nkind: ClusterRegistrationRequest \nmetadata: \n  labels: \n    clusters.clusternet.io/cluster-id: dc91021d-2361-4f6d-a404-7c33b9e01118 \n    clusters.clusternet.io/cluster-name: clusternet-cluster-dzqkw\n    clusters.clusternet.io/registered-by: clusternet-agent\n    name: clusternet-dc91021d-2361-4f6d-a404-7c33b9e01118 \nspec: \n  clusterId: dc91021d-2361-4f6d-a404-7c33b9e01118\n  clusterName: clusternet-cluster-dzqkw\n  clusterType: EdgeCluster\nstatus:\n  caCertificate: REDACTED\n  dedicatedNamespace: clusternet-dhxfs\n  managedClusterName: clusternet-cluster-dzqkw\n  result: Approved\n  token: REDACTED\n</code></pre> \n <p>一旦 status.result 变为 Approved，就代表该集群已经注册成功。这个时候 <strong>clusternet-hub</strong> 会为该集群创建一个专属的 namespace，比如上述例子中就分配了一个名为 clusternet-dhxfs 的命名空间，并有一个名为 clusternet-cluster-dzqkw <strong>ManagedCluster</strong> 的对象与该集群进行关联，所有该集群的状态都会汇报到该对象中。</p> \n <pre><code>apiVersion: clusters.clusternet.io/v1beta1\nkind: ManagedCluster\nmetadata:\n  creationTimestamp: \"2022-01-20T09:20:30Z\"\n  generation: 1\n  labels:\n    clusternet.io/created-by: clusternet-agent\n    clusters.clusternet.io/cluster-id: dc91021d-2361-4f6d-a404-7c33b9e01118\n    clusters.clusternet.io/cluster-name: cls-bx2ro4ak\n  name: clusternet-cluster-dzqkw\n  namespace: clusternet-dhxfs\n  resourceVersion: \"545410287\"\n  selfLink: /apis/clusters.clusternet.io/v1beta1/namespaces/clusternet-dhxfs/managedclusters/clusternet-cluster-dzqkw\n  uid: 1e6a1003-8309-40c5-8969-c15cdf274a5a\nspec:\n  clusterId: dc91021d-2361-4f6d-a404-7c33b9e01118\n  clusterType: EdgeCluster\n  syncMode: Dual\nstatus:\n  allocatable:\n    cpu: 2820m\n    memory: 8657308Ki\n  apiserverURL: https://10.8.0.1:443\n  appPusher: true\n  capacity:\n    cpu: \"6\"\n    memory: 12094876Ki\n  conditions:\n  - lastTransitionTime: \"2022-01-21T03:33:59Z\"\n    message: managed cluster is ready.\n    reason: ManagedClusterReady\n    status: \"True\"\n    type: Ready\n  healthz: true\n  heartbeatFrequencySeconds: 180\n  k8sVersion: v1.21.5\n  lastObservedTime: \"2022-01-21T03:33:59Z\"\n  livez: true\n  nodeStatistics:\n    readyNodes: 3\n  platform: linux/amd64\n  readyz: true\n  serviceCIDR: 10.4.0.0/14\n  useSocket: true\n</code></pre> \n <p>集群注册上来后，就可以对集群进行管理和应用分发了。我们会在下一次文章中，来介绍如何进行应用分发。</p> \n <h2 id=\"如何访问子集群\">如何访问子集群</h2> \n <p>通过 Clusternet，可以对注册成功的集群进行进一步地管控。在一些运维的场景中，可能需要对某个子集群进行额外的单独操作，比如查看日志，事件，节点状态等等。</p> \n <p>需要纳管的目标子集群可能：</p> \n <ul> \n  <li>运行在边缘节点上或者是边缘集群，网络条件差，没有暴露外网地址</li> \n  <li>运行在云上的某个 VPC 内，为了保证安全性，没有做网络打通，或者端口映射</li> \n  <li>运行在自建机房内</li> \n  <li>其他情形</li> \n </ul> \n <p>Clusternet 为了能够提供一致的管理体验，提供了通用的访问子集群的方案，即可以通过父集群做访问代理，将请求转发到子集群中，却依然可以使用动态的 RBAC。这里 Clusternet 使用的 RBAC 是子集群自己的 RBAC，所以这些 RBAC 中用到的敏感信息并不需要在父集群中保留，做到真正的动态权限访问。详细的访问链路，如下图所示。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202201/2041406-20220124095630418-1414944716.png\" alt=\"\" loading=\"lazy\"></p> \n <p>为了方便，Clusternet 也提供了命令行支持，通过 kubectl-clusternet 插件即可上手体验一番。</p> \n <pre><code>$ # 安装 kubectl-clusternet 插件\n$ kubectl krew install clusternet\n$ kubectl get mcls -A \nNAMESPACE          NAME       CLUSTER ID                             SYNC MODE   KUBERNETES                   READYZ   AGE \nclusternet-ml6wg   aws-cd     6c085c18-3baf-443c-abff-459751f5e3d3   Dual        v1.18.4                      true     4d6h \nclusternet-z5vqv   azure-cd   7dc5966e-6736-48dd-9a82-2e4d74d30443   Dual        v1.20.4                      true     43h \n$ # 通过指定 Cluster ID，以及对应 Cluster 的 kubeconfig 文件 (这里的 apiserver 地址可以是内网地址)\n$ kubectl clusternet --cluster-id=7dc5966e-6736-48dd-9a82-2e4d74d30443 --child-kubeconfig=./azure-cd-kubeconfig get ns \nNAME                STATUS   AGE\nclusternet-system   Active   4d20h \ndefault             Active   24d \nkube-node-lease     Active   24d \nkube-public         Active   24d \nkube-system         Active   24d \ntest-nginx          Active   11d \ntest-systemd        Active   11d\n</code></pre> \n <p>关于更多使用细节，请扫描下方二维码进行了解。</p> \n <p><img src=\"https://img2022.cnblogs.com/other/2041406/202201/2041406-20220124095630693-1571061426.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"加入我们\">加入我们</h2> \n <p>请关注 Clusternet 项目 <a href=\"https://github.com/clusternet/clusternet%EF%BC%8C%E7%82%B9%E8%B5%9E%E5%B9%B6%E6%94%AF%E6%8C%81%EF%BC%8C%E4%B9%9F%E6%AC%A2%E8%BF%8E%E5%90%84%E7%A7%8D%E5%BD%A2%E5%BC%8F%E7%9A%84%E8%AE%A8%E8%AE%BA%E4%B8%8E%E5%90%88%E4%BD%9C%E3%80%82\" target=\"_blank\" rel=\"noopener\">https://github.com/clusternet/clusternet，点赞并支持，也欢迎各种形式的讨论与合作。</a></p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <h4 id=\"福利\">福利：</h4> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <p>③公众号后台回复【光速入门】，可获得腾讯腾讯云专家5万字精华教程，光速入门Prometheus和Grafana。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2022.cnblogs.com/other/2041406/202201/2041406-20220124095631113-387959473.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"394","createTime":"2022-01-11 16:27","comment":"0","id":"15788915","title":"SuperEdge再添国产智能加速卡支持，为边缘智能推理再提速10倍","url":"https://www.cnblogs.com/tencent-cloud-native/p/15788915.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>寒武纪AE团队，腾讯云容器中心边缘计算团队，SuperEdge 开发者</p> \n <h2 id=\"superedge-支持国产智能加速卡寒武纪-mlu220\">SuperEdge 支持国产智能加速卡寒武纪 MLU220</h2> \n <p>SuperEdge 对应的商业产品 TKE Edge 也一直在硬件和加速方面在持续耕耘，不但支持 NVIDIA 系列 GPU的加速，还在 GPU 虚拟，QGPU 化等方面持续发力。本次联合寒武纪对国产智能边缘加速卡进行了支持，以利于用户在边缘进行模型训练和边缘智能推理性能的提升。下面是经过寒武纪 AE 团队和 SuperEdge 开源团队的联合测试，对国产寒武纪边缘计算加速卡兼容性的联合声明。</p> \n <p><code>中科寒武纪科技股份有限公司的边缘智能加速卡 MLU220-M.2和分布式边缘容器管理系统 SuperEdge 与相互兼容，能够对搭载M.2的边缘设备在视频、图像、语音等应用上提供数十倍的加速能力，</code> 在此发表联合声明。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202201/2041406-20220111162715439-320229122.png\" alt=\"\" loading=\"lazy\"></p> \n <p>下面给出两个分类网络在 CPU 和 M.2 上的吞吐性能对比。</p> \n <table> \n  <thead> \n   <tr> \n    <th>网络模型</th> \n    <th>M.2(fps)</th> \n    <th>CPU(fps)</th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td>vgg16</td> \n    <td>184</td> \n    <td>13</td> \n   </tr> \n   <tr> \n    <td>resnet50</td> \n    <td>417</td> \n    <td>29</td> \n   </tr> \n  </tbody> \n </table> \n <p>可以看出 vgg16 M.2 是普通 i7-8700K的14倍，Resnet50 也是普通 i7-8700K 的14倍。</p> \n <blockquote> \n  <p>其中，CPU 采用的是 Intel(R) Core(TM) i7-8700K CPU @ 3.70GHz</p> \n </blockquote> \n <h2 id=\"superedge-边缘容器解决方案\">SuperEdge 边缘容器解决方案</h2> \n <p>SuperEdge 是2020年12月腾讯云联合英特尔、VMware 威睿、虎牙、寒武纪、美团、首都在线发布的基于原生Kubernetes 的边缘分布式容器管理系统。该系统把云原生能力扩展到边缘侧，很好的实现了云端对边缘端的管理和控制，极大简化了应用从云端部署到边缘应用的过程。2021年9月已被 CNCF 基金会接受，成为 CNCF Sandbox项目，由 CNCF 监管和运维。</p> \n <p>SuperEdge提供了如下能力：</p> \n <h3 id=\"边缘自治\">边缘自治</h3> \n <p>云边网络往往是弱网络，中间可能是有线、无线、WIFI……连接，可能是4G、5G网络，云边断链是常态。断连时间不定，短则三五分钟，长则数小时、几天，那么如何保证边缘服务不被驱逐，继续提供正常服务呢？<br> SuperEdge 的边缘自治能力，可以保证云边断连的情况下，边缘服务继续稳定运行，即使<strong>边缘节点断电重启</strong>，也能自动恢复已经部署到该节点的边缘服务继续运行。</p> \n <h3 id=\"分布式健康检查\">分布式健康检查</h3> \n <p>SuperEdge 提供的边缘分布式健康检查能力有两个作用：</p> \n <ul> \n  <li><strong>只要边缘节点正常，边缘服务就不会驱逐</strong><br> SuperEdge 会在每个边缘节点部署一个 edge-health 的 deamonset，同一个边缘 Kubernetes 集群的节点会定期 Check 彼此，对彼此的健康性进行投票，并将投票结果反馈到云端。即使边缘 Kubernetes 集群的一个节点云边网络断连，其他节点也会把他的健康性反馈到云端，就不会对该节点进行驱逐。</li> \n  <li><strong>可分组进行分布式健康检查</strong><br> 即把边缘 Kubernetes 集群的边缘节点分成多个组(同一机房，或者同一地域)，每个组内的节点之间相互检查。这样做的好处是避免集群规模增大后节点之间的 Check 数据交互变大，占用节点流量，投票结果也难以达成一致的情况。</li> \n </ul> \n <p>edge-health 的设计避免了由于云边网络不稳定造成的大量的 Pod 迁移和重建，保证了边缘服务的稳定。</p> \n <h3 id=\"服务访问控制\">服务访问控制</h3> \n <p>SuperEdge 自研的 ServiceGroup 实现了基于边缘计算的服务访问控制，主要有三个作用：</p> \n <ul> \n  <li><strong>一键把边缘服务部署到不同站点</strong><br> 可以一键把同一套服务部署到位于同一边缘 Kubernetes 集群的不同站点，各个站点的服务完全保持一致。该特性目前支持 DeploymentGrid 以及 ServiceGrid 两种 Custom Resource，可以便捷的在同一个集群的多个机房或区域中各部署一组服务。</li> \n  <li><strong>同一站点可实现流量闭环</strong><br> 各个站点虽然有同一套服务，但是会把本站点的访问只锁定本站点内，不会跨站点去访问其他站点的同一套服务。</li> \n  <li><strong>新站点自动部署相应服务</strong><br> 新加入的站点，可指定服务标签自动部署同一套站点服务，为站点扩展提供了自动部署服务的支持。</li> \n </ul> \n <h3 id=\"云边隧道\">云边隧道</h3> \n <p>边缘节点一般是没有公网IP的，或者在一个NAT网络背后，云端无法直接访问边缘节点，这就使得 kubectl logs、kubectl exec……等云端访问边缘节点的请求完全失灵。<br> SuperEdge 自研的云边自建隧道(目前支持TCP、HTTP、HTTPS、ssh)打通了不同网络环境下的云边连接问题。实现对无公网 IP 边缘节点的云端统一操作和维护。</p> \n <h3 id=\"批量添加局域网边缘节点及远程运维局域网边缘节点\">批量添加局域网边缘节点及远程运维局域网边缘节点</h3> \n <p>为了解决生产环境海量边缘节点的接入，SuperEdge 团队特提供了<a href=\"https://github.com/superedge/superedge/tree/main/cmd/penetrator-controller\" title=\"penetrator-controller\" target=\"_blank\" rel=\"noopener\">penetrator-controller</a>组件支持了局域网内成千上万边缘节点的接入，并且还可以在云端远程登录到局域网内的边缘节点进行远程运维。</p> \n <p>更多的特性可登录 SuperEdge 官网：<a href=\"https://superedge.io\" target=\"_blank\" rel=\"noopener\">https://superedge.io</a> 进行查看，合作交流可在社区https://github.com/superedge/superedge 提 Issuse。</p> \n <h2 id=\"mlu220-是什么\">MLU220 是什么？</h2> \n <p>MLU220-M.2 是寒武纪为边缘计算专门打造的加速卡，它在手指大小的标准M.2加速卡上集成了 8TOPS 理论峰值性能，功耗仅为 8.25W，可以轻松实现终端设备和边缘端设备的 AI 赋能方案。支持视觉、语音、自然语言处理以及传统机器学习等多样化的人工智能应用，实现各种业务的边缘端智能化解决方案。<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202201/2041406-20220111162716437-161630591.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>MLU220 具有如下特性：</p> \n <ul> \n  <li> <p><strong>小个头大智能</strong><br> 思元220芯片是面向边缘侧量身定制的智能化解决方案，在 U 盘大小的尺寸下就可以提供8路高清视频的实时智能分析，可广泛支持视觉、语音、自然语言处理以及传统机器学习等高度多样化的人工智能应用，为边缘计算节点装上智慧的大脑。</p> </li> \n  <li> <p><strong>新一代寒武纪硬件架构</strong><br> MLUv02 架构不是简单的从上一代升级而来，新架构基于片上网络（NOC）构建，多个 NPU 集群的并行效率。基于硬件的片内数据压缩，提升缓存有效容量和带宽。新架构提供 INT16,INT8,INT4,FP32,FP16 的全面 AI 精度支持，满足多样化神经网络的计算力要求，通用、性能兼备。</p> </li> \n  <li> <p><strong>计算弹性和可编程</strong><br> 思元220芯片支持多类神经网络，NeuWare 软件栈可以轻松部署推理环境。BANG Lang 编程环境可对计算资源做直接定制，满足多样化 AI 定制要求，专业而不专用。</p> </li> \n  <li> <p>加速卡硬件规格</p> <p>加速卡硬件规格可概括如下：</p> \n   <table> \n    <thead> \n     <tr> \n      <th>参数</th> \n      <th>规格</th> \n     </tr> \n    </thead> \n    <tbody> \n     <tr> \n      <td>型号</td> \n      <td>MLU220-M.2</td> \n     </tr> \n     <tr> \n      <td>内存</td> \n      <td>4GB, LPDDR4, 3200MHz</td> \n     </tr> \n     <tr> \n      <td>AI算力</td> \n      <td>8TOPS(INT8)</td> \n     </tr> \n     <tr> \n      <td>编解码能力</td> \n      <td>支持H.264,H.265, VP8, VP9；解码8x1080P@30Hz；编码4x1080P@30Hz</td> \n     </tr> \n     <tr> \n      <td>图片解码</td> \n      <td>支持JEPG最大分辨率8K；解码410 fps@1080P；编码400 fps@1080P</td> \n     </tr> \n     <tr> \n      <td>接口规格</td> \n      <td>M.2 2280, B+M Key (PCIE 3.0 X2)</td> \n     </tr> \n     <tr> \n      <td>功耗</td> \n      <td>8.25W (3.3V 2.5A)</td> \n     </tr> \n     <tr> \n      <td>结构尺寸</td> \n      <td>80mm x 22mm x 7.3mm(无散热)/21.3mm(带散热)</td> \n     </tr> \n     <tr> \n      <td>散热</td> \n      <td>被动散热</td> \n     </tr> \n    </tbody> \n   </table> </li> \n </ul> \n <h2 id=\"mlu220-能用来做什么\">MLU220 能用来做什么？</h2> \n <p>MLU220 小巧的体积，强大的算力，使得它可广泛应用于智慧交通、智能电网、智能制造、智能金融等边缘计算场景，下面是一些典型的应用场景的介绍：</p> \n <h3 id=\"智慧交通\">智慧交通</h3> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202201/2041406-20220111162717208-796802869.jpg\" alt=\"\" loading=\"lazy\"><br> 为保障道路安全和有序，在城市中的十字路口和关键道路部署多路摄像头及 MLU220 边缘加速卡。<br> MLU220 可实现对多路摄像头输入图像的解码处理；基于深度学习技术，MLU220 可实现对监控路段的行人，机动车，和非机动车的检测，跟踪及结构化，在交通业务上进一步做到智能车流人流统计，违法抓拍取证，关键人车的识别抓取等，极大提高交通部门效率。</p> \n <h3 id=\"智慧工厂\">智慧工厂</h3> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202201/2041406-20220111162717964-897255457.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>为打造现代化智能制造的智慧工厂，在厂区工位部署多路摄像头及 MLU220 边缘加速卡。<br> 凭借独立的编解码单元，MLU220 可实现对多路摄像头图像的解码；在强大的算力支持下，MLU220 可实现对工人的检测，姿态识别以及对工件的检测和识别，从而实现检测工人是否在岗，工人操作是否合规以及工件是否按规定摆放等工厂的智能管理。</p> \n <h3 id=\"智慧畜牧\">智慧畜牧</h3> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202201/2041406-20220111162719190-1193538707.jpg\" alt=\"\" loading=\"lazy\"><br> 为实现畜牧业生产管理，安全健康监控和养殖环境智能检测，在养殖基地部署多路摄像头和 MLU220 边缘加速卡；通过深度学习技术，实现对种猪的识别，检测，实例分割和跟踪，进一步实现对种猪的点数，健康检测，吃食统计，屠宰辅助等智能养殖技术，减少人力成本，提供养殖效率。</p> \n <h2 id=\"如何在-superedge-上使用寒武纪-mlu220\">如何在 SuperEdge 上使用寒武纪 MLU220</h2> \n <p>我们基于 SuperEdge 演示如何使用寒武纪边缘智能加速卡：</p> \n <h3 id=\"用-edgeadm-创建一个-superedge-边缘-kubernetes-集群\">用 edgeadm 创建一个 SuperEdge 边缘 Kubernetes 集群</h3> \n <ul> \n  <li> <p>下载 edgeadm 安装包</p> <pre><code class=\"language-javascript\">arch=amd64 version=v0.6.0 &amp;&amp; rm -rf edgeadm-linux-* &amp;&amp; wget https://superedge-1253687700.cos.ap-guangzhou.myqcloud.com/$version/$arch/edgeadm-linux-$arch-$version.tgz &amp;&amp; tar -xzvf edgeadm-linux-* &amp;&amp; cd edgeadm-linux-$arch-$version &amp;&amp; ./edgeadm\n</code></pre> </li> \n  <li> <p>初始化边缘 Kubernetes Master 节点</p> <pre><code class=\"language-javascript\">./edgeadm init --kubernetes-version=1.18.2 --image-repository superedge.tencentcloudcr.com/superedge --service-cidr=10.96.0.0/12 --pod-network-cidr=192.168.0.0/16 --install-pkg-path ./kube-linux-*.tar.gz --apiserver-cert-extra-sans=&lt;Master Public IP&gt; --apiserver-advertise-address=&lt;Master Intranet IP&gt; --enable-edge=true\n</code></pre> </li> \n  <li> <p>加入一个带寒武纪边缘智能加速卡的边缘节点</p> <pre><code class=\"language-javascript\">./edgeadm join &lt;Master Public/Intranet IP Or Domain&gt;:Port --token xxxx --discovery-token-ca-cert-hash sha256:xxxxxxxxxx --install-pkg-path &lt;edgeadm kube-* install package address path&gt; --enable-edge=true\n</code></pre> <p>关于 edgeadm 安装边缘 Kubernetes 集群的详细介绍可参考：<a href=\"https://mp.weixin.qq.com/s/zHs_qmD8781r-h4tkie0qQ\" target=\"_blank\" rel=\"noopener\">用 edgeadm 一键安装边缘 K8s 集群和原生 K8s 集群</a></p> </li> \n </ul> \n <h3 id=\"安装寒武纪边缘智能加速卡的插件\">安装寒武纪边缘智能加速卡的插件</h3> \n <ul> \n  <li> <p>安装边缘智能加速卡的插件</p> <pre><code class=\"language-javascript\">kubectl create -f https://github.com/Cambricon/cambricon-k8s-device-plugin/blob/master/device-plugin/examples/cambricon-device-plugin-daemonset.yaml\n</code></pre> </li> \n  <li> <p>检查插件是否安装成功</p> <pre><code class=\"language-javascript\"> kubectl get node &lt;边缘节点NodeName&gt; -o json --output=\"jsonpath={.status.allocatable}\"\n</code></pre> <p>看到边缘节点 node status.allocatable 有 cambricon.com/mlu 有相关资源值表示边缘智能加速卡及插件安装成功。</p> <pre><code class=\"language-javascript\">\"allocatable\": {\n    \"cambricon.com/mlu\": \"1\", ## MUL卡资源\n    \"cpu\": \"12\",\n    ...\n    \"memory\": \"16164684Ki\",\n    \"pods\": \"110\"\n}\n</code></pre> <p>看到<code>allocatable</code>里面存在<code>cambricon.com/mlu</code>并且其资源值大于等于0，表示寒武纪边缘智能加速卡及其插件已经安装成功。</p> \n   <blockquote> \n    <p>mlu插件下载地址：<a href=\"https://github.com/Cambricon/cambricon-k8s-device-plugin\" target=\"_blank\" rel=\"noopener\">https://github.com/Cambricon/cambricon-k8s-device-plugin</a></p> \n   </blockquote> <p>mlu监控组件：<a href=\"https://github.com/Cambricon/mlu-exporter\" target=\"_blank\" rel=\"noopener\">https://github.com/Cambricon/mlu-exporter</a></p> </li> \n </ul> \n <h3 id=\"使用边缘智能加速卡进行边缘应用加速\">使用边缘智能加速卡进行边缘应用加速</h3> \n <p>在提交边缘相应负载的时候指定 <code>cambricon.com/mlu</code> 来应用寒武纪边缘智能加速卡进行加速， 比如：</p> \n <pre><code class=\"language-javascript\">apiVersion: v1\nkind: Pod\n...\nspec:\n  containers:\n  - image: 10.13.30.52:5000/yolov4:latest\n    name: yolov4-ctr\n    resources:\n      limits:\n        cambricon.com/mlu: 1 ## 指定加速卡limits\n      requests:\n        cambricon.com/mlu: 1 ## 指定加速卡requests\n...\n</code></pre> \n <h2 id=\"未来\">未来</h2> \n <p>未来寒武纪和腾讯云会在边缘硬件和边缘云服务上进行更多的合作，为边缘 AI、边缘 IoT，数字化，人工智能……进行软硬件的赋能，并且相应能力在相关的商业产品中对用户提供支持，欢迎关注腾讯云边缘计算云平台 TKE Edge 和寒武纪相关加速商业产品，试用体验边缘更多的加速产品。</p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202201/2041406-20220111162719623-1615193862.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"257","createTime":"2022-01-11 10:44","comment":"0","id":"15787303","title":"Docker 和 Kubernetes，一周即可快速入门！！云原生技术工坊再度来袭~","url":"https://www.cnblogs.com/tencent-cloud-native/p/15787303.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <p>只需要每天晚上花三两个小时，在一周业余的时间里，你就能快速入门Docker和Kubernetes！！</p> \n <p>第一期云原生在线技术工坊已经圆满结束，好评如潮，下面是部分参与者打卡截图：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202201/2041406-20220111104332470-331822981.gif\" alt=\"\" loading=\"lazy\"></p> \n <p>第二期技术工坊活动再度来袭~~关注“<strong>腾讯云原生</strong>”公众号，回复“技术工坊”即可参与！！</p> \n <h2 id=\"技术工坊简介\">技术工坊简介</h2> \n <p><strong>云原生在线技术工坊</strong>，由<strong>腾讯云原生【燎原社</strong>】精心打造，旨在帮助更多对云原生技术感兴趣的开发者快速且系统的掌握Docker 与 Kubernetes。</p> \n <p>技术工坊配有<strong>非常详细的操作手册，包含具体的操作步骤、完整的代码以及科学的学习方法</strong>。降低了云原生技术学习的门槛，充分做到<strong>零基础</strong>也能学习并掌握云原生技术。</p> \n <h2 id=\"为什么要学习云原生\">为什么要学习云原生？</h2> \n <p>以Docker和Kubernetes为核心的云原生技术改变了软件开发和交付的方式，让应用程序开发更容易、部署更快捷、运行更可靠，也因此成为了云计算时代每个程序员都必备的核心技能。</p> \n <p>无论你是哪门编程语言的程序员，无论你是开发、测试抑或运维，Docker和Kubernetes作为一个实用的工具，都非常值得你掌握。</p> \n <h2 id=\"课程安排\">课程安排</h2> \n <p>（1 月 17 日- 1 月 23日，每晚 19:30）</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202201/2041406-20220111104333036-11812654.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"学习福利\">学习福利</h2> \n <p>参加在线学习的活动，不仅有一群人互相学习进步的氛围，还有讲师在线答疑交流。完成学习群中布置的任务，即有机会领取<strong>腾讯云原生【燎原社】送出的限量周边：</strong></p> \n <ul> \n  <li> <p>完成每日学习打卡任务，并提交一篇部署实践文章到指定平台</p> </li> \n  <li> <p>按打卡任务完成顺序 &amp; 文章优质程度评奖</p> </li> \n  <li> \n   <ul> \n    <li>第1-10名：长鹅；</li> \n    <li>第11-20名：蓝鹅；</li> \n    <li>第21-30名：短鹅</li> \n   </ul> </li> \n </ul> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202201/2041406-20220111104333412-2139011404.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"进阶学习\">进阶学习</h2> \n <p>技术工坊仅供入门学习，适合小白初步建立认知。云原生技术重要且复杂，<strong>腾讯云原生【燎原社】也推出了专业而又系统的线下云原生技术实战营</strong>，需要系统化深入学习的同学，可报名云原生技术实战营课程，腾讯云技术专家现场教学，3天搞定云原生容器化改造过程中的实际问题，还有官方认证证书加持，<strong>扫码或点击“阅读原文”一键直达</strong>：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202201/2041406-20220111104333718-1548730981.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"主办方\">主办方</h2> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202201/2041406-20220111104333957-453769802.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"社区合作伙伴\">社区合作伙伴</h2> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202201/2041406-20220111104334258-1505718873.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"海报详情\">海报详情</h2> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202201/2041406-20220111104334773-1934404676.jpg\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <h3 id=\"福利\">福利：</h3> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <p>③公众号后台回复【光速入门】，可获得腾讯腾讯云专家5万字精华教程，光速入门Prometheus和Grafana。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202201/2041406-20220111104335187-321986027.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"143","createTime":"2022-01-05 17:08","comment":"0","id":"15767879","title":"TKE 用户故事 | 作业帮 Kubernetes 原生调度器优化实践","url":"https://www.cnblogs.com/tencent-cloud-native/p/15767879.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>吕亚霖，2019年加入作业帮，作业帮架构研发负责人，在作业帮期间主导了云原生架构演进、推动实施容器化改造、服务治理、GO微服务框架、DevOps的落地实践。</p> \n <h2 id=\"简介\">简介</h2> \n <p>调度系统的本质是为计算服务/任务匹配合适的资源，使其能够稳定高效地运行，以及在此的基础上进一步提高资源使用密度，而影响应用运行的因素非常多，比如 CPU、内存、IO、差异化的资源设备等等一系列因素都会影响应用运行的表现。同时，单独和整体的资源请求、硬件/软件/策略限制、 亲和性要求、数据区域、负载间的干扰等因素以及周期性流量场景、计算密集场景、在离线混合等不同的应用场景的交织也带来了决策上的多变。</p> \n <p>调度器的目标则是快速准确地实现这一能力，但快速和准确这两个目标在资源有限的场景下会往往产生产生矛盾，需要在二者间权衡。</p> \n <h2 id=\"调度器原理和设计\">调度器原理和设计</h2> \n <p>K8s 默认调度器的整体工作框架，可以简单用下图概括：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202201/2041406-20220105170758131-2096488847.jpg\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"两个控制循环\">两个控制循环</h3> \n <ol> \n  <li> <p>第一个控制循环，称为 Informer Path。它的主要工作，是启动一系列的 Informer，用来监听（Watch）集群中 Pod、Node、Service 等与调度相关的 API 对象的变化。比如，当一个待调度 Pod 被创建出来之后，调度器就会通过 Pod Informer 的 Handler，将这个待调度 Pod 添加进调度队列；同时，调度器还要负责对调度器缓存 Scheduler Cache 进行更新，并以这个 cache 为参考信息，来提高整个调度流程的性能。</p> </li> \n  <li> <p>第二个控制循环，即为对 pod 进行调度的主循环，称为 Scheduling Path。这一循环的工作流程是不断地从调度队列中取出待调度的 pod，运行2个步骤的算法，来选出最优 node。</p> </li> \n </ol> \n <ul> \n  <li> <p>在集群的所有节点中，选出所有“可以”运行该 pod 的节点，这一步被称为 Predicates；</p> </li> \n  <li> <p>在上一步选出的节点中，根据一些列优选算法对节点就行打分，选出“最优”即得分最高的节点，这一步被称为 Priorities。</p> </li> \n </ul> \n <p>调度完成之后，调度器就会为 pod 的 spec.NodeName 赋值这个节点，这一步称为 Bind。而为了不在主流程路径中访问 Api Server 影响性能，调度器只会更新 Scheduler Cache 中的相关 pod 和 node 信息：这种基于乐观的假设的 Api 对象更新方式，在 K8s 中称为 Assume。之后才会创建一个 goroutine 来异步地向 Api Server 发起更新 Bind 操作，这一步就算失败了也没有关系，Scheduler Cache 更新后就会一切正常。</p> \n <h2 id=\"大规模集群调度带来的问题和挑战\">大规模集群调度带来的问题和挑战</h2> \n <p>K8s 默认调度器策略在小规模集群下有着优异的表现，但是随着业务量级的增加以及业务种类的多样性变化，默认调度策略则逐渐显露出了局限性：调度维度较少，无并发，存在性能瓶颈，以及调度器越来越复杂。</p> \n <p>迄今为止，我们当前单个集群规模节点量千级，pod 量级则在 10w 以上，整体资源分配率超过60%，其中更是包含了 gpu，在离线混合部署等复杂场景；在这个过程中，我们遇到了不少调度方面的问题。</p> \n <h4 id=\"问题1高峰期的节点负载不均匀\">问题1：高峰期的节点负载不均匀</h4> \n <p>默认调度器，参考的是 workload 的 request 值，如果我们针对 request 设置的过高，会带来资源的浪费；过低则有可能带来高峰期 CPU 不均衡差异严重的情况；使用亲和策略虽然可以一定程度避免这种，但是需要频繁填充大量的策略，维护成本就会非常大。而且服务的 request 往往不能体现服务真实的负载，带来差异误差。而这种差异误差，会在高峰时体现到节点负载不均上。</p> \n <p>实时调度器，在调度的时候获取各节点实时数据来参与节点打分，但是实际上实时调度在很多场景并不适用，尤其是对于具备明显规律性的业务来说；比如我们大部分服务晚高峰流量是平时流量的几十倍，高低峰资源使用差距剧大，而业务发版一般选择低峰发版，采用实时调度器，往往发版的时候比较均衡，到晚高峰就出现节点间巨大差异，很多实时调度器，往往在出现巨大差异的时候会使用再平衡策略来重新调度，高峰时段对服务 POD 进行迁移，服务高可用角度来考虑是不现实的。显然实时调度是远远无法满足业务场景的。</p> \n <h4 id=\"我们的方案高峰预测时调度\">我们的方案：高峰预测时调度</h4> \n <p>所以针对这种情况，需要预测性调度，根据以往高峰时候 CPU、IO、网络、日志等资源的使用量，通过对服务在节点上进行最优排列组合回归测算，得到各个服务和资源的权重系数，基于资源的权重打分扩展，也就是使用过去高峰数据来预测未来高峰节点服务使用量，从而干预调度节点打分结果。</p> \n <h4 id=\"问题2调度维度多样化\">问题2：调度维度多样化</h4> \n <p>随着业务越来越多样性，需要加入更多的调度维度，比如日志。由于采集器不可能无限速率采集日志且日志采集是基于节点维度。需要将平衡日志采集速率，不能各个节点差异过大。部分服务 CPU 使用量一般但是日志输出量很大；而日志并不属于默认调度器决策的一环，所以当这些日志量很大的服务多个服务的 pod 在同一个节点上的时候，该机器上的日志上报就有可能出现部分延迟。</p> \n <h4 id=\"我们的方案补全调度决策因子\">我们的方案：补全调度决策因子</h4> \n <p>该问题显然需要我们对调度决策补全，我们扩展了预测调度打分策略，添加了日志的决策因子，将日志也作为节点的一种资源，并根据历史监控获取到服务对应的日志使用量来计算分数。</p> \n <h4 id=\"问题3大批量服务扩缩导带来的调度时延\">问题3：大批量服务扩缩导带来的调度时延</h4> \n <p>随着业务的复杂度进一步上升，在高峰时段出现，会有大量定时任务和集中大量弹性扩缩，大批量（上千 POD）同时调度导致调度时延的上涨，这两者对调度时间比较敏感，尤其对于定时任务来说，调度延时的上涨会被明显感知到。原因是 K8s 调度 pod 本身是对集群资源的分配，反应在调度流程上则是预选和打分阶段是顺序进行的；如此一来，当集群规模大到一定程度的时候，大批量更新就会出现可感知到的 pod 调度延迟。</p> \n <h4 id=\"我们的方案拆分任务调度器加大并发调度域批量调度\">我们的方案：拆分任务调度器，加大并发调度域、批量调度</h4> \n <p>解决吞吐能力低下的最直接的方法就是串行改并行，对于资源抢占场景，尽量细化资源域，资源域之间并行。给予以上策略，我们拆分出了独立的 job 调度器，同时使用了 serverless 作为 job 运行的底层资源。K8s serverless 为每一个 JOB POD，单独申请了独立的 POD 运行 sanbox，也就是任务调度器，是完整并行。<strong>以下对比图</strong>：</p> \n <p>原生调度器在晚高峰下节点 CPU 使用率</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202201/2041406-20220105170758519-296471064.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>优化后调度器在晚高峰下节点 CPU 使用率</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202201/2041406-20220105170759567-1183223289.jpg\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"总结\">总结</h2> \n <p>work 节点资源、GPU 资源、serverless 资源这就是我们集群异构资源分属于这三类资源域，这三种资源上运行的服务存在天然的差异性，我们使用 forecast-scheduler、gpu-scheduler、job-schedule 三个调度器来管理这三种资源域上的 pod 的调度情况。</p> \n <p>预测调度器管理大部分在线业务，其中扩展了资源维度，添加了预测打分策略。</p> \n <p>GPU 调度器管理 GPU 资源机器的分配，运行在线推理和离线训练，两者的比例处于长期波动中，高峰期间离线训练缩容、在线推理扩容；非高峰期间离线训练扩容、在线推理缩容；同时处理一些离线图片处理任务来复用 GPU 机器上比较空闲的 CPU 等资源</p> \n <p>Job 调度器负责管理我们定时任务的调度，定时任务量大且创建销毁频繁，资源使用非常碎片化，而且对实效性要求更高；所以我们将任务尽量调度到 Serverless 服务上，压缩集群中为了能容纳大量的任务而冗余的机器资源，提升资源利用率。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202201/2041406-20220105170759996-935657112.jpg\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"未来的演进探讨\">未来的演进探讨</h2> \n <h3 id=\"更细粒度的资源域划分\">更细粒度的资源域划分</h3> \n <p>将资源域划分至节点级别，节点级别加锁来进行。</p> \n <h3 id=\"资源抢占和重调度\">资源抢占和重调度</h3> \n <p>正常场景下，当一个 pod 调度失败的时候，这个 pod 会保持在 pending 的状态，等待 pod 更新或者集群资源发生变化进行重新调度，但是 K8s 调度器依然存在一个抢占功能，可以使得高优先级 pod 在调度失败的时候，挤走某个节点上的部分低优先级 pod 以保证高优 pod 的正常，迄今为止我们并没有使用调度器的抢占能力，即使我们通过以上多种策略来加强调度的准确性，但依然无法避免部分场景下由于业务带来的不均衡情况，这种非正常场景中，重调度的能力就有了用武之地，也许重调度将会成为日后针对异常场景的一种自动修复的方式。</p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202201/2041406-20220105170800452-274294687.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"513","createTime":"2021-12-29 15:19","comment":"4","id":"15745107","title":"TKE 用户故事 - 作业帮 PB 级低成本日志检索服务","url":"https://www.cnblogs.com/tencent-cloud-native/p/15745107.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>吕亚霖，2019年加入作业帮，作业帮架构研发负责人，在作业帮期间主导了云原生架构演进、推动实施容器化改造、服务治理、GO微服务框架、DevOps的落地实践。</p> \n <p>莫仁鹏，2020年加入作业帮，作业帮高级架构师，在作业帮期间，推动了作业帮云原生架构演进，负责作业帮服务治理体系的设计和落地、服务感知体系建设以及自研mesh、MQproxy研发工作。</p> \n <h2 id=\"摘要\">摘要</h2> \n <p>日志是服务观察的主要方式，我们依赖日志去感知服务的运行状态、历史状况；当发生错误时，我们又依赖日志去了解现场，定位问题。日志对研发工程师来说异常关键，同时随着微服务的流行，服务部署越来越分散化，所以我们需要一套日志服务来采集、传输、检索日志</p> \n <p>基于这个情况，诞生了以 ELK 为代表的开源的日志服务。</p> \n <h2 id=\"需求场景\">需求场景</h2> \n <p>在我们的场景下，高峰日志写入压力大（每秒千万级日志条数）；实时要求高：日志处理从采集到可以被检索的时间正常 1s 以内（高峰时期 3s）；成本压力巨大，要求保存半年的日志且可以回溯查询（百 PB 规模）。</p> \n <h2 id=\"elasticsearch-的不足\">ElasticSearch 的不足</h2> \n <p><strong>ELK</strong> 方案里最为核心的就是 <strong>ElasticSearch</strong>， 它负责存储和索引日志， 对外提供查询能力。<strong>Elasticsearch</strong> 是一个搜索引擎， 底层依赖了 <strong>Lucene 的倒排索引技术</strong>来实现检索， 并且通过 **shard **的设计拆分数据分片， 从而突破单机在存储空间和处理性能上的限制</p> \n <h3 id=\"写入性能\">写入性能</h3> \n <p>​ ElasticSearch 写入数据需要对日志索引字段的倒排索引做更新，从而能够检索到最新的日志。为了提升写入性能，可以做聚合提交、延迟索引、减少 refersh 等等，但是始终要建立索引， 在日志流量巨大的情况下（每秒 20GB 数据、千万级日志条数）， 瓶颈明显。离理想差距过大，我们期望写入近乎准实时。</p> \n <h3 id=\"运行成本\">运行成本</h3> \n <p>​ ElasticSearch 需要定期维护索引、数据分片以及检索缓存， 这会占用大量的 CPU 和内存，日志数据是存储在机器磁盘上，在需要存储大量日志且保存很长时间时， 机器磁盘使用量巨大，同时索引后会带来数据膨胀，进一步带来成本提升。</p> \n <h3 id=\"对非格式化的日志支持不好\">对非格式化的日志支持不好</h3> \n <p>​ ELK需要解析日志以便为日志项建立索引， 非格式化的日志需要增加额外的处理逻辑来适配。存在很多业务日志并不规范，且有收敛难度。</p> \n <p>总结：日志检索场景是一个<strong>写多读少</strong>的场景， 在这样的场景下去维护一个庞大且复杂的索引， 在我们看来其实是一个性价比很低的事情。如果采用 ElasticSearch 方案，经测算我们需要几万核规模集群，仍然保证不了写入数据和检索效率，且资源浪费严重。</p> \n <h2 id=\"日志检索设计\">日志检索设计</h2> \n <p>面对这种情况， 我们不妨从一个不同的角度去看待日志检索的场景， 用一个更适合的设计来解决日志检索的需求， 新的设计具体有以下三个点：</p> \n <h3 id=\"日志分块\">日志分块</h3> \n <p>同样的我们需要对日志进行采集，但在处理日志时我们不对日志原文进行解析和索引，而是通过日志时间、日志所属实例、日志类型、日志级别等日志元数据对日志进行分块。这样检索系统可以<strong>不对日志格式做任何要求</strong>，并且因为没有解析和建立索引（这块开销很大）的步骤， 写入速度也能够达到极致（只取决于磁盘的 IO 速度）。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211229151838210-1930378558.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>简单来说， 我们可以将一个实例产生的同一类日志按时间顺序写入到一个文件中， 并按时间维度对文件拆分. 不同的日志块会分散在多台机器上(我们一般会按照实例和类型等维度对日志块的存储机器进行分片)， 这样我们就可以在多台机器上对这些日志块并发地进行处理， 这种方式是支持横向扩展的. 如果一台机器的处理性能不够， 横向再扩展就行。</p> \n <p>那如何对入日志块内的数据进行检索呢？这个很简单， 因为保存的是日志原文，可以直接使用 grep 相关的命令直接对日志块进行检索处理。对开发人员来说， grep 是最为熟悉的命令， 并且使用上也很灵活， 可以满足开发对日志检索的各种需求。因为我们是直接对日志块做追加写入，不需要等待索引建立生效，在日志刷入到日志块上时就可以被立刻检索到， 保证了检索结果的<strong>实时性</strong>。</p> \n <h3 id=\"元数据索引\">元数据索引</h3> \n <p>接下来我们看看要如何对这么一大批的日志块进行检索。</p> \n <p>首先我们当日志块建立时， 我们会基于日志块的元数据信息搭建索引， 像服务名称、日志时间， 日志所属实例， 日志类型等信息， 并将日志块的存储位置做为 value 一起存储。通过索引日志块的元数据，当我们需要对某个服务在某段时间内的某类日志发起检索时，就可以快速地找到需要检索的日志块位置，并发处理。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211229151838548-1015214811.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>索引的结构可以按需构建， 你可以将你关心的元数据信息放入到索引中， 从而方便快速圈定需要的日志块。因为我们只对日志块的元数据做了索引， 相比于对全部日志建立索引， 这个成本可以说降到了极低， 锁定日志块的速度也足够理想。</p> \n <h3 id=\"日志生命周期与数据沉降\">日志生命周期与数据沉降</h3> \n <p>日志数据以时间维度的方向可以理解为一种时序数据， 离当前时间越近的日志会越有价值， 被查询的可能性也会越高， 呈现一种冷热分离的情况。而且冷数据也并非是毫无价值，开发人员要求回溯几个月前的日志数据也是存在的场景， 即我们的日志需要在其生命周期里都能够对外提供查询能力。</p> \n <p>对于这种情况，如果将生命周期内的所有日志块都保存在本地磁盘上， 无疑是对我们的机器容量提了很大的需求。对于这种日志存储上的需求，我们可以采用压缩和沉降的手段来解决。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211229151838922-119232010.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>简单来说，我们将日志块存储分为本地存储(磁盘)、远程存储(对象存储)、归档存储三个级别; 本地存储负责提供实时和短期的日志查询(一天或几个小时)， 远程存储负责一定时期内的日志查询需求(一周或者几周)， 归档存储负责日志整个生命周期里的查询需求。</p> \n <p>现在我们看看日志块在其生命周期里是如何在多级存储间流转的， 首先日志块会在本地磁盘创建并写入对应的日志数据， 完成后会在本地磁盘保留一定时间(保留的时间取决于磁盘存储压力)， 在保存一定时间后， 它首先会被<strong>压缩</strong>然后被上传至远程存储(一般是对象存储中的标准存储类型)， 再经过一段时间后日志块会被迁移到归档存储中保存(一般是对象存储中的归档存储类型).</p> \n <p>这样的存储设计有什么好处呢? 如下面的多级存储示意图所示， 越往下存储的数据量越大， 存储介质的成本也越低， 每层大概为上一层的 1/3 左右， 并且数据是在压缩后存储的， 日志的数据压缩率一般可以达到<strong>10:1</strong>， 由此看归档存储日志的成本能在本地存储的<strong>1%</strong>的左右， 如果使用了 SSD 硬盘作为本地存储， 这个差距还会更大。</p> \n <p>价格参考：</p> \n <table> \n  <thead> \n   <tr> \n    <th>存储介质</th> \n    <th>参考链接</th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td>本地盘</td> \n    <td><a href=\"https://buy.cloud.tencent.com/price/cvm?regionId=8&amp;zoneId=800002\" target=\"_blank\" rel=\"noopener\">https://buy.cloud.tencent.com/price/cvm?regionId=8&amp;zoneId=800002</a></td> \n   </tr> \n   <tr> \n    <td>对象存储</td> \n    <td><a href=\"https://buy.cloud.tencent.com/price/cos\" target=\"_blank\" rel=\"noopener\">https://buy.cloud.tencent.com/price/cos</a></td> \n   </tr> \n   <tr> \n    <td>归档存储</td> \n    <td><a href=\"https://buy.cloud.tencent.com/price/cos\" target=\"_blank\" rel=\"noopener\">https://buy.cloud.tencent.com/price/cos</a></td> \n   </tr> \n  </tbody> \n </table> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211229151839287-1970455201.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>那在多级存储间又是如何检索的呢? 这个很简单， 对于本地存储上的检索， 直接在本地磁盘上进行即可。</p> \n <p>如果检索涉及到远程存储上的日志块， 检索服务会将涉及到的日志块下载到本地存储， 然后在本地完成解压和检索。因为日志分块的设计，日志块的下载同检索一样，我们可以在多台机器上并行操作; 下载回本地的数据复制支持在本地缓存后一定的时间后再删除， 这样有效期内对同一日志块的检索需求就可以在本地完成而不需要再重复拉取一遍(日志检索场景里多次检索同样的日志数据还是很常见).</p> \n <p>对于归档存储， 在发起检索请求前， 需要对归档存储中的日志块发起取回操作， 取回操作一般耗时在几分钟左右， 完成取回操作后日志块被取回到远程存储上，再之后的数据流转就跟之前一致了。即开发人员如果想要检索冷数据， 需要提前对日志块做归档取回的申请，等待取回完成后就可以按照热数据速度来进行日志检索了。</p> \n <h2 id=\"检索服务架构\">检索服务架构</h2> \n <p>在了解上面的设计思路后， 我们看看基于这套设计的日志检索服务是怎么落地的.</p> \n <p>日志检索服务分为以下几个模块:</p> \n <ul> \n  <li><strong>GD-Search</strong></li> \n </ul> \n <p>​ 查询调度器， 负责接受查询请求， 对查询命令做解析和优化， 并从 <strong>Chunk Index</strong> 中获取查询范围内日志块的地址， 最终生成分布式的查询计划</p> \n <p>​ <strong>GD-Search</strong> 本身是无状态的， 可以部署多个实例，通过负载均衡对外提供统一的接入地址。</p> \n <ul> \n  <li><strong>Local-Search</strong></li> \n </ul> \n <p>​ 本地存储查询器， 负责处理 <strong>GD-Search</strong> 分配过来的本地日志块的查询请求。</p> \n <ul> \n  <li><strong>Remote-Search</strong></li> \n </ul> \n <p>​ 远程存储查询器， 负责处理 <strong>GD-Search</strong> 分配过来的远程日志块的查询请求。</p> \n <p>​ <strong>Remote-Search</strong> 会将需要的日志块从远程存储拉取到本地并解压， 之后同 <strong>Local-Search</strong> 一样在本地存储上进行查询。同时 <strong>Remote-Search</strong> 会将日志块的本地存储地址更新到 <strong>Chunk Index</strong> 中，以便将后续同样日志块的查询请求路由到本地存储上。</p> \n <ul> \n  <li>Log-Manager</li> \n </ul> \n <p>​ 本地存储管理器，负责维护本地存储上日志块的生命周期。</p> \n <p>​ <strong>Log-Manager</strong> 会定期扫描本地存储上的日志块， 如果日志块超过本地保存期限或者磁盘使用率到达瓶颈，则会按照策略将部分日志块淘汰（压缩后上传到远程存储， 压缩算法采用了 <strong>ZSTD</strong>）， 并更新日志块在 <strong>Chunk Index</strong> 中的存储信息。</p> \n <ul> \n  <li><strong>Log-Ingester</strong></li> \n </ul> \n <p>​ 日志摄取器模块， 负责从日志 kafka 订阅日志数据， 然后将日志数据按时间维度和元数据维度拆分， 写入到对应的日志块中。在生成新的日志块同时， <strong>Log-Ingester</strong> 会将日志块的元数据写入 <strong>Chunk Index</strong> 中， 从而保证最新的日志块能够被实时检索到。</p> \n <ul> \n  <li><strong>Chunk Index</strong></li> \n </ul> \n <p>​ 日志块元数据存储， 负责保存日志块的元数据和存储信息。当前我们选择了 <strong>Redis</strong> 作为存储介质， 在元数据索引并不复杂的情况下， redis 已经能够满足我们索引日志块的需求， 并且基于内存的查询速度也能够满足我们快速锁定日志块的需求。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211229151839611-1210342876.jpg\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"检索策略\">检索策略</h3> \n <p>在检索策略设计上， 我们认为检索的返回速度是追求更快， 同时避免巨大的查询请求进入系统。</p> \n <p>我们认为日志检索一般有以下三种场景:</p> \n <ol> \n  <li> <p>查看最新的服务日志。</p> </li> \n  <li> <p>查看某个请求的日志， 依据 logid 来查询。</p> </li> \n  <li> <p>查看某类日志， 像访问 mysql 的错误日志， 请求下游服务的日志等等。</p> </li> \n </ol> \n <p>在大部分场景下， 用户是不需要所有匹配到的日志， 拿一部分日志足以处理问题。所以在查询时使用者可以设置 limit 数量， 整个检索服务在查询结果满足 limit设置的日志数量时， 终止当前的查询请求并将结果返回给前端。</p> \n <p>另外 <strong>GD-Search</strong> 组件在发起日志块检索时， 也会提前判断检索的日志块大小总和， 对于超限的大范围检索请求会做拒绝。（用户可以调整检索的时间范围多试几次或者调整检索语句使其更有选择性）</p> \n <h3 id=\"性能一览\">性能一览</h3> \n <p>使用 1KB 每条的日志进行测试， 总的日志块数量在10000左右， 本地存储使用 NVME SSD 硬盘， 远程存储使用 S3 协议标准存储.</p> \n <p>• 写入</p> \n <p>​ 单核可支持 2W条/S的写入速度， 1W 条/S的写入速度约占用 1~2G 左右的内存，可分布式扩展，无上限</p> \n <p>• 查询(全文检索)</p> \n <p>​ 基于本地存储的 1TB 日志数据查询速度可在 3S 以内完成</p> \n <p>​ 基于远程存储的 1TB 日志数据查询耗时在 10S 间。</p> \n <h2 id=\"成本优势\">成本优势</h2> \n <p>在每秒千万级写入，百 PB 存储上，我们使用十几台物理服务器就可以保证日志写入和查询。热点数据在本地 nvme 磁盘上，次热数据在对象存里，大量日志数据存储在归档存储服务上。</p> \n <h3 id=\"计算对比\">计算对比</h3> \n <p>​ 因为不需要建立索引，我们只需要千核级别就可以保证写入，同时日志索引是个写多读少的服务，千核可以保证百级别 QPS 查询。</p> \n <p>​ ES 在这个量级上需要投入几万核规模。来应对写入性能和查询瓶颈，但是仍不能保证写入和查询效率。</p> \n <h3 id=\"存储对比\">存储对比</h3> \n <p>​ 核心是在保证业务需求下，使用更便宜的存储介质（归档存储 VS 本地磁盘）和更少的存储数据（压缩率 1/10vs 日志数据索引膨胀）。能有两个量级的差距。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211229151840073-1617535338.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"299","createTime":"2021-12-28 11:31","comment":"0","id":"15739953","title":"TKE用户故事 | 作业帮检索服务基于Fluid的计算存储分离实践","url":"https://www.cnblogs.com/tencent-cloud-native/p/15739953.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>吕亚霖，2019年加入作业帮，作业帮基础架构-架构研发团队负责人，在作业帮期间主导了云原生架构演进、推动实施容器化改造、服务治理、GO微服务框架、DevOps的落地实践。</p> \n <p>张浩然，2019年加入作业帮，作业帮基础架构-高级架构师，在作业帮期间，推动了作业帮云原生架构演进、负责多云k8s集群建设、k8s组件研发、linux内核优化调优、底层服务容器化相关工作。</p> \n <h2 id=\"背景\">背景</h2> \n <p>大规模检索系统一直都是各个公司平台业务的底层基石，往往是以千台裸金属服务器级别的超大规模集群的方式运行，数据量巨大，对于性能、吞吐、稳定性要求极为苛刻，故障容忍度很低。 除了运行层面外，超大规模集群和海量数据场景下的数据迭代和服务治理也往往是一个巨大的挑战：增量和全量的数据分发效率，短期和长期的热点数据追踪等都是需要深入研究的问题 本文将介绍作业帮内部设计实现的基于 fluid 计算存储分离架构，能够显著降低大规模检索系统类服务的复杂度，使得大规模检索系统可以像正常在线业务一样平滑管理。</p> \n <h2 id=\"大规模检索系统所面临的问题\">大规模检索系统所面临的问题</h2> \n <p>作业帮的众多学习资料智能分析和搜索功能中都依赖于大规模数据检索系统，我们的集群规模在千台以上，总数据量在百 TB 级别以上，整个系统由若干分片组成，每个分片由若干服务器加载相同的数据集，运行层面上我们要求性能达到 P99 1.Xms，吞吐量高峰百 GB 级，稳定性要求 99.999% 以上。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211228113034746-1397261061.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>以往环境中为了提高数据读取效率和稳定性，更多的在考虑数据本地化存储，我们的检索系统每日产生索引项并需要进行 TB 级别的数据更新，这些数据通过离线建库服务产出之后，需要分别更新到对应的分片中，这种模式下带来了许多其他挑战，比较关键的问题集中在数据迭代和扩展性上：</p> \n <ol> \n  <li> <p><strong>数据集合的离散</strong>：由于实际运行中，每个分片的每个节点都需要复制下来本分片所有数据，由此带来了同步数据下发困难的问题。实际运行中如果要同步数据到单服务器节点，需要使用分级下发，先下发一级（十级）由一级分发给二级（百级）再分发给三级（千级），这个分发周期长且需要层层校验来保证数据准确性。</p> </li> \n  <li> <p><strong>业务资源弹性扩缩较弱</strong>：原先的系统架构采用的是计算和存储紧耦合，数据存储和算力资源紧密捆绑，资源灵活扩展能力不高，扩容往往需要以小时为单位进行，缺乏应对突发峰值流量扩容能力。</p> </li> \n  <li> <p><strong>单分片数据扩展性不足</strong>：单分片数据上限受分片集群内的单机存储上限限制。如果达到存储上限，往往需要拆分数据集，而这种拆分不是由业务需求驱动的。</p> </li> \n </ol> \n <p>而数据迭代和扩展性的问题又不得不带来了成本压力和自动化流程上的薄弱。</p> \n <p>通过对检索系统运行和数据更新流程的分析，当前面临的关键问题是由于计算和存储的耦合所带来的，因此我们考虑如何去解耦计算和存储，只有引入计算存储分离的架构才能够从根本上解决复杂度的问题 计算存储分离最主要的就是将每个节点存储本分片全量数据的方式拆分开，将分片内的数据存储在逻辑上的远程机器上 但是计算存储分离又带来了其他的问题，比如稳定性问题，大数据量下的读取方式和读取速度，对业务的入侵程度等等问题，虽然存在这些问题，但是这些问题都是可解决以及易解决的 基于此我们确认计算存储分离一定是该场景下的良方，可以从根本上解决系统复杂度的问题。</p> \n <h2 id=\"计算存储分离架构解决复杂度问题\">计算存储分离架构解决复杂度问题</h2> \n <p>为了解决上述计算存储分离所需要考虑的问题，新的计算存储分离架构必须能达到以下目标：</p> \n <ol> \n  <li> <p>读取的稳定性，计算存储分离终究是通过各种组件配合替换掉了原始文件读取，数据加载方式可以替换，但是数据读取的稳定性依然需要和原始保持同等水平。</p> </li> \n  <li> <p>每个分片千节点同时数据更新场景下，需要最大限度的提升读取速度，同时对网络的压力需要控制在一定程度内。</p> </li> \n  <li> <p>支持通过 POSIX 接口读取数据，POSIX 是最具备对各种业务场景的适应性的方式，这样无需侵入业务场景下，屏蔽了下游变动对上游的影响。</p> </li> \n  <li> <p>数据迭代的流程的可控性，对于在线业务来说，数据的迭代理应被视为和服务迭代等同的 cd 流程，那么数据迭代的可控性就及其重要，因为本身就是 cd 流程的一部分。</p> </li> \n  <li> <p>数据集合的可伸缩性，新的架构需要是一套可复制，易扩展的模式，这样才能面对数据集合的伸缩、集群规模的伸缩具备良好的应对能力。</p> </li> \n </ol> \n <p>为了达成上述目标，我们最终选用了 Fluid 开源项目作为整个新架构的关键纽带。</p> \n <h3 id=\"组件介绍\">组件介绍</h3> \n <p><strong>Fluid 是一个开源的 Kubernetes 原生的分布式数据集编排和加速引擎</strong>，主要服务于云原生场景下的数据密集型应用，例如大数据应用、AI应用等。通过 Kubernetes 服务提供的数据层抽象，可以让数据像流体一样在诸如 HDFS、OSS、Ceph 等存储源和 Kubernetes 上层云原生应用计算之间灵活高效地移动、复制、驱逐、转换和管理。而具体数据操作对用户透明，用户不必再担心访问远端数据的效率、管理数据源的便捷性，以及如何帮助 Kuberntes 做出运维调度决策等问题。</p> \n <p>用户只需以最自然的 Kubernetes 原生数据卷方式直接访问抽象出来的数据，剩余任务和底层细节全部交给 Fluid 处理。Fluid 项目当前主要关注数据集编排和应用编排这两个重要场景。</p> \n <p>数据集编排可以将指定数据集的数据缓存到指定特性的 Kubernetes 节点，而应用编排将指定该应用调度到可以或已经存储了指定数据集的节点上。这两者还可以组合形成协同编排场景，即协同考虑数据集和应用需求进行节点资源调度。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211228113035025-957695265.jpg\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"我们选择使用-fluid-的原因\">我们选择使用 fluid 的原因</h3> \n <ol> \n  <li> <p>检索服务已经完成容器化改造，天然适合 fluid。</p> </li> \n  <li> <p>Fluid 作为数据编排系统，使得上层无需知道具体的数据分布就可以直接使用，同时基于数据的感知调度能力，可以实现业务的就近调度，加速数据访问性能。</p> </li> \n  <li> <p>Fluid 实现了 pvc 接口，使得业务 pod 可以无感知的挂载进入 pod 内部，让 pod 内可以像使用本地磁盘一样无感知。</p> </li> \n  <li> <p>Fluid 提供元数据和数据分布式分层缓存，以及高效文件检索功能。</p> </li> \n  <li> <p>Fluid+alluxio 内置了多种缓存模式（回源模式，全缓存模式），不同的缓存策略（针对小文件场景的优化等）和存储方式（磁盘，内存），对于不同的场景具备良好的适应性，无需太多修改即可满足多种业务场景。</p> </li> \n </ol> \n <h3 id=\"落地实践\">落地实践</h3> \n <ol> \n  <li> <p>缓存节点和计算节点的分离: 虽然使用 fuse 和 worker 结合部署可以获得更好的数据本地性能，但是在在线场景下，我们最终选用了缓存和计算节点分离的方案，原因是通过延长一定的启动时间换来更优的弹性是值得的，以及我们并不希望业务节点稳定性问题和缓存节点的稳定性问题纠缠在一起。Fluid 支持 dataset 的可调度性，换言之就是缓存节点的可调度性，我们通过指定 dataset 的 nodeAffinity 来进行数据集缓存节点的调度，从而保证缓存节点可高效，弹性化的提供缓存服务。</p> </li> \n  <li> <p>在线场景的高要求: 对于在线业务场景，鉴于系统对于数据的访问速度、完整性和一致性有较高的要求，因此不能出现数据的部分更新、非预期的回源请求等; 所以对数据缓存和更新策略的选择就会很关键。</p> \n   <ul> \n    <li> <p><strong>合适的数据缓存策略</strong>: 基于以上需求，我们选择使用 Fluid 的全缓存模式。在全缓存模式下，所有请求只会走缓存，而不在回源到数据源，这样就避免了非预期的长耗时请求。同时 dataload 的过程则由数据更新流程来把控，更安全和标准化。</p> </li> \n    <li> <p><strong>结合权限流的更新流程</strong>: 在线业务的数据更新也是属于 cd 的一种，同样也需要更新流程来管控，通过结合了权限流程的 dataload 模式，使得线上数据发版更安全和标准化。</p> </li> \n    <li> <p><strong>数据更新的原子性</strong>: 由于模型是由许多文件组成，只有所有的文件全部缓存起来之后，才是一份可以被使用的完整的模型；所以在全缓存无回源的前提下，就需要保证 dataload 过程的原子性, 在数据加载的过程中过，新版本数据不能被访问到，只有在数据加载完成之后，才可以读取到新版本数据。</p> </li> \n   </ul> </li> \n </ol> \n <p>以上方案和策略配合我们自动化的建库和数据版本管理功能，大大提高了整体系统的安全性和稳定性，同时使得整个过程的流转更加智能和自动化。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211228113035355-1618658608.jpg\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"总结\">总结</h2> \n <p>基于 Fluid 的计算存储分离架构，我们成功地实现：</p> \n <ol> \n  <li> <p>分钟级百 T 级别的数据分发。</p> </li> \n  <li> <p>数据版本管理和数据更新的原子性，使得数据分发和更新成为一种可管控，更智能的自动化流程。</p> </li> \n  <li> <p>检索服务能够像正常无状态服务一样，从而能够轻松通过 TKE HPA 实现横向扩展，更快捷的扩缩带来了更高的稳定性和可用性。</p> </li> \n </ol> \n <h2 id=\"展望\">展望</h2> \n <p>计算和存储分离的模式使得以往我们认为非常特殊的服务可以被无状态化，可以像正常服务一样被纳入 Devops 体系中，而基于 Fluid 的数据编排和加速系统，则是实践计算和存储分离的一个切口，除了用于检索系统外，我们也在探索基于 Fluid 的 OCR 系统模型训练和分发的模式。</p> \n <p>在未来工作方面，我们计划继续基于 Fluid 优化上层作业的调度策略和执行模式，并进一步扩展模型训练和分发，提高整体训练速度和资源的利用率，另一方面也帮助社区不断演进其可观测性和高可用等，帮助到更多的开发者。</p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211228113036075-777346228.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"378","createTime":"2021-12-23 19:04","comment":"0","id":"15724830","title":"Clusternet 成为首批通过工信部开源成熟度评估项目！！！","url":"https://www.cnblogs.com/tencent-cloud-native/p/15724830.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <p>Clusternet 作为首批项目参与了《信息技术 开源 开源项目评估模型参考架构》测评，并成为通过评估的四个项目之一。《信息技术 开源 开源项目评估模型参考架构》由国防科技大学牵头，工信部电子标准院归口并组织举办多次专家研讨会，来自华东师范大学、腾讯、华为、阿里、百度、Intel、开放原子开源基金会、Linux 基金会、OpenInfra 基金会、Apache 基金会、蚂蚁集团、CSDN、滴滴、开源社、鹏城实验室、浪潮信息等企业和组织的专家积极参与讨论，为标准的制定做出重要贡献。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211223190406012-1498426126.jpg\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"开源-clusternet-项目\">开源 Clusternet 项目</h2> \n <p>Clusternet ( <strong>Cluster</strong> Inter<strong>net</strong> ) 由腾讯联合多点生活、QQ音乐、富途证券、微众银行、酷狗音乐、三七互娱等共同发起，专注 K8s 多集群管理和应用治理方向，希望让管理多集群就像上网一样简单。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211223190406460-527586795.png\" alt=\"\" loading=\"lazy\"></p> \n <p>Clusternet 面向未来云原生多云多集群而设计，领先的架构支持用户以全局视角统一管理各个集群及应用，轻松地将用户业务发布至全球，一次发布处处运行。无论你的 Kubernetes 集群是运行在公有云、私有云、混合云还是边缘云上，都拥有一致的管理/访问体验，利用 K8s API 集中部署和协调多集群的应用程序和服务。</p> \n <p>作为未来分布式云的技术基石，Clusternet 通过组件化方式扩展 K8s，将 K8s 强大的集群、应用和服务能力扩展至分布式云，能够兼容所有 K8s 生态资源和软件，帮助企业应用零成本升级至多云架构，助力传统行业向未来分布式云的转型。</p> \n <p>以 Clusternet 项目为基础实现多云多集群管理平台，为用户提供跨云、跨集群、跨region/zone 的分布式容器服务，将更好的满足多种场景需求。</p> \n <ul> \n  <li>多租户</li> \n  <li>高可用与容灾</li> \n  <li>多云多中心服务</li> \n  <li>边缘计算</li> \n </ul> \n <h2 id=\"加入我们\">加入我们</h2> \n <p>Clusternet 目前已经提交了 CNCF Sandbox 项目的申请，将继续坚持项目中立，与大家一起求实创新，合作共建。</p> \n <p>当前 Clusternet 仍在快速开发迭代中，持续带来更多优秀的特性，欢迎大家关注 <a href=\"https://github.com/clusternet/clusternet\" target=\"_blank\" rel=\"noopener\">https://github.com/clusternet/clusternet</a> ，点赞支持，并加入我们。</p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211223190406833-946197674.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"301","createTime":"2021-12-22 09:35","comment":"0","id":"15718050","title":"大规模服务网格性能优化 | Aeraki xDS 按需加载","url":"https://www.cnblogs.com/tencent-cloud-native/p/15718050.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>钟华，腾讯云专家工程师，Istio project member、contributor，专注于容器和服务网格，在容器化和服务网格生产落地方面具有丰富经验，目前负责 Tencent Cloud Mesh 研发工作。</p> \n <h2 id=\"istio-在大规模场景下-xds-性能瓶颈\">Istio 在大规模场景下 xDS 性能瓶颈</h2> \n <p>xDS 是 istio 控制面和数据面 envoy 之间的通信协议，x 表示包含多种协议的集合，比如：LDS 表示监听器，CDS 表示服务和版本，EDS 表示服务和版本有哪些实例，以及每个服务实例的特征，RDS 表示路由。可以简单的把 xDS 理解为，网格内的服务发现数据和治理规则的集合。xDS 数据量的大小和网格规模是正相关的。</p> \n <p>当前 istio 下发 xDS 使用的是全量下发策略，也就是网格里的所有 sidecar，内存里都会有整个网格内所有的服务发现数据。比如下图，虽然 workload 1 在业务逻辑上只依赖 service 2， 但是 istiod 会把全量的服务发现数据（service 2、3、4）都发送给 workload 1。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211222093427820-1737860056.png\" alt=\"\" loading=\"lazy\"></p> \n <p>这样的结果是，每个 sidecar 内存都会随着网格规模增长而增长，下图是我们对网格规模和内存消耗做的一个性能测试，x 轴是网格规模，也就是包含多少个服务实例，y 轴是单个 envoy 的内存消耗。可以看出，如果网格规模超过 1万个实例，单个 envoy 的内存超过了 250 兆，而整个网格的开销还要再乘以网格规模大小。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211222093428150-911703741.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"istio-当前优化方案\">Istio 当前优化方案</h2> \n <p>针对这个问题，社区提供了一个方案，就是 <a href=\"https://istio.io/latest/docs/reference/config/networking/sidecar/\" title=\"Sidecar\" target=\"_blank\" rel=\"noopener\">Sidecar</a> 这个 CRD，这个配置可以显式的定义服务之间的依赖关系，或者说可见性关系。比如下图这个配置的意思就是 workload 1 只依赖 service 2 ，这样配置以后，istiod 只会下发 service 2 的信息给 workload 1。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211222093428460-83426698.png\" alt=\"\" loading=\"lazy\"></p> \n <p>这个方案本身是有效的。但这种方式在大规模场景下很难落地：首先这个方案需要用户提前配置服务间完整的依赖关系，大规模场景下的服务依赖关系很难梳理清楚，而且通常依赖关系也会随着业务的变化而变化。</p> \n <h2 id=\"aeraki-lazy-xds\">Aeraki Lazy xDS</h2> \n <p>针对上述问题，<a href=\"https://cloud.tencent.com/product/tcm\" title=\"TCM\" target=\"_blank\" rel=\"noopener\">TCM</a> 团队设计了一套无入侵的 xDS 按需加载方案，并开源到 github <a href=\"https://github.com/aeraki-framework/aeraki\" title=\"Aeraki\" target=\"_blank\" rel=\"noopener\">Aeraki</a> 项目，这是 Lazy xDS 具体的实现细节：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211222093428781-528550710.png\" alt=\"\" loading=\"lazy\"></p> \n <p>我们在网格里增加2个组件，一个是 Lazy xDS Egress，Egress 充当类似网格模型中默认网关角色，另一个是 Lazy xDS Controller，用来分析并补全服务间的依赖关系。</p> \n <ol> \n  <li> <p>首先配置 Egress 的服务中转能力：Egress 会获取网格内所有服务信息，并配置所有 HTTP 服务的路由，这样充当默认网关的 Egress 就可以转发网格内任意 HTTP 服务的流量。</p> </li> \n  <li> <p>第2步，对于开启了按需加载特性的服务（图中 Workload 1），利用 envoyfilter，将其访问网格内 http 服务的流量，都路由到 egress。</p> </li> \n  <li> <p>第3步，利用 istio sidecar CRD，限制 Workload 1 的服务可见性。</p> </li> \n  <li> <p>经过步骤3后，Workload 1 初始只会加载最小化的 xDS。</p> </li> \n  <li> <p>当 Workload 1 发起对 Service 2 的访问时，（因为步骤2）流量会转发到 Egress。</p> </li> \n  <li> <p>（因为步骤 1）Egress 会分析接收到的流量特征，并将流量转发到 Service 2。</p> </li> \n  <li> <p>Egress 会将访问日志，异步地上报给 Lazy xDS Controller，上报服务是利用 <a href=\"https://www.envoyproxy.io/docs/envoy/latest/api-v3/service/accesslog/v3/als.proto.html\" title=\"Access Log Service\" target=\"_blank\" rel=\"noopener\">Access Log Service</a>。</p> </li> \n  <li> <p>Lazy xDS Controller 会对接收到的日志进行访问关系分析，然后把新的依赖关系（Workload 1 -&gt; Service 2）表达到 sidecar CRD 中。</p> </li> \n  <li> <p>同时 Controller 还会将（步骤2） Workload 1 需要转发 Service 2 流量到 Egress 的规则去除，这样未来 workload 1 再次访问 Service 2 就会是直连。</p> </li> \n  <li> <p>（因为步骤 8）istiod 更新可见性关系，后续会将 Service 2 的服务信息发给 Workload 1。</p> </li> \n  <li> <p>Workload 1 通过 xDS 接收到 Service 2 的服务信息。</p> </li> \n  <li> <p>当 Workload 1 再次发起对 Service 2 的访问，流量会直达 Service 2（因为步骤9）。</p> </li> \n </ol> \n <p>这个方案的好处：</p> \n <ul> \n  <li> <p>首先不需要用户提前配置服务间的依赖，而且服务间依赖是允许动态的增加的。</p> </li> \n  <li> <p>最终每个 envoy 只会获得自身需要的 xDS，性能最优。</p> </li> \n  <li> <p>这个实现对用户流量影响也比较小，用户的流量不会阻塞。性能损耗也比较小，只有前几次请求会在 Egress 做中转，后面都是直连的。</p> </li> \n  <li> <p>此方案对 istio 和 envoy 没有任何入侵，我们没有修改 istio/envoy 源码，使得这套方案能很好的适应未来 istio 的迭代。</p> </li> \n </ul> \n <p>目前我们只支持七层协议服务的按需加载，原因是流量在 Egress 这里中转的时候，Egress 需要通过七层协议里的 header 判断原始目的地。纯 TCP 协议是没有办法设置额外的 header。不过因为 istio 主要目的就是为了做七层流量的治理，当网格的大部分请求都是七层的，这个情况目前可以接受的。</p> \n <h2 id=\"lazy-xds-性能测试\">Lazy xDS 性能测试</h2> \n <h3 id=\"测试方案\">测试方案</h3> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211222093429134-1609936274.png\" alt=\"\" loading=\"lazy\"></p> \n <p>在同一网格内的不同 namespace 中，我们创建了 2 组 book info，左边 namespace lazy-on 中 productpage 开启按需加载，右边 namespace lazy-off 保持默认情况。</p> \n <p>然后在这个网格内，我们逐渐增加服务数量，使用的是 istio 官方<a href=\"https://github.com/istio/tools/tree/master/perf/load\" title=\"负载测试工具集\" target=\"_blank\" rel=\"noopener\">负载测试工具集</a>（以下简称「负载服务」），每个 namespace 里有 19 个服务， 其中4个 tcp 服务，15个 http 服务，每个服务初始 pod 数目为 5，共95个 pod（75 个http，20 个tcp）。我们逐渐增加负载服务的 namespace 数量， 用于模拟网格规模增长。</p> \n <h3 id=\"性能对比\">性能对比</h3> \n <p>首先是 CDS 和 EDS 的对比，下图每组数据代表负载服务 namespace 的增加，每组数据里 4 个值：前 2 个值是开启按需加载后的 CDS 和 EDS，后面 2个值是没开启按需加载的 CDS 和 EDS。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211222093429476-1874706865.png\" alt=\"\" loading=\"lazy\"></p> \n <p>接下来是内存对比，绿色数据表示开启按需加载后 envoy 的内存消耗，红色的是未开启的情况。900 pods 规模 mesh，envoy 内存减少 14M ，降低比例约 40%；一万 pods 规模 mesh，envoy 内存减少约 150M，降低比例约 60%。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211222093429726-1764262782.png\" alt=\"\" loading=\"lazy\"></p> \n <p>随着服务可见性的限制，envoy 不会再接收全量的 xDS 更新，下图是在测试周期内 envoy 接收到 CDS 更新次数的对比，开启按需加载后，更新次数从 6 千次降低到了 1 千次。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211222093430084-774849959.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"小结\">小结</h2> \n <p>Lazy xDS 已经在 github 开源，请访问 <a href=\"https://github.com/aeraki-framework/aeraki/blob/master/lazyxds/README.md\" title=\"lazyxds README\" target=\"_blank\" rel=\"noopener\">lazyxds README</a>了解如何使用。</p> \n <p>Lazy xDS 功能还在持续演进，未来我们将支持多集群模式、ServiceEntry 按需加载等功能。</p> \n <p>如果您希望了解更多关于 Aeraki 的内容，欢迎访问 Github 主页：<a href=\"https://github.com/aeraki-framework/aeraki\" target=\"_blank\" rel=\"noopener\">https://github.com/aeraki-framework/aeraki</a></p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211222093430506-26967167.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"184","createTime":"2021-12-17 17:14","comment":"0","id":"15703084","title":"云计算 = “潘多拉”？","url":"https://www.cnblogs.com/tencent-cloud-native/p/15703084.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>王孝威：FinOps 认证从业者，热衷传播 FinOps 理论和实践知识，助力云上企业降本增效。</p> \n <h2 id=\"云计算时代已经到来\">云计算时代已经到来</h2> \n <p>云计算时代真的到来了吗？</p> \n <p>云计算（Cloud Computing），从 2006 年 AWS 第一次推出弹性计算云服务，已走过十五年风雨历程。早期被指责成“新瓶装旧酒” 的炒作，后来引发了人们对云上数据隐私的担忧，再到对公有云偶发事故的嘲笑，云计算的成长一直饱受骂名，但云计算市场现状究竟如何？</p> \n <h3 id=\"从中国市场主流软件来看\">从中国市场主流软件来看</h3> \n <p>可能你已经注意到，在部分国民软件的启动页，会看到最下面有个标识：“某某云提供计算服务”。云计算已经渐渐融入了生活，例如想聊天了打开通信软件、无聊了想听歌看视频、饿了想点外卖、找不到方向想看地图，这些软件的启动页下面可能都有一行字：“某某云提供计算服务”，云计算已经给生活带来了无穷便利。</p> \n <h3 id=\"从全球云计算市场规模来看\">从全球云计算市场规模来看</h3> \n <p>公有云在每年超过 <a href=\"https://www.gartner.com/en/newsroom/press-releases/2020-07-23-gartner-forecasts-worldwide-public-cloud-revenue-to-grow-6point3-percent-in-2020#:~:text=The%20worldwide%20public%20cloud%20services,%2C%20according%20to%20Gartner%2C%20Inc\" title=\"1000亿\" target=\"_blank\" rel=\"noopener\">1000亿</a>美元支出的基础上快速增长，2020 年全球共有云市场份额已经超过 1250 亿美元，云计算正在化茧成蝶。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211217171334641-1603597831.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>图1：企业在公有云和数据中心的花费<br> 图源: <a href=\"https://www.srgresearch.com/articles/2020-the-year-that-cloud-service-revenues-finally-dwarfed-enterprise-spending-on-data-centers\" title=\"Synergy Research Group\" target=\"_blank\" rel=\"noopener\">Synergy Research Group</a></p> \n <h3 id=\"为什么云计算市场爆发了\">为什么云计算市场“爆发”了？</h3> \n <p>云计算把所有的计算、存储、网络等资源都抽象成了资源池，如下图2所示。需要用这些资源时只需要在公有云的平台网站上用手指点点点，资源触手可及。这就像你住的家里接通了水、电、网络，只需要打开开关，就能享受现代生活的便利。云计算极大的方便了企业在发展过程中对资源的消耗，无需再提前购买资源、组建团队、专门运营，需要资源只需要在公有云平台上注册一个账号，就可以直接使用多样化的资源服务。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211217171334960-313094428.png\" alt=\"\" loading=\"lazy\"></p> \n <p>图2：云计算将企业需要的资源抽象成了随手可得的水电</p> \n <h2 id=\"潘多拉魔盒已经打开\">潘多拉魔盒已经打开</h2> \n <p>云计算 = “银弹”？</p> \n <p>如图3所示，现代家庭需要管理的一般都是小范围资源的开关，例如一个家庭一般只有几个水龙头、数十个开关和插头、以及一个网络入口，水和电一般都是随用随开、按量付费，网络则是包年包月。水龙头一般会记得关，但很多开关会时会常忘记，例如空调、电视等等，每次较电费时会“心痛不已”。同样的，如果使用个人电脑或者云上的资源做一个小的项目时（例如学校的软件作业），可以自己控制项目的启停。如果忘记关闭项目，因为项目本身会消耗资源，个人电脑就会变卡、如果项目在云端运行，则会持续产生费用。</p> \n <p>如果从现代家庭上升到城市维度，城市管理需要管理的“开关”、“插头”和“网络”成千上万。同样的，如果运行的项目从传统的个人小项目上升到例如微信这样的国民应用，需要消耗的资源也是指数级增长的。如此庞大的资源管理量，用现代家庭（小项目）的资源管理方式可能无法应对，而且管理不当会造成较大浪费。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211217171335432-1275700588.png\" alt=\"\" loading=\"lazy\"></p> \n <p>图3：现代城市的资源管理难题</p> \n <p>从企业资源管理来看，以前一般都有自己的 IT 中心，企业看到到自己的设备、有清晰明确的设备购买流程、有折旧计算方法、有严格的资源审核逻辑、有完整的 IT 中心管理体系。云计算把 IT 中心虚拟化了，变成了纯线上的虚拟平台，让资源随时随地想用就用，这种可变的支出模型一旦没有好好利用，或者是忘记了关闭“开关”，浪费现象显著。如今的公有云，每家厂商都提供了数百种产品，每种产品下又有若干种不同的类型，客户对云资源的管理来产生了新的挑战。这个过程的转变，如果改变现有的管理手段？</p> \n <p>要改变管理手段之前，可以先分析企业资源消费模型的变化，这里最主要的变化是：公司对 IT 资产的投入从传统的资本投资（Capital Expenses）变成了运营支出（Operating Expenses），这种变化主要表现为：</p> \n <table> \n  <thead> \n   <tr> \n    <th style=\"text-align: left\"></th> \n    <th style=\"text-align: left\">传统 IT 消费模型</th> \n    <th style=\"text-align: left\">云上可变消费模型</th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td style=\"text-align: left\">设备的购买流程</td> \n    <td style=\"text-align: left\">当项目团队的新项目需要硬件设备时，需要向财务部和采购部证明其项目是否有足够的商业化价值，通过了才能申请经费、订购设备</td> \n    <td style=\"text-align: left\">任何授权的项目团队成员可以随时随地购买云资源，财务部和采购部失去了管理的作用</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">角色关系</td> \n    <td style=\"text-align: left\">工程师是申请者； 财务部/采购部是审核批准者</td> \n    <td style=\"text-align: left\">工程师可以随时随地购买云资源 spend money with code； 财务部/采购部对花费没有清晰的可见性，失去了监管作用； 且不同角色之间缺少了沟通</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">消费</td> \n    <td style=\"text-align: left\">可预测（根据预测提前购买设备）； 静态的（在下次采购之前都不会发生变化）</td> \n    <td style=\"text-align: left\">不可预测的（随时购买设备）； 动态的（随时随地可能有变化）</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">购买周期</td> \n    <td style=\"text-align: left\">较长</td> \n    <td style=\"text-align: left\">即时</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">失败成本</td> \n    <td style=\"text-align: left\">大</td> \n    <td style=\"text-align: left\">小，但可能造成浪费</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">项目敏捷</td> \n    <td style=\"text-align: left\">低</td> \n    <td style=\"text-align: left\">高</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">支出模型</td> \n    <td style=\"text-align: left\">资本投资（Capital Expenses），像投资一样提前批量购买设备</td> \n    <td style=\"text-align: left\">运营支出（Operating Expenses），像运营一样随时按需购买设备</td> \n   </tr> \n  </tbody> \n </table> \n <p>表1：公司对 IT 资产的消费模型变化</p> \n <p>因此，如果管理方式没有进化，“上云”反而可能成为一种负担。Flexera 发布的《2021 云计算市场发展状态报告》指出，<strong>企业上云后平均浪费了 30% 的云支出</strong>，云成本优化是企业 2021 年最想做的事情。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211217171335888-383780598.png\" alt=\"\" loading=\"lazy\"></p> \n <p>图4：Flexera 调研企业在 2021 年最想做的关于云的事情</p> \n <p>潘多拉魔盒（潘多拉盒子，pandora's box）是一则古希腊经典神话。众神赠予了潘多拉一个魔盒，盒子里面包含人世间所有邪恶——贪婪、虚伪、诽谤、嫉妒等等。云计算虽然让企业过上了资源随时随地即开即用的“现代生活”，但因为其余的配套系统（管理方式、人员培训、运营手段）没有及时跟进，云计算像一个潘多拉盒子一样，给企业也带来了很多难题。本文主要探讨企业上云后最大的问题：如何有效优化云的使用成本？</p> \n <h2 id=\"盖上潘多拉魔盒\">盖上潘多拉魔盒</h2> \n <p>魔盒如何关闭？</p> \n <p>新的企业 IT 消费模型需要新的管理手段，该方案应该是能够覆盖人员、流程和技术的管理，是专门针对云上可变消费模型的治理方案，确保客户在云上花费的每一元获得最大价值。</p> \n <p>如果该方案还可以结合客户自己的商业化指标给出决策性建议，（例如：公司在云上有十个项目，发现2个项目的云资源消耗金额远小于项目的收入，可以考虑是否应该为这两个项目投入更多的资源？发现有3个项目的投入产出比一直在扩大，考虑这三个项目是否该做些调整？）。这样就可以帮助企业如何利用云计算赚钱，而不是一味的追求省钱，充分发挥云计算的价值，将潘多拉魔盒关闭。</p> \n <p>于是，基于企业对云上成本管理诉求的分析，总结如下：</p> \n <ol> \n  <li>看得见：让企业理解自己的用量和成本 \n   <ul> \n    <li>项目维度：具体到每一个项目/服务的成本</li> \n    <li>人员维度：具体到每一个组织架构/团队/人员的成本</li> \n    <li>自定义维度：每一个自定义维度的成本（例如：某一具体云资源的用量；多个团队的成本聚合；不同时段的成本对比；成本趋势图等等）</li> \n   </ul> </li> \n  <li>用得省：提供建议优化成本 \n   <ul> \n    <li>手段：云上资源的付费类型、机型推荐，识别并清理闲置资源，定义预算告警等</li> \n    <li>策略：简化配置优化动作和策略（例如：当机型不合适的时候提示用户手动更换推荐的机型）</li> \n    <li>评估：不同手段的优化收益&amp;风险（例如：对比新旧机型的价格差异；清理闲置资源时可能对波峰流量无法承载的风险）</li> \n    <li>自动化：自动化执行优化策略和告警</li> \n   </ul> </li> \n  <li>持续运营：持续基于商业策略优化成本 \n   <ul> \n    <li>预测：预测未来的成本，预测通过手段优化后的成本变化</li> \n    <li>衡量：如何将成本与项目的 KPIs 结合，衡量项目的投入产出比</li> \n    <li>架构：如何将成本对应公司不同等级的组织架构</li> \n    <li>决策：如何利用洞察的指标帮助项目/公司做更好的决策</li> \n   </ul> </li> \n </ol> \n <p>企业云成本管理的问题已经抛出，是否有一种有效的手段可以完全的解决以上所有问题？</p> \n <p>FinOps（Financial Operations）就是这样的一种最佳实践，帮助云上客户有效洞察云支出、提供手段优化用户成本、以及后续长时间的持续运营和优化。FinOps 涉及的领域：</p> \n <ul> \n  <li>理解云支出和成本（对应企业成本管理问题的“看得见”，帮助企业理解成本构成） \n   <ul> \n    <li>回答这样的一个问题：企业在云上花费了什么？</li> \n    <li>收集有关云使用和成本的所有必要信息，并将其分配到每一个人身上，理解团队中每一个项目/人关于云资源的使用情况</li> \n   </ul> </li> \n  <li>性能追踪和基准测试（对应企业成本管理问题的“持续运营”，帮助企业理解自己的成本是否用的对） \n   <ul> \n    <li>回答这样的一个问题：正在使用/支出的云资源是否使企业能够实现其战略和组织目标？</li> \n    <li>设置其使用情况和成本并将其映射到预算中，使用历史信息进行预测，并建立和衡量关键绩效指标和其他绩效指标。</li> \n   </ul> </li> \n  <li>实时制定决策（对应企业成本管理问题的“持续运营”，帮助企业做决策） \n   <ul> \n    <li>回答这样的一个问题：采取什么行动来更好地实现企业的目标？</li> \n    <li>当企业了解支出，并了解相对于预期和标准的表现时，企业可以在收到新的云支出信息时使用这些信息做出实时决策。</li> \n   </ul> </li> \n  <li>云上支出优化（对应企业成本管理问题的“用的省”，帮助企业选择更合适的云资源） \n   <ul> \n    <li>回答这样的一个问题：如何改变企业支付的费用模型（包年包月/按量付费/竞价实例），以及如何购买在云端使用的东西（应该选择什么机型），以实现更好的价格目标？</li> \n    <li>利用历史使用的数据调整定价模型，帮助企业选择更合适的费用模型和机型实例。</li> \n   </ul> </li> \n  <li>云使用的优化（对应企业成本管理问题的“用的省”，帮助企业更有效管理自己的业务） \n   <ul> \n    <li>回答这样的一个问题：如何更改企业使用的云资源方式，以优化成本？</li> \n    <li>管理业务工作负载、以及云资源实例的数量，在不使用时关闭资源。</li> \n   </ul> </li> \n  <li>团结公司组织（对应企业成本管理问题的“持续运营”，帮助调整企业组织架构，以实现降本增效的文化） \n   <ul> \n    <li>回答这样的一个问题：可以在企业的组织内进行哪些更改，来更有效地使用云？</li> \n    <li>将 FinOps 与现有组织流程、组织单位和技术集成。</li> \n   </ul> </li> \n </ul> \n <h2 id=\"为什么是-finops\">为什么是 FinOps？</h2> \n <p>FinOps 提出了非常详细的云上成本管理手段，包含下图5中的理念、原则、涉及的人员的分工、成本优化的阶段、涉及领域等。</p> \n <h3 id=\"finops-理念\">FinOps 理念</h3> \n <p>FinOps 致力于通过一整套系统、最佳实践、文化，帮助企业去理解云成本，以实现更好的决策。</p> \n <h3 id=\"finops-原则\">FinOps 原则</h3> \n <ol> \n  <li>团队需要合作（团队主要包含：财务团队、技术团队、业务团队）</li> \n  <li>云的价值驱动了决策（帮助执行层洞察云上消费的价值所在，辅助其做决策）</li> \n  <li>每个人都要为自己消耗的云成本负责（将云成本分摊到每一人身上）</li> \n  <li>FinOps 的报告应该是便于访问的、且是实时的（报告应该及时、人人可访问）</li> \n  <li>一个中心化的团队驱动了 FinOps 的云上成本管理理念（必须有一个全局观的团队将不同人员团结起来，使用 FinOps 的理念优化云支出）</li> \n  <li>利用云的可变消费模型（云的消费模式有其特殊使用方法，好好利用才能充分发挥作用）</li> \n </ol> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211217171336373-2056185700.png\" alt=\"\" loading=\"lazy\"></p> \n <p>图5：什么是 <a href=\"https://data.finops.org/\" title=\"FinOps？\" target=\"_blank\" rel=\"noopener\">FinOps</a>？</p> \n <h3 id=\"finops-的影响力\">FinOps 的影响力</h3> \n <p>FinOps 基金会做了一个问卷调查，共收到 804 个回复，参与回复的企业总的年云支出超过 300 亿美元。超过 78% 的回访者指出：FinOps Foundation 是云上成本优化管理信息的最佳来源。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211217171336891-958299724.png\" alt=\"\" loading=\"lazy\"></p> \n <p>图6：<a href=\"https://data.finops.org/\" title=\"云上成本优化管理的渠道\" target=\"_blank\" rel=\"noopener\">云上成本优化管理的渠道</a></p> \n <h3 id=\"finops-全景图\">FinOps 全景图</h3> \n <p>FinOps 基金会是Linux 基金会的一个项目，致力于通过最佳实践、培训、制定标准来推进 云的财务管理。 2019年2月成立 FinOps 基金会，2020年6月加入 Linux 基金会。目前 FinOps 基金会包括来自 1500+ 企业的 3500+ 个人成员，包括 10+ 服务和平台提供商。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211217171337366-312686703.png\" alt=\"\" loading=\"lazy\"></p> \n <p>图7: <a href=\"https://landscape.finops.org/\" title=\"FinOps 全景图\" target=\"_blank\" rel=\"noopener\">FinOps 全景图</a></p> \n <h2 id=\"写在最后\">写在最后</h2> \n <p>云计算的时代已经到来，云上成本管理迫在眉睫，FinOps 中文社区将持续经营和传播 FinOps 相关的理念和知识，期待您的加入，让企业上云的价值会到初心 —— 降本增效。</p> \n <h2 id=\"参考\">参考：</h2> \n <p><a href=\"https://a16z.com/2021/05/27/cost-of-cloud-paradox-market-cap-cloud-lifecycle-scale-growth-repatriation-optimization/\" title=\"The Cost of Cloud, a Trillion Dollar Paradox\" target=\"_blank\" rel=\"noopener\">The Cost of Cloud, a Trillion Dollar Paradox</a></p> \n <p><a href=\"https://www.atlassian.com/blog/platform/what-is-finops\" target=\"_blank\" rel=\"noopener\">https://www.atlassian.com/blog/platform/what-is-finops</a></p> \n <p><a href=\"https://www.finops.org/introduction/what-is-finops/\" target=\"_blank\" rel=\"noopener\">https://www.finops.org/introduction/what-is-finops/</a></p> \n <p><a href=\"https://saasoptics.com/blog/what-is-finops/\" target=\"_blank\" rel=\"noopener\">https://saasoptics.com/blog/what-is-finops/</a></p> \n <p><a href=\"https://data.finops.org/\" title=\"https://data.finops.org\" target=\"_blank\" rel=\"noopener\">https://data.finops.org</a></p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211217171337831-2031139362.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"599","createTime":"2021-12-16 09:54","comment":"0","id":"15696518","title":"KubeCon 2021｜使用 eBPF 代替 iptables 优化服务网格数据面性能","url":"https://www.cnblogs.com/tencent-cloud-native/p/15696518.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>刘旭，腾讯云高级工程师，专注容器云原生领域，有多年大规模 Kubernetes 集群管理及微服务治理经验，现负责腾讯云服务网格 TCM 数据面产品架构设计和研发工作。</p> \n <h2 id=\"引言\">引言</h2> \n <p>目前以 Istio[1] 为代表的服务网格普遍使用 Sidecar 架构，并使用 iptables 将流量劫持到 Sidecar 代理，优点是对应用程序无侵入，但是 Sidecar 代理会增加请求时延和资源占用。</p> \n <p>性能一直是用户十分关心的一个点，也是用户评估是否使用服务网格产品的关键因素，腾讯云 TCM 团队一直致力于优化服务网格性能，上周我们在 KubeCon 分享了使用 eBPF 代替 iptables 优化服务网格数据面性能的方案。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211216095415051-1958343220.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"iptables-实现流量劫持\">iptables 实现流量劫持</h2> \n <p>首先看一下当前社区使用的基于 iptables 的流量劫持方案，下图是一个 Pod 的创建过程，sidecar injector 会向 Pod 中注入两个容器，istio-init 和 istio-proxy</p> \n <ul> \n  <li> <p>istio-init 是一个 init container，负责创建流量劫持相关的 iptables 规则，在创建完成后会退出</p> </li> \n  <li> <p>istio-proxy 中运行着 envoy，负责代理 Pod 的网络流量，iptables 会将请求劫持到 istio-proxy 处理</p> <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211216095415331-1518189265.png\" alt=\"\" loading=\"lazy\"></p> </li> \n </ul> \n <p>下图展示了 iptables 完成流量劫持的整个过程，这里简单说明下，感兴趣的同学可以查看[2]</p> \n <ul> \n  <li> <p>Inbound iptables 将入流量重定向到 15006 端口，也就是 envoy 的 VirtualInboundListener，envoy 会根据请求的原始目的地址转发到应用程序的指定端口</p> </li> \n  <li> <p>Outbound iptables 将出流量重定向到 15001 端口，也就是 envoy 的 VirtualOutboundListener，envoy 会根据请求的原始目的地址以及 Host URL 等信息路由到指定后端</p> <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211216095415610-669197271.png\" alt=\"\" loading=\"lazy\"></p> </li> \n </ul> \n <h2 id=\"ebpf-实现流量劫持\">eBPF 实现流量劫持</h2> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211216095415960-1274615202.png\" alt=\"\" loading=\"lazy\"></p> \n <p>eBPF(extended Berkeley Packet Filter) 是一种可以在 Linux 内核中运行用户编写的程序，而不需要修改内核代码或加载内核模块的技术，目前被广泛用于网络、安全、监控等领域。在 Kubernetes 社区最早也是最有影响的基于 eBPF 项目是 Cilium[4]，Cilium 使用 eBPF 代替 iptables 优化 Service 性能。</p> \n <h3 id=\"inbound\">Inbound</h3> \n <p>首先来看一下对入流量的劫持，对入流量的劫持主要使用 eBPF 程序 hook bind 系统调用完成。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211216095416284-1809178567.png\" alt=\"\" loading=\"lazy\"></p> \n <p>eBPF 程序会劫持 bind 系统调用并修改地址，例如应用程序 bind 0.0.0.0:80 会被修改为 127.0.0.1:80，应用程序还有可能 bind ipv6 的地址，所以这里有两个 eBPF 程序分别处理 ipv4 和 ipv6 的 bind。</p> \n <p>和 iptables 不同，iptables 可以针对每个 netns 单独设置规则，eBPF 程序 attach 到指定 hook 点后，会对整个系统都生效，例如 attach 到 bind 系统调用后，所有 Pod 内以及节点上进程调用 bind 都会触发 eBPF 程序，我们需要区分哪些调用是来自需要由 eBPF 完成流量劫持的 Pod。</p> \n <p>在 K8s 中，除了 hostnetwork 的情况，每个 Pod 都有独立的 netns，而每个 netns 都有唯一的 cookie，因此我们将需要使用 eBPF 完成流量劫持的 Pod 对应的 netns cookie 保存在 <code>cookie_map</code> 中，eBPF 程序通过判断当前 socket 的 netns cookie 是否在 <code>cookie_map</code> 中来决定是否修改 bind 地址。</p> \n <p>修改应用程序的 bind 地址后，还需要下发 pod_ip:80 listener 配置到 envoy，pod_ip:80 listener 会将请求转发到 127.0.0.1:80 也就是应用程序监听的地址，这样就实现了对入流量的劫持。但是这里有一个问题，由于 istio 使用 istio-proxy 用户启动 envoy，默认情况下非 root 用户不能 bind 1024 以下的特权端口，我们通过 istio-init 修改内核参数 <code>sysctl net.ipv4.ip_unprivileged_port_start=0</code> 解决了这个问题。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211216095416600-1172736077.png\" alt=\"\" loading=\"lazy\"></p> \n <p>对比 iptables 和 eBPF 对入流量的劫持，iptables 方案每个包都需要 conntrack 处理，而 eBPF 方案只有在应用程序调用 bind 时执行一次，之后不会再执行，减少了性能开销。</p> \n <h3 id=\"outbound\">Outbound</h3> \n <p>再来看一下对出流量的劫持，对出流量的劫持比较复杂，根据协议分为 TCP 和 UDP 两种情况。</p> \n <h4 id=\"tcp-流量劫持\">TCP 流量劫持</h4> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211216095416916-1017326479.png\" alt=\"\" loading=\"lazy\"></p> \n <p>对 TCP 的出流量劫持过程：</p> \n <ul> \n  <li> <p><code>_coonect4</code> 通过劫持 connect 系统调用将目的地址修改为127.0.0.1:15001，也就是 envoy 的 VirtualOutboundListerer，同时将连接的原始目的地址保存在 <code>sk_storage_map</code></p> </li> \n  <li> <p>在 TCP 连接建立完成后，<code>sockops</code> 会读取 <code>sk_storage_map</code> 中的数据，并以四元组（源IP、目的IP、源端口、目的端口）为 key 将原始目的地址保存在 <code>origin_dst_map</code></p> </li> \n  <li> <p><code>_getsockopt</code>通过劫持 getsockopt 系统调用，读取 <code>origin_dst_map</code> 中的数据将原始目的地址返回给 envoy</p> </li> \n </ul> \n <h4 id=\"udp-流量劫持\">UDP 流量劫持</h4> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211216095417189-1224371056.png\" alt=\"\" loading=\"lazy\"></p> \n <p>istio 在 1.8 版本支持了智能 DNS 代理[5]，开启后 iptables 会将 DNS 请求劫持到 Sidecar 处理，我们也需要用 eBPF 实现相同逻辑，对于 TCP DNS 的劫持和上面类似，对 UDP DNS 的劫持见下图</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211216095417426-183473018.png\" alt=\"\" loading=\"lazy\"></p> \n <p>对 UDP 的出流量劫持过程：</p> \n <ul> \n  <li><code>_connect4</code> 和 <code>_sendmsg4</code> 都是负责修改 UDP 的目的地址为 127.0.0.1:15053 并保存原始的目的地址到 <code>sk_storage_map</code>，因为 Linux 提供两种发送 UDP 数据的方式 \n   <ul> \n    <li>先调用 connect 再调用 send，这种情况由 <code>_connect4</code> 处理</li> \n    <li>直接调用 sendto，这种情况由 <code>_sendmsg4</code> 处理</li> \n   </ul> </li> \n  <li><code>recvmsg4</code> 通过读取 <code>sk_storage_map</code> 将回包的源地址改为原始的目的地址，这是因为有些应用程序，例如 nslookup 会校验回包的源地址。</li> \n </ul> \n <p>对于 TCP 和 connected UDP，iptables 方案每个包都需要 conntrack 处理，而eBPF 方案的开销是一次性的，只需要在 socket 建立时执行一次，降低了性能开销。</p> \n <h3 id=\"sockmap\">Sockmap</h3> \n <p>使用 sockmap 优化服务网格性能的方案最早由 cilium 提出，我们的方案也参考了 cilium，这里借用 cilium 的两张图来说明下优化效果</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211216095417763-1101508171.png\" alt=\"\" loading=\"lazy\"></p> \n <p>优化前 Sidecar 代理与应用程序间的网络通信都需要经过 TCP/IP 协议栈处理</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211216095418192-952373649.png\" alt=\"\" loading=\"lazy\"></p> \n <p>优化后 Sidecar 代理与应用程序间的网络通信绕过了 TCP/IP 协议栈，如果两个 Pod 在同一节点上，两个 Pod 间的网络通信也可以被优化。这里简单说明下 sockmap 的优化原理，感兴趣的同学可以查看[6][7]。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211216095418500-599598623.png\" alt=\"\" loading=\"lazy\"></p> \n <ul> \n  <li><code>sock_hash</code> 是一个存储 socket 信息的 eBPF map，key 是四元组（源IP、目的IP、源端口、目的端口）</li> \n  <li><code>_sockops</code> 负责监听 socket 事件，并将 socket 信息保存在 <code>sock_hash</code></li> \n  <li><code>_sk_msg</code> 会拦截 sendmsg 系统调用，然后到 <code>sock_hash</code> 中查找对端 socket，如果找到会调用 <code>bpf_msg_redirect_hash</code>直接将数据发送给对端 socket</li> \n </ul> \n <h4 id=\"问题\">问题</h4> \n <p>但是用四元组做为 key 可能会存在冲突的问题，例如在同一节点上的两个 Pod 中，envoy 使用同一源端口 50000 请求应用程序的 80 端口。<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211216095418786-193044839.png\" alt=\"\" loading=\"lazy\"></p> \n <p>为了解决这个问题，我们在 key 中添加了 netns cookie，同时对于非 localhost 的请求将 cookie 设置为 0，这样既保证了 key 不会冲突，又可以加速同一节点上两个 Pod 间的网络通信。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211216095419038-1335768158.png\" alt=\"\" loading=\"lazy\"></p> \n <p>但是之前版本的内核不支持在 <code>sockops</code> 和 <code>sk_msg</code> 这两种 eBPF 程序中获取 netns cookie 信息，因此我们提交了两个 patch [8 ][9]到内核社区，目前已合入 5.15 版本。</p> \n <h3 id=\"架构\">架构</h3> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211216095419279-1535255934.png\" alt=\"\" loading=\"lazy\"></p> \n <p>整个方案的架构如图所示，istio-ebpf 以 DaemonSet 的形式运行在节点上，负责 load/attach eBPF 程序和创建 eBPF map。istio-init 容器仍然保留，但是不再创建 iptables 规则，而是更新 eBPF map，istio-init 会将 Pod 的 netns cookie 保存在 cookie_map 中。同时我们也修改了 istiod，istiod 会根据 Pod 的流量劫持模式（iptables/eBPF)下发不同的 xDS 配置。</p> \n <h2 id=\"性能对比\">性能对比</h2> \n <p>测试环境：Ubuntu 21.04 5.15.7</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211216095419494-779194725.png\" alt=\"\" loading=\"lazy\"></p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211216095419856-1293729136.png\" alt=\"\" loading=\"lazy\"></p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211216095420033-1504902403.png\" alt=\"\" loading=\"lazy\"></p> \n <ul> \n  <li>同等条件下，使用 eBPF 可减少 20% 的 System CPU 占用</li> \n  <li>同等条件下，使用 eBPF 可提高 20% QPS</li> \n  <li>同等条件下，使用 eBPF 可降低请求时延</li> \n </ul> \n <h2 id=\"总结\">总结</h2> \n <p>服务网格的 Sidecar 架构不可避免的会增加请求时延和资源占用，我们通过使用 eBPF 代替 iptables 实现流量劫持，同时使用 sockmap 加速 Sidecar 代理和应用程序间的网络通信，在一定程度上降低了请求时延和资源开销，由于内核版本等限制这一方案预计会在明年初上线，TCM 团队将持续探索新的性能优化方向。</p> \n <h2 id=\"reference\">Reference</h2> \n <p>[1] <a href=\"https://istio.io\" target=\"_blank\" rel=\"noopener\">https://istio.io</a></p> \n <p>[2] <a href=\"https://jimmysong.io/blog/sidecar-injection-iptables-and-traffic-routing\" target=\"_blank\" rel=\"noopener\">https://jimmysong.io/blog/sidecar-injection-iptables-and-traffic-routing</a></p> \n <p>[3] <a href=\"https://ebpf.io\" target=\"_blank\" rel=\"noopener\">https://ebpf.io</a></p> \n <p>[4] <a href=\"https://cilium.io\" target=\"_blank\" rel=\"noopener\">https://cilium.io</a></p> \n <p>[5] <a href=\"https://istio.io/latest/blog/2020/dns-proxy\" target=\"_blank\" rel=\"noopener\">https://istio.io/latest/blog/2020/dns-proxy</a></p> \n <p>[6] <a href=\"https://arthurchiao.art/blog/socket-acceleration-with-ebpf-zh\" target=\"_blank\" rel=\"noopener\">https://arthurchiao.art/blog/socket-acceleration-with-ebpf-zh</a></p> \n <p>[7] <a href=\"https://github.com/cilium/cilium/tree/v1.11.0/bpf/sockops\" target=\"_blank\" rel=\"noopener\">https://github.com/cilium/cilium/tree/v1.11.0/bpf/sockops</a></p> \n <p>[8] <a href=\"https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next.git/commit/?id=6cf1770d\" target=\"_blank\" rel=\"noopener\">https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next.git/commit/?id=6cf1770d</a></p> \n <p>[9] <a href=\"https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next.git/commit/?id=fab60e29f\" target=\"_blank\" rel=\"noopener\">https://git.kernel.org/pub/scm/linux/kernel/git/bpf/bpf-next.git/commit/?id=fab60e29f</a></p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211216095420423-1461575015.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"331","createTime":"2021-12-09 11:28","comment":"0","id":"15666316","title":"重磅丨腾讯云开源业界首个 etcd 一站式治理平台 Kstone","url":"https://www.cnblogs.com/tencent-cloud-native/p/15666316.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <p>​ <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211209112744803-620571367.png\" alt=\"img\" loading=\"lazy\"></p> \n <h2 id=\"kstone-开源\">Kstone 开源</h2> \n <p>在 CNCF 云原生基金会举办的2021年12月9日 KubeCon China大会上，<strong>腾讯云容器 TKE 团队发布了 Kstone etcd 治理平台开源项目。</strong></p> \n <p><strong>Kstone</strong> 是腾讯云容器TKE团队发起的一个<strong>基于 Kubernetes 的云原生一站式 etcd 治理项目</strong>。该项目源自腾讯内部大规模 etcd 集群治理和最佳实践，很好的实现了对各类业务场景下的 etcd 集群的可视化管理和运维，极大简化了各类场景的 etcd 运维复杂度，将帮助你及时发现各种潜在的 etcd 集群隐患，显著提高 K8s 和 etcd 集群的稳定性和数据安全性，助力业务更稳更快运行。</p> \n <h2 id=\"kstone-架构及特性\">Kstone 架构及特性</h2> \n <p>​ <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211209112745161-1960142758.png\" alt=\"\" loading=\"lazy\"></p> \n <p>作为一个通用的 etcd 治理开源项目，<strong>Kstone 项目拥有诸多特性：</strong></p> \n <ul> \n  <li> <p><strong>集群管理</strong>：Kstone 不仅支持关联已有集群，而且内置了一个高级版的 kstone-etcd-operator, 它将可以帮助你在 K8s 集群上高可靠的部署 etcd 集群。所以，无论你是存量的 Kubernetes 的 etcd 集群管理诉求，还是你希望创建新的 etcd 集群提供给注册中心、APISIX 网关、配置存储等业务场景使用，kstone 都可以实现以上各类场景的 etcd 集群管理。</p> </li> \n  <li> <p><strong>集群巡检</strong>：Kstone 项目沉淀了腾讯内部大规模的etcd集群治理经验<strong>，</strong>提供了丰富的集群巡检策略，如数据一致性、资源对象数、健康度、热点Key、db满等策略，将帮助你及时发现隐患，提升 etcd 集群稳定性。</p> </li> \n  <li> <p><strong>数据备份</strong>：Kstone 提供分钟级的 etcd 数据备份能力，支持将数据备份到腾讯云 COS 等对象存储。同时，我们还支持通过 kstone-etcd-operator 创建 Learner 实现数据跨城热备。</p> </li> \n  <li> <p><strong>集群监控</strong>：Kstone 支持集群关联和创建时自动开启监控，内置了丰富的 grafana metrics 视图，将帮助你提高定位问题效率。</p> </li> \n  <li> <p><strong>数据迁移</strong>：Kstone 将提供大规模 etcd 集群数据自动迁移能力，并支持多种迁移算法（etcd v2版本到v3版本，etcd v3 版本到 v3 版本，冷迁移，热迁移等）。自动化迁移能力，将帮助你大幅提升集群稳定性。</p> </li> \n  <li> <p><strong>智能诊断</strong>：Kstone 将提供 etcd 集群诊断诊断功能，为你分析集群各类隐患，输出 etcd 专家级优化建议。</p> </li> \n  <li> <p><strong>可视化</strong>：Kstone 提供了一个 web 系统，帮助你轻轻松松完成 etcd 集群管理，涵盖集群管理、监控、巡检、备份、etcd 数据可视化查看。</p> </li> \n  <li> <p><strong>部署简单</strong>：Kstone 提供了 helm 一键部署能力，极大简化了部署复杂度。</p> </li> \n </ul> \n <p>​ <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211209112745587-615835602.png\" alt=\"\" loading=\"lazy\"></p> \n <p>目前，Kstone <strong>已在腾讯云、腾讯会议、腾讯广告、算力平台、腾讯游戏业务等有广泛应用，落地场景覆盖 Kubernetes etcd 集群管理、APISIX 网关、注册中心、配置存储等</strong>。</p> \n <p>未来，我们将坚信开源、社区、生态、中立、标准的价值，与社区的小伙伴们一起，致力于推进Kstone项目的技术发展和应用落地。</p> \n <p><strong>Kstone 正式开源啦！欢迎更多开发爱好者参与</strong>！</p> \n <p><strong>开源项目 GitHub 地址</strong>：<br> <em><a href=\"https://github.com/tkestack/kstone\" target=\"_blank\" rel=\"noopener\">https://github.com/tkestack/kstone</a></em></p> \n <p>只要你对 Kstone 感兴趣，都欢迎加入，参与方式：添加腾小云(TKEplatform)，回复：Kstone，小云会拉你进群。</p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211209112746756-1970629208.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"371","createTime":"2021-12-08 11:47","comment":"1","id":"15660742","title":"游戏案例｜Service Mesh 在欢乐游戏的应用演变和实践","url":"https://www.cnblogs.com/tencent-cloud-native/p/15660742.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>陈智伟，腾讯 12 级后台专家工程师，现负责欢乐游戏工作室公共后台技术研发以及团队管理工作。在微服务分布式架构以及游戏后台运维研发有丰富的经验。</p> \n <h2 id=\"前言\">前言</h2> \n <p>欢乐游戏工作室后台是分布式微服务架构，目前稳定承载着多款游戏，数千万 DAU 以及数百万级在线。原有云下架构脱胎于 QQGame 后台，核心架构已有 10 多年的历史，其中使用了多套目的不同的自研开发框架，自研基础组件，并为适应繁杂的业务场景，衍生出不同的服务模型，最终积累了数百个微服务，整体简化架构如下所示：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211208114632759-1483316112.png\" alt=\"\" loading=\"lazy\"></p> \n <p>在这种大规模平台化的后台系统和复杂多样的业务架构下，还要持续创造更大的业务价值，这给团队带来了较大的挑战和压力。简单列举几个问题：</p> \n <blockquote> \n  <ul> \n   <li><strong>机器资源利用率极低</strong>，集群内 CPU 峰值平均利用率不足 20%；</li> \n   <li><strong>服务治理能力不足</strong>，由于存在多套研发框架且服务管理方式不同，导致整体业务的维护以及基础服务治理能力的研发成本较高；</li> \n   <li><strong>服务部署十分繁琐</strong>，自动化不足，耗时耗力，且容易出外网问题；</li> \n   <li><strong>大量的陈旧业务服务缺乏维护</strong>，陈旧服务可视化能力不足，质量不易保证；</li> \n   <li><strong>整体架构较为复杂，新人上手成本较高，可维护性不足</strong>；</li> \n   <li><strong>每年机房裁撤都要耗费较大人力成本</strong>；</li> \n  </ul> \n </blockquote> \n <p>在云原生时代，借着公司全面“拥抱云原生”的东风，我们深度结合 K8s 以及 Istio 能力，逐模块拆分，细致梳理，经历过各类有状态、无状态服务的上云，协议改造，框架改造适配，服务模型云原生化，数据迁移，完善云上周边服务组件，建立云上服务 DevOps 流程等等众多系统性工程改造。最终，在不停服、平滑兼容过渡的前提下，将整体架构的服务云化以及网格化。</p> \n <p>在整体架构上云技术方案选型上，我们权衡了各类方案的完备性、可扩展性以及改造维护成本等因素，最终选择<strong>使用 <a href=\"https://istio.io/latest/about/service-mesh/\" title=\"Istio\" target=\"_blank\" rel=\"noopener\">Istio</a> 服务网格</strong>作为整体上云的技术方案。</p> \n <p>接下来，我将按照原有架构演进的线路，简单介绍部分模块的上云方案。</p> \n <h2 id=\"研发框架以及架构升级实现低成本无感平滑演进至服务网格\">研发框架以及架构升级，实现低成本无感平滑演进至服务网格</h2> \n <p>为了接入 Istio 以及服务能够平滑过渡，在基础框架和架构上做了较多适配性调整，最终可以实现：</p> \n <ol> \n  <li>存量业务代码无需调整，重编即可支持 gRPC 协议;</li> \n  <li>网格服务之间调用，使用 gRPC 通信；</li> \n  <li>云下服务调用网格服务，既可以使用私有协议也可以使用 gRPC 协议；</li> \n  <li>网格服务调用云下服务，使用 gRPC 协议；</li> \n  <li>旧业务可平滑灰度迁移至网格内；</li> \n  <li>兼容 Client 侧的私有协议请求；</li> \n </ol> \n <p>接下来，对其中部分内容做简要说明。</p> \n <h3 id=\"原有架构引入-grpc\">原有架构引入 gRPC</h3> \n <p>考虑到需要更全面应用 Istio 的服务治理能力，我们在已有开发框架中引入了 gRPC 协议栈。同时为了兼容原有的私有协议的通信能力，使用 gRPC 包装私有协议，并在开发框架层以及架构层都做了兼容性处理。开发框架结构示意图如下所示：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211208114633764-1501164251.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"使用-meshgate-桥接网格以及云下服务\">使用 MeshGate 桥接网格以及云下服务</h3> \n <p>为了使得云上 Istio 中的服务，能够与云下服务互通，我们研发了 <strong>MeshGate 服务桥接云上网格以及云下服务</strong>。</p> \n <p>MeshGate 主要功能是实现服务在网格内外的双边代理注册，并实现 gRPC 与私有协议之间的互转适配，架构如下图所示：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211208114634193-462032908.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"架构演变\">架构演变</h3> \n <p>基于业务重编支持 gRPC 能力，以及网格内外服务兼容性的打通，我们就可以实现新旧业务无感平滑的迁移上云了。</p> \n <p>当然在迁移过程中，我们也并非一味无脑的容器化上云，会对各类服务做针对性的云原生化处理以及服务质量加固，并提高服务的可观测性，最终提升服务的可维护性以及资源利用率。</p> \n <p>服务上云之后，其资源配置粒度变为 Pod 级别，并支持自动伸缩能力，因此无需为具体的服务预留过多资源，绝大部分服务都可以共用 Node 资源。进而可以大幅提高机器资源的利用率，<strong>整体的资源使用降幅可达 60-70% 左右</strong>。</p> \n <p>除了机器资源的减少好处之外，服务使用 helm 声明式一键部署模式，从而 K8s 可以较好地维持服务的可用性，同时架构也获得了 Istio 强大的<a href=\"https://istio.io/latest/about/service-mesh/\" title=\"服务治理能力\" target=\"_blank\" rel=\"noopener\">服务治理能力</a>。最终极好地提升了业务的 DevOps 效能。</p> \n <p>整体架构的演变如下图所示：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211208114634476-88233283.png\" alt=\"\" loading=\"lazy\"></p> \n <p>但心细的同学可能会发现，服务上了网格之后，业务和 Client 侧的通信需要从自研接入集群 Lotus 转发至 MeshGate，并做多次的协议转换以及转发，导致通信链路的性能开销以及时延加大。而对于游戏中时延敏感的业务场景，其中时延的损失，是难以接受的。因此我们迫切需要一个<strong>网格内的网关接入服务</strong>，接下来就介绍一下网关接入的改造方案。</p> \n <h2 id=\"网格内私有协议的接入服务\">网格内私有协议的接入服务</h2> \n <p>原有云下的自研接入集群 Lotus，是<strong>基于私有协议的 TCP 长链接</strong>的 Client 侧接入服务，具备服务注册，大规模用户链接管理，通信鉴权，加解密，转发等等能力。</p> \n <p>除了前述服务迁移至网格后，导致通信效果损耗之外，还存在一些其他问题：</p> \n <ol> \n  <li> <p>Lotus 集群的运维十分繁琐；因为为了防止用户游戏过程中出现链接的断开导致的不好体验，Lotus 进程的停止，需要等待用户侧主动断开，而新链接则不会发送给待停的 Lotus 中，简而言之，<strong>Lotus 的停止需要排空已有长链接</strong>，这也导致 Lotus 的更新需要等待较长的时间。我们有统计过，每次全网跟新发布 Lotus 版本需要持续数天的时间。而遇到问题、裁撤或者新增节点时，其变更需要人工调整全网配置策略，且需要执行十多项步骤，整体效率较低。</p> </li> \n  <li> <p>Lotus 集群的资源利用率低；由于 Lotus 是最基础的服务，且部署不方便，因此为了应对业务流量的变化，就要预留出充足的机器资源。但这也导致了 Lotus 的资源利用率较低，日常 CPU 峰值资源利用率仅 25% 左右；</p> </li> \n </ol> \n <p>为此，我们基于 CNCF 旗下的开源项目 <a href=\"https://www.envoyproxy.io/\" title=\"Envoy\" target=\"_blank\" rel=\"noopener\">Envoy</a> 的基础之上，支持私有协议的转发，并对接 Istio 控制面，使之适配我们原有的业务模型，并实现私有通信鉴权，加解密，客户端链接管理等等能力，最终完成接入服上云的工作。整体技术框架如下图所示：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211208114634744-295015762.png\" alt=\"\" loading=\"lazy\"></p> \n <p>改造完毕之后，云上接入集群在各方面都获得了较好的提升。</p> \n <ol> \n  <li> <p>核心业务场景下的<strong>私有协议转发性能以及延迟开销与云下环境接近</strong>；<br> 针对核心的业务场景，我们做过相应的压力测试，Envoy 在支持私有协议之后，其接入转发的性能开销以及时延与云下直连属于同一个量级。其中测试时延，如下表所示：</p> \n   <table> \n    <thead> \n     <tr> \n      <th>场景</th> \n      <th>平均耗时</th> \n      <th>P95 耗时</th> \n     </tr> \n    </thead> \n    <tbody> \n     <tr> \n      <td>云下直连</td> \n      <td>0.38ms</td> \n      <td>0.67ms</td> \n     </tr> \n     <tr> \n      <td>K8s pod 间转发</td> \n      <td>0.52ms</td> \n      <td>0.90ms</td> \n     </tr> \n     <tr> \n      <td>Istio + TCP 转发(私有协议)</td> \n      <td>0.62ms</td> \n      <td>1.26ms</td> \n     </tr> \n     <tr> \n      <td>Istio + gRPC 转发</td> \n      <td>6.23ms</td> \n      <td>14.62ms</td> \n     </tr> \n    </tbody> \n   </table> </li> \n  <li> <p>天然支持 Istio 的服务治理能力，更贴近云原生 Istio 下的使用方式；</p> </li> \n  <li> <p>通过 <strong>Helm 部署以及定义 Controller 管理</strong>，实现一键服务上架以及滚动更新；整个升级是自动的，且过程中实现排空更新能力，并考虑会负载能力，排空效率更优。</p> </li> \n  <li> <p>由于支持自动伸缩能力，接入服务无需预留过多的资源，因此可以大幅降低资源开销；全量云化后接入集群的 <strong>CPU 节省 50%-60%，内存节省了近 70% 左右</strong>。</p> </li> \n </ol> \n <h3 id=\"架构演变-1\">架构演变</h3> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211208114635009-1925063026.png\" alt=\"\" loading=\"lazy\"></p> \n <p>有了云上接入集群，整体架构演变如上图所示。接下来再以游戏业务中的 GameSvr 作为游戏强状态服务的代表，简单介绍其上云方案。</p> \n <h2 id=\"gamesvr-上云\">GameSvr 上云</h2> \n <p>欢乐工作室以往大都是单局房间类的游戏（<em>注：目前已经远不止这些了，也有 MMO，大世界，SLG 等等各种游戏品类</em>）。云下 GameSvr 架构如下图所示：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211208114635358-31668028.png\" alt=\"\" loading=\"lazy\"></p> \n <p>但以上架构在云下存在一些问题：</p> \n <ol> \n  <li><strong>运维繁琐</strong>；单台 GameSvr 上下架需十余步人工操作，每年不停服机器裁撤需要耗费数周的人力，且容易发生事故；</li> \n  <li><strong>资源利用率低</strong>；同样因为扩缩不易，就需预留足够的资源，做冗余部署，导致高峰期 CPU 利用率仅 20% 左右；</li> \n  <li><strong>整体的容灾能力弱</strong>，宕机后需人工介入处理；</li> \n  <li><strong>对局调度不灵活</strong>，都是依靠人工配置静态策略；</li> \n </ol> \n <p>因此借助云原生的能力，我们打造了一套易伸缩、易维护和高可用的单局类 GameSvr 架构。如下图所示：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211208114635744-2001847675.png\" alt=\"\" loading=\"lazy\"></p> \n <p>在整个迁移上云的过程中，我们是<strong>不停服，不变更前端，用户无感地平滑过渡至云上网格 GameSvr 集群</strong>。最终实现了：</p> \n <ol> \n  <li> <p>资源利用率上获得大幅提升；<strong>整体 CPU 以及内存的使用都减少了近 2/3</strong>。</p> </li> \n  <li> <p>运维效率获大幅提升；通过自定义 CRD 和 Controller 的管理，实现 Helm 一键部署整个集群，上下架十分便捷，仅一个业务项目组每个月因发布 GameSvr 都可以有效节省人力近 10 人天；</p> </li> \n  <li> <p>GameSvr 可根据当前集群的负载压力变化以及历史负载压力的时间序列实现可靠自动伸缩；</p> </li> \n  <li> <p>实现了灵活可靠的单局调度能力；通过简单的配置，即可实现单局根据不同的属性，调度到不同的 Set 中。且在调度的过程中，也会考虑负载和服务质量，最终实现整体调度的较优选择。</p> </li> \n </ol> \n <h3 id=\"架构演变-2\">架构演变</h3> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211208114636180-175735985.png\" alt=\"\" loading=\"lazy\"></p> \n <p>GameSvr 上云之后，整体架构变迁如上图所示，接下来再看 CGI 是如何上云的。</p> \n <h2 id=\"数量庞大的-cgi-上云\">数量庞大的 CGI 上云</h2> \n <p>我们曾大规模使用 Apache 下的 CGI 作为运营类活动开发的框架。但原有 CGI 业务的一些现状：</p> \n <ol> \n  <li> <p>业务种类较多，现网部署约 350 种 CGI 服务，且流量巨大；</p> </li> \n  <li> <p>CGI 同步阻塞的进程模型，导致其单进程的吞吐量极低；大部分 CGI 业务的 QPS 仅个位数，且存在 Apache 的服务调度以及消息分发的性能开销；</p> </li> \n  <li> <p>CGI 之间的资源隔离性差；因为 CGI 是同机多进程部署，极易出现由于某个业务 CGI 突然资源开销暴增，影响其他业务 CGI 的情况；</p> </li> \n </ol> \n <p>面对数量庞大且性能低效的 CGI 的上云，则需要<strong>研发成本以及资源开销都低的上云方案</strong>。一开始我们尝试过将 Apache 以及 CGI 整体打包成一个镜像简单容器化上云，但发现资源开销和部署模型都十分不理想，因此需要更优雅的上云方案。</p> \n <p>接着，我们对 CGI 的流量分布进行分析，发现 90% 的业务流量主要集中在 5% 的 CGI 中，如下图所示。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211208114636549-1355975405.png\" alt=\"\" loading=\"lazy\"></p> \n <p>因此，我们针对不同流量的 CGI，做了一些区分改造上云。</p> \n <ol> \n  <li> <p>针对<strong>头部流量 CGI 进行协程异步化改造</strong>，剥离 Apache，使框架性能获数十倍提升。</p> \n   <ul> \n    <li> <p>在框架层实现监听 http 请求以及异步化：</p> \n     <ul> \n      <li>使用 <a href=\"https://github.com/nodejs/http-parser\" title=\"http-parser\" target=\"_blank\" rel=\"noopener\">http-parser</a> 改造，使的框架自身就支持 http 监听以及处理；</li> \n      <li>基于 <a href=\"https://github.com/Tencent/libco\" title=\"libco\" target=\"_blank\" rel=\"noopener\">libco</a> 改造，使框架底层支持协程，从而实现异步化；</li> \n     </ul> </li> \n    <li> <p>在业务层，也需要针对性做各类适配性处理：</p> \n     <ul> \n      <li>针对全局变量，进行私有化或者关联至协程对象管理；</li> \n      <li>后端网络、io、配置加载以及内存等资源做各类复用化优化，提升效率；</li> \n     </ul> <p>最终业务侧做较小的调整，即可协程异步化改造完。但即使改造成本再低，已有的 CGI 数量还是太多了，全量异步化改造性价比十分低。</p> </li> \n   </ul> </li> \n  <li> <p>针对剩余长尾流量 CGI，与 Apache 一并打包，使用脚本一次性搬迁上云。为了提升可观测性，还对这种单容器内，超多进程的 metrics 采集 export 做了特殊处理。</p> </li> \n </ol> \n <p>最后在上云过程中，充分利用 Apache 的转发机制，实现灰度可回滚上云。<br> 上云后，CGI 的整体资源利用率以及可维护性均获大幅提升。<strong>全量云化之后 CPU 可节省近 85% 的核数，内存可节省 70% 左右</strong>。</p> \n <h3 id=\"架构演变-3\">架构演变</h3> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211208114636970-882875570.png\" alt=\"\" loading=\"lazy\"></p> \n <p>搬迁完 CGI 之后，整体架构如上图所示。接下来介绍一下自研存储 CubeDB 的改造方案。</p> \n <h2 id=\"自研存储业务迁移\">自研存储业务迁移</h2> \n <p>我们云下有具有数十 T 的自研存储数据，自建数百张 MySQL 表，整体的维护成本较高，且上云困难。因此我们的解决方案是“专业的事交给专业的人做”，将存储迁移托管至 TcaplusDB（腾讯 IEG 自研公共存储服务）。整体的迁移步骤简要描述如下：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211208114637274-1360539433.png\" alt=\"\" loading=\"lazy\"></p> \n <ol> \n  <li> <p>研发了适配代理服务，即上图所示的 Cube2TcaplusProxy，将 CubeDB 私有协议适配转换至 TcaplusDB，那么新业务的存储就可以直接使用 TcaplusDB 了；</p> </li> \n  <li> <p>在 CubeDB 的备机同步业务的热数据，在开启同步之后，TcaplusDB 就有业务的最新数据；</p> </li> \n  <li> <p>将冷数据导入至 TcaplusDB，如果 TcaplusDB 中有记录数据，说明它是最新的，则不覆盖；</p> </li> \n  <li> <p>全量比对 MySQL 与 TcaplusDB 的数据，多次校验全量通过后则切换 Proxy 的路由；</p> </li> \n </ol> \n <p>最终通过这种方案，我们实现 DB 存储的无损平滑迁移。</p> \n <h3 id=\"架构演变-4\">架构演变</h3> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211208114637492-1482236476.png\" alt=\"\" loading=\"lazy\"></p> \n <p>我们自研存储服务改造完毕之后，绝大部分服务均可以上云了。同时我们还做了很多云上周边能力的建设和应用，例如云上统一配置中心，grafana as code，promethues，日志中心，染色调用链等等能力。</p> \n <p>最终架构演变为：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211208114637887-173021621.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"多集群的部署模式\">多集群的部署模式</h2> \n <p>在云下，我们是一个全区全服的架构，所有的游戏业务都在一个集群之中。但由于我们组织架构以及业务形态的原因，期望上云之后，不同的业务团队工作在不同的业务 K8s 集群，而对于大家共用的服务，则放到公共集群下管理。因此在迁移上云的过程中，则还需要做更多的适配迁移工作。</p> \n <p>在 Istio 层面，由于我们的 Istio 服务托管给 TCM 团队（<a href=\"https://cloud.tencent.com/product/tcm\" title=\"腾讯云服务网格 TCM\" target=\"_blank\" rel=\"noopener\">腾讯云服务网格 TCM</a>），在 TCM 同学的大力支持下，结合我们目前的组织架构以及业务形态，实现 Istio 多集群下控制面信息的互通，由此我们在多集群之间的互相调用，成本就很低了。如下是 TCM 相关的后台架构：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211208114638258-409627499.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"总结\">总结</h2> \n <p>最终，我们在复杂的游戏业务架构下，经过细致分析和基于云原生技术的持续重构演进，深度结合 K8s 以及 Istio 的能力，最终实现游戏业务场景下架构平稳平滑的高质量上云以及网格化，拥有多框架多语言的微服务框架，自动化，服务发现，弹性伸缩，服务管控，流量调度治理，立体度量监控等等能力，并沉淀游戏各类业务场景上云经验。对于业务模块的可靠性、可观测性、可维护性大幅提高，整体研运效率提升十分明显。</p> \n <p><strong>欢乐游戏工作室旗下拥有欢乐斗地主，欢乐麻将，欢乐升级等数款国民棋牌类游戏，同时在研大世界，MMO，SLG 等多种品类游戏，现大量招聘研发、策划以及美术等各类岗位，欢迎猛戳<a href=\"https://careers.tencent.com/search.html?index=4&amp;keyword=15581\" title=\"招聘链接\" target=\"_blank\" rel=\"noopener\">招聘链接</a>，推荐或者投递简历。</strong></p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211208114638709-187902533.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"484","createTime":"2021-12-06 19:11","comment":"0","id":"15651419","title":"虚拟节点轻松应对 LOL S11 百万并发流量——腾竞体育的弹性容器实践","url":"https://www.cnblogs.com/tencent-cloud-native/p/15651419.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>刘如梦，腾竞体育研发工程师，擅长高并发、微服务治理、DevOps，主要负责电竞服务平台架构设计和基础设施建设。</p> \n <p>詹雪娇，腾讯云弹性容器服务EKS产品经理，主要负责 EKS 虚拟节点、容器实例相关的产品策划。</p> \n <h2 id=\"业务介绍\">业务介绍</h2> \n <p>自 2019 年，腾竞整个电竞赛事数据服务完全由腾讯云 TKE 容器服务承载。腾竞赛事数据开放平台目前主要提供职业赛事数据的授权与查询，随着斗鱼、虎牙、企鹅、掌盟、微信直播、微博等平台的相继接入，平台整体流量有了爆发式的增长。</p> \n <p>此前 2021英雄联盟全球总决赛（以下简称 S11） 期间更是创下了平台流量新高，达到了百万级 QPS、百亿级调用量。面对电竞赛事此类周期性强、并发高的业务场景，有效快速的自动扩缩容、提升资源利用率，是满足业务高速发展、合理控制成本的关键所在。</p> \n <p>这里将介绍 LOL S11 赛事期间，腾竞赛事数据开放平台如何通过 <strong>虚拟节点弹性调度+VPC-CNI</strong> 架构，轻松应对爆发的百万流量。</p> \n <h2 id=\"业务特性\">业务特性</h2> \n <p>电竞赛事具备明显的业务特性，其对服务的自动伸缩能力有非常高的要求。</p> \n <ul> \n  <li>周期性</li> \n </ul> \n <p>电竞赛事具有明显的周期性，比赛时段是流量高峰期，其余时间流量骤减，流量相差数百倍，需要通过弹性扩缩能力，减少波谷时的冗余资源，降低成本。</p> \n <ul> \n  <li>高并发</li> \n </ul> \n <p>比赛期间，服务需要承载百万级 QPS，需要快速的扩容时间、及库存充足的资源池。</p> \n <ul> \n  <li>突增快</li> \n </ul> \n <p>比赛开始时，玩家开始大量涌入直播间，需要保证服务稳定性，避免突增流量过大引发集群雪崩。</p> \n <h2 id=\"架构介绍\">架构介绍</h2> \n <h3 id=\"整体架构\">整体架构</h3> \n <p>集群采用 Istio 作为服务网格框架进行微服务治理，流量经由多条 CLB（解决单条 CLB 带宽上限）进入 Istio Ingress（直连Pod)后进行流量分发，依托于 Istio 的 Sidecar 模式，能够对各服务之间进行非常精细化的流量管理，例如：灰度、限流、熔断等等。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211206191028818-566836772.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"普通节点虚拟节点\">普通节点+虚拟节点</h3> \n <p>开启 VPC-CNI 采用直连 Pod 模式后，集群不再受 NodePort 网络转发能力的限制，少量常规节点应对业务日常低负载场景，利用虚拟节点弹性扩缩容能力应对赛事期间业务超高负载场景。</p> \n <p>​ <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211206191029088-1154732766.png\" alt=\"img\" loading=\"lazy\"></p> \n <h3 id=\"devops\">DevOps</h3> \n <p>基于 Docker 的 CI/CD 服务，支持多环境（云端、本地）、多集群编排服务，满足业务的不同部署需求。</p> \n <p>​ <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211206191029257-1501161320.png\" alt=\"img\" loading=\"lazy\"></p> \n <h2 id=\"弹性扩容方案演变\">弹性扩容方案演变</h2> \n <p>基于上述的业务特性，针对弹性扩容的方案，经历了【手动扩容=&gt;节点池=&gt;虚拟节点】的一系列演变历程，目前的弹性扩容方案可以完美满足业务需求。</p> \n <h3 id=\"业务初期手动扩容\">业务初期：手动扩容</h3> \n <p>业务初期，负载较低，根据业务特征，手动扩缩容基本可以满足需求。</p> \n <p>由于手动扩缩容需要一定的时间窗口，因此需要放置一定数量的冗余资源应对突增流量，资源利用率较低，只有6%左右。</p> \n <h3 id=\"业务发展中节点池\">业务发展中：节点池</h3> \n <p>随着业务发展，周期性的高低峰流量特征愈发明显，面对高频的扩缩容需求时，手动扩缩容不仅人力成本较高，而且无法避免人为失误。</p> \n <p>在突增流量速度较慢的场景下，节点池可以较好满足业务需求，不过需配置服务器，扩容速度较慢，冗余资源仍存在，资源利用率较低。另外，缩容时对节点进行封锁、驱逐等操作，不利于服务的稳定性。</p> \n <h3 id=\"业务高速发展虚拟节点秒级扩容节省30成本\">业务高速发展：虚拟节点，秒级扩容，节省30%成本</h3> \n <p>业务高速发展阶段，高低峰流量相差悬殊、并发逐渐增高、突增流量时间达到秒级，节点池的扩容速度不足以满足业务需求，还有购置服务器时库存不足的风险。</p> \n <p><strong>虚拟节点是 TKE 提供的一种弹性调度能力</strong>，提供了近乎无限资源的扩容能力，可以直接将 Pod 调度至弹性容器服务 EKS 维护的云上资源中，无需扩容节点。相比节点池，虚拟节点的扩容、缩容流程简化了购买、初始化、退还服务器的流程，大大提升了弹性的速度，尽可能降低在扩容流程中可能出现的失败，使得弹性更快、更高效、更节省成本。</p> \n <p>在弹性效率层面，虚拟节点可在数十秒内启动数以百计的 Pod，能够很好的应对 S11 这类高爆发业务场景。在成本层面，避免了普通节点由于无法完美分配 Pod 申请的资源而产生的 buffer 资源，节省了资源成本。</p> \n <p>在此基础上，我们结合业务侧数据，采取自动化资源预热的方式应对高频的突增流量场景；运营类业务场景则需要和运营部门紧密结合做好手动扩容的准备。</p> \n <h2 id=\"网络转发方案优化\">网络转发方案优化</h2> \n <h3 id=\"存在的问题\">存在的问题</h3> \n <p>集群提供公网访问入口时，默认情况下外部流量经由集群节点 NodePort 转发至集群内部，当虚拟节点中部署的 Pod 数量较少，集群整体负载较低时，该模式不会有网络转发性能瓶颈。不过随着部署在虚拟节点中的Pod数量增大，集群整体负载升高，就需要添加更多的节点用于网络转发，这与自动伸缩、快速扩容、降低成本的目标背道而 驰。</p> \n <p>​ <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211206191029469-1686255937.png\" alt=\"img\" loading=\"lazy\"></p> \n <h3 id=\"优化方案\">优化方案</h3> \n <p>开启 VPC-CNI 后采用直连 Pod 模式，容器与节点分布在同一网络平面，每个 Pod 分配有固定 IP，网络直接由 CLB 转入 Istio Ingress，不再经由 NodePort 转发，提高了网络转发效率，集群也不在需要网络转发节点，大大提高了集群的扩容能力。该模式下，集群扩容上限受到集群所分配网段可用 IP 数的限制，因此需要提前做好规划，避免集群扩容受限。</p> \n <p>​ <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211206191029698-1818882825.png\" alt=\"img\" loading=\"lazy\"></p> \n <h2 id=\"最终效果\">最终效果</h2> \n <p>通过虚拟节点和 VPC-CNI 模式下直连 Pod 的结合，目前集群整体承载能力有了很大的提升，在成本控制方面也有了长足的进步。</p> \n <h3 id=\"秒级扩缩容\">秒级扩缩容</h3> \n <p>通过虚拟节点+K8s HPA 能力，<strong>集群可在数十秒内启动数以百计的承载百万级流量的Pod</strong>，可以轻松应对快速扩缩容需求。再结合业务侧数据，自动化进行资源预热，提升集群抗突增流量能力。缩容时也不再需要对节点进行封锁、驱逐等操作，提高了服务的稳定性。</p> \n <h3 id=\"百万承载\">百万承载</h3> \n <p>VPC-CNI 直连 Pod 解决了 NodePort 流量转发瓶颈的问题，加上虚拟节点近乎无限资源的扩容能力大大提高了集群水平扩容的上限，像腾竞赛事数据开放平台这样大量读的场景能<strong>轻松扩容至百万乃至千万级 QPS</strong>。</p> \n <h3 id=\"降低成本\">降低成本</h3> \n <p>虚拟节点的高效扩缩容，配合 K8s 的 HPA 自动伸缩机制，减少了资源的准备和闲置时间，避免普通节点中的碎片化资源问题，有效的提高了资源利用率，最终<strong>为业务节省了30%的成本</strong>。</p> \n <h2 id=\"参考文档\">参考文档</h2> \n <p>容器服务 TKE：<br> <a href=\"https://cloud.tencent.com/document/product/457/6759\" target=\"_blank\" rel=\"noopener\">https://cloud.tencent.com/document/product/457/6759</a></p> \n <p>虚拟节点概述：<br> <a href=\"https://cloud.tencent.com/document/product/457/53027\" target=\"_blank\" rel=\"noopener\">https://cloud.tencent.com/document/product/457/53027</a></p> \n <p>弹性集群：<br> <a href=\"https://cloud.tencent.com/document/product/457/39804\" target=\"_blank\" rel=\"noopener\">https://cloud.tencent.com/document/product/457/39804</a></p> \n <p>VPC-CNI 模式介绍：<br> <a href=\"https://cloud.tencent.com/document/product/457/50355\" target=\"_blank\" rel=\"noopener\">https://cloud.tencent.com/document/product/457/50355</a></p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211206191030363-1435750763.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"222","createTime":"2021-12-06 17:10","comment":"0","id":"15650760","title":"腾讯云联合中国信通院&作业帮等首发《降本之源-云原生成本管理白皮书》","url":"https://www.cnblogs.com/tencent-cloud-native/p/15650760.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <p>在11月4日举办的2021腾讯数字生态大会云原生专场上，腾讯云联合中国信通院、作业帮等率先在国内重磅发布了《降本之源-云原生成本管理白皮书》（简称白皮书），基于腾讯云在业内最大规模的 Kubernetes 实践经验，系统性呈现云原生成本优化方法论和最佳实践路径。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211206171006724-108744247.png\" alt=\"\" loading=\"lazy\"></p> \n <p>腾讯云容器产品总经理邹辉表示：“Kubernetes 是云原生技术栈的核心，腾讯云原生经过多年的技术积累以及众多腾讯内外部复杂业务考验已经步入非常成熟的阶段。TKE 目前拥有国内最大规模的 Kubernetes 集群以及业界最好的 Kubernetes 成本优化实践；目前 TKE 运行着 900 万+个 Pod ，管理了数千万 CPU 核；同时我们大规模在腾讯内部核心业务中应用了成本优化技术，CPU 利用率最高提升了3倍；在腾讯外部，小红书80%的业务都跑在TKE上，成本降低了40%。”</p> \n <p>作业帮基础架构负责人董晓聪表示，容器及kubernetes等云原生技术给企业带来一次技术重塑的机会，我们和腾讯云一起，在性能优化，调度增强，在离线混部，serverless kubernetes等方面做了很多探索和实践，最终取得不错的成绩，容器化的收益显著，同样业务容器化前后，成本下降43%，稳定性提升到99.995%，接口响应提升10%。有效支持了作业帮业务的快速迭代。</p> \n <p>当前，越来越多的企业开始拥抱云计算，但随着用云程度的加深，云资源浪费的问题也变得越发明显。白皮书指出，弹性按需是云原生的资源利用优势，但如果资源配置策略设置不合理可能会导致资源的浪费。此外，云原生资源利用的计量方式如果不够灵活，会使得企业难以准确调控用云成本，因此，企业在应用云原生架构之后，需要考虑如何管理、优化和使用云原生服务来进一步提升业务的数字化转型效。</p> \n <p>基于丰富的海量应用服务经验，腾讯云原生在内部和外部都有着成熟的资源优化方法论。在内部，腾讯云采用资源利用率成熟度模型，通过四个阶段对业务进行容器化，最终实现利用率达到60~70%。在外部，腾讯云推出了容器产品“成本大师”，从成本洞察、成本优化、成本运营三个层面来协助企业做更好的成本管理。</p> \n <p>据介绍，成本大师具有全链路的成本优化能力，能够精确智能的进行成本洞察，一分钟发现资源浪费，并提供8种弹性策略组合，满足任意场景的弹性需求，而全构混部是业内首家云上支持 CPU/GPU 的混部产品，覆盖腾讯千万核资源规模。核心能力 qGPU，是强隔离的 GPU 虚拟化技术，该技术在业内首次实现了 GPU 算力、显存和故障的强隔离，支持算力精细切分共享和多优先级混部， GPU 利用率最高可提升230%。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211206171008717-2140009845.png\" alt=\"\" loading=\"lazy\"></p> \n <p>《降本之源-云原生成本管理白皮书》正是腾讯基于内外云原生成本管理最佳实践，并结合行业优秀案例，提出的一套体系化的云原生成本优化方法论和最佳实践路径。旨在帮助企业改善用云成本，充分发挥云原生的效能和价值。</p> \n <p>此外，白皮书中，腾讯云还通过对数十个客户的详细访谈，了解到在企业实际成本管理中存在的焦点问题，并基于资源利用率的现状和挑战，整理出企业使用的“成本洞察”、“成本优化”、“成本运营”三阶段云原生成本管理模型。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211206171009300-1356124454.png\" alt=\"\" loading=\"lazy\"></p> \n <p>成本洞察即团队需要定义一致的标签和命名空间来改善分配，基于多维度(如云产品、环境、业务线)的资源和成本的可视化分析，能够帮助团队有效地建立起相应的问责机制，并根据获取到的实时数据快速制定优化方案及措施。</p> \n <p>成本优化是对云资源规格、数量的调整，也包含了对业务的架构优化、以及通过弹性能力和资源混部等手段提升资源利用率。主要方案包括：设置合适的资源请求，通过动态调度解决资源碎片的问题，提高装箱率。通过弹性和混部做到按需使用；对于固定资源池，对负载峰值在不同时段的在线应用、在离线应用进行混部，做到分时复用；针对 GPU 资源，实现资源的池化和共享。</p> \n <p>成本运营则是鼓励企业从组织、文化、流程等方面建设成本运营体系，根据目标持续不断调整和优化。具体方案包括：建立成本优化团队，推动成本优化意识，数据驱动成本优化，在流程中考察成本以及量化成本优化交付的业务价值。</p> \n <p>白皮书围绕该模型，并结合企业实际落地情况提供成本管理的最佳实践，帮助企业上云、云原生改造时兼顾成本优化，助力数字化转型。</p> \n <p>此外，白皮书还收录了腾讯内外部10余个企业降本实践案例。将包括作业帮、云集、QQ 浏览器、腾讯广告等企业或业务上云遇到的成本挑战及降本实践全方位呈现，为其他企业运维减负提供了详实的参考。</p> \n <p>除了《云原生成本管理白皮书》，针对容器的安全难题，腾讯云容器服务TKE还联合腾讯安全云鼎实验室，发布了《腾讯云容器安全白皮书》。白皮书对腾讯云容器用户进行了深入的调研和走访，同时结合长期以来的容器安全运营实践，详细梳理并分析了容器环境所面临的安全威胁和挑战，并介绍了腾讯云在云原生容器安全建设上的思路、方案以及实践，希望以这样的方式共同推动云原生安全的发展。这也是国内首次大规模的对容器环境安全现状进行的分析总结。</p> \n <p><img src=\"https://qcloudimg.tencent-cloud.cn/raw/591b70bfb1ca45b346a7ce5d961c8f52.png\" alt=\"\" loading=\"lazy\"></p> \n <p>据介绍，腾讯云一直致力于在云原生领域为用户提供更全面、更稳定、更安全的云原生服务。在云原生产品的设计和实现之初，就充分融入了安全性的设计和考虑，使云原生系统天然具备安全特性，使安全成为像计算、存储、网络一样的基础能力，助力用户实现应用系统的云原生化，并且持续的保障其安全稳定的运行。</p> \n <p>更多细节内容，可点击关注【腾讯云原生】公众号回复“白皮书”下载《降本之源-云原生成本管理白皮书》进行了解。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211206171010179-758393358.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"326","createTime":"2021-12-06 10:00","comment":"0","id":"15648569","title":"作业帮上万个 CronJob 和在线业务混部，如何解决弱隔离问题并进一步提升资源利用率？","url":"https://www.cnblogs.com/tencent-cloud-native/p/15648569.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>吕亚霖，作业帮基础架构 - 架构研发团队负责人。负责技术中台和基础架构工作。在作业帮期间主导了云原生架构演进、推动实施容器化改造、服务治理、GO 微服务框架、DevOps 的落地实践。</p> \n <p>别路，作业帮基础架构-高级研发工程师，在作业帮期间，负责多云 K8s 集群建设、K8s 组件研发、Linux 内核优化调优相关工作。</p> \n <h2 id=\"背景\">背景</h2> \n <p>作业帮在云原生容器化改造的过程中，随着集群规模越来越大、业务混合部署的场景越来越复杂，面临的集群问题也越来越多，走到了 Kubernetes 及容器化的深水区， 尤其是在上万个 CronJob 容器化，和在线业务混合部署在同一个生产集群后，问题就更加明显。</p> \n <p>作业帮在线的生产业务使用 TKE 部署在黑石2.0 物理机上，单个机器规格比较大，部署的pod 也就比较多，而 cronjob 的特性是频繁、定时启动和销毁，同时也需要给这部分业务预留一定的固定资源，所以这块主要有 2 个问题；一是在大规模pod 频繁创建销毁场景下，cgroup 弱隔离性导致的节点稳定性问题，从而影响同一节点其他业务，二是资源预留导致的资源利用率低的问题。这两个问题其实已经超出了 原生 Kubernetes 的能力覆盖范围，我们需要新的思路来解决。</p> \n <p>下面将详细介绍这两个问题产生的原因及解决办法。</p> \n <h2 id=\"问题一集群内节点稳定性\">问题一：集群内节点稳定性</h2> \n <p>由于业务上存在很多分钟级执行的定时任务，导致 pod 的创建和销毁非常频繁，单个节点平均每分钟有上百个容器创建和销毁，机器的稳定性问题频繁出现。</p> \n <p>一个典型的问题是频繁创建 pod 导致节点上 cgroup 过多，特别是 memory cgroup 不能及时回收，读取/sys/fs/cgroup/memory/memory.stat 变慢，由于 kubelet 会定期读取该文件来统计各个 cgroup namespace 的内存消耗，CPU 内核态逐渐上升，上升到一定程度时，部分 CPU 核心会长时间陷入内核态，导致明显的网络收发包延迟。</p> \n <p>在节点 perf record cat /sys/fs/cgroup/memory/memory.stat 和 perf report 会发现，CPU 主要消耗在 memcg_stat_show 上：</p> \n <p>​ <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211206100027427-1221300884.png\" alt=\"img\" loading=\"lazy\"></p> \n <p>而 cgroup-v1 的 memcg_stat_show 函数会对每个 CPU 核心遍历多次 memcg tree，而在一个 memcg tress 的节点数量达到几十万级别时，其带来的耗时是灾难性的。</p> \n <p>为什么 memory cgroup 没有随着容器的销毁而立即释放呢？主要是因为 memory cgroup 释放时会遍历所有缓存页，这可能很慢，内核会在这些内存需要用到时才回收，当所有内存页被清理后，相应的 memory cgroup 才会释放。整体来看，这个策略是通过延迟回收来分摊直接整体回收的耗时，一般情况下，一台机器上创建容器不会太多，通常几百到几千基本都没什么问题，但是在大规模定时任务场景下，一台机器每分钟都有上百个容器被创建和销毁，而节点并不存在内存压力，memory cgroup 没有被回收，一段时间后机器上的 memory cgroup 数量达到了几十万，读取一次 memory.stat 耗时达到了十几秒，CPU 内核态大幅上升，导致了明显的网络延迟。</p> \n <p>​ <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211206100028333-1288740649.png\" alt=\"img\" loading=\"lazy\"></p> \n <p>除此之外，dockerd 负载过高、响应变慢、kubelet PLEG 超时导致节点 unready 等问题。</p> \n <h2 id=\"问题二集群的节点资源利用率\">问题二：集群的节点资源利用率</h2> \n <p>由于我们使用的是 TKE vpc-cni 的网络模式，这种网络模式依赖节点绑定的弹性网卡数量，所以单个节点上的 pod ip 数量存在上限，节点有几乎一半的 podip 是为定时任务的 pod 保留的，造成ip 浪费，另外定时任务的 pod 运行时间普遍很短，这就导致了集群为定时任务预留的资源产生了较多闲置，不利于整体的机器资源使用率提升。</p> \n <h2 id=\"其他问题调度速度服务间隔离性\">其他问题：调度速度、服务间隔离性</h2> \n <p>在某些时段，比如每天 0 点，会同时产生几千个 Job 需要运行。而原生调度器是 K8s 调度 pod 本身对集群资源分配，反应在调度流程上则是预选和打分阶段是顺序进行的，也就是串行。几千个 Job 调度完成需要几分钟，而大部分业务是要求 00：00：00 准时运行或者业务接受误差在 3s 内。</p> \n <p>有些服务 pod 是计算或者 IO 密集型，这种服务会大量抢占节点 CPU 或者 IO，而 cgroup 的隔离并不彻底，所以会干扰其他正常在线服务运行。</p> \n <h2 id=\"解决思路及方案\">解决思路及方案</h2> \n <p>所以，对 CronJob 型任务我们需要一个更彻底的隔离方式，更细粒度的节点，更快的调度模式。</p> \n <p>为解决上诉问题，我们考虑将定时任务 pod 和普通在线服务的 pod 隔离开，但是由于很多定时任务需要和集群内服务互通，还不能通过分集群的方式隔离。</p> \n <p>腾讯云弹性容器服务 EKS 提供的虚拟节点，给我们解决上诉问题提供了一个新的思路，</p> \n <p>EKS 的虚拟节点是 serverless 形态的kubernetes 服务，可以加入到现有的TKE 集群中，部署在虚拟节点上的 pod 具备与部署在正常 TKE 节点上的 pod 具备一致的网络连通性，但虚拟节点上的pod 是在vm 层面做了隔离，又具有无需预留资源，按量计费的特性，可以很好的满足我们这个场景的需求，所以我们将CronJob 这种类型的业务都调度到了虚拟节点，如图所示：</p> \n <p>​ <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211206100028689-618558904.png\" alt=\"img\" loading=\"lazy\"></p> \n <h2 id=\"任务调度器\">任务调度器</h2> \n <p>为解决 K8s 默认串行调度慢的问题，我们针对 job 类任务，开发了任务调度器，所有 CronJob 型 workload 都使用任务调度器，任务调度器批量并行调度任务 pod 到 虚拟 节点，实现大规模pod 任务 ms 级调度，也支持 虚拟节点故障时或者资源不足时调度回标准 TKE 节点。</p> \n <h3 id=\"解决-tke-节点和虚拟节点在运维方式上的差异\">解决 TKE 节点和虚拟节点在运维方式上的差异</h3> \n <p>在使用 虚拟节点前，首先要解决 虚拟节点 pod 和运行在标准节点上的 pod 差异，做到对业务研发无感。</p> \n <h4 id=\"日志采集统一\">日志采集统一</h4> \n <p>在日志采集方面，由于 EKS 这种 nodeless 的形态，无法运行 DaemonSet，而我们的日志采集组件是以 DaemonSet 形式运行的，这就需要对虚拟节点上的日志做单独的采集方案。EKS 虚拟节点 本身提供日志采集agent, 可以将容器的标准输采集并吐到一个 Kafka topic，然后我们统一在这个 topic 里消费。</p> \n <h4 id=\"监控报警统一\">监控报警统一</h4> \n <p>在监控方面，我们对 虚拟节点 上的 pod 做了实时 CPU/内存/磁盘/网络流量等监控，做到了和普通节点上的 pod 一致，暴露 pod sanbox 的 export 接口，promethus 负责统一采集，迁移到 虚拟节点 时做到了业务完全无感。</p> \n <h2 id=\"提升启动性能\">提升启动性能</h2> \n <p>虚拟节点上的 Job 需要具备秒级的启动速度才能满足定时任务对启动速度的要求，比如业务要求 00:00:00 准时运行或者业务接受误差在 3s 内。</p> \n <p><strong>主要耗时在以下两个步骤：</strong></p> \n <ol> \n  <li> <p>业务镜像拉取加速</p> </li> \n  <li> <p>虚拟节点 pod 创建和初始化加速</p> </li> \n </ol> \n <p>针对第一个问题：EKS 提供镜像缓存的功能，第一次拉取的时候稍微慢一些，拉下来后默认会缓存一段时间，同一个业务第二次启动就不需要再拉取镜像，所有镜像下载慢的问题基本就没有了。</p> \n <p>针对第二个问题：业务要求的启动时间误差在 3s 内，所以我们和 腾讯云 EKS 团队沟通后，为这种大规模、高频、短时的计算作业场景进行了针对性优化，提升了频繁启动的效率并降低了运行环境初始化的时间。</p> \n <p>最终实现了虚拟节点上的 Pod 秒级启动。</p> \n <h2 id=\"总结\">总结</h2> \n <p>通过 TKE + EKS 虚拟节点的方式，我们将正常在线任务和定时任务隔离开，有效保障了在线业务的稳定性，结合 自研 Job 任务调度器、EKS 镜像缓存、pod 启动加速等能力，实现 任务pod 秒级调度并启动，同时 TKE + 虚拟节点 都是标准的 K8s API ，做到了业务平滑迁移。最终要的是，我们固定的集群不需要再为 CronJob 类任务预留资源，释放了集群里 10% 的资源，结合 EKS 随用随取、按量计费的特性，定时任务的资源成本降低了 70%左右。</p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211206100028993-1003831150.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"242","createTime":"2021-12-03 16:44","comment":"0","id":"15638741","title":"大型前端项目 DevOps 沉思录 —— CI 篇","url":"https://www.cnblogs.com/tencent-cloud-native/p/15638741.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"摘要\">摘要</h2> \n <blockquote> \n  <p>DevOps 一词源于 Development 和 Operations 的组合，即将软件交付过程中开发与测试运维的环节通过工具链打通，并通过自动化的测试与监控，减少团队的时间损耗，更加高效稳定地交付制品。</p> \n  <p>本篇文章将着重探讨 DevOps 在 持续集成阶段需要提供的能力，将对工作流的设计及流水线的优化思路做一个简要讲解。</p> \n </blockquote> \n <p>随着项目规模越来越大，功能特性与维护人员越来越多，特性交付频率与软件质量之间的矛盾日渐尖锐，如何平衡两者成为了目前团队亟需关注的一个重点，于是，落地一个完善的 <code>DevOps</code>工具链便被提上日程。</p> \n <p>我们认为，从代码集成、功能测试，到部署发布、基础设施架构管理，每一个环节都应该有全面且完善的自动化监控手段，并尽量避免人工介入。只有这样，软件才能同时兼顾质量与效率，在提高发布频率的情况下保证可靠性。这是每一个成功的大型项目最终一定要实现的目标。</p> \n <p>本篇文章将着重探讨 <code>DevOps</code> 在 <code>持续集成阶段</code> 需要提供的能力，将对工作流的设计及流水线的优化思路做一个简要讲解。</p> \n <h2 id=\"当我们在谈论-ci-时我们在谈论什么\">当我们在谈论 CI 时，我们在谈论什么</h2> \n <p>CI(Continuous Integration)，即持续集成，指频繁地（一天多次）将代码集成到主干的行为。</p> \n <p>注意，这里既包含持续将代码集成到主干的含义，也包含持续将源码生成可供实际使用的制品的过程。因此，我们需要通过 CI，自动化地保证代码的质量，并对其构建产物转换生成可用制品供下一阶段调用。</p> \n <p>因此，在 CI 阶段，我们至少有如下阶段需要实现：</p> \n <ol> \n  <li>静态代码检查</li> \n </ol> \n <p>这其中包括，ESLINT/TSLINT 静态语法检查，验证 git commit message 是否符合规范，提交文件是否有对应 owner 可以 review 等等。这些静态检查不需要编译过程，直接扫描源代码就可以完成。</p> \n <ol start=\"2\"> \n  <li>单元测试/集成测试/E2E 测试</li> \n </ol> \n <p>自动化测试这一环节是保障制品质量的关键。测试用例的覆盖率及用例质量直接决定了构建产物的质量，因此，全面且完善的测试用例也是实现持续交付的必备要素。</p> \n <ol start=\"3\"> \n  <li>编译并整理产物</li> \n </ol> \n <p>在中小型项目中，这一步通常会被直接省略，直接将构建产物交由部署环节实现。但对于大型项目来说，多次频繁的提交构建会产生数量庞大的构建产物，需要得到妥善的管理。产物到制品的建立我们接下来会有详细讲解。</p> \n <h2 id=\"利于集成的工作流设计\">利于集成的工作流设计</h2> \n <p>在正式接入 CI 前，我们需要规划好一种新的工作流，以适应项目切换为高频集成后可能带来的问题与难点。这里涉及到的改造层面非常多，除了敦促开发人员习惯的转变以及进行新流程的培训外，我们主要关心的是源码仓库的更新触发持续集成步骤的方式。</p> \n <h3 id=\"流水线的组织形式\">流水线的组织形式</h3> \n <p>我们需要一个合适的组织形式来管理一条 CI 流水线该在什么阶段执行什么任务。</p> \n <p>市面上有非常多的 CI 工具可以进行选择，仔细观察就会发现，无论是 Drone 这样的新兴轻量的工具，亦或是老牌的 Jenkins 等，都原生或通过插件方式支持了这样一个特性： <code>ConfigurationasCode</code>，即使用配置文件管理流水线。</p> \n <p>这样做的好处是相当大的。首先，它不再需要一个 web 页面专门用于流水线管理，这对于平台方来说无疑减少了维护成本。其次对于使用方来说，将流水线配置集成在源码仓库中，享受与源码同步升级的方式，使得 CI 流程也能使用 git 的版本管理进行规范与审计溯源。</p> \n <p>确立了流水线的组织形式后，我们还需要考虑版本的发布模式以及源码仓库的分支策略，这直接决定了我们该以什么样的方式规划流水线进行代码集成。</p> \n <h3 id=\"版本发布模式的取舍\">版本发布模式的取舍</h3> \n <p>在《持续交付 2.0》一书中提到，版本发布模式有三要素： <code>交付时间、特性数量以及交付质量</code>。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211203164427854-378346183.png\" alt=\"\" loading=\"lazy\"></p> \n <p>这三者是相互制衡的。在开发人力与资源相对固定的情况下，我们只能对其中的两个要素进行保证。</p> \n <p>传统的项目制发布模式是牺牲了交付时间，等待所有特性全部开发完成并经历完整人工测试后才发布一次新版本。但这样会使得交付周期变长，并且由于特性数量较多，在开发过程中的不可控风险变高，可能会导致版本无法按时交付。不符合一个成熟的大型项目对于持续交付的要求。</p> \n <p>对于持续集成的思想来说，当我们的集成频率足够高，自动化测试足够成熟且稳定时，完全可以不用一股脑的将特性全堆在一次发布中。每开发完成一个特性就自动进行测试，完成后合入等待发布。接下来只需要在特定的时间周期节点自动将已经稳定的等待中的特性发布出去即可。这对于发布频率越来越高，发布周期越来越短的现代大型项目中无疑是一个最优解。</p> \n <h3 id=\"分支策略\">分支策略</h3> \n <p>与大部分团队一样，我们原有的开发模式也是 <code>分支开发，主干发布</code>的思想，分支策略采用业界最成熟也是最完善的 <code>Git-Flow</code>模式。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211203164428206-303455571.png\" alt=\"\" loading=\"lazy\"></p> \n <p>可以看出，该模式在特性开发，bug 修复，版本发布，甚至是 hotfix 方面都已经考虑到位了，是一个能应用在生产环境中的工作流。但整体的结构也因此变得极为复杂，不便管理。例如进行一次 hotfix 的操作流程是：从最新发布前使用的主干分支拉出 hotfix 分支，修复后合入到 develop 分支中，等待下一次版本发布时拉出到 release 分支中，发布完成后才能合回主干。</p> \n <p>此外，对于 <code>Git-Flow</code>的每一个特性分支来说，并没有一个严格的合入时间，因此对于较大需求来说可能合入时间间隔会很长，这样在合入主干时可能会有大量的冲突需要解决，导致项目工期无端延长。对此，做大型改造与重构的同学应该深有体会。</p> \n <p>针对这一点，我们决定大胆采用 <code>主干开发，主干发布</code>的分支策略。</p> \n <p>我们要求，开发团队的成员尽量每天都将自己分支的代码提交到主干。在到达发布条件时，从主干直接拉出发布分支用于发布。若发现缺陷，直接在主干上修复，并根据需要 <code>cherry pick</code> 到对应版本的发布分支。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211203164428446-1314242238.png\" alt=\"\" loading=\"lazy\"></p> \n <p>这样一来，对于开发人员来说需要关注的分支就只有主干和自己 working 的分支两条，只需要 push 与 merge 两条 git 命令就能完成所有分支操作。同时，由于合入频率的提高，平均每人需要解决的冲突量大大减少，这无疑解决了很多开发人员的痛点。</p> \n <p>需要说明的是，分支策略与版本发布模式没有银弹。我们采用的策略可能并不适合所有团队的项目。提高合入频率尽快能让产品快速迭代，但无疑会让新开发的特性很难得到充分的手工测试及验证。</p> \n <p>为了解决这一矛盾点，这背后需要有强大的基础设施及长期的习惯培养做支持。这里将难点分为如下几个类型，大家可以针对这些难点做一些考量，来确定是否有必要采用主干开发的方式。</p> \n <ol> \n  <li> <p>完善且快速的自动化测试。只有在单元测试、集成测试、E2E 测试覆盖率极高，且通过变异测试得出的测试用例质量较高的情况下，才能对项目质量有一个整体的保证。但这需要团队内所有开发人员习惯 TDD（测试驱动开发）的开发方式，这是一个相当漫长的工程文化培养过程。</p> </li> \n  <li> <p>Owner 责任制的 Code Review 机制。让开发人员具有 Owner 意识，对自己负责的模块进行逐行审查，可以在代码修改时规避许多设计架构上的破坏性修改与坑点。本质上难点其实还是开发人员的习惯培养。</p> </li> \n  <li> <p>大量的基础设施投入。高频的自动化测试其实是一个相当消耗资源的操作，尤其是 E2E 测试，每一个测试用例都需要启动一个无头浏览器来支撑。另外，为了提升测试的效率，需要多核的机器来并行执行。这里的每一项都是较大的资源投入。</p> </li> \n  <li> <p>快速稳定的回滚能力和精准的线上及灰度监控等等。只有在高度自动化的全链路监控下，才能保证该机制下发布的新版本能够稳定运行。这里的建设我会在之后的文章里详细介绍。</p> </li> \n </ol> \n <h2 id=\"大型项目中产物-制品的建立\">大型项目中产物-&gt;制品的建立</h2> \n <p>对于大多数项目来说，在代码编译完成生成产物后，部署项目的方式就是登录发布服务器，将每一次生成的产物粘贴进发布服务器中。生成的静态文件由于 hash 不同可以同时存放，html 采用直接覆盖的方式进行更新。</p> \n <p>直接使用复制粘贴的方式来操作文件的更新与覆盖，这样既不方便对更新历史的审计与追溯，同时这样的更改也很难保证正确性。</p> \n <p>除此之外，当我们需要回滚版本时，由于服务器上并没有存放历史版本的 html，因此回滚的方式其实是重新编译打包生成历史版本的产物进行覆盖。这样的回滚速度显然不是令人满意的。</p> \n <p>一个解决方法是，不要对文件进行任何的覆盖更新，所有的产物都应该被上传持久化存储。我们可以在请求上游增设一个流量分发服务，来判断每一条请求应该返回哪一个版本的 html 文件。</p> \n <p>对于大型项目来说，返回的 html 文件也不一定不是一成不变的。它可能会被注入渠道、用户自定义等标识，以及 SSR 所需要的首屏数据，从而改变其代码形式。因此，我们认为 html 文件的制品提供方应该是一个单独的动态服务，通过一些逻辑完成对模板 html 的替换并最终输出。</p> \n <p>总结一下，在每次编译完成后，产物将会进行如下的整理以生成最终的前端制品：</p> \n <ol> \n  <li> <p>针对静态文件，如 CSS、JS 等资源将会发布到云对象存储中，并以此为源站同步给 CDN 做访问速度优化。</p> </li> \n  <li> <p>针对 HTML 制品，需要一个直出服务做支撑，并打包成 docker 镜像，与后端的微服务镜像同等级别，供上游的流量分发服务（网关）根据用户请求选择调起哪些服务负载进行消费。</p> </li> \n </ol> \n <h2 id=\"速度即效率流水线优化思路\">速度即效率，流水线优化思路</h2> \n <p>对于一个好的工具来说，内部设计可以很复杂，但对于使用者来说必须足够简单且好用。</p> \n <p>在主干开发这样高频的持续集成下，集成速度即效率，流水线的执行时间毫无疑问是开发人员最关心的，也是流水线是否好用的决定性指标。我们可以从几个方面着手，提高流水线执行效率，减少开发人员的等待时间。</p> \n <h3 id=\"流水线任务编排\">流水线任务编排</h3> \n <p>对流水线各个阶段需要执行的任务我们需要遵循一定的编排原则： <code>无前置的任务优先</code>， <code>执行时间短的任务优先</code>， <code>无关联的任务并行</code>。</p> \n <p>根据这一原则，我们可以通过分析流水线中执行的各个任务，对每一个任务做一次最短路径依赖分析，最终得出该任务的最早执行时机。</p> \n <h3 id=\"巧用-docker-cache\">巧用 Docker Cache</h3> \n <p>Docker 提供了这样一个特性：在 Docker 镜像的构建过程中，Dockerfile 的每一条可执行语句都会构建出一个新的镜像层，并缓存起来。在第二次构建时，Docker 会以镜像层为单位逐条检查自身的缓存，若命中相同镜像层，则直接复用该条缓存，使得多次重复构建的时间大大缩短。</p> \n <p>我们可以利用 Docker 的这一特性，在流水线中减少通常会重复执行的步骤，从而提高 CI 的执行效率。</p> \n <p>例如前端项目中通常最耗时的依赖安装 <code>npm install</code>，变更依赖项对于高频集成来说其实是一个较小概率的事件，因此我们可以在第一次构建时，将 <code>node_modules</code>这个文件夹打包成为镜像供下次编译时调用。Dockerfile 示例编写如下：</p> \n <pre><code>FROM node:12 AS dependencies\nWORKDIR /ci\nCOPY . .\nRUN npm install\nENV NODE_PATH=/ci/node_modules\n</code></pre> \n <p>我们给流水线增加一条检查缓存命中的策略：在下次编译之前，先查找是否有该镜像缓存存在。并且，为了保证本次构建的依赖没有更新，我们还必须比对本次构建与镜像缓存中的 <code>package-lock.json</code>文件的 md5 码是否一致。若不一致，则重新安装依赖并打包新镜像进行缓存。若比对结果一致，则从该镜像中直接取到 <code>node_modules</code>文件夹，从而省去大量依赖安装的时间。</p> \n <p>流水线拉取镜像文件夹的方法示例如下，其中 <code>--from</code> 后跟的是之前缓存构建镜像的别名：</p> \n <pre><code>COPY --from=dependencies node_modules/ .# 其他步骤执行\n</code></pre> \n <p>同理，我们也可以将这一特性扩展到 CI 过程中所有更新频率不高，生成时间较长的任务中。例如 Linux 中环境依赖的安装、单元测试每条用例运行前的缓存、甚至是静态文件数量极多的文件夹的复制等等，都能利用 Docker cache 的特性达到几乎跳过步骤，减少集成时间的效果。由于原理大致相同，在此就不赘述了。</p> \n <h3 id=\"分级构建\">分级构建</h3> \n <p>众所周知，流水线的执行时间一定会随着任务数量的增多而变慢。大型项目中，随着各项指标计算的接入，各项测试用例的数量逐渐增多，运行时间迟早会达到我们难以忍受的地步。</p> \n <p>但是，测试用例的数量一定程度上决定着我们项目的质量，质量检查决不能少。那么有没有一种方法既可以让项目质量得到持续保障的同时，减少开发者等待集成的时间呢？答案就是分级构建。</p> \n <p>所谓分级构建，就是将 CI 流水线拆分为主构建和次级构建两类，其中主构建需要在每次提交代码时都要执行，并且若检查不通过无法进行下一步操作。而次级构建不会阻塞工作流，通过旁路的方式在代码合入后继续执行。但是，一旦次级构建验证失败，流水线将会立即发出通知告警，并阻塞其他所有代码的合入，直到该问题被修复为止。</p> \n <p>对于某任务是否应放入次级构建过程，有如下几点原则：</p> \n <ol> \n  <li> <p>次级构建将包含执行时间长（如超过 15 分钟）、耗费资源多的任务，如自动化测试中的 E2E 测试。</p> </li> \n  <li> <p>次级构建应当包含用例优先级低或者出错可能性低的任务，尽量不要包含重要链路。如果自动化测试中的一些测试用例经过实践发现失败次数较高，应当考虑增加相关功能单元测试，并移入主构建过程。</p> </li> \n  <li> <p>若次级构建仍然过长，可以考虑用合适的方法分割测试用例，并行测试。</p> </li> \n </ol> \n <h2 id=\"结语\">结语</h2> \n <p>工欲善其事，必先利其器。腾讯文档项目高频稳定发布的背后，必定需要拥有强大基础设施的支持。</p> \n <p>本篇文章仅主要介绍了持续集成阶段对项目进行的改造，持续部署、持续运营等阶段的具体改造思路将在笔者接下来的文章中详细说明。也欢迎大家多多探讨，对其中需要改进或有误的部分提出建议与斧正。</p> \n <h2 id=\"参考资料\">参考资料</h2> \n <ol> \n  <li>《持续交付 2.0》—— 乔梁 著</li> \n  <li><a href=\"https://www.redhat.com/zh/topics/devops/what-is-ci-cd\" target=\"_blank\" rel=\"noopener\">https://www.redhat.com/zh/topics/devops/what-is-ci-cd</a></li> \n  <li><a href=\"https://www.36kr.com/p/1218375440667012\" target=\"_blank\" rel=\"noopener\">https://www.36kr.com/p/1218375440667012</a></li> \n </ol> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202112/2041406-20211203164428775-1234817144.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"165","createTime":"2021-11-30 10:11","comment":"0","id":"15622982","title":"不止是上云，更是上岸","url":"https://www.cnblogs.com/tencent-cloud-native/p/15622982.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>常耀国，腾讯SRE专家，现就职于PCG-大数据平台部，负责千万级QPS业务的上云、监控和自动化工作。</p> \n <h2 id=\"背景\">背景</h2> \n <p>BeaconLogServer 是灯塔 SDK 上报数据的入口，接收众多业务的数据上报，包括微视、 QQ 、腾讯视频、 QQ 浏览器、应用宝等多个业务，呈现并发大、请求大、流量突增等问题，目前 BeaconLogServer 的 QPS 达到千万级别以上，为了应对这些问题，平时需要耗费大量的人力去维护服务的容量水位，如何利用上云实现 0 人力运维是本文着重分析的。</p> \n <h2 id=\"混合云弹性伸缩\">混合云弹性伸缩</h2> \n <h3 id=\"弹性伸缩整体效果\">弹性伸缩整体效果</h3> \n <p>首先谈一下自动扩缩容，下图是 BeaconLogServer 混合云弹性伸缩设计的方案图</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211130101112726-703373306.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"弹性伸缩方案\">弹性伸缩方案</h3> \n <h4 id=\"资源管理\">资源管理</h4> \n <p>先从资源管理讲起，目前 BeaconLogServer 节点个数是8000多个，需要的资源很大，单独依靠平台的公共资源，在一些节假日流量突增的时候，可能无法实现快速的扩容，因此，经过调研123平台（PAAS 平台）和算力平台（资源平台），我们采用了混合云的方式，来解决这个问题。<br> 分析 BLS 业务场景，流量突增存在下面两种情况：</p> \n <ul> \n  <li> <p>日常业务负载小幅度升高，时间持续较短</p> </li> \n  <li> <p>春节业务负载大幅度升高，并持续一段时间<br> 针对上述的业务场景，我们采用三种资源类型来应对不同场景，具体如下表所述：</p> </li> \n </ul> \n <table> \n  <thead> \n   <tr> \n    <th style=\"text-align: left\">类型</th> \n    <th style=\"text-align: center\">场景</th> \n    <th style=\"text-align: right\">set</th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td style=\"text-align: left\">公共资源池</td> \n    <td style=\"text-align: center\">日常业务</td> \n    <td style=\"text-align: right\">bls.sh.1</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">算力平台</td> \n    <td style=\"text-align: center\">小高峰</td> \n    <td style=\"text-align: right\">bls.sh.2</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">专用资源池</td> \n    <td style=\"text-align: center\">春节</td> \n    <td style=\"text-align: right\">bls.sh.3</td> \n   </tr> \n  </tbody> \n </table> \n <p>日常业务我们使用公共资源池+算力资源，当业务的负载小幅度上升的话，使用算力资源快速扩容，保障服务的容量水位不超过安全阈值。面对春节负载大幅度升高，这时需要构建专有资源池来应对春节的流量升高。</p> \n <h4 id=\"弹性扩缩容\">弹性扩缩容</h4> \n <p>上文阐述了资源的管理，那么针对不同的资源，何时开始扩容，何时开始缩容？</p> \n <p>BeaconLogServer 日常的流量分布是 <strong>123 平台公共资源：算力平台=7:3</strong>。目前设置的自动扩容的阈值时60%，当 CPU 使用率大于60%，平台自动扩容。弹性扩缩容依赖的是 123 平台的调度功能，具体的指标设置如下：</p> \n <table> \n  <thead> \n   <tr> \n    <th style=\"text-align: left\">类型</th> \n    <th style=\"text-align: center\">CPU自动缩容阈值</th> \n    <th style=\"text-align: right\">CPU自动扩容阈值</th> \n    <th style=\"text-align: right\">最小副本数</th> \n    <th style=\"text-align: right\">最大副本数</th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td style=\"text-align: left\">123平台公共资源池</td> \n    <td style=\"text-align: center\">20</td> \n    <td style=\"text-align: right\">60</td> \n    <td style=\"text-align: right\">300</td> \n    <td style=\"text-align: right\">1000</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">算力平台</td> \n    <td style=\"text-align: center\">40</td> \n    <td style=\"text-align: right\">50</td> \n    <td style=\"text-align: right\">300</td> \n    <td style=\"text-align: right\">1000</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">123平台专有资源池</td> \n    <td style=\"text-align: center\">20</td> \n    <td style=\"text-align: right\">60</td> \n    <td style=\"text-align: right\">300</td> \n    <td style=\"text-align: right\">1000</td> \n   </tr> \n  </tbody> \n </table> \n <p>可以看到算力平台自动缩容阈值较大，自动扩容阈值较小，主要考虑算力平台是应对流量突增的情况，而且算力平台资源经常替换，因此优先考虑先扩容或缩容算力平台的资源。最小副本数是保障业务所需的最低资源需求，如果少于这个值，平台会自动补充。最大副本数设置1000，是因为 IAS 平台（网关平台）一个城市支持的最大 RS 节点数是1000。</p> \n <h3 id=\"问题及解决\">问题及解决</h3> \n <p>方案推进的过程中，我们也遇到了很多问题，挑选几个问题和大家分享一下。</p> \n <p>1）首先从接入层来讲，之前接入层业务使用的是 TGW ， TGW 有一个限制，就是RS的节点不能超过200个，目前 BeaconLogServer 的节点是8000多个，继续使用 TGW 需要申请很多个域名，迁移耗时多且不便于维护。我们调研接入层 IAS ， IAS 四层每个城市支持的节点个数是1000个，基本可以满足我们的需求，基于此，我们设计如下的解决方案如下：</p> \n <p>总体上采用“业务+地域”模式分离流量。当集群中一个城市的 RS 节点超过500个就需要考虑拆分业务，例如公共集群的节点超出阈值，可以把当前业务量大的视频业务拆分出来，作为一个单独的集群；如果是一个独立集群的业务节点超出阈值，先考虑增加城市，把流量拆分到新的城市。如果无法新增城市，此时考虑新增一个 IAS 集群，然后在 GLSB 上按照区域把流量分配到不同的集群。</p> \n <p>2）同一个城市不同的资源池设置不同的 set，那么IAS如何接入同一个城市不同 set 呢？<br> 北极星本来有[通配组功能]，但是 IAS 不支持 set 通配符功能实际上，我们推动 IAS 实现了通配组匹配，例如使用 bls.sh.% 可以匹配 bls.sh.1 , bls.sh.2 , bls.sh.3 。注意， IAS 通配符和北极星的不一样，北极星使用的是**<em>， IAS 在上线的时候发现有用户使用</em>做单独匹配，所以使用%来表示通配符。</p> \n <p>3）资源管理这块遇到的难点是 IAS 四层无法使用算力资源的节点，后面在经过沟通，打通了 IAS 到算力资源的。这里的解决方案是使用 SNAT 能力。</p> \n <p>此方案的注意事项</p> \n <ul> \n  <li> <p>只能绑定 IP 地址，无法拉取实例，实例销毁也不会自动解绑，需要通过控制台或 API 主动解绑（已跨账号，拉取不到实例）</p> </li> \n  <li> <p>如果是大规模上量：过哪些网关、哪些容量需要评估、风险控制，需要评估</p> </li> \n </ul> \n <h2 id=\"单机故障自动化处理\">单机故障自动化处理</h2> \n <h3 id=\"单机故障处理效果\">单机故障处理效果</h3> \n <p>单机故障自动化处理，目标是实现0人力维护，如下图是我们自动化处理的截图。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211130101113031-1523176798.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"单机故障处理方案\">单机故障处理方案</h3> \n <p>单机故障主要从系统层面和业务层面两个维度考虑，详情如下：</p> \n <table> \n  <thead> \n   <tr> \n    <th style=\"text-align: left\">维度</th> \n    <th style=\"text-align: center\">告警项</th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td style=\"text-align: left\">系统层面</td> \n    <td style=\"text-align: center\">CPU</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">系统层面</td> \n    <td style=\"text-align: center\">内存</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">系统层面</td> \n    <td style=\"text-align: center\">网络</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">系统层面</td> \n    <td style=\"text-align: center\">磁盘</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">业务层面</td> \n    <td style=\"text-align: center\">ATTA Agent不可用</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">业务层面</td> \n    <td style=\"text-align: center\">队列过长</td> \n   </tr> \n   <tr> \n    <td style=\"text-align: left\">业务层面</td> \n    <td style=\"text-align: center\">发送atta数据成功率</td> \n   </tr> \n  </tbody> \n </table> \n <p>针对单机故障，我们采用的是开源的 Prometheus +公司的 Polaris（注册中心） 的方式解决。Prometheus 主要是用来采集数据和发送告警，然后通过代码把节点从 Polaris 摘除。</p> \n <p>至于告警发生和告警恢复的处理，当告警发生的时候，首先会判断告警的节点个数，如果低于三个以下，我们直接在 Polaris 摘除节点，如果大于3个，可能是普遍的问题，这时候我们会发送告警，需要人工的介入。当告警恢复的时候，我们直接在平台重启节点，节点会重新注册 Polaris 。</p> \n <h3 id=\"atta-agent-异常处理\">ATTA Agent 异常处理</h3> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211130101113425-1946973258.png\" alt=\"\" loading=\"lazy\"></p> \n <p>如图所示，处理流程是两条线，告警触发和告警恢复，当业务异常的时候，首先判断当前异常节点的数量，保证不会大范围的摘掉节点。然后在北极星摘除节点。当业务恢复的时候，直接重启节点。</p> \n <h3 id=\"问题及解决-1\">问题及解决</h3> \n <p>主要的难点是 Prometheus Agent 的健康检查和 BeaconLogServer 节点的动态变化，对于第一个问题，目前主要是由平台方负责维护。对于第二个问题，我们利用了定时脚本从 Polaris 拉取节点和 Prometheus 热加载的能力实现的。</p> \n <h2 id=\"总结\">总结</h2> \n <p>此次上云有效的解决了自动扩缩容和单机故障这两块的问题，减少了手动操作，降低了人为操作错误风险，提升系统的稳定性。通过此次上云，也总结了几点：</p> \n <ul> \n  <li> <p>迁移方案：上云之前做好迁移方案的调研，特别是依赖系统的支持的功能，降低迁移过程因系统不支持的系统性风险 。</p> </li> \n  <li> <p>迁移过程：做好指标监控，迁移流量之后，及时观测指标，出现问题及时回滚。</p> </li> \n </ul> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211130101113832-1600160856.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"418","createTime":"2021-11-26 17:47","comment":"0","id":"15608942","title":"智能 Request 推荐，K8s 资源利用率提升 252%","url":"https://www.cnblogs.com/tencent-cloud-native/p/15608942.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>王孝威，FinOps 认证从业者，腾讯云容器服务产品经理，热衷于为客户提供高效的 Kubernetes 使用方式，为客户极致降本增效服务。</p> \n <p>余宇飞，FinOps 认证从业者，腾讯云专家工程师，从事云原生可观测性、资源管理、降本增效产品的开发。</p> \n <h2 id=\"资源利用率为何都如此之低\">资源利用率为何都如此之低？</h2> \n <p>虽然 Kubernetes 可以有效的提升业务编排能力和资源利用率，但如果没有额外的能力支撑，提升的能力十分有限，根据 TKE 团队之前统计的数据： <a href=\"https://mp.weixin.qq.com/s/8sHsI1pVm-1RX5w1F3uWPg\" target=\"_blank\" rel=\"noopener\">Kubernetes 降本增效标准指南| 容器化计算资源利用率现象剖析</a>，如下图所示：TKE 节点的资源平均利用率在 14% 左右。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211126174658112-1450114534.png\" alt=\"\" loading=\"lazy\"></p> \n <p>为什么 Kubernetes 集群的资源利用率依旧不高？</p> \n <p>这里一个很重要的原因是因为 Kubernetes 的资源调度逻辑，在创建 Kubernetes 工作负载的时候，通常需要为工作负载配置合适的资源 Request 和 Limit，表示对资源的占用和限制，其中对利用率影响最大的是 Request。</p> \n <p>为防止自己的工作负载所用的资源被别的工作负载所占用，或者是为了应对高峰流量时的资源消耗诉求，用户一般都习惯将 Request 设置得较大，这样 Request 和实际使用之间的差值，就造成了浪费，而且这个差值的资源，是不能被其它工作负载所使用的。</p> \n <p>Request 数值不合理的过大，是造成 Kubernetes 集群资源利用率低一个很普遍的现象。另外，每个节点的资源很难被充分分配，如下图所示，节点普遍会存在一些资源的碎片（Leftover），这些都是导致集群整理资源利用率不高的原因。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211126174658496-56286697.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"资源实际利用率到底有多低\">资源实际利用率到底有多低？</h2> \n <p>如何设置更合理的资源 Request，首先需要分析业务对资源的消耗情况。在腾讯云原生 <a href=\"https://mp.weixin.qq.com/s/tjpSneIghbGlRpAg1qkhHA\" target=\"_blank\" rel=\"noopener\">Kubernetes 降本增效标准指南| 资源利用率提升工具大全</a>资源常见浪费场景部分，有对单一的工作负载进行分析，工作负载设置的 Request 中至少有一半的资源没有被使用，而且这部分资源不能被其他的工作负载使用，浪费现象严重。 这时把视角上升到集群维度，下图是某一 TKE 集群的 CPU 分配率和使用率。</p> \n <p>分配率是用所有容器对 CPU 的 Request 之和除以集群所有节点的 CPU 数量，使用率是所有容器对 CPU 的 Usage 之和除以集群所有节点的 CPU 数量：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211126174658862-244418444.png\" alt=\"\" loading=\"lazy\"></p> \n <p>可见集群整体的 CPU 分配率在60%左右，但 CPU 实际的利用率最高不超过 10%。可以理解成用户在云上花了一百元，实际上 90多元都被浪费掉了。</p> \n <h2 id=\"如何设置-request\">如何设置 Request？</h2> \n <p>提升资源利用率有很多种方法，详见 <a href=\"https://mp.weixin.qq.com/s/tjpSneIghbGlRpAg1qkhHA\" target=\"_blank\" rel=\"noopener\">Kubernetes 降本增效标准指南| 资源利用率提升工具大全</a>。本文主要探讨 Request 的设置。</p> \n <p>既然设置了 Request 导致资源利用率如此之低，那是不是干脆不要设置 Request了，然后直接把集群的规模缩减到原来的十分之一，就可以解决上图中的问题？这确实看似是一种简单高效的方法，但存在几个较为严重的问题：</p> \n <ol> \n  <li>Kubernetes 会自动<a href=\"https://kubernetes.io/zh/docs/tasks/configure-pod-container/quality-service-pod/\" title=\"配置 Pod 的服务质量 QoS\" target=\"_blank\" rel=\"noopener\">配置 Pod 的服务质量 QoS</a>，对于没有设置 Request 数值的 Pod，当资源比较紧张时，比较容易被驱逐，业务稳定性受到影响。</li> \n  <li>集群的整理资源实际上并不是一个完整的整体，集群是由很多节点构成的，实际的 CPU 和内存的资源都是节点的属性，每个节点的容量大小有上限，例如64核 CPU，对于比较大的业务来说，可能需要一个数千核乃至数万核的集群，这样集群里的节点数量就会变多，节点数量越多，每个节点的碎片资源越多，碎片资源都无法有效被利用。</li> \n  <li>业务本身可能会有较大波动，例如地铁系统白天繁忙、夜晚空闲，设置固定的 Request 数值必须按照峰值考虑，此时浪费现象依旧突出。</li> \n </ol> \n <p>可以看出，Request 的设置对于运维开发来说一直是个很大难题，Request 设置过小容易导致业务运行时性能受到影响，设置过大势必造成浪费。</p> \n <h2 id=\"request-智能推荐\">Request 智能推荐</h2> \n <p>是否存在一个有效的工具，能基于业务本身的特性自动推荐甚至设置 Request 数值？</p> \n <p>这样无疑对开发运维来说极大的减轻了负担。为解决这样的问题，TKE 成本大师推出了 Request 智能推荐的工具。用户可以通过标准 Kubernetes API（例如：/apis/recommendation.tke.io/v1beta1/namespaces/kube-system/daemonsets/kube-proxy）访问相应的推荐值。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211126174659145-1650906617.png\" alt=\"\" loading=\"lazy\"></p> \n <p>该功能启动后，Request 智能推荐的相关组件会从腾讯云监控（未来支持 Prometheus，InfluxDB，或第三方云厂商）拉取集群中所有 Deployment、DaemonSet、StatefulSet 在过去一段时间存在过的容器的 CPU 和 内存的监控指标，计算相应的 P99 值，再乘以一个安全系数（例如：1.15），当作推荐的 Request。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211126174659553-928716632.png\" alt=\"\" loading=\"lazy\"></p> \n <p>关于 Limit，Request 智能推荐功能推荐的 Limit ，以初始 Request 智能推荐功能设置的 Request 与 Limit 之比计算。例如初始设置的 CPU 的 Request 数值为 1000m，Limit 为 2000m，Request 与 Limit 之比为 1:2。若新推荐的 CPU 的 Request 数值为 500m，则会推荐 Limit 为 1000m。</p> \n <p>更多关于 Request 智能推荐的使用请参考：<a href=\"https://cloud.tencent.com/document/product/457/63338\" title=\"Request 智能推荐产品文档\" target=\"_blank\" rel=\"noopener\">Request 智能推荐产品文档</a>。</p> \n <p>Request 推荐参考应用的历史资源消耗峰值，给出一个相对「合理」并且「安全」的资源请求值，可以很大程度上缓解由于业务 Request 设置不合理导致的资源浪费或者业务不稳定。</p> \n <p>例如在下面的集群中应用 Request 推荐，业务资源使用量在 10 核左右，但手工配置的 Request 是 60 核，实际上 Request 设置在 17 核就足够了，利用率从之前的 16.7%（=10/60） 左右 提升到 58.8%（=10/17），提升了 252%（=（58.8-16.7）/16.7），CPU 节省了 71.7%(=(60-17)/60)。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211126174700013-1778898669.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"ahpa\">AHPA</h2> \n <p>当然 ，Request 智能推荐不是银弹，因为应用的资源消耗并不是一成不变的，大量的应用都存在潮汐现象，业务高峰和低谷所需要的资源存在着几倍甚至几十倍的差距。以高峰期资源需求为准设置的 Request，使得业务在空闲时段占有大量并不使用的资源，导致应用的平均资源利用率依然不高。此时，想要做进一步优化，就需要借助弹性伸缩的手段。</p> \n <p>现阶段，HPA 是 Kubernetes 领域最常用的弹性工具，虽然 HPA 可以一定程度上解决周期性业务流量资源使用弹性的问题，但是 HPA 是有滞后性的。具体表现在：通常 HPA 需要先定义监控的指标，例如 CPU 利用率 60%，然后相关的监控组件监控到负载压力变大，触达了这个使用率的阈值，HPA 才会扩缩容副本数。</p> \n <p>通过对大量运行在腾讯云上的内部和外部用户的实际应用的观察，我们发现许多业务的资源使用在时间序列上是具有周期性的，特别是对于那些直接或间接为“人”服务的业务。这种周期是由人们日常活动的规律性决定的。例如：</p> \n <ul> \n  <li>人们习惯于中午和晚上点外卖</li> \n  <li>早上和晚上是交通高峰期</li> \n  <li>即使对于没有明显模式的服务，如搜索，夜间的请求量也远低于白天</li> \n </ul> \n <p>对于与此类相关的应用程序，从过去几天的历史数据中推断第二天的指标，或从上周一的数据推断下周一的访问流量是一个自然的想法。通过对未来的指标预测，可以更好地管理应用程序实例，稳定系统，同时降低成本。</p> \n <p>CRANE 是 TKE 成本大师的技术底座，专注于通过多种技术，优化资源利用，进而降低用户的云上成本。 CRANE 中的 Predictor 模块可以自动识别出 Kubernetes 集群中应用的各种监控指标（例如 CPU 负载、内存占用、请求 QPS 等）的周期性，并给出未来一段时间的预测序列。在此基础上，我们开发了 AHPA（advanced-horizontal-pod-autoscaler)，它能够识别适合水平自动缩放的应用程序，制定缩放计划，并自动进行缩放操作。它利用了原生 <a href=\"https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/\" title=\"HPA\" target=\"_blank\" rel=\"noopener\">HPA</a> 机制，但它基于预测，并主动提前扩容应用程序，而不是被动地对监测指标做出反应。<strong>与原生 HPA 相比，AHPA 消除了手动配置和自动缩放滞后的问题，彻底解放运维。</strong> 主要有如下特点：</p> \n <ul> \n  <li>可靠性—-保证可伸缩性和可用性</li> \n  <li>响应能力——扩展快，快速应对高负载</li> \n  <li>资源效能——降低成本</li> \n </ul> \n <p>下图是该项目的实际运行效果：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211126174700297-1919996032.png\" alt=\"\" loading=\"lazy\"></p> \n <ul> \n  <li>红线是工作负载的实际资源使用量</li> \n  <li>绿线是预测该工作负载的资源使用量</li> \n  <li>蓝线是给出的弹性推荐的资源使用量</li> \n </ul> \n <p>CRANE 和 AHPA 即将开源，敬请期待。</p> \n <p>更多关于云原生的成本优化原理和实际案例可参考《降本之源-云原生成本管理白皮书》，是腾讯基于内外云原生成本管理最佳实践，并结合行业优秀案例，提出的一套体系化的云原生成本优化方法论和最佳实践路径。旨在帮助企业改善用云成本，充分发挥云原生的效能和价值。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211126174700791-9519971.png\" alt=\"\" loading=\"lazy\"></p> \n <p>更多白皮书细节内容，在【腾讯云原生】公众号回复“白皮书”下载了解。</p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <p>③公众号后台回复【白皮书】，可获得《腾讯云容器安全白皮书》&amp;《降本之源-云原生成本管理白皮书v1.0》</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211126174701473-1084171924.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"51","createTime":"2021-11-24 16:04","comment":"0","id":"15598550","title":"国内首家！腾讯云正式成为 FinOps 基金会顶级会员","url":"https://www.cnblogs.com/tencent-cloud-native/p/15598550.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <p>11月24日，腾讯云正式宣布加入FinOps基金会，作为国内首家FinOps基金会顶级会员，腾讯云将联合FinOps基金会，全面推进对FinOps标准和最佳实践的贡献，为企业提供云财务管理的最佳解决方案。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211124160340611-914525029.png\" alt=\"\" loading=\"lazy\"></p> \n <p>“作为中国云原生技术和应用的领导者，腾讯云拥有中国最大的Kubernetes集群。我们非常期待能够与腾讯云进行合作，帮助企业和组织有效管理云使用成本，实现云的商业价值最大化。同时，借助腾讯云在FinOps社区的专业能力，我们将进一步推动云和FinOps在中国的持续发展。”FinOps基金会的Mike Fuller表示。</p> \n <p>FinOps基金会隶属于Linux基金会，致力于通过最佳实践、培训、制定标准来提升企业中云财务管理从业人员的能力。FinOps是“云财务管理”的简写，它的核心是确保企业在云中花费的每一分钱都获得最大价值。FinOps旨在通过云平台、最佳实践和文化的结合，提高组织了解云成本和进行业务权衡的能力。FinOps通过将技术、业务和财务专业人士与一组新流程聚集在一起，优化云成本，提升云上业务的投入产出比。</p> \n <p>当前，越来越多的企业开始拥抱云计算，但随着越来越多的业务迁移到云上，云资源浪费的问题也变得越发明显。针对资源配置策略设置不合理、计量方式不够灵活等问题，腾讯云通过助力企业高效管理、优化和使用云原生服务，在帮助企业数字化升级的同时，最大化降低企业用云的成本。</p> \n <p>腾讯云原生团队服务腾讯内部和外部客户，针对海量应用进行了云资源优化，积累了大量经验，并制定了一系列资源优化标准及最佳实践指南。在腾讯内部，团队制定了云原生成熟度评估模型，结合弹性、混部等云原生技术对业务进行改造，在保障业务稳定性的前提下，最终实现了资源利用率达到70%的目标；产品层面，腾讯云推出了云原生成本管理产品“成本大师”，从成本洞察、成本优化、成本运营三个层面来协助企业做更好的成本管理，助力多个企业实现降本增效。</p> \n <p>腾讯云容器产品总经理邹辉表示：“Kubernetes是云原生技术栈的核心，腾讯云原生经过多年的技术积累以及众多腾讯内外部复杂业务考验已经步入非常成熟的阶段。TKE目前拥有国内最大规模的Kubernetes集群以及业界最好的Kubernetes成本优化实践；目前TKE 运行着900万+个Pod ，管理了数千万CPU核；同时我们大规模在腾讯内部核心业务中应用了成本优化技术，CPU利用率最高提升了300%，GPU利用率最高提升了230%，大大提升了业务的数字化转型效率。”</p> \n <p>以腾讯云的典型客户为例，作业帮在采取弹性和全构混部等成本优化技术后，成本下降43%，稳定性提升到99.995%，有效支持了作业帮业务的快速迭代；小红书目前80%的业务都运行在腾讯云上，在通过一系列云原生成本优化手段后，成本大幅下降，比如AI训练和推荐场景下成本下降了40%。</p> \n <p>近日，腾讯基于内外云原生成本管理最佳实践，结合行业优秀案例，和信通院共同提出了一套体系化的云原生成本管理方法论和最佳实践路径——《降本之源—云原生成本管理白皮书》，旨在帮助企业改善用云成本，充分发挥云原生的效能和价值，为各行各业数字化转型、高效利用云资源提供理论和优质案例参考。</p> \n <p>值得一提的是，腾讯开源联盟主席单致豪和腾讯云专家工程师孟凡杰分别加入了FinOps基金会的理事会和技术咨询委员会（TAC），腾讯云将参与到围绕云财务管理最佳实践的标准制定。此外，腾讯云团队正在探索通过最佳实践、研究和分析以及开发者社区工作组为社区做出更多贡献。基于腾讯云原生的突出技术优势和丰富服务经验，将为社区带来更多的解决方案思路，为全面践行FinOps基金会使命提供更多助力。</p> \n <p>中国信通院云大所治理与审计部主任、FinOps产业推进方阵常务副理事长杨玲玲表示：“首先恭喜腾讯成为FinOps基金会国内首家正式会员单位。FinOps的提出，是对客户痛点与需求的响应，信通院也在一年前便积极布局FinOps产业生态，发起成立了FinOps产业推进方阵，我们可以感觉到国内的需求正在释放和扩大，信通院愿与FinOps基金会和包括腾讯在内的产业各界机构，共同为培育国内产业生态、促进产业发展贡献力量。”</p> \n <p>腾讯云副总裁刘颖表示：“我们很高兴参与FinOps基金会对云财务管理最佳实践的探索，FinOps 和我们腾讯云以客户为中心的理念是一致，腾讯云希望借助FinOps的标准和最佳实践，持续为基金会做贡献的同时为客户创造更多价值。”</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211124160341535-938027951.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"404","createTime":"2021-11-22 16:32","comment":"0","id":"15589116","title":"Aggregated APIServer 构建云原生应用最佳实践","url":"https://www.cnblogs.com/tencent-cloud-native/p/15589116.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>张鹏，腾讯云容器产品工程师，拥有多年云原生项目开发落地经验。目前主要负责腾讯云 TKE 云原生 AI 产品的开发工作。</p> \n <p>谢远东，腾讯高级工程师，Kubeflow Member、Fluid（CNCF Sandbox） 核心开发者，负责腾讯云 TKE 在 AI 场景的研发和支持工作。</p> \n <h2 id=\"概述\">概述</h2> \n <p>随着 Kubernetes 的日趋成熟，越来越多的公司、企业开始使用 K8s 来构建自己的云原生平台，基于 kubernetes 良好的扩展性以及成熟稳定的架构，你可以快速部署并管理自己的云原生应用。</p> \n <p>目前我们也在基于 kubernetes 打造一个云原生 AI 平台（我们称它为：<strong>SKAI</strong>），该平台具备<strong>极致弹性</strong>、<strong>多云兼容性</strong>、<strong>高易用</strong>、<strong>可观测性</strong>、<strong>可复现性</strong>的特点，旨在利用云原生的思想和技术，为 AI 场景的数据处理、模型训练、模型上线推理等需求构建弹性可扩展的系统架构，从而提升资源利用率。</p> \n <p>为了使我们的平台更加的云原生，我们没有选择常用的 web 框架来构建 API 服务，而是使用 kubernetes 扩展来构建整个平台，这样使我们的平台能更好的和 kubernetes 融合，可以无缝适配任何基于 k8s 的多云混合云环境。</p> \n <h2 id=\"为什么选择-aggregated-apiserver\">为什么选择 Aggregated APIServer？</h2> \n <h3 id=\"选择独立-api-还是-aggregated-apiserver-\">选择独立 API 还是 Aggregated APIServer ？</h3> \n <p>尽管使用 gin、go-restful 等 go 语言 web 框架可以轻易地构建出一个稳定的 API 接口服务，但以 kubernetes 原生的方式构建 API 接口服务还是有很多优势，例如:</p> \n <ul> \n  <li>能利用 kubernetes 原生的认证、授权、准入等机制，有更高的开发效率;</li> \n  <li>能更好的和 K8s 系统融合，借助 K8s 生态更快的推广自己的产品，方便用户上手;</li> \n  <li>借助于 K8s 成熟的 API 工具及规范，构建出的 API 接口更加规范整齐;</li> \n </ul> \n <p>但是在很多场景下，我们还是不能确定到底使用聚合 API（Aggregated APIServer）还是独立 API 来构建我们的服务，官方为我们提供了两种选择的对比；如果你不能确定使用聚合 API 还是独立 API，下面的表格或许对你有帮助:</p> \n <table> \n  <thead> \n   <tr> \n    <th>考虑 API 聚合的情况</th> \n    <th>优选独立 API 的情况</th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td>你在开发新的 API</td> \n    <td>你已经有一个提供 API 服务的程序并且工作良好</td> \n   </tr> \n   <tr> \n    <td>你希望可以是使用 <code>kubectl</code> 来读写你的新资源类别</td> \n    <td>不要求 <code>kubectl</code> 支持</td> \n   </tr> \n   <tr> \n    <td>你希望在 Kubernetes UI （如仪表板）中和其他内置类别一起查看你的新资源类别</td> \n    <td>不需要 Kubernetes UI 支持</td> \n   </tr> \n   <tr> \n    <td>你希望复用 <a href=\"https://kubernetes.io/zh/docs/concepts/extend-kubernetes/api-extension/custom-resources/#common-features\" title=\"Kubernetes API 支持特性\" target=\"_blank\" rel=\"noopener\">Kubernetes API 支持特性</a></td> \n    <td>你不需要这类特性</td> \n   </tr> \n   <tr> \n    <td>你有意愿取接受 Kubernetes 对 REST 资源路径所作的格式限制，例如 API 组和名字空间。（参阅 <a href=\"https://kubernetes.io/zh/docs/concepts/overview/kubernetes-api/\" title=\"API 概述\" target=\"_blank\" rel=\"noopener\">API 概述</a>）</td> \n    <td>你需要使用一些特殊的 REST 路径以便与已经定义的 REST API 保持兼容</td> \n   </tr> \n   <tr> \n    <td>你的 API 是<a href=\"https://kubernetes.io/zh/docs/concepts/extend-kubernetes/api-extension/custom-resources/#declarative-apis\" title=\"声明式的\" target=\"_blank\" rel=\"noopener\">声明式的</a></td> \n    <td>你的 API 不符合<a href=\"https://kubernetes.io/zh/docs/concepts/extend-kubernetes/api-extension/custom-resources/#declarative-apis\" title=\"声明式\" target=\"_blank\" rel=\"noopener\">声明式</a>模型</td> \n   </tr> \n   <tr> \n    <td>你的资源可以自然地界定为集群作用域或集群中某个名字空间作用域</td> \n    <td>集群作用域或名字空间作用域这种二分法很不合适；你需要对资源路径的细节进行控制</td> \n   </tr> \n  </tbody> \n </table> \n <p><strong>首先我们希望我们的 SKAI 平台能更好的和 k8s 结合，并且它是一个声明式的 API，尽可能的复用 Kubernets API 的特性，显然聚合 API 对我们来说更加适合。</strong></p> \n <h3 id=\"选择-crds-还是-aggregated-apiserver\">选择 CRDs 还是 Aggregated APIServer？</h3> \n <p>除了聚合 API，官方还提供了另一种方式以实现对标准 kubernetes API 接口的扩展：CRD（Custom Resource Definition ），能达到与聚合 API 基本一样的功能，而且更加易用，开发成本更小，但相较而言聚合 API 则更为灵活。针对这两种扩展方式如何选择，官方也提供了相应的参考。</p> \n <p>通常，如果存在以下情况，CRD 可能更合适：</p> \n <ul> \n  <li>定制资源的字段不多；</li> \n  <li>你在组织内部使用该资源或者在一个小规模的开源项目中使用该资源，而不是在商业产品中使用；<br> 聚合 API 可提供更多的高级 API 特性，也可对其他特性进行定制；例如，对存储层进行定制、对 protobuf 协议支持、对 logs、patch 等操作支持。</li> \n </ul> \n <p>两种方式的核心区别是定义 api-resource 的方式不同。在 Aggregated APIServer 方式中，api-resource 是通过代码向 API 注册资源类型，而 Custom Resource 是直接通过 yaml 文件向 API 注册资源类型。</p> \n <p>简单来说就是 CRD 是让 kube-apiserver 认识更多的对象类别（Kind），Aggregated APIServer 是构建自己的 APIServer 服务。虽然 CRD 更简单，但是缺少更多的灵活性，更详细的 CRDs 与 Aggregated API 的对比可参考<a href=\"https://kubernetes.io/zh/docs/concepts/extend-kubernetes/api-extension/custom-resources/#compare-ease-of-use\" title=\"官方文档\" target=\"_blank\" rel=\"noopener\">官方文档</a>。</p> \n <p><strong>对于我们而言，我们希望使用更多的高级 API 特性，例如 \"logs\" 或 \"exec\"，而不仅仅局限于 CRUD ，所以我们最终选择了 Aggregated APIServer 。</strong></p> \n <h2 id=\"apiserver-扩展的基本原理\">APIServer 扩展的基本原理</h2> \n <p>kube-apiserver 作为整个 Kubernetes 集群操作 etcd 的唯一入口，负责 Kubernetes 各资源的认证&amp;鉴权，校验以及 CRUD 等操作，提供 RESTful APIs，供其它组件调用：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211122163133956-1813519278.png\" alt=\"\" loading=\"lazy\"></p> \n <p><strong>kube-apiserver 其实包含三种 APIServer：</strong></p> \n <ul> \n  <li><strong>AggregatorServer</strong>：负责处理 <code>apiregistration.k8s.io</code> 组下的 APIService 资源请求，同时将来自用户的请求拦截转发给 Aggregated APIServer(AA)；</li> \n  <li><strong>KubeAPIServer</strong>：负责对请求的一些通用处理，包括：认证、鉴权以及各个内建资源(pod, deployment，service)的 REST 服务等；</li> \n  <li><strong>ApiExtensionsServer</strong>：负责 CustomResourceDefinition（CRD）apiResources 以及 apiVersions 的注册，同时处理 CRD 以及相应 CustomResource（CR）的REST请求(如果对应 CR 不能被处理的话则会返回404)，也是 apiserver Delegation 的最后一环；</li> \n </ul> \n <p>三个 APIServer 通过 delegation 的关系关联，在 kube-apiserver 初始化创建的过程中，首先创建的是 APIExtensionsServer，它的 delegationTarget 是一个空的 Delegate，即什么都不做，继而将 APIExtensionsServer 的 GenericAPIServer，作为 delegationTarget 传给了 KubeAPIServer，创建出了 KubeAPIServer，再然后，将 kubeAPIServer 的 GenericAPIServer 作为 delegationTarget 传给了 AggregatorServer，创建出了 AggregatorServer，所以他们之间 delegation 的关系为: Aggregator -&gt; KubeAPIServer -&gt; APIExtensions，如下图所示：<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211122163134172-1714092045.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"如何快速构建-aggregated-apiserver\">如何快速构建 Aggregated APIServer？</h2> \n <p>虽然官方提供了一个 <a href=\"https://github.com/kubernetes/sample-apiserver\" title=\"sample-apiserver\" target=\"_blank\" rel=\"noopener\">sample-apiserver</a>，我们可以参考实现自己的 Aggregated APIServer。但完全手工编写太过复杂，也不便于后期维护，我们最终选择了官方推荐的工具 <a href=\"https://github.com/kubernetes-sigs/apiserver-builder-alpha\" title=\"apiserver-builder\" target=\"_blank\" rel=\"noopener\">apiserver-builder</a>，apiserver-builder 可以帮助我们快速创建项目骨架，并且使用 apiserver-builder 构建的项目目录结构比较清晰，更利于后期维护。</p> \n <h3 id=\"安装-apiserver-builder-工具\">安装 apiserver-builder 工具</h3> \n <p>通过 Go Get 安装</p> \n <pre><code>$ GO111MODULE=on go get sigs.k8s.io/apiserver-builder-alpha/cmd/apiserver-boot\n</code></pre> \n <p>通过安装包安装</p> \n <ul> \n  <li><a href=\"https://github.com/kubernetes-sigs/apiserver-builder-alpha/releases\" title=\"下载\" target=\"_blank\" rel=\"noopener\">下载</a>最新版本</li> \n  <li>解压到 /usr/local/apiserver-builder/</li> \n  <li>如果此目录不存在，则创建此目录</li> \n  <li>添加/usr/local/apiserver-builder/bin到您的路径 <code>export PATH=$PATH:/usr/local/apiserver-builder/bin</code></li> \n  <li>运行<code>apiserver-boot -h</code></li> \n </ul> \n <h3 id=\"初始化项目\">初始化项目</h3> \n <p>完成 apiserver-boot 安装后，可通过如下命令来初始化一个 Aggregated APIServer 项目：</p> \n <pre><code>$ mkdir skai-demo\n$ cd skai-demo \n$ apiserver-boot init repo --domain skai.io\n</code></pre> \n <p>执行后会生成如下目录：</p> \n <pre><code>.\n├── BUILD.bazel\n├── Dockerfile\n├── Makefile\n├── PROJECT\n├── WORKSPACE\n├── bin\n├── cmd\n│   ├── apiserver\n│   │   └── main.go\n│   └── manager\n│       └── main.go -&gt; ../../main.go\n├── go.mod\n├── hack\n│   └── boilerplate.go.txt\n├── main.go\n└── pkg\n    └── apis\n        └── doc.go\n</code></pre> \n <ul> \n  <li>hack 目录存放自动脚本</li> \n  <li>cmd/apiserver 是 aggregated server的启动入口</li> \n  <li>cmd/manager 是 controller 的启动入口</li> \n  <li>pkg/apis 存放 CR 相关的结构体定义，会在下一步自动生成</li> \n </ul> \n <h3 id=\"生成自定义资源\">生成自定义资源</h3> \n <pre><code>$ apiserver-boot create group version resource --group animal --version v1alpha1 --kind Cat --non-namespaced=false\nCreate Resource [y/n]\ny\nCreate Controller [y/n]\nn\n</code></pre> \n <p>可根据自己的需求选择是否生成 Controller，我们这里暂时选择不生成, 对于需要通过 namespace 隔离的 resource 需要增加 --non-namespaced=false 的参数，默认都是 true。</p> \n <p>执行完成后代码结构如下：</p> \n <pre><code>└── pkg\n    └── apis\n        ├── animal\n        │   ├── doc.go\n        │   └── v1alpha1\n        │       ├── cat_types.go\n        │       ├── doc.go\n        │       └── register.go\n        └── doc.go\n</code></pre> \n <p>可以看到在 pkg/apis 下生成了 animal 的 group 并在 v1alpha1 版本下新增了 <code>cat_types.go</code> 文件，此文件包含了我们资源的基础定义，我们在 spec 中增加字段定义，并在已经实现的 <code>Validate</code> 方法中完成基础字段的校验。</p> \n <pre><code>// Cat\n// +k8s:openapi-gen=true\ntype Cat struct {\n        metav1.TypeMeta   `json:\",inline\"`\n        metav1.ObjectMeta `json:\"metadata,omitempty\"`\n        Spec   CatSpec   `json:\"spec,omitempty\"`\n        Status CatStatus `json:\"status,omitempty\"`\n}\n// CatSpec defines the desired state of Cat\ntype CatSpec struct {\n    Name string `json:\"name\"`\n}\nfunc (in *Cat) Validate(ctx context.Context) field.ErrorList {\n    allErrs := field.ErrorList{}\n    if len(in.Spec.Name) == 0 {\n        allErrs = append(allErrs, field.Invalid(field.NewPath(\"spec\", \"name\"), in.Spec.Name, \"must be specify\"))\n    }\n    return allErrs\n}\n</code></pre> \n <h3 id=\"部署运行\">部署运行</h3> \n <p>完成以上步骤，你其实已经拥有一个完整的 Aggregated APIServer，接下来我们试着将它运行起来；apiserver-boot 本身提供了两种运行模式：in-cluster、local; local 模式下只作为单独的 API 服务部署在本地方便做调试，过于简单这里不做过多介绍，主要关注一下 in-cluster 模式；in-cluster 可以将你的 Aggregated APIServer 部署在任何 K8s 集群中，例如：minikube，腾讯 TKE，EKS 等，我们这里使用 EKS 集群作为演示。</p> \n <h4 id=\"创建eks集群配置好本地kubeconfig\">创建<a href=\"https://cloud.tencent.com/document/product/457/39813\" title=\"EKS集群\" target=\"_blank\" rel=\"noopener\">EKS集群</a>&amp;配置好本地<a href=\"https://cloud.tencent.com/document/product/457/39814\" title=\"kubeconfig\" target=\"_blank\" rel=\"noopener\">kubeconfig</a>；</h4> \n <h4 id=\"执行部署命令-\">执行部署命令 ；</h4> \n <pre><code>$ apiserver-boot run in-cluster --image=xxx/skai.io/skai-demo:0.0.1 --name=skai-demo --namespace=default\n</code></pre> \n <p>在执行部署命令过程中，apiserver-boot 主要帮我们做了如下几件事情：</p> \n <ul> \n  <li>自动生成 APIServer Dockerfile 文件；</li> \n  <li>通过 APIServer Dockerfile 构建服务镜像，并将镜像推送到指定仓库；</li> \n  <li>在config目录下生成 CA 及其他 APIServer 部署需要的证书文件；</li> \n  <li>在config目录下生成 APIServer 部署需要的 Deployment、Service、APIService、ServiceAccount 等 yaml 文件；</li> \n  <li>将上一步生成的 yaml 文件部署到集群中；</li> \n </ul> \n <h3 id=\"功能验证\">功能验证</h3> \n <h4 id=\"确认-resource-注册成功\">确认 Resource 注册成功</h4> \n <pre><code>$ kubectl api-versions |grep animal\nanimal.skai.io/v1alpha1\n</code></pre> \n <h4 id=\"确认-aggregated-apiserver-能正常工作\">确认 Aggregated APIServer 能正常工作</h4> \n <pre><code>$ kubectl get apiservice v1alpha1.animal.skai.io \nNAME                      SERVICE             AVAILABLE   AGE\nv1alpha1.animal.skai.io   default/skai-demo   True        19h\n</code></pre> \n <h4 id=\"创建并查看新增的-resource\">创建并查看新增的 Resource</h4> \n <p>创建</p> \n <pre><code>$ cat lucky.yaml\napiVersion: animal.skai.io/v1alpha1\nkind: Cat\nmetadata:\n  name: mycat\n  namespace: default\nspec:\n  name: lucky\n# 创建自定义 resource\n$ kubectl apply -f lucky.yaml\n</code></pre> \n <p>查找</p> \n <pre><code># 查找自定义 resource 列表\n$ kubectl get cat\nNAME    CREATED AT\nmycat   2021-11-17T09:08:10Z\n# 查找自定义资源详情\n$ kubectl get cat mycat -oyaml\napiVersion: animal.skai.io/v1alpha1\nkind: Cat\nmetadata:\n  annotations:\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"animal.skai.io/v1alpha1\",\"kind\":\"Cat\",\"metadata\":{\"annotations\":{},\"name\":\"mycat\"},\"spec\":{\"name\":\"lucky\"}}\n  creationTimestamp: \"2021-11-17T09:08:10Z\"\n  name: mycat\n  resourceVersion: \"17\"\n  uid: 98af0905-f01d-4042-bad3-71b96c0919f4\nspec:\n  name: lucky\nstatus: {}\n</code></pre> \n <h2 id=\"总结\">总结</h2> \n <p>本文从实战角度出发介绍我们开发 SKAI 平台过程中选择 Aggregated API 的原因，以及 kube-apisever 的扩展原理，最后介绍了 apiserver-builder 工具，并演示如何一步一步构建起自己的 Aggregated API，并将它部署到 EKS 集群中。希望该篇 Aggregated APIServer 最佳实践可以帮助即将使用 K8s API 扩展来构建云原生应用的开发者。</p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211122163134539-1577816867.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"323","createTime":"2021-11-19 17:25","comment":"0","id":"15578374","title":"用户案例 | 腾讯小视频&转码平台云原生容器化之路","url":"https://www.cnblogs.com/tencent-cloud-native/p/15578374.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>李汇波，腾讯业务运维高级工程师，目前就职于TEG 云架构平台部 技术运营与质量中心，现负责微信、QQ社交类业务的视频转码运维。</p> \n <h2 id=\"摘要\">摘要</h2> \n <p>随着短视频兴起和快速发展，对于视频转码处理的需求也越来越多。低码率高清晰，4K、超清、高清、标清适配不同终端和不同网络环境来提升用户体验，以及水印、logo、裁剪、截图等多样化的用户需求。对于资源的多样化需求和弹性扩缩容也需要快速响应，而随着公司自研上云项目的推进，设备的稳定行和多样性可提供更多选择，来满足像朋友圈、视频号、广告、公众号等转码业务快速、稳定、抗突发的资源需求。</p> \n <h2 id=\"服务场景\">服务场景</h2> \n <p>MTS（Media transcoding service）的定位是点播场景准实时（及离线）视频处理服务。为业务提供分钟级可完成的高清压缩、截图水印、简单剪辑等基本视频处理功能，同时具备向下集成定制画质增加，质量测评等深度功能的能力。</p> \n <p>业务开发者定义批量处理模板，当内容生产方上传数据时，触发转码作业输出多规格压缩视频和视频封面，即可发表推送。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211119172446720-74088805.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"背景\">背景</h2> \n <p>微信侧和小视频平台承接着非常多视频文件，而这些视频基本都在转码平台根据业务需求进行处理，为了降低码率减少成本，降低用户因网络而卡顿等功能。最早转码平台基本上是各个业务维护一个独立集群，集群繁多，集群之间资源也不能互相调度使用，并且单集群容量较小，请求量大的业务不得不部署多套集群支撑。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211119172446926-610099490.png\" alt=\"\" loading=\"lazy\"></p> \n <p>这给运营带来很大的挑战，需要一套容量上限更大，资源调度更灵活，运营更便捷的平台。而随着公司自研上云项目的推进和 TKE 容器化，转码平台需要能快速对接 TKE 资源，利用公司海量计算资源来满足业务对视频转码的诉求。</p> \n <h2 id=\"建设思路和规划\">建设思路和规划</h2> \n <p>视频接入和转码过程经常面临多业务突发，在保障业务质量前提下又需要提升利用率，提高运营的效率。</p> \n <p><strong>平台能力建设</strong>：单集群能力上限提高，业务频控隔离互不影响，资源调度灵活调整</p> \n <p><strong>资源管理建设</strong>：围绕 TKE 容器平台充分挖掘空闲碎片资源，通过 HPA 错开高低峰弹性扩缩容，提升 CPU 利用率。与此同时，利用视频接入服务流量高、CPU 使用率低，转码服务流量低、CPU 使用率高特点，通过两种场景混部充分利用物理机资源，防止纯流量集群低负载</p> \n <p><strong>运营系统建设</strong>：适配业务场景，完善变更上下架流程，进程监控告警剔除，建立稳定保障平台</p> \n <h2 id=\"平台能力建设\">平台能力建设</h2> \n <h3 id=\"架构升级\">架构升级</h3> \n <h4 id=\"老转码平台架构\">老转码平台架构：</h4> \n <ol> \n  <li> <p>为 master/slave 主从结构，容灾能力相对较弱，而且受限 Master 性能，单集群大概管理8000台 worker</p> </li> \n  <li> <p>资源调度层面不能友好区分不同核数的 worker，导致有些负载高，有些负载低</p> </li> \n  <li> <p>不能够基于业务维度做频控，单业务突发影响整个集群</p> <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211119172447248-727317551.png\" alt=\"\" loading=\"lazy\"></p> </li> \n </ol> \n <h4 id=\"新转码平台架构\">新转码平台架构：</h4> \n <ol> \n  <li>合并 Master/Access 模块为 sched，sched 调度模块分布式部署，任一节点挂了可自动剔除掉</li> \n  <li>worker 和 sched 建立心跳并且上报自身状态和 cpu 核数等信息，便于调度根据 worker 负载来分配任务，保障同一个集群部署不同规格 cpu worker 负载均衡</li> \n  <li>单集群管理能力 3w+ worker，满足节假日业务突增</li> \n  <li>业务合并到公共大集群，可对单业务进行频控，减少业务直接的干扰</li> \n </ol> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211119172447526-610814713.png\" alt=\"\" loading=\"lazy\"></p> \n <p>架构的升级，平台不再受限单集群能力，日常和节假日高峰可快速满足需求，并且业务合并大集群错开高低峰，可资源利用</p> \n <p><strong>接入服务 svpapi 升级 DevOps 2.0</strong></p> \n <p>借助业务上 tke 东风，小视频平台接入服务 svpapi 实现标准化升级。重要改进包括：</p> \n <ol> \n  <li>整合原有多变更系统、多监控系统、多基础资源管理系统到智研统一入口，具体包括研发测试、日常版本发布、资源弹性扩缩容、业务监控告警、业务日志检索分析。通过 CICD 流程屏蔽直接对 TKEStack 操作，安全性更好</li> \n  <li>模块配置区分使用场景托管于七彩石，并支持1分钟级业务开关切换，支持节假日期间灵活的流量调度和业务流控频控</li> \n  <li>下半年接入服务计划利用智研监控集群流量水平，结合 TKEStack 根据流量 HPA 能力，实践资源扩容无人值守能力</li> \n </ol> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211119172447759-110658381.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"资源管理建设\">资源管理建设</h2> \n <p>具备平台能力后，下一步需要对不同容器规格的资源进行分类并均衡调度，这里主要的难点：</p> \n <p>1、业务场景多样性：TKE 集群涉及很多，性能规格也各不相同，从6核到40核都需要能使用</p> \n <p>2、资源管理和运营需要考虑：Dockerfile 镜像制作，适配 TApp 不同集群配置，容器上下架，运维变更规范等</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211119172447993-1529329372.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"梳理出-tke-不同集群下容器配置\">梳理出 TKE 不同集群下容器配置</h3> \n <pre><code class=\"language-javascript\"># 不同cpu规格适配不同环境变量\n- name: MTS_DOCKER_CPU_CORE_NUM\n  value: \"16\"\n- name: MTS_DOCKER_MEM_SIZE\n  value: \"16\"\n</code></pre> \n <pre><code class=\"language-javascript\"># 算力平台亲和性设置，当负载超过70%，则驱逐该pod\naffinity:\n    nodeAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n        - matchExpressions:\n          - key: max_vm_steal\n            operator: Lt\n            values:\n            - \"70\"\n</code></pre> \n <h3 id=\"资源调度均衡\">资源调度均衡</h3> \n <p>转码属于异步任务，处理的每个任务请求时间是不一样的，并且有状态，所以无法基于北极星去均衡调度任务，需要平台侧来设计调度策略</p> \n <ol> \n  <li>基于不同规格 CPU 机器 worker 性能，均衡分配任务</li> \n  <li>根据不同 worker 版本进行调度，支持小业务快速版本迭代</li> \n </ol> \n <p>在对不同规格容器，通过 Score 和版本来均衡调度</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211119172448261-1559007658.png\" alt=\"\" loading=\"lazy\"></p> \n <p>基于调度能力的在不同 CPU 规格上的任务均衡，C6 和 C12 利用率较相近，不会导致大规格容器资源浪费</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211119172448576-1651476845.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"运营系统建设\">运营系统建设</h2> \n <p>转码集群的 worker 资源怎样扩容到对应集群，这里增加了一层资源管理层，需要手动调用将指定的 worker 从集群上下架。对应平台侧开发专业 OSS 系统，将集群的 sched/worker/任务做成页面便于运营，并且封装上下架的 API。而 TKE 跟转码平台其实无任何关联，为了实现解耦，运维侧开发对接 TKE 上下架的功能，制定流程，将 TKE 扩缩容的资源调用 OSS API 实现同步，具体逻辑如图：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211119172448916-1981661516.png\" alt=\"\" loading=\"lazy\"></p> \n <p>TKE 支持北极星服务，将对应的 TApp 关联到北极星服务名，将北极星服务作为不同转码集群扩缩容 IP 的元数据管理，保障 TKE 和转码侧资源的一致性</p> \n <h3 id=\"进程监控\">进程监控</h3> \n <p>转码平台管理的 worker 有上万台，在运行过程或者新版本发布中不能及时监控容器进程状态是怎么样，通过批量扫描时间太长，不能快速知道进程异常状态，因此结合组内进程监控平台，建设转码容器的进程监控告警，异常 worker 通过机器人企业微信、电话告警及时通知剔除，提升服务质量</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211119172449362-1624211584.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"资源利用优化\">资源利用优化</h2> \n <p>转码业务目前基本是社交的自研业务，节假日效应突发比较明显，而且资源需求较大，大部分还是准实时，对于转码耗时也比较敏感。因此平时在保障速度外，会预留30%~50的 buff，而业务凌晨基本上是低峰，因此部分资源在凌晨是浪费的。TKE 支持根据系统指标自动伸缩，并且它计费模式也是根据一天内实际使用量收费，这里我们基于 CPU 利用率指标，来配置弹性伸缩，低峰时缩容，高峰时自动扩容，减少资源的占用，从而减少成本</p> \n <h3 id=\"弹性扩缩容\">弹性扩缩容</h3> \n <p>根据实际负载节点副本数在凌晨低峰缩容<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211119172449787-215904369.png\" alt=\"\" loading=\"lazy\"></p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211119172450013-1675599927.png\" alt=\"\" loading=\"lazy\"></p> \n <p>Workloads CPU 实际使用占 request 百分比峰值能够达到75%以上，在保障业务稳定的情况下，提升 CPU 利用率</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211119172450194-1373312076.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"成果小结\">成果小结</h2> \n <p>目前转码平台从分散小集群合并的三地大集群，运营能力的提升+资源利用率提升，正在努力提升云原生成熟度，截止到2021年5月。</p> \n <ol> \n  <li>业务累计接入微信朋友圈、视频号、c2c、公众号、看一看、广告、QQ 空间等内部视频业务，每天视频转码处理1亿+</li> \n  <li>日常保持在70%左右 CPU 利用率，根据负载自动弹性扩缩容，业务成熟度显著提高</li> \n </ol> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211119172450469-491063693.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"450","createTime":"2021-11-09 16:34","comment":"0","id":"15529666","title":"腾讯发布 K8s 多集群管理开源项目 Clusternet","url":"https://www.cnblogs.com/tencent-cloud-native/p/15529666.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <p>11月4日，在腾讯数字生态大会上，腾讯宣布了云原生领域一项重磅开源进展—— K8s 多集群管理项目 Clusternet 正式开源。</p> \n <p>Clusternet 由腾讯联合多点生活、QQ音乐、富途证券、微众银行、酷狗音乐、三七互娱等共同发起，专注 K8s 多集群管理和应用治理方向，希望让管理多集群就像上网一样简单。</p> \n <p>作为未来分布式云的技术基石，Clusternet 通过组件化方式扩展 K8s，将 K8s 强大的集群、应用和服务能力扩展至分布式云，能够兼容所有 K8s 生态资源和软件，帮助企业应用零成本升级至多云架构，助力传统行业向未来分布式云的转型。腾讯在本次大会中发布的腾讯云原生分布式云中心 TDCC 产品正是以 Clusternet 作为核心技术。</p> \n <p>此次开源，也是来自于腾讯内部多集群治理经验的总结创新，并通过Clusternet 项目对外开源共享，腾讯内部的星辰算力团队已基于多集群方案完成了近千万核规模的管控。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211109163409961-682536266.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>通过 Clusternet，无论集群是运行在公有云、私有云、混合云还是边缘云上，都可以获得统一的管理和一致的访问体验，实现 K8s API 集中部署和多集群的应用程序和服务的协同调度。</p> \n <p>作为新一代的开源多集群治理软件，Clusternet 具备独特的优势：</p> \n <h3 id=\"最轻量化架构\">最轻量化架构</h3> \n <p>采用了 K8s AA （Aggregated APIServer）方式部署，不依赖额外的存储和端口，无需额外学习和维护不同平台软件和系统的差异，大大降低了运维复杂度。</p> \n <h3 id=\"一站式连接各类集群\">一站式连接各类集群</h3> \n <p>同时支持 Pull 和 Push 模式管理 K8s 集群，首创 Dual 模式自动化一站式管理海量集群。即使在无专网通道的情况下，仍可实现跨集群路由访问。</p> \n <h3 id=\"零成本升级多云架构\">零成本升级多云架构</h3> \n <p>原有单云单集群架构业务，可以零学习和改造成本升级至多云多集群架构，完全兼容 K8s 的标准 API、Helm Chart 以及自定义的 CRD，无需额外学习复杂的多集群 API。</p> \n <h3 id=\"丰富灵活的策略配置\">丰富、灵活的策略配置</h3> \n <p>提供了多种类型的配置策略，包括分发策略、差异化策略等，通过灵活的搭配即可满足复杂的业务场景，减少人工干预和重复劳动。</p> \n <h3 id=\"便捷接入\">便捷接入</h3> \n <p>Clusternet 提供了完善的对接能力，支持 kubectl plugin 以及 client-go，方便业务一键接入，具备管理多集群的能力。</p> \n <p>遵循云原生理念全新设计架构，Clusternet 完全兼容原生 K8s 资源，方便业务快速集成和使用。更通过腾讯云原生分布式云中心 TDCC 产品为用户提供一站托管式多集群管理和应用治理服务，将成熟稳定的云服务交付至更靠近用户和数据的位置，保证长期的平台运营、治理、更新和演进，并且提供可靠性和安全合规保证。</p> \n <p>Clusternet 网址：<br> <a href=\"https://github.com/clusternet/clusternet\" target=\"_blank\" rel=\"noopener\">https://github.com/clusternet/clusternet</a></p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <pre><code>   ①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~\n\n   ②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。\n</code></pre> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211109163410472-30719851.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"331","createTime":"2021-11-02 18:45","comment":"0","id":"15500443","title":"用户案例 | 腾讯医疗资讯平台云原生容器化之路","url":"https://www.cnblogs.com/tencent-cloud-native/p/15500443.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>yuhuliu，腾讯研发工程师，关注存储、大数据、云原生领域。</p> \n <h2 id=\"摘要\">摘要</h2> \n <p>医疗资讯业务在高速发展过程中，形成了覆盖不同场景、不同用户、不同渠道的几十个业务，以及上千个服务。为了高效满足用户多样化的需求，医疗技术团队通过 TKE 上云，使用 Coding DevOps 平台，以及云上可观测技术，来提升研发效率、降低运营运维成本。本文介绍我们在上云过程中一些实践和经验，以及一些思考和选择。</p> \n <h2 id=\"业务背景\">业务背景</h2> \n <ul> \n  <li>stage1: 医疗资讯主要包括了医典、医生、医药等核心业务，其中医典主要提供医疗相关内容获取、医疗知识科普传递；医生满足医生和患者的互联；医药服务了广大药企。在业务发展过程中我们原来基于 taf 平台构建了大量后台服务，完成了初期业务的快速搭建。由于业务数量较多，大量业务有多地域的述求，最终我们在 taf 平台部署多个业务集群。这个时候发布、运维、问题排查纯靠人工阶段，效率较低。</li> \n </ul> \n <h2 id=\"业务上云\">业务上云</h2> \n <ul> \n  <li> <p>stage2: 随着业务规模的急速扩张，传统的开发、运维方式在敏捷、资源、效率方面对业务迭代形成较大的制约。随着公司自研上云项目推进，拥抱云原生化，基于 K8s 来满足业务对不同资源多样化需求和弹性调度，基于现有成熟 devops 平台来进行敏捷迭代，越来越成为业务正确的选择。医疗后台团队开始了整体服务上云的迁移。</p> </li> \n  <li> <p>上云之前，还有几个问题需要考虑</p> </li> \n </ul> \n <p>​ 1：服务众多，代码如何管理</p> \n <p>​ 2：上云后怎么快速进行问题定位、排查</p> \n <p>​ 3：监控告警平台如何选择</p> \n <p>​ 4：基础镜像怎么选择</p> \n <h3 id=\"关于服务代码管理\">关于服务代码管理</h3> \n <p>使用 git 做代码版本控制，按业务建立项目组，每个服务使用单独的代码仓库，仓库名使用同一命名规范。</p> \n <h3 id=\"关于问题排查\">关于问题排查</h3> \n <p>调研云上有成熟的 elk 服务，业务只需要把日志放到同一目录，通过 filebeat 采集后，通过 ETL 逻辑可以把日志方便导入 Elasticsearch。这样的做法还有个优点就是可以同时支持前后端服务日志的采集，技术较为成熟，复用了组件能力，通过在请求中埋点加入 traceid，方便在全链路定位问题。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211102184510144-1839318144.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"关于监控告警平台\">关于监控告警平台</h3> \n <p>CSIG 提供了基于日志监控的 CMS 平台，将业务日志导入到 CMS 后，可以基于上报的日志配置监控和告警，监控维度、指标业务可以自己定义。我们采用了主调、被调、接口名等维度，调用量、耗时、失败率等指标，满足业务监控告警诉求。基于日志的监控可以复用同一条数据采集链路，系统架构统一简洁。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211102184510399-1170962382.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"关于基础镜像\">关于基础镜像</h3> \n <p>为了方便业务初期快速上云，以及统一服务启动、数据采集上报，有必要对业务的基础镜像进行处理，预先建立对应目录，提供脚本和工具，方便业务快速接入。这里我们提供了不同语言、版本的基础镜像，封装了 supervisord 和 filebeat，通过 supervisord 来拉起 filebeat 和业务服务。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211102184510661-508854877.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"devops\">Devops</h2> \n <ul> \n  <li>stage2: 在上云过程中，也通过和质量同学逐步完善，将开发过程中原有人工操作的步骤 pipeline 化，来提高迭代效率，规范开发流程；通过单测和自动化拨测，提升服务稳定性。采用统一的流水线后，开发、部署效率从原来的小时级别降低到分钟级别。</li> \n </ul> \n <p>这里主要使用了 coding 平台，为了区分不同环境，建立了开发、测试、预发布、测试四套不同流水线模板，还引入了合流机制来加入人工 code review 阶段。</p> \n <p>在合流阶段：通过 MR HOOK，自动轮询 code review 结果，确保代码在 review 通过后才能进行下一步（不同团队可能要求不一样）。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211102184510953-833360874.png\" alt=\"\" loading=\"lazy\"></p> \n <p>在 CI 阶段：通过代码质量分析，来提升代码规范性，通过单元测试，来保证服务质量。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211102184511298-577407230.png\" alt=\"\" loading=\"lazy\"></p> \n <p>在 CD 阶段：通过引入人工审批和自动化拨测，提高服务稳定性。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211102184511723-1207377011.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"资源利用率提升\">资源利用率提升</h2> \n <ul> \n  <li>stage3：在业务整体上云后，由于不少业务有多地域部署（广州、南京、天津、香港）的述求，加上每个服务需要四套（开发、测试、预发布、正式）不同的环境，上云后我们初步整理，一共有3000+不同 workload。由于不同业务访问量具有很大不确定性，初期基本上按照理想状态来配置资源，存在不少的浪费。</li> \n </ul> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211102184512010-1550861594.png\" alt=\"\" loading=\"lazy\"></p> \n <p>为了提高资源整体利用率，我们进行了一系列优化，大致遵循如下规范：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211102184512336-2080571438.png\" alt=\"\" loading=\"lazy\"></p> \n <p>这里由于 HPA 会导致业务容器动态扩缩，在停止过程中如果原有流量还在访问，或者启动还未完成就导入流量，会导致业务的失败，因此需要需要预先开启 TKE 上 preStop 以及就绪检测等配置。</p> \n <p>1：优雅停止，进程停止前等北极星、cl5 路由缓存过期；<br> 入口：tke-&gt;工作负载-&gt;具体业务-&gt;更新工作负载<br> 如果使用的服务发现是 CL5，推荐 preStop70s，北极星配置 10s 足够了</p> \n <p>2：就绪、存活检测，进程启动完成后再调配流量；<br> 入口：tke-&gt;工作负载-&gt;具体业务-&gt;更新工作负载，根据不同业务配置不同探测方式和时间间隔。</p> \n <p>通过上面一系列调整优化，我们的资源利用率大幅提升，通过 TKE 上弹性升缩，在保证业务正常访问同时，局部高峰访问资源不足的问题基本解决，避免了资源浪费，也提升了服务稳定性；但多环境问题还是会导致存在一定损耗。</p> \n <h2 id=\"可观测性技术\">可观测性技术</h2> \n <ul> \n  <li> <p>stage4：初期使用基于日志的方式来做（log/metric/tracing），满足了业务快速上云、问题排查效率提升的初步述求，但随着业务规模增长，愈加庞大的日志流占用了越来越多的资源，日志堆积在高峰期成为常态， CMS 告警可能和实际发生时已经间隔了半个小时，ELK的维护成本也急剧上升。云原生的可观测技术已经成为必要，这里我们引入了 Coding 应用管理所推荐的可观测技术方案，通过统一的 coding-sidecar 对业务数据进行采集：</p> <p>​ <img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211102184512716-1436969018.png\" alt=\"\" loading=\"lazy\"></p> </li> \n </ul> \n <p>监控：云监控中台</p> \n <p>日志：CLS</p> \n <p>Tracing：APM</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211102184513084-1770115727.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>通过接入这些平台的能力，我们的问题发现、定位、排查效率有了极大的提高，业务的运营维护成本较大降低，通过监控、和 tracing，也发现了不少系统潜在的问题，提高了服务质量。</p> \n <h2 id=\"结尾\">结尾</h2> \n <p>最后，要感谢上云过程中全体开发同学的辛勤付出，以及各位研发 leader 的大力支持。</p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <p>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <p>②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202111/2041406-20211102184513447-2114798792.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"643","createTime":"2021-10-26 21:48","comment":"0","id":"15468049","title":"如何接入 K8s 持久化存储？K8s CSI 实现机制浅析","url":"https://www.cnblogs.com/tencent-cloud-native/p/15468049.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>王成，腾讯云研发工程师，Kubernetes contributor，从事数据库产品容器化、资源管控等工作，关注 Kubernetes、Go、云原生领域。</p> \n <h2 id=\"概述\">概述</h2> \n <p>进入 K8s 的世界，会发现有很多方便扩展的 Interface，包括 CSI, CNI, CRI 等，将这些接口抽象出来，是为了更好的提供开放、扩展、规范等能力。</p> \n <p>K8s 持久化存储经历了从 in-tree Volume 到 CSI Plugin(out-of-tree) 的迁移，一方面是为了将 K8s 核心主干代码与 Volume 相关代码解耦，便于更好的维护；另一方面则是为了方便各大云厂商实现统一的接口，提供个性化的云存储能力，以期达到云存储生态圈的开放共赢。</p> \n <p>本文将从持久卷 PV 的 创建(Create)、附着(Attach)、分离(Detach)、挂载(Mount)、卸载(Unmount)、删除(Delete) 等核心生命周期，对 CSI 实现机制进行了解析。</p> \n <h3 id=\"相关术语\">相关术语</h3> \n <table> \n  <thead> \n   <tr> \n    <th>Term</th> \n    <th>Definition</th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td>CSI</td> \n    <td>Container Storage Interface.</td> \n   </tr> \n   <tr> \n    <td>CNI</td> \n    <td>Container Network Interface.</td> \n   </tr> \n   <tr> \n    <td>CRI</td> \n    <td>Container Runtime Interface.</td> \n   </tr> \n   <tr> \n    <td>PV</td> \n    <td>Persistent Volume.</td> \n   </tr> \n   <tr> \n    <td>PVC</td> \n    <td>Persistent Volume Claim.</td> \n   </tr> \n   <tr> \n    <td>StorageClass</td> \n    <td>Defined by provisioner(i.e. Storage Provider), to assemble Volume parameters as a resource object.</td> \n   </tr> \n   <tr> \n    <td>Volume</td> \n    <td>A unit of storage that will be made available inside of a CO-managed container, via the CSI.</td> \n   </tr> \n   <tr> \n    <td>Block Volume</td> \n    <td>A volume that will appear as a block device inside the container.</td> \n   </tr> \n   <tr> \n    <td>Mounted Volume</td> \n    <td>A volume that will be mounted using the specified file system and appear as a directory inside the container.</td> \n   </tr> \n   <tr> \n    <td>CO</td> \n    <td>Container Orchestration system, communicates with Plugins using CSI service RPCs.</td> \n   </tr> \n   <tr> \n    <td>SP</td> \n    <td>Storage Provider, the vendor of a CSI plugin implementation.</td> \n   </tr> \n   <tr> \n    <td>RPC</td> \n    <td><a href=\"https://en.wikipedia.org/wiki/Remote_procedure_call\" title=\"Remote Procedure Call\" target=\"_blank\" rel=\"noopener\">Remote Procedure Call</a>.</td> \n   </tr> \n   <tr> \n    <td>Node</td> \n    <td>A host where the user workload will be running, uniquely identifiable from the perspective of a Plugin by a node ID.</td> \n   </tr> \n   <tr> \n    <td>Plugin</td> \n    <td>Aka “plugin implementation”, a gRPC endpoint that implements the CSI Services.</td> \n   </tr> \n   <tr> \n    <td>Plugin Supervisor</td> \n    <td>Process that governs the lifecycle of a Plugin, MAY be the CO.</td> \n   </tr> \n   <tr> \n    <td>Workload</td> \n    <td>The atomic unit of \"work\" scheduled by a CO. This MAY be a container or a collection of containers.</td> \n   </tr> \n  </tbody> \n </table> \n <blockquote> \n  <p>本文及后续相关文章都基于 K8s v1.22</p> \n </blockquote> \n <h3 id=\"流程概览\">流程概览</h3> \n <p>PV 创建核心流程：</p> \n <ul> \n  <li><code>apiserver</code> 创建 Pod，根据 <code>PodSpec.Volumes</code> 创建 Volume；</li> \n  <li><code>PVController</code> 监听到 PV informer，添加相关 Annotation(如 pv.kubernetes.io/provisioned-by)，调谐实现 PVC/PV 的绑定(Bound)；</li> \n  <li>判断 <code>StorageClass.volumeBindingMode</code>：<code>WaitForFirstConsumer</code> 则等待 Pod 调度到 Node 成功后再进行 PV 创建，<code>Immediate</code> 则立即调用 PV 创建逻辑，无需等待 Pod 调度；</li> \n  <li><code>external-provisioner</code> 监听到 PV informer, 调用 RPC-CreateVolume 创建 Volume；</li> \n  <li><code>AttachDetachController</code> 将已经绑定(Bound) 成功的 PVC/PV，经过 InTreeToCSITranslator 转换器，由 CSIPlugin 内部逻辑实现 <code>VolumeAttachment</code> 资源类型的创建；</li> \n  <li><code>external-attacher</code> 监听到 VolumeAttachment informer，调用 RPC-ControllerPublishVolume 实现 AttachVolume；</li> \n  <li><code>kubelet</code> reconcile 持续调谐：通过判断 <code>controllerAttachDetachEnabled || PluginIsAttachable</code> 及当前 Volume 状态进行 AttachVolume/MountVolume，最终实现将 Volume 挂载到 Pod 指定目录中，供 Container 使用；</li> \n </ul> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211026214739606-367484326.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"从-csi-说起\">从 CSI 说起</h2> \n <p>CSI(Container Storage Interface) 是由来自 Kubernetes、Mesos、Docker 等社区 member 联合制定的一个行业标准接口规范(<a href=\"https://github.com/container-storage-interface/spec\" title=\"https://github.com/container-storage-interface/spec\" target=\"_blank\" rel=\"noopener\">https://github.com/container-storage-interface/spec</a>)，旨在将任意存储系统暴露给容器化应用程序。</p> \n <p>CSI 规范定义了存储提供商实现 CSI 兼容的 Volume Plugin 的最小操作集和部署建议。CSI 规范的主要焦点是声明 Volume Plugin 必须实现的接口。</p> \n <p>先看一下 Volume 的生命周期：</p> \n <pre><code>   CreateVolume +------------+ DeleteVolume\n +-------------&gt;|  CREATED   +--------------+\n |              +---+----^---+              |\n |       Controller |    | Controller       v\n+++         Publish |    | Unpublish       +++\n|X|          Volume |    | Volume          | |\n+-+             +---v----+---+             +-+\n                | NODE_READY |\n                +---+----^---+\n               Node |    | Node\n              Stage |    | Unstage\n             Volume |    | Volume\n                +---v----+---+\n                |  VOL_READY |\n                +---+----^---+\n               Node |    | Node\n            Publish |    | Unpublish\n             Volume |    | Volume\n                +---v----+---+\n                | PUBLISHED  |\n                +------------+\n\nThe lifecycle of a dynamically provisioned volume, from\ncreation to destruction, when the Node Plugin advertises the\nSTAGE_UNSTAGE_VOLUME capability.\n</code></pre> \n <p>从 Volume 生命周期可以看到，一块持久卷要达到 Pod 可使用状态，需要经历以下阶段：</p> \n <blockquote> \n  <p>CreateVolume -&gt; ControllerPublishVolume -&gt; NodeStageVolume -&gt; NodePublishVolume</p> \n </blockquote> \n <p>而当删除 Volume 的时候，会经过如下反向阶段：</p> \n <blockquote> \n  <p>NodeUnpublishVolume -&gt; NodeUnstageVolume -&gt; ControllerUnpublishVolume -&gt; DeleteVolume</p> \n </blockquote> \n <p>上面流程的每个步骤，其实就对应了 CSI 提供的标准接口，云存储厂商只需要按标准接口实现自己的云存储插件，即可与 K8s 底层编排系统无缝衔接起来，提供多样化的云存储、备份、快照(snapshot)等能力。</p> \n <h2 id=\"多组件协同\">多组件协同</h2> \n <p>为实现具有高扩展性、out-of-tree 的持久卷管理能力，在 K8s CSI 实现中，相关协同的组件有：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211026214740033-1014116527.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"组件介绍\">组件介绍</h3> \n <ul> \n  <li>kube-controller-manager：K8s 资源控制器，主要通过 PVController, AttachDetach 实现持久卷的绑定(Bound)/解绑(Unbound)、附着(Attach)/分离(Detach)；</li> \n  <li>CSI-plugin：K8s 独立拆分出来，实现 CSI 标准规范接口的逻辑控制与调用，是整个 CSI 控制逻辑的核心枢纽；</li> \n  <li>node-driver-registrar：是一个由<strong>官方 K8s sig 小组维护的辅助容器(sidecar)</strong>，它使用 kubelet 插件注册机制向 kubelet 注册插件，需要请求 CSI 插件的 Identity 服务来获取插件信息；</li> \n  <li>external-provisioner：是一个由<strong>官方 K8s sig 小组维护的辅助容器(sidecar)</strong>，主要功能是实现持久卷的创建(Create)、删除(Delete)；</li> \n  <li>external-attacher：是一个由<strong>官方 K8s sig 小组维护的辅助容器(sidecar)</strong>，主要功能是实现持久卷的附着(Attach)、分离(Detach)；</li> \n  <li>external-snapshotter：是一个由<strong>官方 K8s sig 小组维护的辅助容器(sidecar)</strong>，主要功能是实现持久卷的快照(VolumeSnapshot)、备份恢复等能力；</li> \n  <li>external-resizer：是一个由<strong>官方 K8s sig 小组维护的辅助容器(sidecar)</strong>，主要功能是实现持久卷的弹性扩缩容，需要云厂商插件提供相应的能力；</li> \n  <li>kubelet：K8s 中运行在每个 Node 上的控制枢纽，主要功能是调谐节点上 Pod 与 Volume 的附着、挂载、监控探测上报等；</li> \n  <li>cloud-storage-provider：由各大云存储厂商基于 CSI 标准接口实现的插件，包括 Identity 身份服务、Controller 控制器服务、Node 节点服务；</li> \n </ul> \n <h3 id=\"组件通信\">组件通信</h3> \n <p>由于 CSI plugin 的代码在 K8s 中被认为是不可信的，因此 CSI Controller Server 和 External CSI SideCar、CSI Node Server 和 Kubelet 通过 Unix Socket 来通信，与云存储厂商提供的 Storage Service 通过 gRPC(HTTP/2) 通信：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211026214740345-605456697.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"rpc-调用\">RPC 调用</h2> \n <p>从 CSI 标准规范可以看到，云存储厂商想要无缝接入 K8s 容器编排系统，需要按规范实现相关接口，相关接口主要为：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211026214740681-1564930593.png\" alt=\"\" loading=\"lazy\"></p> \n <ul> \n  <li>Identity 身份服务：Node Plugin 和 Controller Plugin 都必须实现这些 RPC 集，协调 K8s 与 CSI 的版本信息，负责对外暴露这个插件的信息。</li> \n  <li>Controller 控制器服务：Controller Plugin 必须实现这些 RPC 集，创建以及管理 Volume，对应 K8s 中 attach/detach volume 操作。</li> \n  <li>Node 节点服务：Node Plugin 必须实现这些 RPC 集，将 Volume 存储卷挂载到指定目录中，对应 K8s 中的 mount/unmount volume 操作。</li> \n </ul> \n <p>相关 RPC 接口功能如下：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211026214741088-1870305761.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"创建删除-pv\">创建/删除 PV</h2> \n <p>K8s 中持久卷 PV 的创建(Create)与删除(Delete)，由 external-provisioner 组件实现，相关工程代码在：【<a href=\"https://github.com/kubernetes-csi/external-provisioner%E3%80%91\" target=\"_blank\" rel=\"noopener\">https://github.com/kubernetes-csi/external-provisioner】</a></p> \n <p>首先，通过标准的 cmd 方式获取命令行参数，执行 newController -&gt; Run() 逻辑，相关代码如下：</p> \n <pre><code class=\"language-go\">// external-provisioner/cmd/csi-provisioner/csi-provisioner.go\nmain() {\n...\n\t// 初始化控制器，实现 Volume 创建/删除接口\n\tcsiProvisioner := ctrl.NewCSIProvisioner(\n\t\tclientset,\n\t\t*operationTimeout,\n\t\tidentity,\n\t\t*volumeNamePrefix,\n\t\t*volumeNameUUIDLength,\n\t\tgrpcClient,\n\t\tsnapClient,\n\t\tprovisionerName,\n\t\tpluginCapabilities,\n\t\tcontrollerCapabilities,\n\t\t...\n\t)\n\t...\n\t// 真正的 ProvisionController，包装了上面的 CSIProvisioner\n\tprovisionController = controller.NewProvisionController(\n\t\tclientset,\n\t\tprovisionerName,\n\t\tcsiProvisioner,\n\t\tprovisionerOptions...,\n\t)\n\t...\n\trun := func(ctx context.Context) {\n\t\t...\n        // Run 运行起来\n\t\tprovisionController.Run(ctx)\n\t}\n}\n</code></pre> \n <p>接着，调用 PV 创建/删除流程：</p> \n <blockquote> \n  <p>PV 创建：runClaimWorker -&gt; syncClaimHandler -&gt; syncClaim -&gt; provisionClaimOperation -&gt; Provision -&gt; CreateVolume<br> PV 删除：runVolumeWorker -&gt; syncVolumeHandler -&gt; syncVolume -&gt; deleteVolumeOperation -&gt; Delete -&gt; DeleteVolume</p> \n </blockquote> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211026214741446-1296464632.png\" alt=\"\" loading=\"lazy\"></p> \n <p>由 sigs.k8s.io/sig-storage-lib-external-provisioner 抽象了相关接口：</p> \n <pre><code class=\"language-go\">// 通过 vendor 方式引入 sigs.k8s.io/sig-storage-lib-external-provisioner\n// external-provisioner/vendor/sigs.k8s.io/sig-storage-lib-external-provisioner/v7/controller/volume.go\ntype Provisioner interface {\n\t// 调用 PRC CreateVolume 接口实现 PV 创建\n\tProvision(context.Context, ProvisionOptions) (*v1.PersistentVolume, ProvisioningState, error)\n\t// 调用 PRC DeleteVolume 接口实现 PV 删除\n\tDelete(context.Context, *v1.PersistentVolume) error\n}\n</code></pre> \n <h2 id=\"controller-调谐\">Controller 调谐</h2> \n <blockquote> \n  <p>K8s 中与 PV 相关的控制器有 PVController、AttachDetachController。</p> \n </blockquote> \n <h3 id=\"pvcontroller\">PVController</h3> \n <p>PVController 通过在 PVC 添加相关 Annotation(如 pv.kubernetes.io/provisioned-by)，由 external-provisioner 组件负责完成对应 PV 的创建/删除，然后 PVController 监测到 PV 创建成功的状态，完成与 PVC 的绑定(Bound)，调谐(reconcile)任务完成。然后交给 AttachDetachController 控制器进行下一步逻辑处理。</p> \n <p>值得一提的是，PVController 内部通过使用 local cache，高效实现了 PVC 与 PV 的状态更新与绑定事件处理，相当于在 K8s informer 机制之外，又自己维护了一个 local store 进行 Add/Update/Delete 事件处理。</p> \n <p>首先，通过标准的 newController -&gt; Run() 逻辑：</p> \n <pre><code class=\"language-go\">// kubernetes/pkg/controller/volume/persistentvolume/pv_controller_base.go\nfunc NewController(p ControllerParameters) (*PersistentVolumeController, error) {\n\t...\n\t// 初始化 PVController\n\tcontroller := &amp;PersistentVolumeController{\n\t\tvolumes:                       newPersistentVolumeOrderedIndex(),\n\t\tclaims:                        cache.NewStore(cache.DeletionHandlingMetaNamespaceKeyFunc),\n\t\tkubeClient:                    p.KubeClient,\n\t\teventRecorder:                 eventRecorder,\n\t\trunningOperations:             goroutinemap.NewGoRoutineMap(true /* exponentialBackOffOnError */),\n\t\tcloud:                         p.Cloud,\n\t\tenableDynamicProvisioning:     p.EnableDynamicProvisioning,\n\t\tclusterName:                   p.ClusterName,\n\t\tcreateProvisionedPVRetryCount: createProvisionedPVRetryCount,\n\t\tcreateProvisionedPVInterval:   createProvisionedPVInterval,\n\t\tclaimQueue:                    workqueue.NewNamed(\"claims\"),\n\t\tvolumeQueue:                   workqueue.NewNamed(\"volumes\"),\n\t\tresyncPeriod:                  p.SyncPeriod,\n\t\toperationTimestamps:           metrics.NewOperationStartTimeCache(),\n\t}\n\t...\n\t// PV 增删改事件监听\n\tp.VolumeInformer.Informer().AddEventHandler(\n\t\tcache.ResourceEventHandlerFuncs{\n\t\t\tAddFunc:    func(obj interface{}) { controller.enqueueWork(controller.volumeQueue, obj) },\n\t\t\tUpdateFunc: func(oldObj, newObj interface{}) { controller.enqueueWork(controller.volumeQueue, newObj) },\n\t\t\tDeleteFunc: func(obj interface{}) { controller.enqueueWork(controller.volumeQueue, obj) },\n\t\t},\n\t)\n\t...\n\t// PVC 增删改事件监听\n\tp.ClaimInformer.Informer().AddEventHandler(\n\t\tcache.ResourceEventHandlerFuncs{\n\t\t\tAddFunc:    func(obj interface{}) { controller.enqueueWork(controller.claimQueue, obj) },\n\t\t\tUpdateFunc: func(oldObj, newObj interface{}) { controller.enqueueWork(controller.claimQueue, newObj) },\n\t\t\tDeleteFunc: func(obj interface{}) { controller.enqueueWork(controller.claimQueue, obj) },\n\t\t},\n\t)\n\t...\n\treturn controller, nil\n}\n</code></pre> \n <p>接着，调用 PVC/PV 绑定/解绑逻辑：</p> \n <blockquote> \n  <p>PVC/PV 绑定：claimWorker -&gt; updateClaim -&gt; syncClaim -&gt; syncBoundClaim -&gt; bind<br> PVC/PV 解绑：volumeWorker -&gt; updateVolume -&gt; syncVolume -&gt; unbindVolume</p> \n </blockquote> \n <h3 id=\"attachdetachcontroller\">AttachDetachController</h3> \n <p>AttachDetachController 将已经绑定(Bound) 成功的 PVC/PV，内部经过 InTreeToCSITranslator 转换器，实现由 in-tree 方式管理的 Volume 向 out-of-tree 方式管理的 CSI 插件模式转换。</p> \n <p>接着，由 CSIPlugin 内部逻辑实现 <code>VolumeAttachment</code> 资源类型的创建/删除，调谐(reconcile) 任务完成。然后交给 external-attacher 组件进行下一步逻辑处理。</p> \n <p>相关核心代码在 reconciler.Run() 中实现如下：</p> \n <pre><code class=\"language-go\">// kubernetes/pkg/controller/volume/attachdetach/reconciler/reconciler.go\nfunc (rc *reconciler) reconcile() {\n\n\t// 先进行 DetachVolume，确保因 Pod 重新调度到其他节点的 Volume 提前分离(Detach)\n\tfor _, attachedVolume := range rc.actualStateOfWorld.GetAttachedVolumes() {\n\t\t// 如果不在期望状态的 Volume，则调用 DetachVolume 删除 VolumeAttachment 资源对象\n\t\tif !rc.desiredStateOfWorld.VolumeExists(\n\t\t\tattachedVolume.VolumeName, attachedVolume.NodeName) {\n\t\t\t...\n\t\t\terr = rc.attacherDetacher.DetachVolume(attachedVolume.AttachedVolume, verifySafeToDetach, rc.actualStateOfWorld)\n\t\t\t...\n\t\t}\n\t}\n\t// 调用 AttachVolume 创建 VolumeAttachment 资源对象\n\trc.attachDesiredVolumes()\n\t...\n}\n</code></pre> \n <h2 id=\"附着分离-volume\">附着/分离 Volume</h2> \n <p>K8s 中持久卷 PV 的附着(Attach)与分离(Detach)，由 external-attacher 组件实现，相关工程代码在：【<a href=\"https://github.com/kubernetes-csi/external-attacher%E3%80%91\" target=\"_blank\" rel=\"noopener\">https://github.com/kubernetes-csi/external-attacher】</a></p> \n <p>external-attacher 组件观察到由上一步 AttachDetachController 创建的 VolumeAttachment 对象，如果其 .spec.Attacher 中的 Driver name 指定的是自己同一 Pod 内的 CSI Plugin，则调用 CSI Plugin 的ControllerPublish 接口进行 Volume Attach。</p> \n <p>首先，通过标准的 cmd 方式获取命令行参数，执行 newController -&gt; Run() 逻辑，相关代码如下：</p> \n <pre><code class=\"language-go\">// external-attacher/cmd/csi-attacher/main.go\nfunc main() {\n    ...\n    ctrl := controller.NewCSIAttachController(\n\t\tclientset,\n\t\tcsiAttacher,\n\t\thandler,\n\t\tfactory.Storage().V1().VolumeAttachments(),\n\t\tfactory.Core().V1().PersistentVolumes(),\n\t\tworkqueue.NewItemExponentialFailureRateLimiter(*retryIntervalStart, *retryIntervalMax),\n\t\tworkqueue.NewItemExponentialFailureRateLimiter(*retryIntervalStart, *retryIntervalMax),\n\t\tsupportsListVolumesPublishedNodes,\n\t\t*reconcileSync,\n\t)\n\n\trun := func(ctx context.Context) {\n\t\tstopCh := ctx.Done()\n\t\tfactory.Start(stopCh)\n\t\tctrl.Run(int(*workerThreads), stopCh)\n\t}\n    ...\n}\n</code></pre> \n <p>接着，调用 Volume 附着/分离逻辑：</p> \n <blockquote> \n  <p>Volume 附着(Attach)：syncVA -&gt; SyncNewOrUpdatedVolumeAttachment -&gt; syncAttach -&gt; csiAttach -&gt; Attach -&gt; ControllerPublishVolume<br> Volume 分离(Detach)：syncVA -&gt; SyncNewOrUpdatedVolumeAttachment -&gt; syncDetach -&gt; csiDetach -&gt; Detach -&gt; ControllerUnpublishVolume</p> \n </blockquote> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211026214741605-622723414.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"kubelet-挂载卸载-volume\">kubelet 挂载/卸载 Volume</h2> \n <blockquote> \n  <p>K8s 中持久卷 PV 的挂载(Mount)与卸载(Unmount)，由 kubelet 组件实现。</p> \n </blockquote> \n <p>kubelet 通过 VolumeManager 启动 reconcile loop，当观察到有新的使用 PersistentVolumeSource 为CSI 的 PV 的 Pod 调度到本节点上，于是调用 reconcile 函数进行 Attach/Detach/Mount/Unmount 相关逻辑处理。</p> \n <pre><code class=\"language-go\">// kubernetes/pkg/kubelet/volumemanager/reconciler/reconciler.go\nfunc (rc *reconciler) reconcile() {\n\t// 先进行 UnmountVolume，确保因 Pod 删除被重新 Attach 到其他 Pod 的 Volume 提前卸载(Unmount)\n\trc.unmountVolumes()\n\n\t// 接着通过判断 controllerAttachDetachEnabled || PluginIsAttachable 及当前 Volume 状态\n\t// 进行 AttachVolume / MountVolume / ExpandInUseVolume\n\trc.mountAttachVolumes()\n\n\t// 卸载(Unmount) 或分离(Detach) 不再需要(Pod 删除)的 Volume\n\trc.unmountDetachDevices()\n}\n</code></pre> \n <p>相关调用逻辑如下：</p> \n <blockquote> \n  <p>Volume 挂载(Mount)：reconcile -&gt; mountAttachVolumes -&gt; MountVolume -&gt; SetUp -&gt; SetUpAt -&gt; NodePublishVolume<br> Volume 卸载(Unmount)：reconcile -&gt; unmountVolumes -&gt; UnmountVolume -&gt; TearDown -&gt; TearDownAt -&gt; NodeUnpublishVolume</p> \n </blockquote> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211026214741802-2115570199.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"小结\">小结</h2> \n <p>本文通过分析 K8s 中持久卷 PV 的 创建(Create)、附着(Attach)、分离(Detach)、挂载(Mount)、卸载(Unmount)、删除(Delete) 等核心生命周期流程，对 CSI 实现机制进行了解析，通过源码、图文方式说明了相关流程逻辑，以期更好的理解 K8s CSI 运行流程。</p> \n <p>可以看到，K8s 以 CSI Plugin(out-of-tree) 插件方式开放存储能力，一方面是为了将 K8s 核心主干代码与 Volume 相关代码解耦，便于更好的维护；另一方面在遵从 CSI 规范接口下，便于各大云厂商根据业务需求实现相关的接口，提供个性化的云存储能力，以期达到云存储生态圈的开放共赢。</p> \n <p><em>PS: 更多内容请关注 <a href=\"https://github.com/k8s-club/k8s-club\" title=\"k8s-club\" target=\"_blank\" rel=\"noopener\">k8s-club</a></em></p> \n <h3 id=\"相关资料\">相关资料</h3> \n <ol> \n  <li><a href=\"https://github.com/container-storage-interface/spec\" title=\"CSI 规范\" target=\"_blank\" rel=\"noopener\">CSI 规范</a></li> \n  <li><a href=\"https://github.com/kubernetes/kubernetes\" title=\"Kubernetes 源码\" target=\"_blank\" rel=\"noopener\">Kubernetes 源码</a></li> \n  <li><a href=\"https://github.com/kubernetes-csi\" title=\"kubernetes-csi 源码\" target=\"_blank\" rel=\"noopener\">kubernetes-csi 源码</a></li> \n  <li><a href=\"https://github.com/kubernetes-sigs/sig-storage-lib-external-provisioner\" title=\"kubernetes-sig-storage 源码\" target=\"_blank\" rel=\"noopener\">kubernetes-sig-storage 源码</a></li> \n  <li><a href=\"https://blog.csdn.net/zhonglinzhang/article/details/89532389\" title=\"K8s CSI 概念\" target=\"_blank\" rel=\"noopener\">K8s CSI 概念</a></li> \n  <li><a href=\"https://www.cnblogs.com/yangyuliufeng/p/14360558.html\" title=\"K8s CSI 介绍\" target=\"_blank\" rel=\"noopener\">K8s CSI 介绍</a></li> \n </ol> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <pre><code>   ①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~\n\n   ②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。\n</code></pre> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211026214742111-1222013819.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"408","createTime":"2021-10-21 15:41","comment":"1","id":"15433719","title":"Clusternet v0.5.0 重磅发布： 全面解决多集群应用分发的差异化配置难题","url":"https://www.cnblogs.com/tencent-cloud-native/p/15433719.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>徐迪，腾讯云容器技术专家。<br> 汝英哲，腾讯云高级产品经理。</p> \n <h2 id=\"摘要\">摘要</h2> \n <p>在做多集群应用分发的时候，经常会遇到以下的差异化问题，比如：</p> \n <ol> \n  <li>在分发的资源上全部打上统一的标签，比如 <code>apps.my.company/deployed-by: my-platform</code>；</li> \n  <li>在分发到子集群的资源上标记集群的信息，比如 <code>apps.my.company/running-in: cluster-01</code>；</li> \n  <li>调整应用在每个集群中的副本数目、镜像名称等等，比如有一个名为 <code>my-nginx</code> （声明的副本数为 3）的 <code>Deployment</code> 应用要分发到集群 cluster-01，集群 cluster-02，集群 cluster-03 中，我希望在这三个集群的副本数目分别为 3，5，7；</li> \n  <li>在分发到集群 cluster-01 之前，调整应用在该集群中的一些配置，比如注入一个 Sidecar 容器等；</li> \n  <li>遇到某些特殊场景时，例如大促，动态扩容，应用灰度升级时，希望可以针对某个集群进行操作，变更范围小，不影响到其他集群，同时出现问题的时候，可以及时回滚，恢复到变更前的状态；</li> \n  <li>如果定义了多个差异化配置，相互之间出现冲突时，该如何解决；</li> \n </ol> \n <h2 id=\"开源-clusternet-项目简介\">开源 Clusternet 项目简介</h2> \n <p>Clusternet ( <strong>Cluster</strong> Inter<strong>net</strong> ) 是腾讯云开源的兼具多集群管理和跨集群应用编排的云原生管控项目，让使用多集群就像上网一样简单。无论你的 Kubernetes 集群是运行在公有云、私有云、混合云还是边缘云上，都拥有一致的管理/访问体验，利用 K8s API 集中部署和协调多集群的应用程序和服务。</p> \n <p>Clusternet 采用 <strong>Addon</strong> 插件的方式，方便用户一键安装、运维及集成，轻松地管理数以百万计的 Kubernetes 集群，让云计算像 Internet 一样无所不在，自由便捷。</p> \n <p>Clusternet 支持向不同集群分发和管理各种应用资源，包括原生 Kubernetes 各类资源（Deployment/StatefulSet/ConfigMap/Secret 等）、各类 CRD 资源，以及 HelmChart 应用等等。</p> \n <h2 id=\"clusternet-如何解决这些差异化配置难题\">Clusternet 如何解决这些差异化配置难题</h2> \n <p>Clusternet 在设计应用分发模型的时候，就充分考虑到了上述的那些场景，不希望引入过多的复杂设计，尽量减少用户的重复定义，做到精简化、方便配置、可扩展性强、便于变更回滚等等。</p> \n <p>如果我们将上述的差异化问题进行归纳，大致可以归纳为以下两类：</p> \n <ol> \n  <li> <p>通用化配置或者全局化配置，比如对于某些资源进行无差异化的打标签，预配置等等；</p> </li> \n  <li> <p>专属于某个集群的配置，比如更改 <code>Deployment</code> 在某集群对应的副本数，升级镜像，增加 Sidecar 容器等等；</p> </li> \n </ol> \n <p>下图是 Clusternet 的多集群应用分发模型，其中绿色的模块是需要用户去创建的，紫色的模块是 Clusternet 内部做流转的资源对象。Clusternet 提供了 kubectl 插件，可以通过 “kubectl clusternet apply” 命令来创建资源。欢迎阅读 <a href=\"https://mp.weixin.qq.com/s/4kBmo9v35pXz9ooixNrXdQ\" target=\"_blank\" rel=\"noopener\">Clusternet - 新一代开源多集群管理与应用治理项目</a>，了解图中的相关概念。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211021154054810-757436769.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>Clusternet 资源分发模型采用松耦合的设计，用户无须更改或重新编写已有的资源对象，仅需要额外定义分发策略 （<code>Subscription</code>）和差异化配置（<code>Localization</code>/<code>Globalization</code>）即可实现多集群的应用分发。</p> \n <h3 id=\"localization-与-globalization\">Localization 与 Globalization</h3> \n <p>在 Clusternet 中，每个注册的集群，都会拥有一个专属的 namespace (命名空间)，因此我们分别定义了 <code>Localization</code> 和 <code>Globalization</code> 这两个 CRD 用于声明差异化配置。其中 <code>Localization</code> 描述 namespace-scoped （命名空间作用域）的差异化配置策略，可用于对单个集群进行配置，比如 <code>Deployment</code> 在这个集群中的副本数目等。而 <code>Globalization</code> 描述 cluster-scoped （集群作用域） 的差异化配置策略，比如修改某个 <code>HelmChart</code> 的通用配置等。</p> \n <h3 id=\"override-策略\">Override 策略</h3> \n <p>Clusternet 还提供了两种 Overide 策略：<code>ApplyLater</code>（默认的策略）和 <code>ApplyNow</code>。<code>ApplyLater</code> 意味着该 <code>Localization</code>/<code>Globalization</code> 的差异化配置不会立即应用到资源上，只会在随后新创建出来的 <code>Description</code> 对象或者 <code>HelmChart</code>/<code>Subscription</code>/<code>Description</code> 等各个资源对象更新的时候才生效。而 <code>ApplyNow</code> 意味着会创建后即时生效，Clusternet 会将定义的差异化配置应用到所有匹配的对象中，即时下发到对应的子集群中。</p> \n <h3 id=\"priority-优先级\">Priority 优先级</h3> \n <p>此外，两者均支持按照 <strong>Priority</strong>（优先级）进行管理和配置，优先级的高低通过 0-1000 的数值来定义，值越小，优先级越低，默认是500。在进行差异化渲染的时候，Clusternet 会按照 <code>Globalization</code> (低优先级) -&gt; <code>Globalization</code> (高优先级) -&gt; <code>Localization</code> (低优先级) -&gt; <code>Localization</code> (高优先级) 的次序，依次将声明的 Override 进行 apply。</p> \n <p>正是借助于这种<strong>两阶段基于优先级</strong>（<strong>two-stage priority based</strong>）的差异化配置能力，Clusternet 可以很方便地支持面向多集群的蓝绿发布、金丝雀发布、版本升级等场景。在使用过程中， 你可以定义多个 <code>Globalization</code> 和 <code>Localization</code> 对象，并设置不同的优先级策略。</p> \n <h3 id=\"支持-patch-操作\">支持 Patch 操作</h3> \n <p>Clusternet 支持两种格式的 Override，<code>JSON Patch</code> (<a href=\"https://tools.ietf.org/html/rfc6902\" title=\"RFC 6902\" target=\"_blank\" rel=\"noopener\">RFC 6902</a>) 和 <code>JSON Merge Patch</code> (<a href=\"https://tools.ietf.org/html/rfc7386\" title=\"RFC 7396\" target=\"_blank\" rel=\"noopener\">RFC 7396</a>)。有关 JSON patch 和 JSON 合并 patch 的比较，大家可以查看 <a href=\"https://erosb.github.io/post/json-patch-vs-merge-patch/\" title=\"JSON Patch 和 JSON Merge Patch\" target=\"_blank\" rel=\"noopener\">JSON Patch 和 JSON Merge Patch</a>，也可以参照如下的典型示例。</p> \n <h2 id=\"典型示例\">典型示例</h2> \n <p>下面我们来看几个典型的差异化配置场景。在如下的例子中，我们通过 <code>Localization</code> 对象来统一展示。这里使用 <code>Globalization</code> 也是可以的，这两者的 Spec 定义都是一样的，唯一的区别这两者的作用域和优先级差别。大家在实际使用的时候，可以根据需要进行改写。</p> \n <h3 id=\"增加更新标签\">增加/更新标签</h3> \n <p>如果我们想给某个对象增加或者更新标签，可以这么定义如下的 <code>Localization</code> 对象。在使用的时候，请将 <code>metadata.namespace</code> 的值替换为真实的注册集群的专属 namespace。</p> \n <pre><code>apiVersion: apps.clusternet.io/v1alpha1\nkind: Localization\nmetadata:\n  name: nginx-local-overrides-demo-label\n  namespace: clusternet-5l82l # 请更新这个值为对应集群的 namespace\nspec:\n  overridePolicy: ApplyLater\n  # 优先级反映着该对象的重要性，数值范围从 0 到 1000，值越小表示优先级越低\n  # 默认的值为 500.\n  priority: 300\n  feed: # 这里表示要 override 的对象\n    apiVersion: apps/v1\n    kind: Deployment\n    name: my-nginx\n    namespace: foo\n  overrides: # 这里可以定义着多个 override\n    - name: add-update-labels\n      type: MergePatch # 这里需要指定 override 的类型\n      # value 可以是 yaml 格式，也可以是 json 格式。\n      # 如下是 json 格式的例子\n      value: '{\"metadata\":{\"labels\":{\"deployed-in-cluster\":\"clusternet-5l82l\"}}}'\n</code></pre> \n <p>可以在一个 <code>Localization</code> 对象中定义多个 overrides，在上面的例子中，我们只定义了一个名为 <code>add-update-labels</code> 的 override，其值为 json 格式的字符串，目的是增加或者更新一个标签 <code>deployed-in-cluster: clusternet-5l82l</code> 到 <code>spec.feed</code> 所定义的对象中。</p> \n <p>这里 override 的值也可以 yaml 格式，见如下的例子。</p> \n <pre><code>apiVersion: apps.clusternet.io/v1alpha1\nkind: Localization\nmetadata:\n  name: nginx-local-overrides-demo-label\n  namespace: clusternet-5l82l # 请更新这个值为对应集群的 namespace\nspec:\n  overridePolicy: ApplyLater\n  # 优先级反映着该对象的重要性，数值范围从 0 到 1000，值越小表示优先级越低\n  # 默认的值为 500.\n  priority: 300\n  feed: # 这里表示要 override 的对象\n    apiVersion: apps/v1\n    kind: Deployment\n    name: my-nginx\n    namespace: foo\n  overrides: # 这里定义着 override value\n    - name: add-update-labels\n      type: MergePatch\n      # value 可以是 yaml 格式，也可以是 json 格式。\n      # 如下是 yaml 格式的例子\n      value: |-\n        metadata:\n          labels:\n            deployed-in-cluster: clusternet-5l82l\n</code></pre> \n <h3 id=\"替换镜像及副本数目\">替换镜像及副本数目</h3> \n <p>Override 的类型也可以指定为 <code>JSONPatch</code>。在实际使用的时候，可以根据需要选择一个合适的 override 类型即可。</p> \n <p>通过如下的例子，可以将 Deployment <code>foo/my-nginx</code> 在 <code>clusternet-5l82l</code> 子集群中的副本数更改为 <strong>3</strong>，替换容器的镜像为 <code>nginx:1.14.0-alpine</code>，并增加一个新的注释 <code>foo: bar</code>。</p> \n <pre><code>apiVersion: apps.clusternet.io/v1alpha1\nkind: Localization\nmetadata:\n  name: nginx-local-overrides-demo-image-replicas\n  namespace: clusternet-5l82l # 请更新这个值为对应集群的 namespace\nspec:\n  overridePolicy: ApplyLater\n  # 优先级反映着该对象的重要性，数值范围从 0 到 1000，值越小表示优先级越低\n  # 默认的值为 500.\n  priority: 400\n  feed: # 这里表示要 override 的对象\n    apiVersion: apps/v1\n    kind: Deployment\n    name: my-nginx\n    namespace: foo\n  overrides: # 这里定义着 override value\n    - name: scale-and-add-annotations\n      type: JSONPatch\n      # value 可以是 yaml 格式，也可以是 json 格式。\n      value: |-\n        - path: /spec/replicas\n          value: 3\n          op: replace\n        - path: \"/spec/template/spec/containers/0/image\"\n          value: \"nginx:1.14.0-alpine\"\n          op: replace\n        - path: /metadata/annotations\n          value:\n            foo: bar\n          op: add\n</code></pre> \n <h3 id=\"注入-sidecar-容器\">注入 Sidecar 容器</h3> \n <p>我们还可以通过 <code>Localization</code> 来为 Deployment <code>foo/my-nginx</code> 在 <code>clusternet-5l82l</code> 子集群下的实例注入 Sidecar 容器，见如下的示例，</p> \n <pre><code>apiVersion: apps.clusternet.io/v1alpha1\nkind: Localization\nmetadata:\n  name: nginx-local-overrides-demo-sidecar\n  namespace: clusternet-5l82l # 请更新这个值为对应集群的 namespace\nspec:\n  overridePolicy: ApplyLater\n  # 优先级反映着该对象的重要性，数值范围从 0 到 1000，值越小表示优先级越低\n  # 默认的值为 500.\n  priority: 600\n  feed: # 这里表示要 override 的对象\n    apiVersion: apps/v1\n    kind: Deployment\n    name: my-nginx\n    namespace: foo\n  overrides: # 这里定义着 override value\n    - name: inject-new-container\n      type: JSONPatch\n      # value 可以是 yaml 格式，也可以是 json 格式。\n      value: |-\n        - op: add\n          path: \"/spec/template/spec/containers/1\"\n          value:\n            name: \"redis-container\"\n            image: \"redis:6.2.5\"\n</code></pre> \n <p>通过 <code>Localization</code> 和 <code>Globalization</code> 不仅仅可以做如上的差异化配置，还有更多的场景等待着大家去发掘。</p> \n <p>为了方便大家上手体验一番，Clusternet 提供了<a href=\"https://github.com/clusternet/clusternet/tree/main/examples/applications\" title=\"例子\" target=\"_blank\" rel=\"noopener\">例子</a>，大家可以参照 <a href=\"https://github.com/clusternet/clusternet#deploying-applications-to-multiple-clusters\" title=\"README 中的步骤\" target=\"_blank\" rel=\"noopener\">README 中的步骤</a>来实践一下多集群的应用分发。</p> \n <h2 id=\"加入我们\">加入我们</h2> \n <p>Clusternet 项目开源进行时，请关注 <a href=\"https://github.com/clusternet/clusternet\" target=\"_blank\" rel=\"noopener\">https://github.com/clusternet/clusternet</a> 点赞支持，欢迎加入我们一起贡献更多的功能。</p> \n <h2 id=\"相关链接\">相关链接</h2> \n <p>[1] <a href=\"https://github.com/clusternet/clusternet\" target=\"_blank\" rel=\"noopener\">https://github.com/clusternet/clusternet</a></p> \n <p>[2] <a href=\"https://github.com/clusternet/kubectl-clusternet\" target=\"_blank\" rel=\"noopener\">https://github.com/clusternet/kubectl-clusternet</a></p> \n <p>[3] <a href=\"https://krew.sigs.k8s.io/plugins/\" target=\"_blank\" rel=\"noopener\">https://krew.sigs.k8s.io/plugins/</a></p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <pre><code>①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~\n\n②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。\n</code></pre> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211021154055234-335649561.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"209","createTime":"2021-10-20 11:18","comment":"0","id":"15428136","title":"宙斯盾 DDoS 防护系统“降本增效”的云原生实践","url":"https://www.cnblogs.com/tencent-cloud-native/p/15428136.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>tomdu，腾讯云高级工程师，主要负责宙斯盾安全防护系统管控中心架构设计和后台开发工作。</p> \n <h2 id=\"导语\">导语</h2> \n <p>宙斯盾 DDoS 防护系统作为公司级网络安全产品，为各类业务提供专业可靠的 DDoS/CC 攻击防护。在黑客攻防对抗日益激烈的环境下， DDoS 对抗不仅需要“降本”还需要“增效”。随着云原生的普及，宙斯盾团队持续投入云原生架构改造和优化，以提升系统的处理能力及效率。本文主要介绍宙斯盾防护调度平台上云过程实践与思考。</p> \n <h2 id=\"为什么上云\">为什么上云？</h2> \n <p>云原生作为近年来相当热门的概念，无论在公司内各部门，还是公司外各大同行友商，都受到追捧。云原生涉及技术包括容器、微服务、 DevOps 、持续交付等，这些新的技术和理念能带来哪些收益？在我们看来，</p> \n <h3 id=\"资源共享动态扩缩容降本\">资源共享，动态扩缩容——“降本”</h3> \n <p>以宙斯盾防护调度平台为例，因为以前申请的物理机资源还在服役期，所以当前大部分后台服务还是运行在物理机。申请时会适当预留 buffer （资源消耗跟外部攻击威胁有关，波峰波谷相差可达十倍）。这部分 buffer 虽然作为 backup ，但同时大部分时间处于空闲状态，物理机也不便于跨系统、项目共享。在资源上云阶段， CVM 已经对物理机做了虚拟化，一定程度上实现资源共享。随着容器化管理平台的出现，资源控制粒度更细。例如在 TKE 平台上，一个容器分配的资源可以精确到0.1核 CPU 、1 MB 内存，根据负载随时扩缩容。同时所有资源作为一个大池子来共享，减少资源浪费。</p> \n <h3 id=\"容器化管理快速部署增效\">容器化管理，快速部署——“增效”</h3> \n <p>要提升迭代速度，除了开发环节，测试、发布、运维都需要做优化。原来物理机部署时，需要运维同学手工或者通过专门的运维发布平台来完成发布，期间还可能因为机器环境的差异出现发布失败或者异常，需要人工处理。现在通过容器化部署，可以保证服务的运行环境一致性，避免“雪花服务器”。同时借助容器管理平台，可以实现一键发布、快速扩缩容，通用的容器容灾策略为服务的稳定性提供了基本保证。</p> \n <h2 id=\"怎么上云\">怎么上云？</h2> \n <h3 id=\"当前架构\">当前架构</h3> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211020111757927-1996542398.png\" alt=\"\" loading=\"lazy\"></p> \n <p>如上图所示， DDoS 防护流程包括攻击检测（发现攻击）和攻击防护（攻击流量清洗及正常流量回源）。</p> \n <p>在这个过程中，还需要一个主控“大脑”来协调检测系统和防护系统，以实现全流程的自动化处理——这个“大脑”就是防护调度平台。在检测到 DDoS/CC 攻击时，防护调度平台会自动化决策需要调用的防护设备机房、数量、以及需要下发的防护策略，遇上强对抗时还需要实时调整防护设备上的防护策略，其重要程度可见一斑。</p> \n <p>当前防护调度平台整体架构如下图所示。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211020111758193-1805438041.png\" alt=\"\" loading=\"lazy\"></p> \n <ul> \n  <li>防护设备：分为 ADS （ Anti-DDoS System ）、 HTTP CC 、 HTTPS CC 三大类，结合多年来团队在 DDoS/CC 攻防对抗上的积累，分别集成了各种协议/场景下的自研防护算法。防护设备部署在全球各地机房入口，在触发攻击告警后牵引并清洗攻击流量，然后回源。其上部署有管控 agent ，负责与后台通信、并管理防护设备。</li> \n  <li>接入层：多点接入，内网、公网接入。管控 agent 启动后随机选择一个可用接入进行 TCP 连接。</li> \n  <li>后台服务：多主/主备部署，向接入注册心跳，所有后台请求通过接入分发、负载均衡，所有 agent 请求通过接入转发。</li> \n </ul> \n <p>如果按照当前架构直接部署到 TKE 上，系统是可以运行起来，但是由于机器部署和容器部署的特性不同，直接部署总会有些冲突、别扭的地方。考虑方案时，我们觉得当前架构不适应 TKE 部署的主要地方有：</p> \n <ul> \n  <li>服务发现：后台服务根据预配置的接入 IP 列表注册心跳，容器化部署后 IP 切换频繁，通过配置的方式加载接入已经不适用。</li> \n  <li>无状态：容器化部署可以做到根据负载快速扩容，但需要服务做到完全无状态才能达到完全水平扩展。当前多主部署的服务都是无状态的，可以直接迁移，但主备部署的服务则需要改造。</li> \n  <li>配置管理：当前按机器维度管理，与运行环境相关/无关的配置混在一起。</li> \n </ul> \n <p>同时，借着这次上云的机会，我们也希望对系统架构做一次大的优化，接入公司成熟的公共服务如北极星名字服务、七彩石配置中心、智研，提升研效。</p> \n <h3 id=\"上云架构\">上云架构</h3> \n <p>基于当前架构，除了把服务做镜像打包、迁移到 TKE 上部署，同时对不适应的地方做改造、优化。改造后的大致架构及流程如下：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211020111758480-951035949.png\" alt=\"\" loading=\"lazy\"></p> \n <ul> \n  <li>服务发现：后台服务全部接入北极星名字服务，向北极星注册实例、定期发送心跳，接入从北极星获取各类服务健康实例来分发请求。</li> \n  <li>无状态：当前系统存在状态的场景主要有两类。 \n   <ul> \n    <li>文件下载：主要是防护设备的策略文件下载，无状态化改造涉及待下载文件在多个文件服务实例间同步。解决方案是选择使用 CFS 来同步文件。</li> \n    <li>策略分包下发：策略太大时应用层做了分包，同一请求哈希到同一后台策略服务实例。解决方案是请求中带上当前分包状态信息，任一策略服务实例可以处理且结果一致。</li> \n   </ul> </li> \n  <li>配置管理：与运行环境无关的配置，接入七彩石配置中心，保证同一类型部署的实例配置一致。</li> \n  <li>日志监控：迁移到智研日志汇、监控宝。</li> \n </ul> \n <h2 id=\"两大拦路虎\">两大“拦路虎”</h2> \n <h3 id=\"如何平滑迁移\">如何平滑迁移</h3> \n <p>当前物理机环境稳定运行，计划逐步灰度、切量到TKE环境，因此会有一段时间是物理机+ TKE 混跑的状态。管控接入、后台服务迁移 TKE ，对于防护设备 agent 是透明的。因为防护设备 agent 只会选择一个可用接入建立连接，即 agent 只会连到物理机环境或 TKE 环境，因此后台服务与 agent 交互时，混跑状态下涉及物理机环境和 TKE 环境互访的情况。这种情况 TKE 提供了灵活的配置支持。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211020111758690-451789191.png\" alt=\"\" loading=\"lazy\"></p> \n <p>在 TKE 上部署服务时，提供了两种网络模块：</p> \n <ul> \n  <li>Global Route ： VPC 内私有 IP ，无法从集群外访问，不可以注册到 CMDB 。开启随机端口映射后可从集群外访问，并可绑定 CLB 和北极星。</li> \n  <li>ENI IP ：公司内可路由 IP ，可从集群外访问，可以注册 CMDB 、 CLB 和北极星。</li> \n </ul> \n <p>在混跑灰度期间，接入部署选择 ENI IP 的方式，物理机后台服务访问 TKE 接入跟访问普通内网服务无异。迁移完成后，后台服务改用 Global Route 的方式，仅允许集群内互访。后台服务间通过原生的 service 访问，对外只通过 CLB 暴露服务。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211020111758903-1371733455.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"不断变化的-ip\">不断变化的 IP</h3> \n <p>由于 DDoS 攻防对抗的业务特性，我们长期跟 IP 打交道，对 IP 有一种特殊的情节。在内部交流中，我们发现大家在迁移 TKE 过程中都会遇到一些共性问题。其中，跟 IP 相关的问题就会经常被提及。</p> \n <p>在物理机部署环境，机器 IP 是固定的且变化频率较低（几年一次的机器裁撤）。但是在 TKE 环境，重启一次服务，分配到的容器 IP 、节点就可能变了，导致系统中依赖 IP 实现的功能无法很好适应 TKE 环境。</p> \n <h4 id=\"访问鉴权\">访问鉴权</h4> \n <p>比较简单的鉴权是基于源 IP 加白，如接口访问、 DB 访问。对于接口访问，我们定义了一套基于 JWT 的接口鉴权规范，所有对外接口不再使用源 IP 加白的方式。对于 DB 访问，当前是使用不限源的独立 DB 账号，并对权限做更细的划分（精确到表）。后续 DB 权限支持实时申请，当容器起来以后通过接口申请当前容器所在节点的访问权限。</p> \n <h4 id=\"服务发现\">服务发现</h4> \n <p>原来的架构中，管控接入层实现了简单的服务注册、服务发现功能，后台服务通过 IP 配置来注册、上报心跳。如果接入层不迁移到 TKE 、继续保持相对固定，那么这套方案还是可行的。但是，接入层迁移到 TKE 后，自身的部署节点也在不断变化，因此需要一个独立与接入、相对固定的服务注册与发现模块。集群内部署的服务可以使用 K8s / TKE 原生的 service ，对于物理机和 TKE 混跑的情况则可以考虑北极星名字服务。</p> \n <h4 id=\"服务暴露\">服务暴露</h4> \n <p>这里包含两层含义，一个是该暴露给外部的服务如何保持稳定，另一个是不该暴露给外部的服务如何隐藏起来。</p> \n <p>（1）暴露服务给外部</p> \n <p>在物理机环境，机器裁撤导致服务IP变化就是经常出现的问题，通过域名、 VIP 都可以解决。在 TKE 上，通过 CLB 来实现。</p> \n <p>（2）隐藏内部服务</p> \n <p>通过 VPC 内私有 IP ，就能保证服务无法从集群外访问，实现隔离。</p> \n <p>我们系统的最终目标是：所有对外服务通过接入层暴露出去，做好鉴权；内部的后台服务都隐藏起来，保证安全性。</p> \n <h2 id=\"上云效果\">上云效果</h2> \n <p>防护调度平台上云之后，</p> \n <p>(1)在降低成本方面，预计资源使用率可以达到50%以上。之前为了保证 DDoS 攻击峰值时能正常运行而预留的一大部分资源，闲时放到整个大资源池里共享，忙时动态扩容。</p> \n <p>(2)在部署效率方面，部署、扩容耗时从天降到分钟。原来需要运维同学专人专职完成发布，上 TKE 后只需开发同学简单配置即可完成。同时，随着业务场景的快速变化，通过 TKE 满足了我们对高防、网关、第三方云等场景的快速部署和扩容。</p> \n <p>随着公司内云上服务越来越丰富，通过上云和接入公共服务，优化宙斯盾防护调度平台的架构，从而提升系统扩展性和迭代效率。<br> 另外，宙斯盾的核心能力是 DDoS 、 CC 防护，除了管控上云，我们也正在探索防护能力虚拟化的可能性，为云上各种业务、场景提供灵活、弹性的防护能力。</p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <pre><code>   ①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~\n\n   ②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。\n</code></pre> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211020111759315-1111552681.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"379","createTime":"2021-10-18 16:28","comment":"0","id":"15421088","title":"云原生的弹性 AI 训练系列之三：借助弹性伸缩的 Jupyter Notebook，大幅提高 GPU 利用率","url":"https://www.cnblogs.com/tencent-cloud-native/p/15421088.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <blockquote> \n  <p>Jupyter Notebooks 在 Kubernetes 上部署往往需要绑定一张 GPU，而大多数时候 GPU 并没有被使用，因此利用率低下。为了解决这一问题，我们开源了 <a href=\"https://github.com/tkestack/elastic-jupyter-operator/\" title=\"elastic-jupyter-operator\" target=\"_blank\" rel=\"noopener\">elastic-jupyter-operator</a>，将占用 GPU 的 Kernel 组件单独部署，在长期空闲的情况下自动回收，释放占用的 GPU。这篇文章主要介绍了这一开源项目的使用方式以及工作原理。</p> \n </blockquote> \n <p>Jupyter Notebooks 是目前应用最为广泛的交互式开发环境，它很好地满足了数据科学、深度学习模型构建等场景的代码开发需求。不过 Jupyter Notebooks 在方便了算法工程师和数据科学家们日常开发工作的同时，也对基础架构提出了更多的挑战。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211018162759695-335894947.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"资源利用率的问题\">资源利用率的问题</h2> \n <p>最大的挑战来自于 GPU 资源利用率。在运行的过程中即使没有代码在运行，Notebook 也会长期占用着 GPU，造成 GPU 的空置等问题。在大规模部署 Jupyter 实例的场景下，一般会通过 Kubernetes 创建多个 Notebook 实例，分配给不同的算法工程师使用。而在这样的情况下，我们需要在对应的 Deployment 中事先申请 GPU，这样 GPU 会与对应的 Notebook 实例绑定，每个 Notebook 实例都会占用一张 GPU 显卡。</p> \n <p>然而同一时间，并不是所有的算法工程师都在使用 GPU。在 Jupyter 中，编辑代码的过程是不需要使用计算资源的，只有在执行 Cell 中的代码片段时，才会使用 CPU 或 GPU 等硬件资源，执行并返回结果。由此可以预见，如果通过这样的部署方式会造成相当程度的资源浪费。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211018162759961-1357777225.png\" alt=\"\" loading=\"lazy\"></p> \n <p>造成这一问题的原因主要是原生的 Jupyter Notebooks 没有很好地适配 Kubernetes。在介绍问题原因之前，先简单概述一下 Jupyter Notebook 的技术架构。如下图所示，Jupyter Notebook 主要由三部分组成，分别是用户和浏览器端，Notebook Server 和 Kernel。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211018162800223-30967986.png\" alt=\"\" loading=\"lazy\"></p> \n <p>其中用户和浏览器端是 Jupyter 的前端，主要负责展示代码和执行结果等。Notebook Server 是它的后端服务器，来自浏览器的代码执行请求会被 Notebook Server 处理，分派给 Kernel 执行。Kernel 是真正负责执行代码，返回结果。</p> \n <p>在传统的使用方式中，用户会通过 <code>jupyter notebook $CODE_PATH</code> 等命令，在本地运行 Jupyter Notebook Server，随后访问浏览器中的 Jupyter 交互式开发界面。当代码需要执行时，Notebook Server 会创建一个独立的 Kernel 进程，这一进程会使用 GPU 等运行。在 Kernel 长期空闲，没有代码需要执行时，这一进程会被终止，GPU 也就不再会被占用。</p> \n <p>而当部署在 Kuberenetes 之上后，问题就产生了。Notebook Server 和 Kernel 运行在同一个 Pod 的同一个容器下，尽管只有执行代码时才需要运行的 Kernel 组件是需要 GPU 的，而长期运行的 Notebook Server 是不需要的，但是受限于 Kubernetes 的资源管理机制，还是需要给其提前申请 GPU 资源。</p> \n <p>在 Notebook Server 的整个生命周期中，这一块 GPU 始终与 Pod 绑定。在 Kernel 进程空闲时虽然会被回收，但是已经分配给 Pod 的 GPU 卡却不能再交还给 Kubernetes 进行调度了。</p> \n <h2 id=\"解决方案\">解决方案</h2> \n <p>为了解决这一问题，我们开源了项目 <a href=\"https://github.com/tkestack/elastic-jupyter-operator/\" title=\"elastic-jupyter-operator\" target=\"_blank\" rel=\"noopener\">elastic-jupyter-operator</a>。思路非常朴素：问题源于 Notebook Server 和 Kernel 在同一个 Pod 中，导致我们无法分别为这两个组件申请计算资源。那只要将他们分开部署，让 Notebook Server 在单独的 Pod 中，Kernel 也在单独的 Pod 中，相互之间通过 ZeroMQ 通信即可。</p> \n <p>通过这样的方式，Kernel 会在空闲时被释放。在需要时会再次被临时性地申请 GPU，运行起来。为了实现这一目的，我们在 Kubernetes 中实现了 5 个 CRD，同时为 Jupyter 引入了一个新的 KernelLauncher 实现。通过它们，用户可以在 GPU 空闲时将 Kernel 回收释放，在需要执行代码时再动态地申请 GPU 资源，创建 Kernel Pod 进行代码执行。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211018162800459-728341212.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"简单的例子\">简单的例子</h3> \n <p>下面我们将通过一个例子介绍使用方式。首先我们需要创建 JupyterNotebook CR（CustomResource），这一个 CR 会创建出对应的 Notebook Server：</p> \n <pre><code>apiVersion: kubeflow.tkestack.io/v1alpha1\nkind: JupyterNotebook\nmetadata:\n  name: jupyternotebook-elastic\nspec:\n  gateway:\n    name: jupytergateway-elastic\n    namespace: default\n  auth:\n    mode: disable\n</code></pre> \n <p>其中指定了 gateway，这是另外一个 CR JupyterGateway。为了能够让 Jupyter 支持远程的 Kernel，需要这样一个网关进行请求的转发。我们同样需要创建这样一个 CR：</p> \n <pre><code>apiVersion: kubeflow.tkestack.io/v1alpha1\nkind: JupyterGateway\nmetadata:\n  name: jupytergateway-elastic\nspec:\n  cullIdleTimeout: 3600\n  image: ccr.ccs.tencentyun.com/kubeflow-oteam/enterprise-gateway:2.5.0\n</code></pre> \n <p>JupyterGateway CR 中的配置 <code>cullIdleTimeout</code> 指定了经过多久的空闲时间后，其管理的 Kernel Pod 会被系统回收释放。在例子中是 1 个小时。创建完这两个资源后，就可以体验到弹性伸缩的 Jupyter Notebook 了。如果在一个小时内一直没有使用的话，Kernel 会被回收。</p> \n <pre><code>$ kubectl apply -f ./examples/elastic/kubeflow.tkestack.io_v1alpha1_jupyternotebook.yaml\n$ kubectl apply -f ./examples/elastic/kubeflow.tkestack.io_v1alpha1_jupytergateway.yaml\n$ kubectl port-forward deploy/jupyternotebook-elastic 8888:8888\n$ kubectl get pods \nNAME                                          READY   STATUS    RESTARTS   AGE\njovyan-219cfd49-89ad-428c-8e0d-3e61e15d79a7   1/1     Running   0          170m\njupytergateway-elastic-868d8f465c-8mg44       1/1     Running   0          3h\njupyternotebook-elastic-787d94bb4b-xdwnc      1/1     Running   0          3h10m\n</code></pre> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211018162800787-70098832.png\" alt=\"\" loading=\"lazy\"></p> \n <p>除此之外，由于 Notebook 和 Kernel 解耦的设计，使得用户可以方便地修改 Kernel 的镜像与资源配额、向已经在运行的 Notebook 中添加新的 Kernel 等。</p> \n <h2 id=\"设计与实现\">设计与实现</h2> \n <p>在介绍完使用方式后，我们简单介绍其设计与实现。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211018162801019-1429237775.png\" alt=\"\" loading=\"lazy\"></p> \n <p>当用户在浏览器中选择执行代码时，首先请求会发送给在 Kubernetes 上运行的 Notebook Server。由于目前集群上没有正在运行的 Kernel，代码执行任务无法分配下去，所以 Notebook Server 会向 Gateway 发送一个创建 Kernel 的请求。Gateway 负责管理远端的 Kernel 的生命周期，它会在 Kubernetes 集群中创建对应的 JupyterKernel CR。随后会与集群中已经创建好的 Kernel 通过 ZeroMQ 进行交互，然后将代码执行的请求发送给 Kernel 进行执行，随后将结果发送给 Notebook Server 再将其返回给前端进行渲染和展示。</p> \n <p>而 Gateway 会根据在 JupyterGateway CR 中定义的有关资源回收的参数，定时检查目前管理的 Kernel 中有没有满足要求，需要被回收的实例。当 Kernel 空闲时间达到了定义的阈值时，Gateway 会删除对应的 JupyterKernel CR，将其回收，释放 GPU。</p> \n <h2 id=\"总结\">总结</h2> \n <p>目前深度学习在开发与落地生产的过程中仍然存在着诸多的挑战。elastic-jupyter-operator 瞄准了在开发过程中的 GPU 利用率与开发效率的问题，提出了一种可行的方案，将占用 GPU 的 Kernel 组件单独部署，在长期空闲的情况下自动回收，释放占用的 GPU，通过这样的方式提高资源的利用率的同时，也给予了算法工程师用户更多的灵活度。</p> \n <p>从算法工程师的角度来说，elastic-jupyter-operator 支持自定义的 Kernel，可以自行选择在 Kernel 的容器镜像中安装 Python 包或者系统依赖，不需要担心与团队内部的 Notebook 统一镜像的版本一致性问题，提高研发效率。</p> \n <p>而从运维与资源管理的角度来说，elastic-jupyter-operator 遵循了云原生的设计理念，以 5 个 CRD 的方式对外提供服务，对于已经落地 Kuerbenetes 的团队来说具有较低的运维成本。</p> \n <h2 id=\"license\">License</h2> \n <ul> \n  <li>This article is licensed under <a href=\"https://creativecommons.org/licenses/by-nc-sa/3.0/\" title=\"CC BY-NC-SA 3.0\" target=\"_blank\" rel=\"noopener\">CC BY-NC-SA 3.0</a>.</li> \n  <li>Please contact me for commercial use.</li> \n </ul> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211018162801415-1491986955.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"97","createTime":"2021-10-14 16:33","comment":"0","id":"15407284","title":"SuperEdge v0.6.0 版本正式发布","url":"https://www.cnblogs.com/tencent-cloud-native/p/15407284.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>SuperEdge 开发者团队</p> \n <p>SuperEdge 是基于原生 Kubernetes 的分布式边缘云容器管理系统，由腾讯云牵头，联合英特尔、VMware 威睿、虎牙、寒武纪、美团、首都在线等多家厂商在2020年12月共同发起的边缘计算开源项目，旨在将把 Kubernetes 强大的容器管理能力无缝的扩展到边缘计算和分布式资源管理的场景中，为边缘 IoT，边缘 AI，边缘智慧行业等赋能，推动物联网和数字化的落地。目前已经成为 CNCF Sandbox 项目，由 CNCF 基金会进行托管。</p> \n <h2 id=\"superedge-v060-版本正式发布\">SuperEdge v0.6.0 版本正式发布</h2> \n <p>SuperEdge 在2021-09-28发布了 v0.6.0 版本，具体 changelog 见：<a href=\"https://github.com/superedge/superedge/releases/tag/v0.6.0\" target=\"_blank\" rel=\"noopener\">https://github.com/superedge/superedge/releases/tag/v0.6.0</a></p> \n <p>经过社区技术讨论，本次更新主要聚焦于生产集成，让 SuperEdge 真正在用户生产环境落地，添加了本地持久化存储的支持，边缘 IoT 设备的接入，ServiceGroup 的部署状态和事件的反馈，以及对微服务使用框架 Tars、边缘应用监控数据的采集、Tengine AI 框架在 SuperEdge 使用的 Demo，具体内容如下：</p> \n <h3 id=\"集成-topolvm支持边缘本地持久化存储\">集成 TopoLVM，支持边缘本地持久化存储</h3> \n <ul> \n  <li>动态配置 PV：创建 PVC 对象时自动创建边缘节点 PV 资源；</li> \n  <li>动态扩容存储容量：可编辑 PVC 对象自动扩容 PV 的容量；</li> \n  <li>容量指标采集：可从 kubelet 中采集容量指标，进行存储容量和读写监控；</li> \n  <li>扩展调度器存储策略：TopoLVM 扩展了 Kube-scheduler，使用 CSI 拓扑功能将 Pod 调度到 LVM 卷所在节点，并且可设置存储容量调度策略；</li> \n  <li>统一管理本地存储资源：可把多个物理卷组加入 VolumeGroup 中，屏蔽了底层物理卷细节，对 Pod 统一进行存储资源分配；</li> \n </ul> \n <p>该功能使用文档见：<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211014163242152-1495853931.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"集成-edgex-foundry接入边缘-iot-设备\">集成 EdgeX Foundry，接入边缘 IoT 设备</h3> \n <ul> \n  <li>集成了原生的 EdgeX Foundry，可以一键在 SuperEdge 边缘集群 Addon EdgeX Foundry 组件，进行边缘 IoT 组件的接入；</li> \n  <li>EdgeX Foundry 各组件可选，用户可根据自己需求部署自己需要的组件，所有组件属性用户可自定义；</li> \n </ul> \n <p>该功能使用文档见：<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211014163242435-185039436.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"添加-servicegroup-部署的状态和事件反馈\">添加 ServiceGroup 部署的状态和事件反馈</h3> \n <ul> \n  <li>添加 ServiceGroup 部署的状态和失败事件的反馈，增加用户对边缘站点应用状态的掌握和运维的便利性；</li> \n  <li>DeploymentGrid 使用 templateHasher 修改后的模版作为创建对象，避免创建后的立即更新操作；</li> \n  <li>Fix ServiceGroup 中使用的 event scheme；</li> \n </ul> \n <h3 id=\"添加3个使用-demo\">添加3个使用 Demo</h3> \n <ul> \n  <li>添加在 SuperEdge 部署 Tars 的示例，帮助用户在边缘站点上使用 Tars 开发框架；</li> \n  <li>添加采集边缘应用监控数据的示例，以便用户接入边缘应用的监控，更好的掌握边缘应用的状态；</li> \n  <li>添加用 Tengine + SuperEdge 一条指令跨平台部署边缘AI应用示例，帮助用户在 SuperEdge 使用 AI 相关框架；</li> \n </ul> \n <p>Demo 用例使用文档：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211014163242658-369138748.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"携手社区\">携手社区</h2> \n <p>扫描下面的二维码加入我们的交流群，共同探讨 SuperEdge、研究边缘容器技术。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211014163242890-1531056782.png\" alt=\"\" loading=\"lazy\"></p> \n <p>项目链接：<a href=\"https://github.com/superedge/superedge\" target=\"_blank\" rel=\"noopener\">https://github.com/superedge/superedge</a></p> \n <p>Release 链接：<a href=\"https://github.com/superedge/superedge/releases/tag/v0.6.0\" target=\"_blank\" rel=\"noopener\">https://github.com/superedge/superedge/releases/tag/v0.6.0</a></p> \n <p>变更记录：<a href=\"https://github.com/superedge/superedge/blob/main/CHANGELOG/CHANGELOG-0.6.md\" target=\"_blank\" rel=\"noopener\">https://github.com/superedge/superedge/blob/main/CHANGELOG/CHANGELOG-0.6.md</a></p> \n <p>项目文档：<a href=\"https://github.com/superedge/superedge/tree/main/docs\" target=\"_blank\" rel=\"noopener\">https://github.com/superedge/superedge/tree/main/docs</a></p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <pre><code>   ①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~\n\n   ②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。\n</code></pre> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211014163243224-641256110.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"132","createTime":"2021-10-12 10:33","comment":"0","id":"15396686","title":"天狮集团云函数实践：自定义业务逻辑实现跨境电商全球直播","url":"https://www.cnblogs.com/tencent-cloud-native/p/15396686.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <p>业务覆盖全球190多个国家和地区，服务全球用户超过4000万，业务领域横跨生物技术、健康管理、酒店旅游、教育培训、金融投资......运营这样一家跨国集团的全球化业务，需要在全球部署多少 IT 管理中心？</p> \n <p>天狮集团作为这样一家跨国公司，给出的答案是：3个。</p> \n <h2 id=\"01-一个-小目标加速实现全球直播\">01. 一个 “小目标”：加速实现全球直播</h2> \n <p>天狮的全球化业务，主要由位于天津、北京和杭州的 3 个精简的 IT 团队负责，<strong>积极通过技术创新提升业务开发效率</strong>，源源不断地为天狮在全球输出业务动力。</p> \n <p>2021 年，天狮将快速实现海内外直播服务提高为战略目标：</p> \n <ol> \n  <li> <p>将直播运用到全球电商直播带货，覆盖全球逾 190 个海外市场；</p> </li> \n  <li> <p>将直播运用到内部培训、金牌讲师、教育宣讲等领域，服务于集团的全球化协同管理；</p> </li> \n </ol> \n <p>全球直播既关系到集团的全球销售利益，也影响到集团内部的跨国运营效率。</p> \n <p><img src=\"https://main.qcloudimg.com/raw/bbf4a07cf73fa441ceaf324e9462f3d5.png\" alt=\"\" loading=\"lazy\"></p> \n <p>（天狮直播需求数据流）</p> \n <p>天狮全球直播的特点与需求：</p> \n <h3 id=\"自定义业务逻辑\">自定义业务逻辑</h3> \n <p>集团内部全员大会的实时直播，需要使用专业设备推 中文、西班牙语、印尼语、俄语、法语、英语等多语言视频流， 且内容需要在全球 190 多个国家和地区进行直播和转播。</p> \n <h3 id=\"服务器成本\">服务器成本</h3> \n <p>全球不定期的电商运营活动，单独设立服务器的成本高，底层服务部署周期长。</p> \n <h3 id=\"并发不可控\">并发不可控</h3> \n <p>跨境电商的出口国家时区不同，对于集团总部在国内的公司来讲，难以根据全球时区进行 24 小时不间断的运维管理。</p> \n <p><img src=\"https://main.qcloudimg.com/raw/f0560ed8408b73b70bbd42c5bef167cd.png\" alt=\"\" loading=\"lazy\"></p> \n <p>（天狮 Serverless 云函数直播架构图）</p> \n <h2 id=\"02云函数在线视频转推\">02.云函数在线视频转推</h2> \n <p>将主播的录播视频或者 RTMP 直播流推送到实时音视频 TRTC 房间进行直播，同时选择使用 Redis 开启推流直播的实时记录，由 API 网关将进度实时写入 Redis。天狮集团的完整直播流程包括直播推流、转码、录制、鉴黄、CDN 旁路加速等综合功能，通过腾讯云 Serverless 云函数远程调用函数服务快速构建，实现回放视频直播服务，缩短开发周期。</p> \n <p>性能提升：1 秒可弹 1000+ 实例；</p> \n <p>稳定性提升：可用性 99.99；</p> \n <p>网络质量提升：全组件内网互访，延迟小于 5ms；</p> \n <p>成本优化：引入云函数异步 Invoke API，节省消息队列费用；</p> \n <p>云函数的可编程性，可以基于不同的编程语言（Python / Node / PHP / Java / Go），撰写<strong>自定义业务逻辑</strong>，整合其他云服务及第三方服务，<strong>扩展业务边界，高效创新玩法</strong>。在天狮全球直播服务中，通过腾讯云 TRTC 音视频服务、SCF 云函数、IM 即时通讯、VOD 云直播、云存储等相关服务，整合对接第三方的实时语音识别和 AI 文本翻译，实现海外直播字幕翻译功能，解决全球电商直播带货、全球会议转播和实时互动的需求，达成集团战略目标。</p> \n <p><img src=\"https://i.loli.net/2021/10/11/zuVevnp1wUcqoOP.png\" alt=\"\" loading=\"lazy\"></p> \n <p>（天狮全球会议、电商直播 业务实现效果图）</p> \n <h3 id=\"自定义业务逻辑-1\">自定义业务逻辑</h3> \n <p>对接第三方的实时语音识别和 AI 文本翻译，实现海外直播多语种字幕的翻译功能。</p> \n <h3 id=\"主播端\">主播端</h3> \n <p>专业设备推流，一路视频流同时满足多个 App 直播互动；针对电商的销售属性，主播端保障商品上架、互动连麦等助销功能使用顺畅。</p> \n <h3 id=\"海量并发处理\">海量并发处理</h3> \n <p>每秒最高支持10万并发请求数，面对直播过程中不可控的突发流量，高并发承载能力稳定支撑密集的业务峰值。</p> \n <h3 id=\"流媒体处理\">流媒体处理</h3> \n <p>采用流式拉取源视频文件，流式上传转码文件的工作方式，搭配对象存储，一键构建自动化转码流程；直播过程中，对直播内容进行录制截图以满足回播和违规内容审查需求。</p> \n <p><strong>“持续保持技术创新，用技术赋能市场，以更快更好的项目交付成果达成集团战略目标。”</strong></p> \n <p><strong>——天狮集团高级经理 鱼箴。</strong></p> \n <h2 id=\"03电商业务中云函数典型应用场景\">03.电商业务中云函数典型应用场景</h2> \n <h3 id=\"1-电商直播等-cpu-密集型业务\">1. 电商直播等 CPU 密集型业务</h3> \n <p>直播带货已成为线上电商平台的标配功能。电商直播中，需要专业、稳定的直播推流、转码、分发、播放等服务，满足超低延迟、超高画质、超大并发访问量的要求。在直播结束后，通常需要对回播视频进行处理，例如音视频转码和混流、回播视频二次分发和存储等。相较于自建转码服务器，云函数 SCF 无需考虑转码服务器闲置时间的利用效率、以及服务器运维等问题。</p> \n <p><img src=\"https://main.qcloudimg.com/raw/27e10796818dd211b2b85c6950e1a33b.png\" alt=\"\" loading=\"lazy\"></p> \n <p>（云函数电商直播方案）</p> \n <h4 id=\"平滑迁移快速上线\">平滑迁移快速上线</h4> \n <p>支持用户自定义配置 FFmpeg 命令参数、以及部署自建 FFmpeg，转码方式灵活，也可以便捷地从物理机、云主机或容器中移植到云函数。</p> \n <h4 id=\"解决算力瓶颈\">解决算力瓶颈</h4> \n <p>大规格实例最高支持 128GB/64C 进行 4K 高清视频转码，结合资源弹性伸缩能力，有效保证转码效率。</p> \n <h4 id=\"按量计费成本优势\">按量计费成本优势</h4> \n <p>视频转码是高运算负荷的 CPU 密集型业务，需要对输入的视频流进行全解码、视频过滤/图像处理、并对输出格式进行全编码。云函数的 1 毫秒粒度按用量计费，拥有显著的成本优势。</p> \n <h3 id=\"2-电商大促等波峰波谷型业务\">2. 电商大促等波峰波谷型业务</h3> \n <p>每年双11、618等电商大促期间，电商行业线上渠道面临历史级别的流量挑战，中大型电商平台的峰值调用量可达上千万 / 分钟，面临高于日常10至20倍的流量压力；日常运营活动中，例如精品秒杀、限时抢购等，电商平台也同样面临大流量高并发、波峰波谷用户流量明显分化的典型场景。云函数 SCF 提供弹性、可扩展的基础设施和护航服务，帮助电商客户把握业务增长的机遇，从容应对挑战。</p> \n <p><img src=\"https://main.qcloudimg.com/raw/f9d76762138a0b177f7710d2edb0f7b0.png\" alt=\"\" loading=\"lazy\"></p> \n <p>（电商弹性大促架构图）</p> \n <h4 id=\"瞬时冷启动\">瞬时冷启动</h4> \n <p>云函数 SCF 底层采用自研的轻量级虚拟化技术，Micro Vm 启动时间短至 90 毫秒，函数冷启动减低至 200 毫秒，并且支持上万台计算节点同时扩容。</p> \n <h4 id=\"实时扩缩容\">实时扩缩容</h4> \n <p>基于函数请求实时计算的模式，动态的扩缩函数实例，优化函数冷启动的体验问题，以及控制函数计算的资源成本 。</p> \n <h4 id=\"预置并发\">预置并发</h4> \n <p>在秒杀、抢购等场景中，瞬间需要海量的计算资源。云函数预置并发，可支持并发实例按配置预先启动，提前 “预热” 函数，为业务高峰提前准备计算资源，消除冷启动、降低运行环境初始化及业务代码初始化引起的耗时。</p> \n <h3 id=\"3-智能图片处理等事件驱动型业务\">3. 智能图片处理等事件驱动型业务</h3> \n <p>在电商平台上，每天都会有大量商品图片的查询请求和更新请求。高峰情况下，每天有千万级甚至亿级的图片处理需求。云函数 SCF 提供图片裁剪、增加水印等多种处理能力，满足电商业务的图片处理诉求。同时针对图片处理、存储的高可用要求，可以支持对象存储的跨区域高可用部署。</p> \n <p>传统方案需要搭建一个在线服务器并部署 Web 应用来进行图片处理，程序按照一定规则定时触发事件。在传统方案中，主要有三个困扰：没有请求时，空置率较高；需要专门维护一套运行处理代码；需要考虑并发和定时器的执行方法，来保障图片处理的及时性。</p> \n <p>而在 Serverless 架构中，用户仅需要在云函数 SCF 上设置触发器+函数，当用户把图片上传到对象存储中，将会触发函数代码进行图片处理，并把图片转移到新的存储桶中。整个过程，不需要搭建 Web 服务器，无需编写触发条件，也无需关注业务运维。</p> \n <p><img src=\"https://main.qcloudimg.com/raw/b8a13b2aa4999bf72370d6f24063fe5d.png\" alt=\"\" loading=\"lazy\"></p> \n <p>（云函数图像处理方案）</p> \n <p>GitHub: github.com/serverless<br> 官网: cloud.tencent.com/product/serverless-catalog</p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <pre><code>   ①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~\n   \n   ②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。</code></pre> \n</div>"}
{"read":"595","createTime":"2021-10-11 15:11","comment":"0","id":"15393481","title":"峰值利用率80%+，视频云离线转码自研上云TKE实践","url":"https://www.cnblogs.com/tencent-cloud-native/p/15393481.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>刘兆瑞，腾讯云高级研发工程师，负责腾讯明眸极速高清，画质重生等产品。专注于codec优化，画质增强等技术。</p> \n <h2 id=\"背景和问题\">背景和问题</h2> \n <p>随着流量资费的降低和带宽的增加，视频成为人们获取信息越来越重要的方式，随之而来的是云点播、视频处理等视频相关业务的飞速发展，而视频转码平台作为云点播、视频处理的基础产品，面临着高并发、高 SLA、高压缩率等等多样的需求，面临着极大的挑战。</p> \n <p>对于一般流程来说，我们面临着下面几个挑战和诉求：</p> \n <ol> \n  <li>不同的转码产品对核心数的需求不同，比如：极速高清、延时敏感的业务，需要大核心来保证复杂运算的稳定性，普通转码则可以用小核心来替代。分布式转码中的合并和切片服务则对 IO 性能，硬盘大小比较关注。</li> \n  <li>转码业务对 avx 指令集的利用率很高，因此通用 CPU 算力往往并不会成为瓶颈，avx 指令集的计算频率则成为转码业务的关注重点。而集群内 CPU 型号往往是多样的，因此合理的选择 CPU 型号对于转码业务非常重要，TKE 扩展 pod 时候需要能够选择 CPU 型号。</li> \n  <li>短期、高并发需求多：客户会用我们的能力实现不同的玩法，比如：客户需要对其全站的视频进行极速高清压缩或者画质增强，这里短期内需要能够获取到巨大的资源，并在使用过后能够快速退回节省成本。</li> \n  <li>模型、服务迭代快：云服务厂商间的竞争非常激烈，经常会有客户提出新的需求，pod 能够支持快速、无损的更新迭代版本。</li> \n </ol> \n <h2 id=\"容器化--全量上云记录\">容器化 &amp; 全量上云记录</h2> \n <h3 id=\"容器化\">容器化</h3> \n <p>这里的容器化过程，主要包括对业务的服务流程梳理，整体的发布流程规范化：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211011151121640-364391223.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"业务不同性能机型申请\">业务不同性能机型申请</h3> \n <p>迁移 TKE 之前，物理机的型号往往是固定的，固定 CPU 核数、内存、硬盘容量的搭配，而这些对于指定业务来说往往会造成资源的浪费，无法充分利用所有的资源。比如：转码业务关心 CPU 性能，对于内存的利用则很低，而物理机 48C 的机型往往搭配 64G 内存，造成一定程度的内存浪费。</p> \n <p>迁移 TKE 之后，根据不同的业务模型场景，可以精确的分配业务所需要的 CPU、内存、硬盘资源，充分利用起每一项资源。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211011151121904-227928531.png\" alt=\"\" loading=\"lazy\"></p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211011151122120-297057527.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"cpu-型号限制\">CPU 型号限制</h3> \n <p>转码业务对 avx 指令集的利用率很高，而很多型号的 CPU 虽然通用计算频率高，但是指令集被限频了，这种型号的 CPU 虽然核数多，但是编码效率很低。因此业务进行 pod 扩展时，希望能够规避剔除掉某些型号的 CPU。</p> \n <p>为了解决这一问题，TKE 支持了 CPU 亲和性配置，配置如下：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211011151122314-1727456208.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"快速扩缩容\">快速扩缩容</h3> \n <p>转码业务虽然是离线业务，但是重点客户对 SLA 还是有很高的要求。需要能更快速扩缩容，满足客户动态需求。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211011151122461-1899558024.png\" alt=\"\" loading=\"lazy\"></p> \n <p>面对这种突发的请求，TKE 可以通过动态的扩缩容满足需求，同时业务流量突发结束后，也可以快速缩容来降低使用成本。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211011151122632-881313991.png\" alt=\"\" loading=\"lazy\"></p> \n <p>当然，动态扩缩容也会带来额外的挑战。对于转码业务来说，很多任务都是长时任务，不能中断的。比如：个100+小时的视频转码，已经转了50小时+，不能因为扩缩容而中断任务，重新转码。针对这种场景，TKE 也给出了很好的解决方案，可以通过删除保护完美支持这一诉求。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211011151122802-1578498730.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"业务快速更新上线\">业务快速更新上线</h3> \n <p>云端转码服务多个云上基础产品，大量公司内外客户，需求和发布节奏都很快，每周都会有新的版本升级变更。因此能够支持快速发布，是业务的强诉求。同时，发布不能中断业务正在处理的任务，针对这一情况，TKE支持了原地升级选项，升级 POD 业务代码，不需要销毁重建 runtime 运行中容器，支持服务运行中实现热更新。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211011151122945-915887073.png\" alt=\"\" loading=\"lazy\"></p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211011151123119-193301629.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"lxcfs--固定-ip-助力任务精准调度\">lxcfs &amp; 固定 IP 助力任务精准调度</h3> \n <p>转码的业务与通用的业务请求不同，在开始转码前是无法预知当前转码请求的资源消耗量的。比如：游戏直播视频和课堂教育视频，资源的消耗量会相差一个量级。因此转码任务的调度是依赖转码机主动上报当前任务数和每个任务的负载情况，由调度根据当前的实际负载情况来分发新的任务请求。</p> \n <p>然而，通用的 pod 内进行 ps 等操作获取的是母机的负载信息，而不是当前 pod 的实际负载信息，这样会导致调度失衡。为了解决这一问题，TKE 支持 lxcfs 配置，通过 lxcfs 可以精准获取当前 pod 的实际负载信息。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211011151123281-82520246.png\" alt=\"\" loading=\"lazy\"></p> \n <p>面对上面的场景，另一个问题是如果每次 POD 重建过程都会重新申请 IP，那无疑会对调度的 IP 管理造成额外的负担。针对这种情况，TKE 也支持了固定 IP，IP 保留等能力。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211011151123477-1744897112.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"上线成果\">上线成果</h2> \n <p>视频云离线转码服务，CPU 平均利用率50%+。峰值利用率80%+. 同时，动态的扩缩容和快速上线的支持，都有效的为业务需求和流量突发保障护航。</p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：</p> \n <pre><code>   ①公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~\n   \n   ②公众号后台回复【系列】，可获得《15个系列100+篇超实用云原生原创干货合集》，包含Kubernetes 降本增效、K8s 性能优化实践、最佳实践等系列。\n</code></pre> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202110/2041406-20211011151124376-1867097063.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"429","createTime":"2021-09-29 18:02","comment":"0","id":"15353978","title":"腾讯首个CNCF沙箱开源项目","url":"https://www.cnblogs.com/tencent-cloud-native/p/15353978.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>SuperEdge开发者、腾讯云容器产品中心边缘计算团队、腾讯开源生态管理协会</p> \n <h2 id=\"superedge-进入-cncf-沙箱\">SuperEdge 进入 CNCF 沙箱</h2> \n <p>2021 年 9 月 14 日，云原生分布式边缘容器系统 SuperEdge 通过了全球顶级开源基金会 CNCF 技术监督委员会的评定<strong>正式成为 CNCF 沙箱项目</strong>。后续该项目代码、文档、官网等内容的所有权将正式转交给 CNCF 基金会进行托管。这不仅意味着 SuperEdge 得到了云原生开源社区的认可，也标志着该项目与其背后的所有商业公司完全解耦，为原生的 Kubernetes 在边缘落地迈出了重要一步。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929180211830-641549666.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>SuperEdge 是基于原生 Kubernetes 的分布式边缘云容器管理系统，由腾讯云牵头，联合英特尔、VMware 威睿、虎牙、寒武纪、美团、首都在线等多家厂商在2020年12月共同发起的边缘计算开源项目，旨在将把 Kubernetes 强大的容器管理能力无缝的扩展到边缘计算和分布式资源管理的场景中，为边缘 IoT，边缘 AI，边缘智慧行业等赋能，推动物联网和数字化的落地。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929180212452-388923629.png\" alt=\"\" loading=\"lazy\"></p> \n <p>边缘计算在云计算领域处在一个承上启下的位置。SuperEdge 项目在开源之初就联合了从硬件厂商，到边缘应用开发商、到边缘应用使用方的各类型企业，以开源治理的方式去推进 SuperEdge 的发展和边缘标准的确立。本次将项目捐赠给 CNCF 云原生计算基金会，最大程度的保障了项目的中立性，有利于全球开发者、技术社区、合作伙伴等共同参与边缘的建设，协作共赢，加速边缘技术的落地和边缘标准的建立。</p> \n <h2 id=\"superedge社区和开发者\">SuperEdge社区和开发者</h2> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929180213086-1902975577.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>自 SuperEdge 开源以来，10个月已经发布6个稳定版本，30多篇技术文章，吸引了30+ Contributors，590+ Github Star 和 137 Fork，前后有600多人参与讨论或者使用过 SuperEdge。在此感谢一下十大杰出开发者，没有你们的贡献，就不会有 SuerEdge。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929180213388-1445850033.png\" alt=\"\" loading=\"lazy\"></p> \n <p>欢迎使用SuperEdge和参与SuperEdge的开发，SuperEdge欢迎每个使用者和开发者和我们共建边缘生态。</p> \n <h2 id=\"腾讯云边缘容器产品\">腾讯云边缘容器产品</h2> \n <p>SuperEdge 来自腾讯云边缘容器产品 TKE Edge，是其边缘能力的集合。 值得一提的是自 SuperEdge 开源开始，腾讯云内部就删除了 SuperEdge 的内部仓库，商业产品公有云 TKE Edge 和私有化 TKE Edge 所有边缘能力的开发和问题修复都在 Github 的 <a href=\"https://github.com/superedge/superedge\" target=\"_blank\" rel=\"noopener\">https://github.com/superedge/superedge</a> 统一进行，无一例外。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929180213598-128282414.png\" alt=\"\" loading=\"lazy\"></p> \n <p>腾讯云 TKE Edge 是腾讯云边缘计算基础设施最重要的部分。它向下连接腾讯云 ECM、AIoT 网关、CDC、TStack、边缘设备等各种边缘基础 IaaS，对上屏蔽底层细节的复杂性，承载物联网、工业云、CDN、AI、音视频直播、云游戏等各种业务场景，涉及智慧出行、智慧城市、智慧零售、车联网、云游戏、视频直播、AR/VR、医疗保健、金融银行、工业互联网等多个行业。</p> \n <p>腾讯云物联网平台 IECP 借助 SuperEdge 连接边缘众多的边缘设备，进行云端的统一管控和运维。在物联网、设备控制、边缘推理方面落地场景较多，将腾讯云众多优秀的云边解决方案应用到了物联网和边缘设备方面。</p> \n <p>腾讯工业互联网平台 WeMake 通过 SuperEdge 将平台数据落到客户机房，实现了客户数据本地化以及低时延等需求。同时 SuperEdge 的云端管控的方案极大地提高了运维效率，为相关制造企业实现了明显的降本增效。</p> \n <p>私有化 TKE Edge 的功能已经集成到了 TKE 的企业版，由灵雀云进行专业的私有化交付和维保。在智慧安防、智慧城市、智慧交通、智慧校警、边缘 AI 等方面对外已经落地多个私有化项目。</p> \n <h2 id=\"展望未来\">展望未来</h2> \n <h3 id=\"云上\">云上：</h3> \n <p>基于和客户对边缘容器深入交流和探讨，边缘计算团队发现用户不仅对于云端管控边缘节点有需求，同时对云端管控边缘集群也有着强烈的需求。在分析用户实际的需求中，从SuperEdge 项目中又孵化出了<a href=\"https://github.com/clusternet/clusternet\" title=\" 分布式集群管理的项目Clusternet \" target=\"_blank\" rel=\"noopener\"> 分布式集群管理的项目Clusternet </a>。这两个项目相辅相成，极大的促进了腾讯云在分布式数据中心和边缘计算领域的建设。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929180213779-1658370591.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"边上\"><strong>边上：</strong></h3> \n <p>SuperEdge 最近先后推出了集群管理、节点管理、远端运维等功能，旨在让用户能够通过少量的操作即可完成边上资源的管理和运维。还有一个重大的功能即将发布，让边缘 Pod 和 Service 在边缘像在中心的 Kubernetes 一样能实现无感知访问和互访，和合作伙伴一道推出了解决方案，即将提供到 SuperEdge 供众多的开发者试用。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929180213978-513226877.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"端上\"><strong>端上：</strong></h3> \n <p>SuperEdge 已经可以一键在边缘 Kubernetes 集群上部署 Edgex Foundry， 后续还会和更多的边缘设备平台进行抽象和集成，为更通用的<strong>多平台边缘设备无缝接入</strong>而奋斗，为用户提供更简单、更通用、更有用的物联网解决方案。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929180214209-1345763761.png\" alt=\"\" loading=\"lazy\"></p> \n <p>除此之外，SuperEdge 未来将会进一步与各行业深入合作，持续建设边缘基础设施，丰富边缘落地场景。同时也会进一步探索边缘系统高可用、边缘服务网格、边缘 Serverless、应用容灾、提高系统易用性等方面的内容，为用户提供更稳定、更有用的边缘解决方案。</p> \n <p>最后，这次 SuperEdge 进入 CNCF Sandbox 是腾讯内部项目首次进入CNCF云原生计算基金会。从内部的代码开放到自主研发的技术开源，再到社区参与及代码贡献，腾讯一直的在坚定拥抱开源。</p> \n <p>目前，腾讯在 GitHub 上开源了130多个开源项目，累计 Star 超过37万，是全球开源贡献最大的科技公司之一。本次 SuperEdge 进入 CNCF Sandbox 也是对腾讯及其开发者的一种肯定，未来腾讯将会在开源的路上继续深耕，与全球开发者一起建设开源生态。</p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929180214489-1097487709.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"604","createTime":"2021-09-29 10:08","comment":"0","id":"15351484","title":"斗鱼直播云原生实践之注册中心篇","url":"https://www.cnblogs.com/tencent-cloud-native/p/15351484.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>孔令圳，斗鱼首席架构师，全面负责斗鱼全站技术架构体系规划和建设，10 余年中大型互联网产品架构经验，擅长高并发、高可用场景下的架构与方案设计。</p> \n <p>于竞，斗鱼技术保障运维专家，负责斗鱼高可用基础架构建设，擅长注册中心、监控体系等技术领域，同时也是斗鱼多活基础保障负责人。</p> \n <p>唐聪，腾讯云资深工程师，极客时间专栏《etcd 实战课》作者，etcd 活跃贡献者，主要负责腾讯云大规模 k8s/etcd 平台、有状态服务容器化、在离线混部等产品研发设计工作。</p> \n <p>陈鹏，腾讯云容器服务产品架构师，多年专注云原生领域，帮助了大量用户云原生容器化改造和生产落地，拥有丰富的一线实践经验，也发表了海量的云原生技术文章。</p> \n <h2 id=\"业务背景和痛点\">业务背景和痛点</h2> \n <p>斗鱼直播作为业界领先的游戏直播平台，每天为数以亿计的互联网用户提供优质的游戏直播观看、互动和娱乐等服务。</p> \n <p>随着近年直播市场的火热，斗鱼直播平台作为业内口碑和体验俱佳的互联网公司，用户量也出现井喷式增长。海量用户给平台带来的稳定性技术挑战也越发强烈，斗鱼的老架构如下图所示，无论是业务支撑还是架构设计，均存在一定的风险和隐患。</p> \n <h3 id=\"斗鱼老架构\">斗鱼老架构</h3> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100803495-277904826.png\" alt=\"\" loading=\"lazy\"></p> \n <p>图一 斗鱼老架构</p> \n <p>为了给用户带来更好的可用性体验，斗鱼急需解决单一数据中心的问题，将老架构从单数据中心升级到多数据中心。</p> \n <h3 id=\"多数据中心挑战\">多数据中心挑战</h3> \n <p>在实现单活升级为多活的过程中，为了确保无故障的迁移升级，我们面临一系列挑战，比如：</p> \n <p>有状态服务 etcd、zookeeper 等如何多数据中心同步？<br> 应用彼此之间存在 1 个复杂的树状或网状依赖关系，应该从哪里开始迁移？<br> 按什么维度来划分目标的边界，怎么避免业务焊死在一起，造成无从下手的局面？<br> 如果迁移后出现问题，如何快速恢复，并且不牵连已迁移成功的业务？<br> 因单活升级到多活的过程中，涉及系统众多，本文将是斗鱼直播多活改造系列的第一篇，只聚焦于注册中心模块，因此我们先和你介绍下注册中心背后的 etcd 和 zookeeper。</p> \n <h4 id=\"zketcd-承担的角色\">zk/etcd 承担的角色</h4> \n <p>dubbo 通过注册中心来解决大规模集群下的服务注册与发现问题，以下是注册中心架构图：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100803754-796316865.png\" alt=\"\" loading=\"lazy\"></p> \n <p>dubbo 默认支持 zookeeper 注册中心，虽然新版也有 etcd 实现，但该实现尚缺乏大规模投产的先例，Java 技术栈采用 etcd 作为注册中心的案例也比较罕见。</p> \n <p>当采用 zookeeper 作为 dubbo 注册中心时，其注册关系为树形结构，详细结构如下图所示：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100804095-1454645516.png\" alt=\"\" loading=\"lazy\"></p> \n <p>因为 zookeeper 是基于类似文件系统的树形结构来存储数据，但 etcd 却是采用键值对存储，二者之间的差异会给注册关系同步带来较大困难。</p> \n <p>此外，如果从 zookeeper 迁移到 etcd，则在整个迁移过程中：已有的线上服务不能受损，更不能停服；如果迁移失败，还要能回退到到 zookeeper。</p> \n <h3 id=\"同城双活与多活新架构\">同城双活与多活新架构</h3> \n <p>为了实现多活，我们通过跨数据中心的同步服务、服务依赖梳理与边界划分、可控变更等技术手段和运维理念，成功解决了以上挑战，设计了如下一套新的架构来实现多活，如下图所示：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100804400-1241807576.png\" alt=\"\" loading=\"lazy\"></p> \n <p>图二 斗鱼多活新架构</p> \n <p>在新的架构下，可以按域名甚至是 URL 来细粒度的调度流量，RPC 层面也具备了自动就近调用的能力，其中注册中心的局部架构图如下：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100804690-417339864.png\" alt=\"\" loading=\"lazy\"></p> \n <p>图三 斗鱼注册中心老架构</p> \n <h3 id=\"注册中心多活方案选型与目标\">注册中心多活方案选型与目标</h3> \n <p>在注册中心多活改造过程中，我们面临多个方案，如下表所示：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100804934-652081201.png\" alt=\"\" loading=\"lazy\"><br> <img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100805220-932965876.png\" alt=\"\" loading=\"lazy\"><br> <img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100805509-139623905.png\" alt=\"\" loading=\"lazy\"></p> \n <p>由于历史原因，我们有 zookeeper（以下简称 zk）和 etcd 这 2 套注册中心，加上我们有 Java、Go、C++、PHP 这 4 个技术栈，因此在注册中心领域仍然一些不足，希望能统一到 etcd 来解决痛点问题，并达到以下目标：</p> \n <p>降低维护成本：此前需要运维 zk+etcd 两套注册中心，更困难的是做多活解决方案时也需要适配 zk+etcd，这导致注册中心多活研发成本翻倍。由于 etcd 是 k8s 的一部分，运维 etcd 又不可避免，这是选择 etcd 的第 1 个原因。</p> \n <p>拥抱更繁荣的生态：etcd 有云原生托管解决方案，有厂商通过 etcd 管理 10K node 级别的 k8s 集群，etcd 还自带 proxy、cache、mirror 等各种周边工具，java 侧 dubbo 也支持以 etcd 作为注册中心，etcd 相对于 zk 来说发展前景更好，这是选择 etcd 的第 2 个原因。</p> \n <p>增强跨语言能力：etcd 可基于 http 或 grpc 协议通讯，并且支持长轮询，具有较强的跨语言能力。而 zk 需要引入专用客户端，除 java 客户端之外，其它语言客户端尚不成熟。而我们有 JAVA、Go、C++、PHP 等 4 种研发语言，这是选择 etcd 的第 3 个原因。</p> \n <p>基于以上原因，我们选择了方案四，方案四大新架构如下图所示:</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100805762-1683429519.png\" alt=\"\" loading=\"lazy\"></p> \n <p>图四 斗鱼注册中心新架构</p> \n <h3 id=\"注册中心多活难点与挑战\">注册中心多活难点与挑战</h3> \n <p>为了实现新注册中心，达到我们期望的设计目标，注册中心在改造过程中，面临以下难点与挑战:</p> \n <p>如何解决 zk 的多数据中心同步问题？尤其是 zookeeper watch 机制是不可靠的，可能出现丢失 watch 事件的问题？（正确性）<br> 如何解决 etcd 的多数据中心同步问题？从下面方案选型中，我们可以看到社区目前并无任何成熟、生产环境可用的解决方案。（正确性）<br> 如何解决跨数据中心读的性能问题？（性能）<br> 如何解决跨数据中心的服务稳定性问题？网络链路上，比如内网专线若中断了怎么办？同步服务设计上，是否会导致 etcd/zk 同步服务进入性能极慢的全同步逻辑，同步服务本身是否具备高可用等等？容灾测试上，我们又该如何设计测试用例验证？运维上，我们又该如何快速发现隐患、消除潜在的故障，建设可视化、灵活的多活运维系统？（稳定性、可运维性）</p> \n <h2 id=\"注册中心多活难点分析\">注册中心多活难点分析</h2> \n <h3 id=\"迁移过程中如何保证新旧服务互通\">迁移过程中如何保证新旧服务互通？</h3> \n <h4 id=\"开发--zk2etcd\">开发 zk2etcd</h4> \n <p>我们很多 java 开发的业务使用 dubbo 框架做服务治理，注册中心是 zookeeper，我们希望 java 和 go 开发的业务全部都统一使用 etcd 作为注册中心，也为跨语言调用的可能性做好铺垫。</p> \n <p>由于业务众多，改造和迁移的周期会很长，预计持续 1~2 年，在此过程中我们需要将 zookeeper 中的注册数据同步到 etcd 中，实时同步，而且要保证数据一致性以及高可用，当前市面上没有找到满足我们需求的工具，于是我们和腾讯云 TKE 团队合作开发了一个 zk2etcd 来同步实现 zookeeper 数据到 etcd，并且已将其开源，整体方案落地篇我们将详细介绍。</p> \n <h3 id=\"如何实现-etcd-异地容灾\">如何实现 etcd 异地容灾?</h3> \n <p>通过 zk2etcd 同步服务，我们成功解决了 zookeeper 数据迁移问题，使得新老业务的注册中心数据都使用 etcd 来存储。</p> \n <p>因此，etcd 的重要性不言而喻，它的可用性决定着我们的整体可用性，而斗鱼直播目前的部署架构又严重依赖某核心机房，一旦核心机房出现故障，将导致整体不可用。因此斗鱼直播下一个痛点就是提升 etcd 的可用性，期望实现 etcd 跨城容灾、异地容灾能力。</p> \n <p>斗鱼直播理想中的 etcd 跨城同步服务应该具备如下特性:</p> \n <p>etcd 跨城容灾部署后，读写性能不显著下降，能满足业务场景基本诉求。<br> 同步组件达到生产环境可用级别，具备完备的一致性检测、日志、metrics 监控等。<br> 对数据一致性要求不强的业务可就近访问同地区的 etcd 集群服务、强一致诉求业务可访问主 etcd 集群。<br> 主集群故障后，业务运维能根据一致性监控等，快速将备集群提升为主集群。<br> 那么有哪些方案呢？各个方案又有哪些优缺点呢？最终评估了如下几种方案:</p> \n <h4 id=\"单集群多地部署方案\">单集群多地部署方案</h4> \n <p>etcd 社区 make-mirror 方案<br> etcd 社区 learner 方案<br> 腾讯云 etcd-syncer 方案<br> 单集群多地部署方案<br> 单集群多地部署方案图如下：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100805963-1526478813.png\" alt=\"\" loading=\"lazy\"></p> \n <p>在此方案中，etcd Leader 节点通过 Raft 协议将数据复制到各个地域的 Follower 节点。</p> \n <p>此方案它的优点如下：</p> \n <p>各地域网络互通后，部署简单，无需运维额外组件</p> \n <p>数据跨城强一致同步，3 节点部署场景中，可容忍任一城市故障，并且不丢失任何数据</p> \n <p>介绍完它的优点后，我们再看看它的缺点，如下所示：</p> \n <p>在 3 节点部署的场景下，任意写请求至少需要两个节点应答确认，而不同节点部署在各地，ping 延时会从几毫秒上升到 30ms 左右（深圳 - 上海)，因此会导致写性能急剧下降。</p> \n <p>etcd 默认的读请求是线性读，当 Follower 节点收到 Client 发起的读请求后，它也需要向 Leader 节点获取相关信息，确认本地数据追赶上 Leader 后才能返回数据给 client，避免读取到旧数据等，在这过程中也会导致 etcd 读延时上升、吞吐量下降。</p> \n <p>跨城部署网络之间质量也较容易波动，导致服务质量抖动等。</p> \n <p>client 访问 etcd 集群的配置，为了防止单点故障，必须配置多个 etcd 节点，而这又可能导致 client 访问到异地的 etcd 节点，导致服务请求延时增大等。</p> \n <h4 id=\"etcd-社区-make-mirror-方案\">etcd 社区 make-mirror 方案</h4> \n <p>介绍完单集群多地部署方案后，我们再看看 etcd 社区提供的 make-mirror 方案，它的原理图如下：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100806442-299690765.png\" alt=\"\" loading=\"lazy\"></p> \n <p>在此方案中，我们分别在不同城市部署了一套独立的 etcd 集群，通过 etcd 社区提供的 make-mirror 工具实现跨城数据复制。</p> \n <p>make-mirror 工具原理如下：</p> \n <p>指定数据同步的前缀后，通过 etcd Range 读接口从主集群遍历此前缀下的所有数据，写入到目的 etcd。（全量同步）<br> 随后通过 etcd Watch 接口指定读请求返回的“版本号”，监听从此版本号后的所有变更事件。<br> make-mirror 收到主 etcd 集群推送的 key-value 变化事件后，通过 txn 事务接口将数据写入到热备集群。（增量同步）<br> 此方案它的优点如下：</p> \n <p>主 etcd 集群读写性能高，整体上不受跨地域网络延时、网络质量波动影响<br> 若业务可容忍短暂不一致，可就近访问距离最近的 etcd 集群<br> 若业务要求强一致，可通过内网专线访问主 etcd 集群<br> 不依赖高版本 etcd<br> 介绍完它的优点后，我们再看看它的缺点，如下所示：</p> \n <p>当写请求较大的时候，备集群可能存在一定的数据落后，可能读到脏数据。<br> 社区自带的 make-mirror 同步链路中断后，退出重启会再次进入全量同步模式，性能较差，无法满足生产环境诉求。<br> 社区自带的 make-mirror 工具缺少 leader 选举、数据一致性检测、日志、metrics 等一系列特性，不具备生产环境可用性。<br> 不支持同步非 key-value 数据，如 auth 鉴权相关数据、lease 数据等。</p> \n <h4 id=\"etcd-社区-learner-方案\">etcd 社区 learner 方案</h4> \n <p>介绍完 etcd 社区的 make-mirror 方案后，我们再看看 etcd 社区提供的 learner 方案，它的原理图如下：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100806619-830929778.png\" alt=\"\" loading=\"lazy\"></p> \n <p>它的核心原理如下：</p> \n <p>etcd raft 算法库在 2017 年的时候就已经支持了 learner 节点，详情可参考 pr 8751。<br> etcd 社区在 2019.8 月推出的 3.4 版本中，正式支持 Learner 节点，它作为非投票 (Non-Voting) 的成员节点加入集群，不参与集群选举等投票，只进行数据复制。<br> Leader 收到写请求后，将日志同步给 Follower 和 Learner 节点，并在内存中使用一个名为 Progress 的数据结构，维护 Follower 和 Learner 节点的日志同步进展信息。<br> 当 Learner 节点的数据与 Leader 数据差距较小的时候，它就可以被提升为可投票的成员节点加入集群。<br> 此方案它的优点如下：</p> \n <p>各地域网络互通后，部署简单，只需往 etcd 集群中添加一个 Learner 节点，无需运维额外组件<br> Learner 节点可同步任意类型数据，如 key-value、auth 鉴权数据、lease 数据<br> 介绍完它的优点后，我们再看看它的缺点，如下所示：</p> \n <p>Learner 节点只允许串行读，也就是业务如果就近读，会读到旧数据。<br> 依赖高版本 etcd，etcd 3.4 及以上版本才支持 Learner 特性，并且只允许一个 Learner 节点 .<br> 主集群全面故障后，无法快速将 Learner 节点提升为可写的独立 etcd 集群。<br> 介绍完已有的几种方案后，我们发现它们都无法满足业务生产环境诉求，于是我们自研完成了生产环境可用的 etcd 同步服务落地，在整体方案落地章节将详细介绍。</p> \n <h3 id=\"如何确保-etcd-和-zk-同步服务的稳定性可运维性\">如何确保 etcd 和 zk 同步服务的稳定性、可运维性?</h3> \n <p>为了确保 etcd、zk 同步服务的稳定性，模拟 5 类常见的故障，检验服务在这些典型故障场景下的自愈能力，详细测试方案如下。</p> \n <h4 id=\"故障场景\">故障场景</h4> \n <p>redis 闪断（zk2etcd 服务依赖），例如：redis 版本升级、非平滑扩容。</p> \n <p>zk2etcd 离线，例如：OOM、容器驱逐、宿主机故障。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100806847-1006340870.png\" alt=\"\" loading=\"lazy\"></p> \n <p>etcd2etcd 离线 ，例如：OOM、容器驱逐、宿主机故障</p> \n <p>网络闪断，例如：OOM、容器驱逐、宿主机故障。</p> \n <p>弱网环境，例如：专线断掉后临时用公网顶替。</p> \n <p>上述 5 种场景的实际触发原因有多种多样，只需要模拟出一种情况。</p> \n <h4 id=\"演练方案\">演练方案</h4> \n <p>redis 闪断：通过改 host 模拟 redis 不可达，此时自动订正停止；模拟 redis 恢复后，自动订正亦自动恢复。</p> \n <p>zk2etcd 离线：通过杀容器节点模拟 zk2etcd 挂掉，15 秒内 k8s 自动拉起，拉起完成后同步正常、数据一致。</p> \n <p>etcd2etcd 离线 ：通过杀容器节点模拟 zk2etcd 挂掉，15 秒内 k8s 自动拉起，拉起完成后同步正常、数据一致。</p> \n <p>网络闪断： 通过改 host 模拟 zk、etcd 不可达，此时同步中断，后去掉 host 模拟网络恢复，恢复后同步正常、数据一致。</p> \n <p>弱网环境： 通过切公网模拟弱网环境，切公网后同步效率降低在 4 倍以内，1 次全量同步仍然可在 1 分钟内完成。</p> \n <p>另外针对可运维性问题，无论是 etcd 还是 zk 同步服务，都提供了详细的 metrics、日志，我们针对各个核心场景、异常场景都配置了可视化的观测视图，并配置了告警策略。</p> \n <h2 id=\"整体方案落地\">整体方案落地</h2> \n <h3 id=\"整体架构\">整体架构</h3> \n <p>etcd 集群多活架构图如下所示:</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100807043-1905801283.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>说明</p> \n <p>黑实线：正常情况下的专线访问</p> \n <p>黑虚线：切公网方式访问</p> \n <p>红实线：etcd 集群发生主备切换后的专线访问</p> \n <p>红虚线：etcd 集群发生主备切换后的公网访问</p> \n <p>etcd2etcd/zk2etcd 数据同步服务图如下所示:</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100807552-847220575.png\" alt=\"\" loading=\"lazy\"><br> <img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100807880-518622571.jpg\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"zk同步服务工程化实践\">zk同步服务工程化实践</h3> \n <p>zookeeper 与 etcd 存储结构不一致，加大了同步的实现难度。zookeeper 存储是树状结构，而 etcd v3 是扁平结构。zookeeper 无法像 etcd 一样按照 prefix 来 list 所有 key；etcd 无法像 zookeeper 一样通过 list chilren 来查询某个目录下的子节点，也加大了实现同步的难度。</p> \n <p>如何感知 zookeeper 中的数据变化？zookeeper 的 watch 不像 etcd 一样可以简单的感知到任意 key 的新增，需要递归的 watch 所有的节点，收到 ChildrenChanged 事件后拿到该事件对应节点下的所有子节点，再与 etcd 中的数据进行比对，就可以得到新增的数据，并将其同步 put 到 etcd 中。类似的，可以用递归的方法 watch 所有节点的删除事件，并同步删除 etcd 中的数据。</p> \n <p>另外 zookeeper 的 watch 有着先天性的缺陷，watch 是一次性的，所以每次收到事件后又必须重新 watch，两次 watch 之间理论上是可能丢事件的，主要是在同一个 key 连续多次变更的时候可能会发生。如果丢事件发生就会破坏了数据一致性，我们引入了自动 diff 和订正的能力，即计算 zookeeper 和 etcd 中数据存在的差异，每次都会经过两轮 diff 计算，因为在频繁变更数据的情况下，一轮 diff 计算往往存在一些因不是强一致性同步导致的\"伪差异\"，当 diff 计算出了结果就会自动 fix 掉这些差异。</p> \n <p>如何解决与 etcd2etcd 共存？当同一个路径下，即有 etcd2etcd 同步写入的数据，又有 zk2etcd 写入的数据，在 zk2etcd 的自动订正逻辑里面，会计算出差异并订正差异，但我们不希望因此而误删 etcd2etcd 写入的数据。我们通过为 zk2etcd 引入了 redis 来存储状态解决了这个问题，在 zk2etcd 往 etcd 中同步写入或删除数据时，也同步在 redis 中记录和删除:</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100808052-210353024.png\" alt=\"\" loading=\"lazy\"></p> \n <p>然后 zk2etcd 在自动订正计算差异的时候，只考虑本工具写入过的数据，避免误删其它同步工具写入的数据。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100808215-608784022.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"etcd2etcd-工程化实践\">etcd2etcd 工程化实践</h3> \n <p>为了解决 etcd 同步难题，我们调研了如下两种方案，接下来我们就详细介绍下它的原理：</p> \n <h4 id=\"etcd-syncer-之-mirror-plus-版\">etcd-syncer 之 mirror-plus 版</h4> \n <p>首先我们介绍下 etcd-syncer 的 mirror-plus 方案，顾名思义，它是 etcd 社区 make-mirror 的加强版。为了解决 make-mirror 的各种缺陷，它实现了以下特性、优点:</p> \n <p>支持多种同步模式，全量同步、断点续传，不再担忧专线、公网网络质量抖动<br> 高可用，负责同一数据路径复制的实例支持多副本部署, 一副本故障后，其他副本将在 5 秒后获得锁，在之前实例同步的进度基础上，进行快速恢复<br> 支持一致性检查（全量数据检查、快照检查)<br> 支持多实例并发复制提升性能（不同实例负责不同的路径），建议生产环境配置多实例，每个实例负责不同路径<br> 良好的运维能力，基于 k8s deployment 一键部署，丰富的 metrics、日志，完备的 e2e 测试用例覆盖核心场景（http/https 场景，服务异常中断、网络异常等 ）<br> 那么它的缺点是什么呢？因为它核心原理依然是依赖 etcd 的 mvcc+watch 特性，因此数据无法保证强一致性和只同步 key-value 数据。</p> \n <p>断点续传依赖 mvcc 历史版本保留时间，最好业务能保存至少 1 个小时的历史数据。<br> 当写请求较大的时候，备集群可能存在一定的数据落后，可能读到脏数据。<br> 不支持同步非 key-value 数据，如 auth 鉴权相关数据、lease 数据等。</p> \n <h4 id=\"etcd-syncer-之-raft-版\">etcd-syncer 之 Raft 版</h4> \n <p>为了解决所有类型的数据同步问题以及消除对 etcd mvcc 历史数据的依赖，腾讯云还可提供基于 Raft 日志的同步方案 etcd-syncer 之 raft 版本。</p> \n <p>它的部署图如下所示,etcd-syncer 同步服务作为一个类似 learner 节点的身份，加入主 etcd 集群。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100808540-1545396188.png\" alt=\"\" loading=\"lazy\"></p> \n <p>主 etcd 集群 Leader 将 Raft 日志数据通过 MsgApp/Snapshot 等消息同步给 etcd-syncer, etcd-syncer 解析 Raft 日志，将 Raft 日志条目对应的 Txn/Delete/Auth 等请求应用到目的 etcd 集群。</p> \n <p>它具备如下优点：</p> \n <p>具备 etcd-syncer 之 mirror-plus 版本的所有特性和优点，同时不依赖 etcd mvcc 历史数据。</p> \n <p>基于 etcd 底层的 Raft 日志同步数据，可以同步 key-value、auth、lease 等各种类型的数据。</p> \n <p>不依赖高版本的 etcd。</p> \n <h3 id=\"完备的容灾测试\">完备的容灾测试</h3> \n <h4 id=\"grpc-proxy\">grpc-proxy</h4> \n <p>此方案引入了 grpc-proxy 代理服务，也是头一次使用。为了了解此代理服务的性能情况，我们使用 etcd 自带的 benchmark 进行了读和写的测试，另外手写了一个小工具做了一下 watch 测试。以下为部分测试内容。</p> \n <p>写入测试</p> \n <p>直接访问 etcd 服务的负载均衡入口</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100808736-1403776452.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>走 grpc-proxy 代理访问 etcd 服务的情况</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100808912-1322606095.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>grpc-proxy 代理在 endpoints 配置走专线或公网情况下，都能正常写入<br> 写入 key 总数一定的情况下，连接数和客户端数越大，总耗时越低<br> 写入 key 总数越大，单次写入的平均耗时（Average）会有所增加，但仍为毫秒级<br> 当一次写入 key 总数为 10 万时，直连 etcdserver 会出现 too many requests 的报错，但 grpc-proxy 没有<br> 公网情况比专线性能有所下降<br> 走 grpc-proxy 代理的平均耗时相比直连有所增加，但满足需求<br> 读取测试</p> \n <p>直接访问 etcd 服务的负载均衡入口</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100809151-2069486569.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>走 grpc-proxy 代理访问 etcd 服务的情况</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100809408-1407683799.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>grpc-proxy 代理在 endpoints 配置走专线或公网情况下，都能正常读取</p> \n <p>走 grpc-proxy 代理的平均耗时相比直连有所增加，但在可接受范围</p> \n <h4 id=\"watch-测试\">watch 测试</h4> \n <p>根据我们自己写的一个 etcdwatcher 服务对 grpc-proxy 进行 watch 测试：可以设置总 watcher 数量，更新频率，以及测试时间，结束时打印出简报</p> \n <p>./etcdwatch -num=100 -span=500 -duration=10 -endpoint=http://grpc-proxy-addr:23791<br> test done<br> total 100 task<br> 0 task failed<br> current revision is 631490<br> least revision is 631490<br> 0 task is not synced</p> \n <h4 id=\"参数说明\">参数说明：</h4> \n <p>num 任务数量</p> \n <p>span 更新间隔，单位毫秒</p> \n <p>duration 总测试时间，单位秒</p> \n <p>current revision：代表写入的 revision</p> \n <p>least revision：表示 num 个任务中同步最慢的 revision</p> \n <p>failed 为 0 说明正常；如果过出现 task not sync 说明 watch 和 put 不同步</p> \n <p>以上测试结果来看：failed 数为 0，watch 测试正常</p> \n <h4 id=\"zk2etcd\">zk2etcd</h4> \n <p>我们使用的是 1.2.5 版本，通过 k8s 的 deployment 方式部署</p> \n <h4 id=\"模拟-zk-server-失联\">模拟 zk server 失联</h4> \n <p>场景<br> 通过将 hosts 中注入错误解析地址</p> \n <p>现象<br> 期间没有发现 zk 失联的报错日志<br> 监控指标没有发现异常<br> 此后执行重启，fixed 操作数没有出现凸增情况（在 1.2.4 版本中，存在 full sync 虽然在定时执行，但是并没有感知到需要 fix 的 key 的 bug。导致重启 zk2etcd 服务实例后，可能观察到 fixed 操作凸增的现象）<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100809621-939988543.png\" alt=\"\" loading=\"lazy\"></p> \n <h4 id=\"模拟-redis-失联\">模拟 redis 失联</h4> \n <p>模拟操作<br> 09:56:49 将 hosts 中注入 redis 错误解析地址<br> 10:07:34 恢复 redis<br> 10:16:00 重启同步服务 pod（操作重启是为了观察 full sync 是否正常）<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100809825-1281378550.png\" alt=\"\" loading=\"lazy\"></p> \n <p>现象<br> 期间 fixed operation 数量没有增长，其他监控指标未发现明显异常<br> 实例重启后没有出现 fixed 数凸增的情况</p> \n <h4 id=\"模拟etcd失联\">模拟etcd失联</h4> \n <p>模拟操作<br> 16:15:10 etcd server 失联</p> \n <p>16:30 恢复</p> \n <p>16:45 重启 pod</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100810013-1416586325.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>现象<br> 期间 fixed operation 数量没有增长，其他监控指标未发现明显异常</p> \n <p>此后重启，fixed operation 数量有所增涨（不能确定是 full sync 未生效，还是重启后刚好有更新修复导致）</p> \n <p>总结</p> \n <p>只要 full sync 机制工作正常，各异常场景发生后，都能在下一个 full sync 触发后被恢复</p> \n <p>恢复的最小时间间隔取决于设置的 full sync 定时执行间隔时间（默认为 5m），业务对此间隔时间容忍情况自行调整参数</p> \n <p>此外，为了避免异常发生后，full sync 机制定时运行但也没能感知到情况发生，保险起见事后可以第一时间重启一下 zk2etcd 服务</p> \n <p>对于追加的 etcd 公网测试，full sync completed 和 zk、etcd 操作耗时，相比内网情况有一定（秒级）增长</p> \n <h4 id=\"etcd2etcd\">etcd2etcd</h4> \n <p>etcd2etcd 的同步服务，我采用 deployment 双副本部署</p> \n <p>多副本 backup 能力</p> \n <p>期望<br> ⼯作节点故障后备⽤节点会在 5s 后接管同步任务</p> \n <p>测试方案<br> etcd syncer 双实例部署</p> \n <p>杀掉正在运行的工作节点进行观察</p> \n <p>结论<br> 不论是增量同步还是全量同步过程中，主备切换都能正常工作（需要注意的是，当全量同步中发生主备切换后会变为增量同步，从而可能导致比对较慢）</p> \n <p>断点续传能力</p> \n <p>期望<br> 故障恢复后能从断点继续开始同步</p> \n <p>其实在第 1 部分，备节点切换为主后接管同步工作，fast_path 变为 1 也证明了断点续传能力，我们还额外补充几个验证场景：</p> \n <p>(a) 短时间故障</p> \n <p>故障场景</p> \n <p>中心 etcd 集群到热备集群的同步过程中，因作为源的中心 etcd 集群中也存在 -etcd-syncer-meta- 的 key，触发了同步服务报错（同 txn 中不能包含相同的 key），出现了数据差异</p> \n <p>现象</p> \n <p>将同步服务运行参数添加对 -etcd-syncer-meta- 的过滤，然后观察进过一段时间追赶数据后，最终 miss 数降去达到一致</p> \n <p>(b) 长时间故障</p> \n <p>故障场景</p> \n <p>停止同步服务的部署 deployment</p> \n <p>等待两边 etcd 集群产生数据差异，并发生一次 compact 后再启动同步服务</p> \n <p>现象</p> \n <p>等产生数据差异，并发生 compact 后，重新启动同步服务，其日志如下：因 compacted 发生，触发全量同步</p> \n <p>同步服务监控指标：(a) dst miss key 很快降下去；(b) src miss key 有所增加，并持续不降</p> \n <p>分析</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100810215-29271856.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>同步服务停止以后，源 etcd 的 key 数量发生不少变化，监控图看出期间有下降，说明发生过 key 的删除</p> \n <p>这里也暴露出一个小问题，当出现 src miss key 的时候，目前不能自动修复，需要人工接入清理多余的 key</p> \n <ol start=\"3\"> \n  <li>reset 触发全量同步<br> 当同步发生重大差异（如，发生 dst miss）进行紧急修复的时候，通过配置 --reset-last-synced-rev 参数删除断点续传信息，来触发全量同步修复差异</li> \n </ol> \n <p>现象<br> 因某种异常，同步出现 dst miss（图中黄线实例）的情况。为了进行修复，新实例添加 --reset-last-synced-rev 参数后运行</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100810380-1884722320.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100810555-203013787.jpg\" alt=\"\" loading=\"lazy\"></p> \n <p>分析</p> \n <p>slow_path 为 1，说明触发全量同步（图中绿线实例）</p> \n <p>绿线实例的 dst miss 值没有增长起来，说明已经达到一致</p> \n <ol start=\"4\"> \n  <li>网络故障<br> 两 etcd 集群之间专线中断</li> \n </ol> \n <p>增量同步中</p> \n <p>全量同步中</p> \n <p>测试方案</p> \n <p>当专线中断切换公网时，需要修改运行参数中的 etcd 集群访问地址，即：必会发生重启（重启场景测试前面已经涵盖，这里不再重复）</p> \n <h2 id=\"总结\">总结</h2> \n <p>etcd-syncer 同步服务有较好的主备机制，能够及时有效的进行切换</p> \n <p>短时间故障后的断点续传表现符合预期；对于长时间故障，同时发生 compact 的复杂情况时，恢复同步后出现 src miss 的情况，可能需要人工接入</p> \n <p>通过配置 --reset-last-synced-rev 参数对 src miss 的异常修复有较好的效果</p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210929100810992-1535630810.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"495","createTime":"2021-09-28 18:04","comment":"0","id":"15349230","title":"Superedge的新特性和未来之路","url":"https://www.cnblogs.com/tencent-cloud-native/p/15349230.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>王冬，腾讯云高级研发工程师，专注于Kubernetes、容器等云原生领域，SuperEdge 核心开发人员，现负责腾讯云边缘容器TKE Edge私有化相关工作。</p> \n <h2 id=\"背景\">背景</h2> \n <p>2021年9月27号，，在VMware 联合了 Intel、 PingCAP 等多家合作公司举办的2021智能云边开源峰会边缘计算专场上，来自腾讯云的高级工程师王冬，发表《 SuperEdge 的新特性和未来之路》的分享。</p> \n <p><a href=\"https://link.segmentfault.com/?url=https%3A%2F%2Fgithub.com%2Fsuperedge%2Fsuperedge\" title=\"SuperEdge\" target=\"_blank\" rel=\"noopener\">SuperEdge</a> 是2020年由腾讯联合 Intel、VMware、虎牙直播、寒武纪、首都在线和美团等多家公司共同发起的<strong>边缘计算分布式容器管理系统</strong>，旨在将 Kubernetes 集中式资源管理能力无缝拓展到边缘计算和分布式资源管理场景，统管边缘设备和应用，为众多的 IoT 设备赋能。</p> \n <p>以下是分享全文。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210928180409857-1647674305.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"superedge-的四大特性\">SuperEdge 的四大特性</h2> \n <ul> \n  <li> <p>SuperEdge 来源</p> <p>SuperEdge 是腾讯云边缘容器管理系统 TKE Edge 产品族中的一个开源产品，其对应的商业产品是 TKE Edge 公有云服务和 TKE Edge 私有化服务。其公有云服务在2018年就在内部进行孵化，2019年正式公测并对外提供服务，目前对外完全免费；其私有化产品目前由灵雀云对外提供整体的交付和维保。</p> </li> \n </ul> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210928180410124-422804161.png\" alt=\"\" loading=\"lazy\"></p> \n <ul> \n  <li> <p>SuperEdge 和 TKE Edge 的关系</p> <p>SuperEdge 开源的是 TKE Edge 的边缘能力组件，并不包含其商业产品集群创建的部分。其边缘能力组件是完全开源的，开源产品和商业产品的边缘能力是完全一致的，甚至其开源产品 SuperEdge 的功能会比其商业产品更新的还要早。因为腾讯目前内外只维护了一个仓库，就是 Github 的 SuperEdge。</p> </li> \n </ul> \n <p>SuperEdge 核心的边缘能力有4个:</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210928180410430-1871883225.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"l3级边缘自治能力\">L3级边缘自治能力</h3> \n <p>这个能力主要由浅红色的<code>lite-apiserver</code>提供。为什么需要能力？有两个原因：</p> \n <ul> \n  <li>第一是因为云边一般是弱网，也可能断网，在弱网和断网情况下要保证边缘服务稳定。lite-apiserver 在云边网络正常的情况下直接从云端 Kube-apiserver 请求数据，但是云端请求不到的时候就会从本地缓存中取出相关组件管控缓存返回给请求端，保证边缘服务的稳定。</li> \n  <li>第二是边缘节点或者边缘站点可能会断电重启，特别是在云边断网的时候重启边缘节点，边缘节点上的业务容器会无法拉起。有了 lite-apiserver 的本地缓存就能避免这个问题，会从本地存储中把业务容器加载起来。</li> \n </ul> \n <p>除此之外 lite-apiserver 还提供了一些其他能力。比如：</p> \n <ul> \n  <li>以 InCluster 方式访问 kube-apiserver</li> \n  <li>支持所有类型资源的缓存，包括 CRD</li> \n  <li>边缘节点安全：lite-apiserver 用代理组件的权限去请求 kube-apiserver，而不是超级权限</li> \n  <li>支持多种缓存存储：Light Edge 可用本地文件存储，Heavy Edge 可以用 SQLite 等 KV 存储；</li> \n </ul> \n <h3 id=\"云边协同能力\">云边协同能力</h3> \n <p>这个能力主要由浅绿色的<code>tunnel-cloud</code>和<code>tunnel-edge</code>两个组件提供。这两个组件是腾讯云边缘计算团队完全自研的云边隧道，目前可以代理 TCP、HTTP、HTTPS、SSH 四种协议请求。为什么需要云边隧道能力？</p> \n <ul> \n  <li>第一是边缘节点一般是没有公网 IP 的，边缘节点可以主动访问云端的 Kube-apiserver，但是云端却无法直接访问边缘节点，所以需要云边反向隧道进行打通。</li> \n  <li>第二是为云边数据传输做准备，边缘部分数据是要回传云端进行分析和处理的，高效、安全的加密隧道是必要的条件。</li> \n </ul> \n <p>不过 SuperEdge 这个云边隧道并不专属 SuperEdge，任何需要隧道的地方都可以拿去按自己的场景进行配置和直接使用。</p> \n <h3 id=\"海量站点管理能力\">海量站点管理能力</h3> \n <p>这个能力主要由浅紫色的<code>application-grid-conterlloer</code>和<code>application-grid-wrapper</code>两个组件提供。为什么需要这两个组件？</p> \n <ul> \n  <li> <p>第一是边缘一般有很多类似的站点，需要部署同一套应用，我们不可能一一去部署，直接循环部署有的站点还会有差异，<br> <code>application-grid-conterlloer</code>就是为解决这问题而诞生的。用户的一份应用在云端一次提交便能同时部署到边缘多个站点，并且允许站点灰度能力，允许站点配置上有差异。</p> </li> \n  <li> <p>第二是防止边缘应用跨站点访问。因为各个站点基本提供一样的边缘服务，服务就可能会跨站点进行访问，跨站点访问会引起两个问题。A 站点可能会把 B 站点数据写紊乱，跨站点访问的延时不可控。</p> </li> \n </ul> \n <p>这个就是<code>application-grid-wrapper</code>解决的问题，他能把一个站点的流量锁定在一个站点之内，智能的配置后端的<code>endponit</code>，把服务锁定在用户想要的范围内。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210928180410748-552293068.png\" alt=\"\" loading=\"lazy\"></p> \n <p>上图便是这两个组件的一个典型使用示例图。站点 NodeUnit-1 和站点 NodeUnit-2 可以同时部署同一套服务 ServiceGroup-1，站点 NodeUnit-3 需要部署服务 ServiceGroup-2，并且各站点服务访问只在各站点内进行。站点的划分也是逻辑的，一个小机房可以划为一个或者多个站点，小机房内的节点也可以同属于多个站点，不同站点可以部署不同服务，来充分利用小机房内的资源。</p> \n <h3 id=\"分布式健康检查\">分布式健康检查</h3> \n <p>这个能力主要由浅黄色的<code>edge-health-admission</code>和<code>edge-health</code>两个组件提供。为什么需要这两个组件？</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210928180411249-1799504420.png\" alt=\"\" loading=\"lazy\"></p> \n <ul> \n  <li> <p>第一是需要在云边断网的时候尽可能的反馈边缘节点的健康性。比如某个边缘的小机房的某个可用区云边断网了，云上暂时无法知道只是云边断网了，还是这个可用区宕机了。这个健康状况云上是没有办法知道，但是这个小机房的其他可用区可以通过定期 Check 去反馈彼此的健康状况。<code>edge-health</code>就起到了这个作用。</p> </li> \n  <li> <p>第二是维护边缘服务的稳定性，避免被反复重建。在把原生 Kubernetes 推向边缘后，原生 Kubernetes 的驱逐能力是不完全符合边缘的。在边缘弱网或者断网，节点的状态可能会出现反复的<code>NotReady</code>，但是边缘服务是正常的，并不受云边弱网的影响。可是云上的 Kubernetes 可不这么认为，一但节点不<code>NotReady</code>就可以引起边缘服务驱逐，将边缘服务反复迁移和重建，引起边缘服务的不稳定。而<code>edge-health-admission</code>就是为解决这个问题，他把<code>edge-health</code>反馈的边缘节点真实的健康状况反馈给 Kube-apiserver，防止边缘服务被误驱逐。</p> </li> \n </ul> \n <h2 id=\"superedge-的新特性及原理\">SuperEdge 的新特性及原理</h2> \n <p>从去年12月开源到现在，SuperEdge 已经发了5个版本，带来了许多新特性，这里是4个比较典型的，其他的可关注 SuperEdge 社区。</p> \n <h3 id=\"新特性一易用性-一键创建-与-一键集成\">新特性一：易用性 一键创建 与 一键集成</h3> \n <p>从开源到现在，SuperEdge 一直在简单性和易用性上深耕。</p> \n <ul> \n  <li> <p>一键创建边缘 K8s 集群</p> <p>在用户没有 K8s 集群的时候，可以通过<code>edgeadm init</code>一键创建边缘 K8s 集群：</p> <pre><code class=\"language-javascript\">## 一键创建边缘集群\n./edgeadm init --apiserver-cert-extra-sans=…\n\n## 一键Join边缘节点\n./edgeadm join  kube-api-addr   --token xxxx…\n</code></pre> <p>只需要一个 Master 节点和一个 Node 节点，2C2G 的资源便可以轻松玩转边缘，纳管用户洒落在任何地方的边缘节点和边缘设备。</p> <p>实现上是改造了<code>Kubeadm</code>，在<code>Kubeadm init</code>之前加了<code>Init node</code>和<code>Install container runtime</code>, 之后 Addon CNI 网络插件和上面提到了边缘能力组件。</p> <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210928180411578-2069283683.png\" alt=\"\" loading=\"lazy\"></p> <p>使用方式上和<code>Kubeadm</code>完全一样，只比<code>Kubeadm</code>多了2个参数。具体可查看：<a href=\"https://mp.weixin.qq.com/s/zHs_qmD8781r-h4tkie0qQ\" target=\"_blank\" rel=\"noopener\">用 edgeadm 一键安装边缘 K8s 集群和原生 K8s 集群</a></p> </li> \n  <li> <p>一键集成边缘能力</p> <p>在用户已经有了原生的 K8s 集群，可以通过<code>Addon SuperEdge</code>一键集成边缘能力。</p> <pre><code class=\"language-javascript\">## 一键Addon SuperEdge集成边缘能力\n./edgeadm addon edge-apps --master-addr …\n\n## 一键Join任意位置的边缘节点\n./edgeadm  join kube-api-addr  --token=…\n</code></pre> <p>集成边缘能力之后原生的K8s集群将具备既能管理中心节点和中心应用，也能管理边缘节点和边缘应用的能力，实现中心和边缘混管、混部和互弹。能 Join 任意位置的边缘节点，不要求 SSH 到边缘节点，只要这个边缘节点能访问到中心的 Kube-apiserver 就能被 Join。除此之外，当然也具备 SuperEdge 所有的边缘能力。</p> </li> \n </ul> \n <p>实现的原理如下图：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210928180411815-1678798652.png\" alt=\"\" loading=\"lazy\"></p> \n <p>用户通过任何方式搭建的原生K8s集群，<code>edgeadm addon SuperEdge</code>会把他配置成标准的<code>Kubeadm Kubernetes</code>集群，如果是 Kubeadm Kubernetes 更就可以直接跳过这步。之后准备<code>Addon SuperEdge</code>和<code>Join edge node</code>的前提条件。这里比较有挑战的点就是准备<code>Join edge node</code>的条件，实现任何 K8s 集群都能一键 join 进去任意位置的边缘节点。更详细原理可查看：<a href=\"https://mp.weixin.qq.com/s/1CnvqASzLnOShj8Hoh-Trw\" target=\"_blank\" rel=\"noopener\">Addon SuperEdge 让原生 K8s 集群可管理边缘应用和节点</a></p> \n <h3 id=\"新特性二边缘托管集群--边缘独立集群--边缘联级集群\">新特性二：边缘托管集群 + 边缘独立集群 + 边缘联级集群</h3> \n <p><strong>下面这个图是 SuperEdge 向边缘分布式多集群迈进的第一步</strong>。</p> \n <p>SuperEdge 目前可以通过腾讯云边缘计算团队新开源的分布式多集群项目<code>clusternet</code>，实现在中心统一管控边缘托管集群，纳管边缘独立集群，甚至是边缘联级集群。</p> \n <p>其中纳管的边缘独立集群不限于 SuperEdge 类型的 K8s 集群，还包括轻量级的 K3s 集群、MicroK8s 集群……及其他原生的 K8s 集群。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210928180412125-395954962.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"新特性三tunnel-远程登录内网节点和-hpa\">新特性三：Tunnel 远程登录内网节点和 HPA</h3> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210928180412325-1045401706.png\" alt=\"\" loading=\"lazy\"></p> \n <p>tunnel-cloud 和 tunnel-edge 是云边隧道的两端，SuperEdge 每个 tunnel-cloud 实例 Pod 上并不是保留了所有边缘节点的的连接，而是每个 tunnel-cloud 只是承担了一部分边缘节点的 tunnel-edge 隧道连接，也就是每个云边隧道只有一条长连接。而其他大部分云边隧道项目都是云端每个实例需要保持和边缘节点的所有长链接：</p> \n <pre><code class=\"language-javascript\">长链接数量 = 隧道云端实例数 * 边缘节点个数\n</code></pre> \n <p>这样做的目的主要是支持 tunnel-cloud 自动扩缩容</p> \n <p>随着一个边缘集群的边缘节点数量不断打破 SuperEdge 的上限，tunnel-cloud 不能再静态的去维护固定数量的实例，而要动态的去扩容去 tunnel-cloud 实例，以便接入更多的长连接，纳管更多的边缘节点，这就是 tunnel-cloud 自动 HPA 需求来源。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210928180412496-1522076309.png\" alt=\"\" loading=\"lazy\"></p> \n <p>最后这个小特性是借助 tunnel 隧道，SuperEdge 支持了远程安全的SSH到无公网IP的边缘节点，为用户远程操作无公网 IP 的边缘节点带来了极大的便利性。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210928180412723-641601850.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"新特性四远程批量添加边缘节点\">新特性四：远程批量添加边缘节点</h3> \n <p>新特性的最后一个是远程批量添加边缘节点。这是 SuperEdge 落地生产批量化的一个需求，相关代码已经开源到 SuperEdge 的<code>penetrator</code>模块。远程批量添加边缘节点分为两种情况：</p> \n <ul> \n  <li> <p>云端能 SSH 到的边缘节点</p> <p>云端能 SSH 到边缘节点这个操作比较常规，通过下发一个 SSH 的 Job, 批量 SSH 远程执行命令添加边缘节点。<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210928180413008-1176695280.png\" alt=\"\" loading=\"lazy\"><br> <code>penetrator</code>的关键是无法直接SSH到的边缘节点怎么实现批量添？</p> </li> \n  <li> <p>云端不能 SSH 到的边缘节点</p> <p>不能直接 SSH 到的边缘节点，如下图，可以通过一个代理或者其他办法把同一子网的一个节点加入到边缘 K8s 集群。以这个边缘节点为跳板，然后把任务 Job 下发到这个跳板节点，然后就可以批量的执行添加和这个跳板节点同一内网的边缘节点。这样就实现了远程批量添加不能 SSH 到的边缘内网节点。</p> <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210928180413195-1465238526.png\" alt=\"\" loading=\"lazy\"></p> </li> \n </ul> \n <h2 id=\"superedge-未来的云边端\">SuperEdge 未来的云边端</h2> \n <h3 id=\"superedge-未来的云上\">SuperEdge 未来的云上</h3> \n <p>腾讯云边缘团队最近刚开源了团队的第二个开源项目 <a href=\"https://github.com/clusternet/clusternet\" title=\"Clusternet\" target=\"_blank\" rel=\"noopener\">Clusternet</a>，这并不是一个集群网络相关的开源项目，而是为了实现<code>像访问Internet网络一样，访问用户各处K8s集群</code>的目标而构建的一个分布式多集群管理开源项目。为什么需要这个项目？</p> \n <ul> \n  <li> <p>第一是为了满足海量边缘节点的管理</p> <p>一个 K8s 集群管理的边缘节点是有限的，原生的 K8s 集群目前社区给出的节点上限是5000。K8s 集群管理的节点越多，维护成本和技术难度都将指数级上升。把数量庞大的节点放在一个集群里面，本身面临的风险就是比较高的，一旦中心有问题，节点的应用可能都会受到影响。<br> 要管理上万的边缘节点，单集群并不优雅，反而是小而美的多集群更安全更稳定。clusternet 目前能够纳管各式各样的 K8s 集群，包括公有云的、私有化的和边缘K8s集群。可以实现在中心一个控制面统一管理和访问和各个 K8s 集群，并且可以实现从纳管的集群互相访问。</p> </li> \n  <li> <p>第二是为了满足站点和应用容灾的需要</p> <p>纳管各种 K8s 集群只是实现分布式多集群管理的第一步，集群容灾、应用容灾才是目的。边缘站点断网断电的可能性要比中心更高也更频繁。站点宕机之后相应站点服务需要在临近站点或者备份站点上继续提供服务，集群迁移、同城双活是迫切的需求。边缘的应用也不会只部署在一个站点之内，一个站点崩溃还需要在其他站点上继续提供服务。</p> </li> \n </ul> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210928180413402-248935237.png\" alt=\"\" loading=\"lazy\"></p> \n <p>上图是 Clusternet 的架构，目前由两个组件<code>clusternet-agent</code> 和 <code>clusternet-hub</code>组成。<code>clusternet-agent</code>负责把 K8s 集群注册到父集群，<code>clusternet-hub</code>负责处理注册、聚合各个子 K8s 集群 Kube-apiserver，以及把应用部署到多个 K8s 集群。</p> \n <h3 id=\"superedge-未来的边上\">SuperEdge 未来的边上</h3> \n <p><strong>下图表述的是目前边缘 K8s 集群云边 Service 互访和边边 Service 互访的现状。</strong></p> \n <p><strong>云边 Service 互访</strong>大多都是以 NodePort 方式对外暴露，很少有边缘项目实现像原生 K8s 集群一样，<code>在一个集群内Service无缝进行互访</code>。</p> \n <p><strong>边边 Service 互访</strong>困难更高，要是边边之间是单向网络还能通过打隧道互访，要是物理网络完全不通只能通过云端中转。就算实现了云边 Service 互访和边边 Service 互访，又如何避免性能损失，以及突破云边和边边物理网络的不稳定性？<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210928180413627-291945991.png\" alt=\"\" loading=\"lazy\"></p> \n <p>这里的解决方案可关注 SuperEdge 社区，后续会推出相关的解决方案。</p> \n <h3 id=\"superedge-未来的端上\">SuperEdge 未来的端上</h3> \n <p>端上 SuperEdge 已经实现 Addon 原生的 Edgex Foundry, 可以通过如下命令有选择的部署 Edgex Foundry 的各层组件：</p> \n <pre><code class=\"language-javascript\">attlee➜  ✗ ./edgeadm addon edgex -h\nAddon edgex to Kubernetes cluster\n\nUsage:\nedgeadm addon edgex [flags]\n\nFlags:\n--core       Addon the edgex core-services to cluster.\n--app        Addon the edgex application-services to cluster.\n--device     Addon the edgex device-services to cluster.\n--ui         Addon the edgex ui  web to your cluster.\n</code></pre> \n <p>详细的操作可查看<a href=\"https://mp.weixin.qq.com/s/DNfU0-8h6ycWadJ7hgNPrQ\" target=\"_blank\" rel=\"noopener\">在 SuperEdge 上用 EdgeX Foundry 接入 IoT 设备。</a></p> \n <p>这只是 SuperEdge 实现边缘设备管理的第一步，EdgeX Foundry 也只是众多设备管理平台中的一种，后续 SuperEdge 还会和更多的缘设备平台进行抽象和集成，推出<code>多平台边缘设备平台无缝衔接</code>的解决方案。但无论是那种方案，SuperEdge 都会以 Addon 的方式让用户去自由选择，绝不强绑定任何边缘设备平台。</p> \n <p><strong>最后这张图是目前 SuperEdge 和 EdgeX Foundry 在端边的部署方式，以及设备的接入方式</strong>。一个站点只用部署 SuperEdge 和 EdgeX Foundry 的一套边端服务即可管理相应站点的边缘设备。<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210928180413841-2114110198.png\" alt=\"\" loading=\"lazy\"></p> \n <p>后续 SuperEdge也 会面向边缘站点做一系列的支持，包括站点自治、站点 Workload、站点容灾等，在云端统一管理用户的边缘站点。</p> \n <p>最后送大家一句话：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210928180415227-663509528.png\" alt=\"\" loading=\"lazy\"></p> \n <p>边缘计算技术将成为万物互联成功的关键，将低延迟和低成本的服务于 5G 和数字化！</p> \n <p>演讲原视频<br> <a href=\"https://attlee-1251707795.cos.ap-chengdu.myqcloud.com/superedge/v0.6.0/superedge_future.mp4\" target=\"_blank\" rel=\"noopener\">https://attlee-1251707795.cos.ap-chengdu.myqcloud.com/superedge/v0.6.0/superedge_future.mp4</a></p> \n <p>关注【腾讯云原生】公众号，后台回复关键词【云边开源峰会】可获取演讲PPT原稿。</p> \n <p>SuperEdge 相关文章：</p> \n <ul> \n  <li><a href=\"https://mp.weixin.qq.com/s/RmujKdSK58digZTJOcNw-w\" target=\"_blank\" rel=\"noopener\">腾讯云联合多家生态伙伴，重磅开源 SuperEdge 边缘容器项目</a></li> \n  <li><a href=\"https://mp.weixin.qq.com/s/n0gYKKZgPIr1ZopU4aefUw\" target=\"_blank\" rel=\"noopener\">【TKE 边缘容器系列】SuperEdge易学易用 【6个短频教学合集】</a></li> \n  <li><a href=\"https://mp.weixin.qq.com/s/aWgGJv5sDQX1dvGE-b_vYw\" target=\"_blank\" rel=\"noopener\">【TKE 边缘容器系列】从0到N了解 SuperEdge【18篇干货合集】</a></li> \n  <li><a href=\"https://mp.weixin.qq.com/s/V29ga-fOM2KEq-dlKo-FuA\" target=\"_blank\" rel=\"noopener\">【TKE 边缘容器系列】一文读懂 SuperEdge 边缘容器架构与原理</a></li> \n  <li><a href=\"https://mp.weixin.qq.com/s/zHs_qmD8781r-h4tkie0qQ\" target=\"_blank\" rel=\"noopener\">【TKE 边缘容器系列】用 edgeadm 一键安装边缘 K8s 集群和原生 K8s 集群</a></li> \n  <li><a href=\"https://mp.weixin.qq.com/s/1CnvqASzLnOShj8Hoh-Trw\" target=\"_blank\" rel=\"noopener\">【TKE 边缘容器系列】Addon SuperEdge 让原生 K8s 集群可管理边缘应用和节点</a></li> \n  <li><a href=\"https://mp.weixin.qq.com/s/DNfU0-8h6ycWadJ7hgNPrQ\" target=\"_blank\" rel=\"noopener\">【TKE 边缘容器系列】在SuperEdge 上用 EdgeX Foundry 接入 IoT 设备</a></li> \n  <li><a href=\"https://mp.weixin.qq.com/s/JmzQuiBBkNwS9hpS0hIg7A\" target=\"_blank\" rel=\"noopener\">【TKE 边缘容器系列】打破内网壁垒，从云端一次添加成百上千的边缘节点</a></li> \n  <li><a href=\"https://mp.weixin.qq.com/s/J-sxkiL62FAjGBRHERPbKg\" target=\"_blank\" rel=\"noopener\">【TKE 边缘容器系列】SuperEdge 云边隧道新特性：从云端SSH运维边缘节点</a></li> \n  <li><a href=\"https://mp.weixin.qq.com/s/RId4f-ia326-9wFn4VKE2w\" target=\"_blank\" rel=\"noopener\">【TKE 边缘容器系列】SuperEdge 高可用云边隧道有哪些特点？</a></li> \n </ul> \n <p>落地案例相关资料：</p> \n <ul> \n  <li><a href=\"https://mp.weixin.qq.com/s/evalqNiqoM2dly57A0Cgrg\" target=\"_blank\" rel=\"noopener\">腾讯WeMake工业互联网平台的边缘容器化实践：打造更高效的工业互联网</a></li> \n  <li><a href=\"https://mp.weixin.qq.com/s/FMO6V1pvG-Xyi9xfBttCQA\" target=\"_blank\" rel=\"noopener\">完爆！用边缘容器，竟能秒级实现团队七八人一周的工作量</a></li> \n  <li><a href=\"https://mp.weixin.qq.com/s?__biz=MzkzNDE3MTc4OA==&amp;mid=2247485924&amp;idx=1&amp;sn=e6e31cc94c286cd90bd4455957cb6ad1&amp;chksm=c2400c07f53785114a60416ab4ae40b7987ce06400c91e4cfb380ba108ace991192831a5e03a&amp;mpshare=1&amp;scene=1&amp;srcid=1228BnTlOKDJrbASAWZ8ZqHa&amp;sharer_sharetime=1609163853965&amp;sharer_shareid=1d93fb5fa2b29b35d135653bdc08e257%C2%ACreplace=true#rd\" target=\"_blank\" rel=\"noopener\">基于边缘容器技术的工业互联网平台建设</a></li> \n  <li><a href=\"https://mp.weixin.qq.com/s/0OOBazTMJQh4SXItNaVIMQ\" target=\"_blank\" rel=\"noopener\">使用TKE Edge部署EdgeX Foundry</a></li> \n </ul> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210928180416201-21437862.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"140","createTime":"2021-09-24 15:03","comment":"0","id":"15330467","title":"腾讯云与 Grafana Labs 达成深度合作， 推出全新 Grafana 托管服务","url":"https://www.cnblogs.com/tencent-cloud-native/p/15330467.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <p>9 月 23 日，腾讯云宣布与业界领先的开源数据可视化公司 Grafana Labs 达成深度合作协议，共同开发和验证全新的 Grafana 托管服务，通过 Grafana Labs 开源软件与腾讯云的整合，帮助用户快速对云上负载及性能指标数据进行可视化监测。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210924150327217-1317490468.png\" alt=\"\" loading=\"lazy\"></p> \n <p>据了解，Grafana Labs 基于领先的开源可视化及仪表板技术 Grafana 项目，为用户提供开放且灵活的数据可视化观测系统，目前其全球安装量已超过 750,000 次。腾讯云自今年 4 月开始就与 Grafana Labs 展开合作，通过将腾讯云 Grafana 云监控应用插件加入至 Grafana 开源生态中， 针对包括云服务器（Cloud Virtual Machine）和腾讯云数据库（Tencent DB）等云产品，为用户提供负载及性能指标可视化监测能力。作为云原生时代的可观测性事实标准，Grafana 被越来越多地应用于分布式应用和容器数据观测，Grafana 托管服务当前也正与腾讯云容器服务进行深 度结合，致力于提升云原生场景下的可观测性。</p> \n <p>此次，双方合作推出的全新 Grafana 托管服务，可让超过 500 万 Grafana 用户透过腾讯云的单点登录（SSO），应用插件等整合功能连接用户云上数据，让他们能在腾讯云上安全、简易地运行 Grafana。</p> \n <p>腾讯云国际高级副总裁杨宝树（Poshu Yeung）表示：“腾讯云自今年 4 月宣布与 Grafana 合作以来，推出的腾讯云 Grafana 云监控应用插件收到众多用户的良好反馈。我们期待能进一步为 Grafana Labs 用户提供更多服务并推出 Grafana 托管服务。这项新服务让用户能体验到 Grafana 先进的数据可视化功能，助力用户进一步提升云数据的使用体验，减少对基础设施管理的工作量。”</p> \n <p>Grafana Labs 联合创始人兼行政总裁 Raj Dutt 表示：“ Grafana 自今年首次宣布与腾讯云达成合作后，成功取得众多用户的正面反馈，因此，我们决定继续加强和腾讯云的合作，并联手推出全新的 Grafana 托管服务，为腾讯云和 Grafana 用户提供了云端负载和性能监测数据的原生解决方案，助力用户进一步提升基础设施管理效率，全力开拓新业务。”</p> \n <p>作为一家安全、可靠和高性能的公有云服务供应商，腾讯云正基于全球领先的云计算、大数据、 人工智能等技术产品与服务，为政务、金融、游戏、电商、医疗、教育等众多行业提供全球可达、 先进的基础架构和弹性的云计算服务，助力产业数字化升级。</p> \n <p>值得一提的是，凭借顶级安全标准水平及具竞争力服务，腾讯云近期刚刚获得 Frost &amp; Sullivan 颁发的“2020 最佳实践奖 ─ 全球云端竞争策略和领导力”。而在此之前，腾讯云已经获得超过 70 个国际标准认可，包括 ISO22301、ISO27001、ISO20000、ISO9001、中国可信云服务认证 Trusted Cloud Services、信息安全等级保护 （第三级或以上）、云端安全性联盟（CSA） STAR 认证、外判服务供应商审计报告（OSPAR）认证，以及多层云安全云端安全标准认证 （MTCS SS）等。</p> \n <p>点击文末阅读原文，立即申请内测，成为腾讯云 Grafana 可视化服务首批用户。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210924150327612-1804065099.jpg\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210924150327912-2096433771.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"207","createTime":"2021-09-22 18:03","comment":"0","id":"15321045","title":"成本降低40%、资源利用率提高20%的 AI 应用产品云原生容器化之路","url":"https://www.cnblogs.com/tencent-cloud-native/p/15321045.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>郭云龙，腾讯云高级工程师，目前就职于 CSIG 云产品三部-AI 应用产品中心，现负责中心后台业务框架开发。</p> \n <h2 id=\"导语\">导语</h2> \n <p>为了满足 AI 能力在公有云 SaaS 场景下，服务和模型需要快速迭代交付的需求，保障服务在不稳定高并发时的高成功率，以及进一步提升资源利用率，AI 应用产品中心进行了一系列的调研与实践，本篇将重点介绍团队在容器化方面的实践经验。</p> \n <h2 id=\"背景和问题\">背景和问题</h2> \n <p>公有云 AI SaaS 产品（如<a href=\"https://cloud.tencent.com/product/facefusion\" title=\"人脸融合\" target=\"_blank\" rel=\"noopener\">人脸融合</a>)的一般服务流程为：C 端或 B 端客户通过采集设备采集图像、音视频等，经由云 API 等接入方式传入，服务端利用强大的计算能力、充足的资源和相对成熟的算法对客户输入的多媒体内容进行处理。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210922180246764-1010215613.png\" alt=\"\" loading=\"lazy\"></p> \n <p>如上图所示，对于一般流程来说，我们面临着三个挑战。</p> \n <ol> \n  <li><strong>采集质量不稳定</strong>：由于采集设备之间存在差异，采集到的质量也会存在差异，拿图像处理来说，大图和小图会给我们的服务带来不同的压力，有时服务会因为集中的大图并发产生失败。</li> \n  <li><strong>短期、高并发需求多</strong>：我们的客户会用我们的能力实现不同的玩法，使用人脸融合来进行游戏活动宣传就是一个很常见的运营手段，但是这种活动会给我们的服务带来短期内的高并发压力。</li> \n  <li><strong>模型、服务迭代快</strong>：AI SaaS 服务的竞争非常激烈，经常会有客户提出新的需求，加上算法难免会有 badcase，所以我们的服务也要进行很频繁的升级迭代。</li> \n </ol> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210922180247200-1971466429.png\" alt=\"\" loading=\"lazy\"></p> \n <p>我们再来看下我们容器化前的精简架构（如上图所示），物理机的开发部署大背景下，我们的逻辑服务<strong>不论是结构上还是基础上都属于大泥球模式，另外算法服务也常有混布的现象存在</strong>。</p> \n <p>这种架构也导致了忙时服务间抢占资源的情况频繁发生，影响服务成功率及耗时，导致我们没有办法很好的满足客户的需求；而闲时资源利用率非常低，容易造成资源浪费。</p> \n <p>以<strong>两个实际的例子</strong>来说明：</p> \n <ol> \n  <li>升级发布时，我们需要先从LB中剔除一个节点，并在节点上观察没有流量进入后进行服务升级。升级完成后，人工对服务进行成功性检测，检测结果ok后再加回LB中。</li> \n  <li>客户搞活动时提出高并发需求，如果当前物理机/vm资源池不满足，需要向资源同学紧急提物理机需求，资源同学协调到机器后，我们需要人工对机器环境/网络重新初始化，然后执行上述1操作。待活动结束后机器闲置，易造成成本浪费。</li> \n </ol> \n <p>为了更好的满足客户不断迭代的需求，减轻研发的运维负担，补齐弹性能力和接入高效的服务管控平台对我们来说是迫切需要的。趁着公司推动上云的时机，我们对架构组件进行了几轮调研和优化。本文<strong>主要对容器化过程</strong>进行阐述。</p> \n <h2 id=\"容器化过程记录\">容器化过程记录</h2> \n <p>我们的容器化上云到现在为止可以分为三步：<strong>容器化，稳定性提升和利用率提升</strong>。</p> \n <h3 id=\"容器化\">容器化</h3> \n <p>这里的容器化映射到业务上来说，除了将服务载体由物理机迁移到容器上，更主要是<strong>将原来的复杂逻辑解耦，微服务化</strong>。</p> \n <p>如下图所示，我们先对服务本身做了瘦身微服务化，另外借助于容器的能力，将原来混布的服务彻底分开。如何进行微服务化会因业务的不同存在差异，本篇对此不做赘述。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210922180247361-1413867090.png\" alt=\"\" loading=\"lazy\"></p> \n <h3 id=\"稳定性提升\">稳定性提升</h3> \n <p>在第一步容器化之后，我们很快享受到了<strong>飞一般的服务升级和扩容速度</strong>。同时对容器化比较浅显的理解也给我们带来了一些新的问题。</p> \n <ol> \n  <li>调用量波动较大的服务由于频繁扩缩容导致业务失败</li> \n  <li>一些客户传的大图在低核容器上处理效率较低</li> \n  <li>集群资源紧缺导致的容器无法按需扩容等。</li> \n </ol> \n <p>对于上述三个问题，我们也分别找出了应对方案。</p> \n <h4 id=\"灵活使用探针\">灵活使用探针</h4> \n <p>起初我们的服务都是没有设置存活和就绪检测（<a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/\" title=\"探针\" target=\"_blank\" rel=\"noopener\">探针</a> ）的，Prestop 给缩容时加上了一层保护，但是并不彻底，而且在扩容时难免会有服务失败。</p> \n <p><strong>探针给我们提供了另一种强大的解决方式</strong>。一开始时，我们参照链接中的示例，进行简单的端口检查来判断服务是否正常运行。后来我们发现了更多灵活的运用技巧和使用场景。以下列出几个例子供大家参考以及发散出更多有趣实践。</p> \n <p><strong>例子1</strong>：在一开始时大家经常遇到 LB Agent 启动时获取路由必然失败的情况，我们可以使用就绪探针来进行 LB 的预加载（如下图），即可达到 LB 获取成功后标记服务启动成功的效果。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210922180247536-509956229.png\" alt=\"\" loading=\"lazy\"></p> \n <p><strong>例子2</strong>：由于一些低版本OS的实例存在弱口令的问题，大家需要把所有依赖旧版OS的镜像全部升级，这个工作对我们来说是及其繁重的，于是我们同样利用了探针，在容器标记服务启动前把弱口令全部干掉。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210922180247759-915022440.png\" alt=\"\" loading=\"lazy\"></p> \n <p><strong>例子3</strong>：某个服务比较特殊，内存占用经常波动，当内存小于某个值时，服务会偶现失败，但是端口正常存活。这时我们可以使用 ConfigMap+python 脚本来进行一些复杂的检测：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210922180248006-443659677.png\" alt=\"\" loading=\"lazy\"></p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210922180248225-1291490332.png\" alt=\"\" loading=\"lazy\"></p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210922180248535-2062760493.png\" alt=\"\" loading=\"lazy\"></p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210922180248718-444702123.png\" alt=\"\" loading=\"lazy\"></p> \n <h4 id=\"针对大图进行筛选适配\">针对大图进行筛选适配</h4> \n <p>容器化后，我们发现某个算法在接收到高分辨率图片时，服务成功率会出现波动，原因是<strong>算法在对提特征时会出现更多的消耗</strong>，这一现象在物理机上部署时被物理机核数多的优势掩盖住了，一旦到了核数较低的容器上就显露了出来。为了解决这个问题，我们在上层逻辑中新增了大图筛选功能（如下图所示），如果检测到是大图，则走回物理机集群（由于初始时 TKEx 提供最高规格容器核数为 8 核，后来才扩充支持了 24 核及以上），如果是一般图片，则走容器集群。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210922180248944-1689259567.png\" alt=\"\" loading=\"lazy\"></p> \n <h4 id=\"多集群部署\">多集群部署</h4> \n <p>在使用 TKEx 时，我们经常会碰到部署的 workload 会因为整体集群资源不足的原因，无法扩容到指定的 max 值，一度非常苦恼。</p> \n <p>TKEx 的同学也是推荐我们在其他的集群复制一份资源，当一个集群扩不出来时，另一个集群充当备份角色。在这么调整过后，我们的扩容成功率逐步上升。</p> \n <p>后来又出现了整个地域的资源都比较紧缺的情况，于是我们把一些对时延不那么敏感的服务进行了多地域部署（如下图），最终将集群资源不足的风险进一步降低。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210922180249129-2027348176.png\" alt=\"\" loading=\"lazy\"></p> \n <p>当一地资源不足的情况下使用多地域部署以及 LB 时，一般 LB 都会根据后端响应时间动态调整各节点权重，所以我们应注意以下两点：</p> \n <ol> \n  <li>关闭就近访问</li> \n  <li>根据上下游调整 LB 权重（比如上游服务部署在广州，下游同时部署了南京和广州，这是南京和广州的 LB 权重分别为130，100）</li> \n </ol> \n <h3 id=\"利用率提升\">利用率提升</h3> \n <p>在进行过一轮稳定性提升之后，我们可以<strong>更加自信的利用弹性能力，利用率也有了显著提升</strong>。不过依旧有两个问题阻碍着我们的利用率更进一步。一个是有些服务模型大，启动慢，流量突增时服务无法很及时的扩容出来，这时我们必须要提前占用一些资源导致利用率提不上去。</p> \n <p>针对第一个问题，我们挑选了部分流量有规律的服务。<strong>利用 TKE 提供的定时 HPA 能力，在已知流量高峰前定时进行一轮扩容</strong>。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210922180249461-870993512.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"成果\">成果</h2> \n <table> \n  <thead> \n   <tr> \n    <th></th> \n    <th>优化前</th> \n    <th>优化后</th> \n   </tr> \n  </thead> \n  <tbody> \n   <tr> \n    <td><strong>资源占用</strong></td> \n    <td>1500+CPU 物理机 ( 8w+ 核)800+GPU 物理机 (P4 1600 卡)</td> \n    <td>CPU 6w 核 T4 1000 卡</td> \n   </tr> \n   <tr> \n    <td><strong>资源利用率</strong></td> \n    <td>10%</td> \n    <td>30%</td> \n   </tr> \n   <tr> \n    <td><strong>成本</strong></td> \n    <td>-</td> \n    <td>-40%</td> \n   </tr> \n   <tr> \n    <td><strong>服务成功率</strong></td> \n    <td>99.9%</td> \n    <td>99.95%</td> \n   </tr> \n   <tr> \n    <td><strong>服务扩容效率</strong></td> \n    <td>小规模 (&lt;2000核)： 3 小时 大规模： 2天</td> \n    <td>小规模 (&lt;2000核)： 10分钟 大规模： 6小时</td> \n   </tr> \n   <tr> \n    <td><strong>服务升级效率</strong></td> \n    <td>小规模 (&lt;50实例)： 6 小时 大规模： 2天</td> \n    <td>小规模 (&lt;50实例)： 30分钟 大规模： 6小时</td> \n   </tr> \n  </tbody> \n </table> \n <p>当前我们的 AI 服务已经基本完成容器化的升级。成功率高，扩容快，欢迎大家扫码进行体验。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210922180249685-435714943.jpg\" alt=\"img\" loading=\"lazy\"></p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210922180249931-1955233897.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"770","createTime":"2021-09-22 15:57","comment":"0","id":"15320277","title":"qGPU on TKE - 腾讯云发布下一代 GPU 容器共享技术","url":"https://www.cnblogs.com/tencent-cloud-native/p/15320277.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"背景\">背景</h2> \n <p>qGPU 是腾讯云推出的 GPU 共享技术，支持在多个容器间共享 GPU卡，并提供容器间显存、算力强隔离的能力，从而在更小粒度的使用 GPU 卡的基础上，保证业务安全，达到提高 GPU 使用率、降低客户成本的目的。</p> \n <p>qGPU on TKE 依托腾讯云 TKE 对外开源的 <a href=\"https://github.com/nano-gpu\" title=\"Nano GPU 调度框架\" target=\"_blank\" rel=\"noopener\">Nano GPU 调度框架</a>，可实现对 GPU 算力与显存的细粒度调度，并支持多容器共享 GPU 与多容器跨 GPU 资源分配。同时依赖底层强大的 qGPU 隔离技术，可做到 GPU 显存和算力的强隔离，在通过共享使用 GPU 的同时，尽最大可能保证业务性能与资源不受干扰。</p> \n <h2 id=\"功能优势\">功能优势</h2> \n <p>qGPU 方案通过对 NVIDIA GPU 卡上任务更有效的调度，达到给多个容器共享使用的目的，支持的功能如下：</p> \n <p><strong>灵活性</strong>：用户可以自由配置 GPU 的显存大小和算力占比</p> \n <p><strong>云原生</strong>：支持标准的 Kubernetes，兼容 NVIDIA Docker 方案</p> \n <p><strong>兼容性</strong>：镜像不修改/CUDA 库不替换/业务不重编，易部署，业务无感知</p> \n <p><strong>高性能</strong>：在底层对 GPU 设备进行操作，高效收敛，吞吐接近0损耗</p> \n <p><strong>强隔离</strong>：支持显存和算力的严格隔离，业务共享不受影响</p> \n <h2 id=\"技术架构\">技术架构</h2> \n <p>qGPU on TKE 使用 Nano GPU 调度框架，通过Kubernetes扩展调度机制，同时支持 GPU 算力与显存资源调度。并且依赖 Nano GPU 的容器定位机制，支持精细化 GPU 卡调度，同时支持多容器 GPU 卡共享分配与多容器 GPU 跨卡分配。</p> \n <p>qGPU 直接采用英伟达 GPU 底层硬件特性进行调度，实现细粒度算力隔离，打破传统上 CUDA API 劫持方案的只能以 CUDA Kernel 为粒度进行算力隔离的限制，提供更好的 QoS 保证。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210922155726586-995420137.png\" alt=\"\" loading=\"lazy\"></p> \n <h2 id=\"客户收益\">客户收益</h2> \n <ol> \n  <li>多任务灵活共享 GPU，提升利用率</li> \n  <li>GPU 资源强隔离，业务共享不受影响</li> \n  <li>完全面向 Kubernetes，业务使用零成本</li> \n </ol> \n <h2 id=\"未来规划\">未来规划</h2> \n <p>● <strong>支持细粒度资源监控</strong>：qGPU on TKE 将支持对 Pod 和容器级的 GPU 使用率采集，实现更细粒度的资源监控和与 GPU 弹性能力的整合</p> \n <p>● <strong>支持在离线混部</strong>：qGPU on TKE 将支持在线业务和离线业务的高低优先级混部，最大限度地提升 GPU 利用率</p> \n <p>● <strong>支持 qGPU 算力池化</strong>：基于 qGPU 的 GPU 算力池化，实现 CPU、内存资源与异构计算资源解耦</p> \n <h2 id=\"内测申请\">内测申请</h2> \n <p>qGPU 已经开放免费内测，欢迎添加腾讯云原生小助手：TKEplatform，备注”qGPU内测申请“进行试用！</p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210922155727419-420128016.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"658","createTime":"2021-09-14 18:08","comment":"0","id":"15268959","title":"如何高效掌控K8s资源变化？K8s Informer实现机制浅析","url":"https://www.cnblogs.com/tencent-cloud-native/p/15268959.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"作者\">作者</h2> \n <p>王成，腾讯云研发工程师，Kubernetes contributor，从事数据库产品容器化、资源管控等工作，关注 Kubernetes、Go、云原生领域。</p> \n <h2 id=\"概述\">概述</h2> \n <p>进入 K8s 的世界，会发现有很多的 Controller，它们都是为了完成某类资源(如 pod 是通过 DeploymentController, ReplicaSetController 进行管理)的调谐，目标是保持用户期望的状态。</p> \n <p>K8s 中有几十种类型的资源，如何能让 K8s 内部以及外部用户方便、高效的获取某类资源的变化，就是本文 Informer 要实现的。本文将从 Reflector(反射器)、DeletaFIFO(增量队列)、Indexer(索引器)、Controller(控制器)、SharedInformer(共享资源通知器)、processorListener(事件监听处理器)、workqueue(事件处理工作队列) 等方面进行解析。</p> \n <blockquote> \n  <p>本文及后续相关文章都基于 K8s v1.22</p> \n </blockquote> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210914180751255-1268177199.png\" alt=\"\" loading=\"lazy\">（K8s-informer）</p> \n <h2 id=\"从-reflector-说起\">从 Reflector 说起</h2> \n <p>Reflector 的主要职责是从 apiserver 拉取并持续监听(ListAndWatch) 相关资源类型的增删改(Add/Update/Delete)事件，存储在由 DeltaFIFO 实现的本地缓存(local Store) 中。</p> \n <p>首先看一下 Reflector 结构体定义：</p> \n <pre><code class=\"language-js\">// staging/src/k8s.io/client-go/tools/cache/reflector.go\ntype Reflector struct {\n\t// 通过 file:line 唯一标识的 name\n\tname string\n\n\t// 下面三个为了确认类型\n\texpectedTypeName string\n\texpectedType     reflect.Type\n\texpectedGVK      *schema.GroupVersionKind\n\n\t// 存储 interface: 具体由 DeltaFIFO 实现存储\n\tstore Store\n\t// 用来从 apiserver 拉取全量和增量资源\n\tlisterWatcher ListerWatcher\n\n\t// 下面两个用来做失败重试\n\tbackoffManager         wait.BackoffManager\n\tinitConnBackoffManager wait.BackoffManager\n\n\t// informer 使用者重新同步的周期\n\tresyncPeriod time.Duration\n\t// 判断是否满足可以重新同步的条件\n\tShouldResync func() bool\n\t\n\tclock clock.Clock\n\t\n\t// 是否要进行分页 List\n\tpaginatedResult bool\n\t\n\t// 最后同步的资源版本号，以此为依据，watch 只会监听大于此值的资源\n\tlastSyncResourceVersion string\n\t// 最后同步的资源版本号是否可用\n\tisLastSyncResourceVersionUnavailable bool\n\t// 加把锁控制版本号\n\tlastSyncResourceVersionMutex sync.RWMutex\n\t\n\t// 每页大小\n\tWatchListPageSize int64\n\t// watch 失败回调 handler\n\twatchErrorHandler WatchErrorHandler\n}\n</code></pre> \n <p>从结构体定义可以看到，通过指定目标资源类型进行 ListAndWatch，并可进行分页相关设置。</p> \n <p>第一次拉取全量资源(目标资源类型) 后通过 syncWith 函数全量替换(Replace) 到 DeltaFIFO queue/items 中，之后通过持续监听 Watch(目标资源类型) 增量事件，并去重更新到 DeltaFIFO queue/items 中，等待被消费。</p> \n <p>watch 目标类型通过 Go reflect 反射实现如下：</p> \n <pre><code class=\"language-js\">// staging/src/k8s.io/client-go/tools/cache/reflector.go\n// watchHandler watches w and keeps *resourceVersion up to date.\nfunc (r *Reflector) watchHandler(start time.Time, w watch.Interface, resourceVersion *string, errc chan error, stopCh &lt;-chan struct{}) error {\n\n\t...\n\tif r.expectedType != nil {\n\t\tif e, a := r.expectedType, reflect.TypeOf(event.Object); e != a {\n\t\t\tutilruntime.HandleError(fmt.Errorf(\"%s: expected type %v, but watch event object had type %v\", r.name, e, a))\n\t\t\tcontinue\n\t\t}\n\t}\n\tif r.expectedGVK != nil {\n\t\tif e, a := *r.expectedGVK, event.Object.GetObjectKind().GroupVersionKind(); e != a {\n\t\t\tutilruntime.HandleError(fmt.Errorf(\"%s: expected gvk %v, but watch event object had gvk %v\", r.name, e, a))\n\t\t\tcontinue\n\t\t}\n\t}\n\t...\n}\n</code></pre> \n <blockquote> \n  <p>通过反射确认目标资源类型，所以命名为 Reflector 还是比较贴切的； List/Watch 的目标资源类型在 NewSharedIndexInformer.ListerWatcher 进行了确定，但 Watch 还会在 watchHandler 中再次比较一下目标类型；</p> \n </blockquote> \n <h2 id=\"认识-deltafifo\">认识 DeltaFIFO</h2> \n <p>还是先看下 DeltaFIFO 结构体定义：</p> \n <pre><code class=\"language-js\">// staging/src/k8s.io/client-go/tools/cache/delta_fifo.go\ntype DeltaFIFO struct {\n\t// 读写锁、条件变量\n\tlock sync.RWMutex\n\tcond sync.Cond\n\n\t// kv 存储：objKey1-&gt;Deltas[obj1-Added, obj1-Updated...]\n\titems map[string]Deltas\n\n\t// 只存储所有 objKeys\n\tqueue []string\n\n\t// 是否已经填充：通过 Replace() 接口将第一批对象放入队列，或者第一次调用增、删、改接口时标记为true\n\tpopulated bool\n\t// 通过 Replace() 接口将第一批对象放入队列的数量\n\tinitialPopulationCount int\n\n\t// keyFunc 用来从某个 obj 中获取其对应的 objKey\n\tkeyFunc KeyFunc\n\n\t// 已知对象，其实就是 Indexer\n\tknownObjects KeyListerGetter\n\n\t// 队列是否已经关闭\n\tclosed bool\n\n\t// 以 Replaced 类型发送(为了兼容老版本的 Sync)\n\temitDeltaTypeReplaced bool\n}\n</code></pre> \n <p>DeltaType 可分为以下类型：</p> \n <pre><code class=\"language-js\">// staging/src/k8s.io/client-go/tools/cache/delta_fifo.go\ntype DeltaType string\n\nconst (\n\tAdded   DeltaType = \"Added\"\n\tUpdated DeltaType = \"Updated\"\n\tDeleted DeltaType = \"Deleted\"\n\tReplaced DeltaType = \"Replaced\" // 第一次或重新同步\n\tSync DeltaType = \"Sync\" // 老版本重新同步叫 Sync\n)\n</code></pre> \n <p>通过上面的 Reflector 分析可以知道，DeltaFIFO 的职责是通过队列加锁处理(queueActionLocked)、去重(dedupDeltas)、存储在由 DeltaFIFO 实现的本地缓存(local Store) 中，包括 queue(仅存 objKeys) 和 items(存 objKeys 和对应的 Deltas 增量变化)，并通过 Pop 不断消费，通过 Process(item) 处理相关逻辑。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210914180751630-607348081.png\" alt=\"\" loading=\"lazy\">（K8s-DeltaFIFO）</p> \n <h2 id=\"索引-indexer\">索引 Indexer</h2> \n <p>上一步 ListAndWatch 到的资源已经存储到 DeltaFIFO 中，接着调用 Pop 从队列进行消费。实际使用中，Process 处理函数由 sharedIndexInformer.HandleDeltas 进行实现。HandleDeltas 函数根据上面不同的 DeltaType 分别进行 Add/Update/Delete，并同时创建、更新、删除对应的索引。</p> \n <p>具体索引实现如下：</p> \n <pre><code class=\"language-js\">// staging/src/k8s.io/client-go/tools/cache/index.go\n// map 索引类型 =&gt; 索引函数\ntype Indexers map[string]IndexFunc\n\n// map 索引类型 =&gt; 索引值 map\ntype Indices map[string]Index\n\n// 索引值 map: 由索引函数计算所得索引值(indexedValue) =&gt; [objKey1, objKey2...]\ntype Index map[string]sets.String\n</code></pre> \n <p>索引函数(IndexFunc)：就是计算索引的函数，这样允许扩展多种不同的索引计算函数。默认也是最常用的索引函数是：<code>MetaNamespaceIndexFunc</code>。</p> \n <p>索引值(indexedValue)：有些地方叫 indexKey，表示由索引函数(IndexFunc) 计算出来的索引值(如 ns1)。</p> \n <p>对象键(objKey)：对象 obj 的 唯一 key(如 ns1/pod1)，与某个资源对象一一对应。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210914180751937-573852130.png\" alt=\"\" loading=\"lazy\">（K8s-indexer）</p> \n <p>可以看到，Indexer 由 ThreadSafeStore 接口集成，最终由 threadSafeMap 实现。</p> \n <blockquote> \n  <p>索引函数 IndexFunc(如 MetaNamespaceIndexFunc)、KeyFunc(如 MetaNamespaceKeyFunc) 区别：前者表示如何计算索引，后者表示如何获取对象键(objKey)； 索引键(indexKey，有些地方是 indexedValue)、对象键(objKey) 区别：前者表示由索引函数(IndexFunc) 计算出来的索引键(如 ns1)，后者则是 obj 的 唯一 key(如 ns1/pod1)；</p> \n </blockquote> \n <h2 id=\"总管家-controller\">总管家 Controller</h2> \n <p>Controller 作为核心中枢，集成了上面的组件 Reflector、DeltaFIFO、Indexer、Store，成为连接下游消费者的桥梁。</p> \n <p>Controller 由 controller 结构体进行具体实现：</p> \n <blockquote> \n  <p>在 K8s 中约定俗成：大写定义的 interface 接口，由对应小写定义的结构体进行实现。</p> \n </blockquote> \n <pre><code class=\"language-js\">// staging/src/k8s.io/client-go/tools/cache/controller.go\ntype controller struct {\n\tconfig         Config\n\treflector      *Reflector // 上面已分析的组件\n\treflectorMutex sync.RWMutex\n\tclock          clock.Clock\n}\n\ntype Config struct {\n\t// 实际由 DeltaFIFO 实现\n\tQueue\n\n\t// 构造 Reflector 需要\n\tListerWatcher\n\n\t// Pop 出来的 obj 处理函数\n\tProcess ProcessFunc\n\n\t// 目标对象类型\n\tObjectType runtime.Object\n\n\t// 全量重新同步周期\n\tFullResyncPeriod time.Duration\n\n\t// 是否进行重新同步的判断函数\n\tShouldResync ShouldResyncFunc\n\n\t// 如果为 true，Process() 函数返回 err，则再次入队 re-queue\n\tRetryOnError bool\n\n\t// Watch 返回 err 的回调函数\n\tWatchErrorHandler WatchErrorHandler\n\n\t// Watch 分页大小\n\tWatchListPageSize int64\n}\n</code></pre> \n <p>Controller 中以 goroutine 协程方式启动 Run 方法，会启动 Reflector 的 ListAndWatch()，用于从 apiserver 拉取全量和监听增量资源，存储到 DeltaFIFO。接着，启动 processLoop 不断从 DeltaFIFO Pop 进行消费。在 sharedIndexInformer 中 Pop 出来进行处理的函数是 HandleDeltas，一方面维护 Indexer 的 Add/Update/Delete，另一方面调用下游 sharedProcessor 进行 handler 处理。</p> \n <h2 id=\"启动-sharedinformer\">启动 SharedInformer</h2> \n <p>SharedInformer 接口由 SharedIndexInformer 进行集成，由 sharedIndexInformer(这里看到了吧，又是大写定义的 interface 接口，由对应小写定义的结构体进行实现) 进行实现。</p> \n <p>看一下结构体定义：</p> \n <pre><code class=\"language-js\">// staging/src/k8s.io/client-go/tools/cache/shared_informer.go\ntype SharedIndexInformer interface {\n\tSharedInformer\n\t// AddIndexers add indexers to the informer before it starts.\n\tAddIndexers(indexers Indexers) error\n\tGetIndexer() Indexer\n}\n\ntype sharedIndexInformer struct {\n\tindexer    Indexer\n\tcontroller Controller\n\n\t// 处理函数，将是重点\n\tprocessor *sharedProcessor\n\n\t// 检测 cache 是否有变化，一把用作调试，默认是关闭的\n\tcacheMutationDetector MutationDetector\n\n\t// 构造 Reflector 需要\n\tlisterWatcher ListerWatcher\n\n\t// 目标类型，给 Reflector 判断资源类型\n\tobjectType runtime.Object\n\n\t// Reflector 进行重新同步周期\n\tresyncCheckPeriod time.Duration\n\n\t// 如果使用者没有添加 Resync 时间，则使用这个默认的重新同步周期\n\tdefaultEventHandlerResyncPeriod time.Duration\n\tclock                           clock.Clock\n\n\t// 两个 bool 表达了三个状态：controller 启动前、已启动、已停止\n\tstarted, stopped bool\n\tstartedLock      sync.Mutex\n\n\t// 当 Pop 正在消费队列，此时新增的 listener 需要加锁，防止消费混乱\n\tblockDeltas sync.Mutex\n\n\t// Watch 返回 err 的回调函数\n\twatchErrorHandler WatchErrorHandler\n}\n\ntype sharedProcessor struct {\n\tlistenersStarted bool\n\tlistenersLock    sync.RWMutex\n\tlisteners        []*processorListener\n\tsyncingListeners []*processorListener // 需要 sync 的 listeners\n\tclock            clock.Clock\n\twg               wait.Group\n}\n</code></pre> \n <p>从结构体定义可以看到，通过集成的 controller(上面已分析) 进行 Reflector ListAndWatch，并存储到 DeltaFIFO，并启动 Pop 消费队列，在 sharedIndexInformer 中 Pop 出来进行处理的函数是 HandleDeltas。</p> \n <p>所有的 listeners 通过 sharedIndexInformer.AddEventHandler 加入到 processorListener 数组切片中，并通过判断当前 controller 是否已启动做不同处理如下：</p> \n <pre><code class=\"language-js\">// staging/src/k8s.io/client-go/tools/cache/shared_informer.go\nfunc (s *sharedIndexInformer) AddEventHandlerWithResyncPeriod(handler ResourceEventHandler, resyncPeriod time.Duration) {\n\t...\n\n\t// 如果还没有启动，则直接 addListener 加入即可返回\n\tif !s.started {\n\t\ts.processor.addListener(listener)\n\t\treturn\n\t}\n\n\t// 加锁控制\n\ts.blockDeltas.Lock()\n\tdefer s.blockDeltas.Unlock()\n\n\ts.processor.addListener(listener)\n\t\n\t// 遍历所有对象，发送到刚刚新加入的 listener\n\tfor _, item := range s.indexer.List() {\n\t\tlistener.add(addNotification{newObj: item})\n\t}\n}\n</code></pre> \n <p>接着，在 HandleDeltas 中，根据 obj 的 Delta 类型(Added/Updated/Deleted/Replaced/Sync) 调用 sharedProcessor.distribute 给所有监听 listeners 处理。</p> \n <h2 id=\"注册-sharedinformerfactory\">注册 SharedInformerFactory</h2> \n <p>SharedInformerFactory 作为使用 SharedInformer 的工厂类，提供了高内聚低耦合的工厂类设计模式，其结构体定义如下：</p> \n <pre><code class=\"language-js\">// staging/src/k8s.io/client-go/informers/factory.go\ntype SharedInformerFactory interface {\n\tinternalinterfaces.SharedInformerFactory // 重点内部接口\n\tForResource(resource schema.GroupVersionResource) (GenericInformer, error)\n\tWaitForCacheSync(stopCh &lt;-chan struct{}) map[reflect.Type]bool\n\n\tAdmissionregistration() admissionregistration.Interface\n\tInternal() apiserverinternal.Interface\n\tApps() apps.Interface\n\tAutoscaling() autoscaling.Interface\n\tBatch() batch.Interface\n\tCertificates() certificates.Interface\n\tCoordination() coordination.Interface\n\tCore() core.Interface\n\tDiscovery() discovery.Interface\n\tEvents() events.Interface\n\tExtensions() extensions.Interface\n\tFlowcontrol() flowcontrol.Interface\n\tNetworking() networking.Interface\n\tNode() node.Interface\n\tPolicy() policy.Interface\n\tRbac() rbac.Interface\n\tScheduling() scheduling.Interface\n\tStorage() storage.Interface\n}\n\n// staging/src/k8s.io/client-go/informers/internalinterfaces/factory_interfaces.go\ntype SharedInformerFactory interface {\n\tStart(stopCh &lt;-chan struct{}) // 启动 SharedIndexInformer.Run\n\tInformerFor(obj runtime.Object, newFunc NewInformerFunc) cache.SharedIndexInformer // 目标类型初始化\n}\n</code></pre> \n <p>以 PodInformer 为例，说明使用者如何构建自己的 Informer，PodInformer 定义如下：</p> \n <pre><code class=\"language-js\">// staging/src/k8s.io/client-go/informers/core/v1/pod.go\ntype PodInformer interface {\n\tInformer() cache.SharedIndexInformer\n\tLister() v1.PodLister\n}\n\n由小写的 podInformer 实现(又看到了吧，大写接口小写实现的 K8s 风格)：\n\ntype podInformer struct {\n\tfactory          internalinterfaces.SharedInformerFactory\n\ttweakListOptions internalinterfaces.TweakListOptionsFunc\n\tnamespace        string\n}\n\nfunc (f *podInformer) defaultInformer(client kubernetes.Interface, resyncPeriod time.Duration) cache.SharedIndexInformer {\n\treturn NewFilteredPodInformer(client, f.namespace, resyncPeriod, cache.Indexers{cache.NamespaceIndex: cache.MetaNamespaceIndexFunc}, f.tweakListOptions)\n}\n\nfunc (f *podInformer) Informer() cache.SharedIndexInformer {\n\treturn f.factory.InformerFor(&amp;corev1.Pod{}, f.defaultInformer)\n}\n\nfunc (f *podInformer) Lister() v1.PodLister {\n\treturn v1.NewPodLister(f.Informer().GetIndexer())\n}\n</code></pre> \n <p>由使用者传入目标类型(&amp;corev1.Pod{})、构造函数(defaultInformer)，调用 SharedInformerFactory.InformerFor 实现目标 Informer 的注册，然后调用 SharedInformerFactory.Start 进行 Run，就启动了上面分析的 SharedIndexedInformer -&gt; Controller -&gt; Reflector -&gt; DeltaFIFO 流程。</p> \n <blockquote> \n  <p>通过使用者自己传入目标类型、构造函数进行 Informer 注册，实现了 SharedInformerFactory 高内聚低耦合的设计模式。</p> \n </blockquote> \n <h2 id=\"回调-processorlistener\">回调 processorListener</h2> \n <p>所有的 listerners 由 processorListener 实现，分为两组：listeners, syncingListeners，分别遍历所属组全部 listeners，将数据投递到 processorListener 进行处理。</p> \n <blockquote> \n  <p>因为各 listeners 设置的 resyncPeriod 可能不一致，所以将没有设置(resyncPeriod = 0) 的归为 listeners 组，将设置了 resyncPeriod 的归到 syncingListeners 组； 如果某个 listener 在多个地方(sharedIndexInformer.resyncCheckPeriod, sharedIndexInformer.AddEventHandlerWithResyncPeriod)都设置了 resyncPeriod，则取最小值 minimumResyncPeriod；</p> \n </blockquote> \n <pre><code class=\"language-js\">// staging/src/k8s.io/client-go/tools/cache/shared_informer.go\nfunc (p *sharedProcessor) distribute(obj interface{}, sync bool) {\n\tp.listenersLock.RLock()\n\tdefer p.listenersLock.RUnlock()\n\n\tif sync {\n\t\tfor _, listener := range p.syncingListeners {\n\t\t\tlistener.add(obj)\n\t\t}\n\t} else {\n\t\tfor _, listener := range p.listeners {\n\t\t\tlistener.add(obj)\n\t\t}\n\t}\n}\n</code></pre> \n <p>从代码可以看到 processorListener 巧妙地使用了两个 channel(addCh, nextCh) 和一个 pendingNotifications(由 slice 实现的滚动 Ring) 进行 buffer 缓冲，默认的 initialBufferSize = 1024。既做到了高效传递数据，又不阻塞上下游处理，值得学习。</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210914180752147-1317551307.png\" alt=\"\" loading=\"lazy\">（K8s-processorListener）</p> \n <h2 id=\"workqueue-忙起来\">workqueue 忙起来</h2> \n <p>通过上一步 processorListener 回调函数，交给内部 ResourceEventHandler 进行真正的增删改(CUD) 处理，分别调用 OnAdd/OnUpdate/OnDelete 注册函数进行处理。</p> \n <p>为了快速处理而不阻塞 processorListener 回调函数，一般使用 workqueue 进行异步化解耦合处理，其实现如下：</p> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210914180752408-572666059.png\" alt=\"\" loading=\"lazy\">（K8s-workqueue）</p> \n <p>从图中可以看到，workqueue.RateLimitingInterface 集成了 DelayingInterface，DelayingInterface 集成了 Interface，最终由 rateLimitingType 进行实现，提供了 rateLimit 限速、delay 延时入队(由优先级队列通过小顶堆实现)、queue 队列处理 三大核心能力。</p> \n <p>另外，在代码中可看到 K8s 实现了三种 RateLimiter：BucketRateLimiter, ItemExponentialFailureRateLimiter, ItemFastSlowRateLimiter，Controller 默认采用了前两种如下：</p> \n <pre><code class=\"language-js\">// staging/src/k8s.io/client-go/util/workqueue/default_rate_limiters.go\nfunc DefaultControllerRateLimiter() RateLimiter {\n\treturn NewMaxOfRateLimiter(\n\t\tNewItemExponentialFailureRateLimiter(5*time.Millisecond, 1000*time.Second),\n\t\t// 10 qps, 100 bucket size.  This is only for retry speed and its only the overall factor (not per item)\n\t\t&amp;BucketRateLimiter{Limiter: rate.NewLimiter(rate.Limit(10), 100)},\n\t)\n}\n</code></pre> \n <p>这样，在用户侧可以通过调用 workqueue 相关方法进行灵活的队列处理，比如失败多少次就不再重试，失败了延时入队的时间控制，队列的限速控制(QPS)等，实现非阻塞异步化逻辑处理。</p> \n <h2 id=\"小结\">小结</h2> \n <p>本文通过分析 K8s 中 Reflector(反射器)、DeletaFIFO(增量队列)、Indexer(索引器)、Controller(控制器)、SharedInformer(共享资源通知器)、processorListener(事件监听处理器)、workqueue(事件处理工作队列) 等组件，对 Informer 实现机制进行了解析，通过源码、图文方式说明了相关流程处理，以期更好的理解 K8s Informer 运行流程。</p> \n <p>可以看到，K8s 为了实现高效、非阻塞的核心流程，大量采用了 goroutine 协程、channel 通道、queue 队列、index 索引、map 去重等方式；并通过良好的接口设计模式，给使用者开放了很多扩展能力；采用了统一的接口与实现的命名方式等，这些都值得深入学习与借鉴。</p> \n <p><em>PS: 更多内容请关注</em><br> k8s-club GitHub地址：<a href=\"https://github.com/k8s-club/k8s-club\" target=\"_blank\" rel=\"noopener\">https://github.com/k8s-club/k8s-club</a></p> \n <h3 id=\"参考资料\">参考资料</h3> \n <p>[1] Kubernetes 官方文档：【<a href=\"https://kubernetes.io/%E3%80%91\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/】</a></p> \n <p>[2] Kubernetes 源码：【<a href=\"https://github.com/kubernetes/kubernetes%E3%80%91\" target=\"_blank\" rel=\"noopener\">https://github.com/kubernetes/kubernetes】</a></p> \n <p>[3] Kubernetes Architectural Roadmap：【<a href=\"https://github.com/kubernetes/community/blob/master/contributors/design-proposals/architecture/architectural-roadmap.md%E3%80%91\" target=\"_blank\" rel=\"noopener\">https://github.com/kubernetes/community/blob/master/contributors/design-proposals/architecture/architectural-roadmap.md】</a></p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210914180752774-467467857.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"381","createTime":"2021-09-08 17:44","comment":"0","id":"15243826","title":"云原生 AI 前沿：Kubeflow Training Operator 统一云上 AI 训练","url":"https://www.cnblogs.com/tencent-cloud-native/p/15243826.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"分布式训练与-kubeflow\">分布式训练与 Kubeflow</h2> \n <p>当开发者想要讲深度学习的分布式训练搬上 Kubernetes 集群时，首先想到的往往就是 Kubeflow 社区中形形色色的 operators，如 tf-operator、mpi-operator。</p> \n <p>这些服务于各种深度学习训练（TensorFlow、PyTorch、MXNet 等）的 operators <strong>主要的工作包括</strong>：</p> \n <ol> \n  <li>在 Kubernetes 集群上创建 Pod 以拉起各个训练进程</li> \n  <li>配置用作服务发现的信息（如 <code>TF_CONFIG</code>）以及创建相关 Kubernetes 资源（如 Service）</li> \n  <li>监控并更新整个任务的状态</li> \n </ol> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210908174412387-1365620815.png\" alt=\"\" loading=\"lazy\"></p> \n <p>事实上，<strong>Kubeflow 的训练 Operators 已经成为在 Kubernetes 上运行分布式训练任务的实际标准</strong>。</p> \n <p>不仅各大公有云厂商都已经基本收录或集成了 Kubeflow 的训练 operators，社区上其他与深度学习训练相关的项目（如用以自动机器学习的 Katib，又如提供自动化编排功能的 Flyte）都对接了 Kubeflow 中的 operators 作为下发创建分布式训练任务的工具。</p> \n <h2 id=\"kubeflow-operators-的问题\">Kubeflow Operators 的问题</h2> \n <p>在 2019 年初，Kubeflow 社区启动了 kubeflow/common 项目用以维护 operator 之间重复使用的部分代码。经过一年多的迭代和重构，在 2020 年中该项目<strong>逐渐稳定并开始接入训练 operator</strong> 。当前，tf-operator、mxnet-operator 和 xgboost-operator 即为构建在 kubeflow/common 项目之上的训练 operators。</p> \n <p>然而，整个 Kubeflow 训练 operators 的项目维护依然存在许多挑战。</p> \n <p><strong>主要包括</strong>：</p> \n <ol> \n  <li>大量开发者的精力耗费在针对不同训练框架的功能增强和故障修复上</li> \n  <li>难以将测试和发布的基础功能与服务在不同 operators 之间复用</li> \n  <li>第三方组件需要对接大量不同的 operators</li> \n  <li>新的训练框架需要开发完整的对应的 operator 才能使用，开发成本过高</li> \n  <li>众多的 operators 对刚刚接触 Kubeflow 的新人开发者而言学习成本过高</li> \n </ol> \n <p>以上问题都是 Kubeflow 的开发者和维护者面对的。除此之外，<strong>这些 operator 的使用者同样面临一些问题</strong>：</p> \n <ol> \n  <li>用户需要安装多个 operator 组件才能支持多种训练 APIs</li> \n  <li>各种 Kubeflow Jobs 的 JobSpec 看上去很类似，但是又有些许不同，并没有提供统一的使用体验</li> \n </ol> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210908174412614-483980840.png\" alt=\"\" loading=\"lazy\"></p> \n <p>这问题的原因主要在于<strong>每个深度学习框架都对应一个的 operator 独立在一个 repository 中进行维护</strong>。这种分开维护的模式使得诸如构建环境、测试环境、部署方式以及代码逻辑都无法做到很好的整合。</p> \n <p>尽管深度学习框架的数量处在收敛的过程中，但依然会有源源不断的新框架希望通过 Kubeflow 可以快速接入 Kubernetes 进行分布式训练，而这些新的增量使得问题变得更为严重。</p> \n <h2 id=\"proposalall-in-one\">Proposal：All-in-One</h2> \n <p>针对上面提到的各项问题，经过社区会议的多次讨论，决定尝试<strong>通过融合的方式将多个 Kubeflow 的训练 operator 代码汇聚到一个仓库</strong>。</p> \n <p>同时，参照 controller-runtime 中推荐的 One-Manager-Multi-Controller 的模式，让多个处理不同 API 的 controller 可以共享一个 Manager 及其 cache，在<strong>简化代码的同时也减少了在多个 operator 同时部署时冗余的 APIServer 请求</strong>：</p> \n <pre><code>    mgr, err := ctrl.NewManager(ctrl.GetConfigOrDie(), ctrl.Options{...})\n    ...\n    for _, s := range enabledSchemes {\n        setupFunc, supported := controller_v1.SupportedSchemeReconciler[s]\n        if !supported {os.Exit(1)}\n        if err = setupFunc(mgr, enableGangScheduling); err != nil {\n            setupLog.Error(err, \"unable to create controller\", \"controller\", s)\n            os.Exit(1)\n        }\n    }\n</code></pre> \n <p>所有的 Controller（Reconciler）都需要向 <code>SupportedSchemeReconciler</code> 提前完成注册：</p> \n <pre><code>var SupportedSchemeReconciler = map[string]ReconcilerSetupFunc{\n    tensorflowv1.Kind: func(mgr manager.Manager, enableGangScheduling bool) error {\n        return tensorflowcontroller.NewReconciler(mgr, enableGangScheduling).SetupWithManager(mgr)\n    },\n    pytorchv1.Kind: func(mgr manager.Manager, enableGangScheduling bool) error {\n        return pytorchcontroller.NewReconciler(mgr, enableGangScheduling).SetupWithManager(mgr)\n    },\n    ...,\n}\n</code></pre> \n <p>用户可以在启动 operator 进程时通过 <code>--enable-scheme</code> 来指定需要开启支持的 API。后续有新的 Controller 接入，按照这种“<strong>先注册后启动</strong>”的方式来选择性地开启对应的 controllers。</p> \n <h2 id=\"进展与近期规划\">进展与近期规划</h2> \n <p><strong>当前融合已经正式并入 tf-operator 的 master 分支</strong>。用户很快可以在即将发布的 Kubeflow 1.4 Release 中体验到融合后的 tf-operator：部署单个 operator 即可支持包括 TFJob、PyTorchJob、MXNetJob 和 XGBoostJob 在内的四种 API 支持。</p> \n <p><strong>在代码仓库层面的融合是 Kubeflow Training Operator 迈向下一个阶段的第一步</strong>。这一步更多地解决了在项目运营层面，包括环境复用、整体代码管理上的一致性。而针对开发者的低代码开发，包括<strong>新功能增强、bug 修复和新 API 接入</strong>，将是我们规划的下一步目标。</p> \n <p>根据这样的设计，开发者只需要修改非常有限的几个函数即可接入新的 API。</p> \n <p><strong>主要包括</strong>：</p> \n <pre><code>// 根据 ctrl.Request 获取对应的自定义 Job\nGetJob(ctx context.Context, req ctrl.Request) (client.Object, error)\n// 从自定义 Job 中以 map[commonv1.ReplicaType]*commonv1.ReplicaSpec 的格式抽取 ReplicasSpecs\nExtractReplicasSpec(job client.Object) (map[commonv1.ReplicaType]*commonv1.ReplicaSpec, error)\n// 从自定义 Job 中抽取 RunPolicy\nExtractRunPolicy(job client.Object) (*commonv1.RunPolicy, error)\n// 从自定义 Job 中抽取 JobStatus\nExtractJobStatus(job client.Object) (*commonv1.JobStatus, error)\n</code></pre> \n <p><img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210908174412851-1589841316.png\" alt=\"\" loading=\"lazy\"></p> \n <p>开发者如果需要注入一些用以服务发现的环境变量，可以覆盖方法 <code>DecoratePod(rtype commonv1.ReplicaType, podTemplate *corev1.PodTemplateSpec, job client.Object)</code> 在 client 向 APIServer 提交创建请求前修改 Pod。</p> \n <p>以上低代码开发方式的基础已经以 <code>pkg/reconciler.v1</code> 的形态<a href=\"https://github.com/kubeflow/common/pull/141\" title=\"合入\" target=\"_blank\" rel=\"noopener\">合入</a> <a href=\"https://github.com/kubeflow/common/tree/master/pkg/reconciler.v1/common\" title=\"kubeflow/common\" target=\"_blank\" rel=\"noopener\">kubeflow/common</a> 仓库。很快，我们也将在 tf-operator 上引入基于该 <code>reconciler.v1</code> 包的基础 API，希望可以在验证 <code>reconciler.v1</code> 的同时为更多通用的实用案例提供一种更为简便接入 Kubernetes 的方式。</p> \n <p>如果开发者希望以更低层 API 的方式对 controller 进行开发，<code>pkg/controller.v1</code> 包可以满足这一类开发者的需求。</p> \n <h2 id=\"远景展望\">远景展望</h2> \n <p>尽管针对 Kubeflow Training Operator 的优化改造还在进行中，我们并没有止步于此。对于 Training Operator 的未来的发展，我们认为存在以下几个领域值得持续投入：</p> \n <ol> \n  <li><strong>首先</strong>是进一步提高 Kubeflow Training Operator 适配定制化需求 Job 时的灵活性。我们计划提出与深度学习训练框架解耦的一种 Job API 以支持更广泛的任务定义，并允许用户可以借助 kubeflow/common 中的 controller.v1 和 reconciler.v1 进行定制化开发，但其学习成本和开发成本依然过高。甚至在将来，初级开发者可以不修改 operator 而仅仅添加/修改一些 webhook 或是 decorator server 来实现定制化修改。</li> \n  <li><strong>第二个方面</strong>是进一步增强 Kubeflow Training Operator 和其他第三方组件交互时的便利性。我们希望未来利用 Kubeflow Training Operator 来构建 AI 平台的开发者可以方便地将其与其他模块对接，实现诸如任务队列、流水线、超参数搜索等功能。</li> \n  <li><strong>最后也是最关键的</strong>，我们依然希望可以进一步提升 Kubeflow Training Operator 的稳定性。</li> \n </ol> \n <p>我们欢迎更多的同学能够尝试、体验 Kubeflow 并且投入到 Kubeflow 项目中来。</p> \n <p>参考资料</p> \n <p>[1]add reconciler.v1: 【<a href=\"https://github.com/kubeflow/common/pull/141%E3%80%91\" target=\"_blank\" rel=\"noopener\">https://github.com/kubeflow/common/pull/141】</a></p> \n <p>[2]<br> reconciler.v1 implementation: 【<a href=\"https://github.com/kubeflow/common/tree/master/pkg/reconciler.v1/common%E3%80%91\" target=\"_blank\" rel=\"noopener\">https://github.com/kubeflow/common/tree/master/pkg/reconciler.v1/common】</a></p> \n <p>[3] All-in-one Kubeflow Training Operator: 【<a href=\"https://docs.google.com/document/d/1x1JPDQfDMIbnoQRftDH1IzGU0qvHGSU4W6Jl4rJLPhI/edit%E3%80%91\" target=\"_blank\" rel=\"noopener\">https://docs.google.com/document/d/1x1JPDQfDMIbnoQRftDH1IzGU0qvHGSU4W6Jl4rJLPhI/edit】</a></p> \n <h2 id=\"关于我们\">关于我们</h2> \n <p>更多关于云原生的案例和知识，可关注同名【腾讯云原生】公众号~</p> \n <p>福利：公众号后台回复【手册】，可获得《腾讯云原生路线图手册》&amp;《腾讯云原生最佳实践》~</p> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210908174413394-1152670306.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
{"read":"377","createTime":"2021-09-08 10:20","comment":"0","id":"15241551","title":"十大云原生最佳用户案例实践，你最喜欢哪篇","url":"https://www.cnblogs.com/tencent-cloud-native/p/15241551.html","content":"<div id=\"cnblogs_post_body\" class=\"blogpost-body cnblogs-markdown\"> \n <h2 id=\"腾讯云原生\">腾讯云原生</h2> \n <p>腾讯云原生产品体系和架构已非常完善，涵盖了软件研发流程、计算资源、架构框架、数据存储和处理、安全等五大领域的多个场景。依托这些云原生产品，我们正在为不同行业、不同规模和不同发展阶段的数十万家客户提供云原生服务。</p> \n <h2 id=\"让用云更简单\">让用云“更简单”</h2> \n <p>在服务这些客户的同时，我们进一步明确了腾讯云原生的定位，就是成为企业数字化的助推器，<strong>让用云“更简单”</strong>。</p> \n <p>企业用云的目的归根到底，还是在于利用云厂商在技术和资源这里的规模化效应，<strong>降低企业成本，提高企业的效率</strong>。</p> \n <p>企业为什么要用云？企业用云之后，对企业有什么改变，产生了什么效果？</p> \n <p>为解决大家的疑问，小云“熬秃了头”，给大家整理出近期<strong>腾讯云的十大最佳实践案例</strong>，一起来看看吧！</p> \n <h2 id=\"容器案例\">容器案例</h2> \n <h4 id=\"完爆用边缘容器竟能秒级实现团队七八人一周的工作量\"><a href=\"https://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247488702&amp;idx=1&amp;sn=7e1b0b3c25a19a36221d2f31136bbb04&amp;scene=21#wechat_redirect\" target=\"_blank\" rel=\"noopener\">完爆！用边缘容器，竟能秒级实现团队七八人一周的工作量</a></h4> \n <ul> \n  <li>云端管控、边缘计算、处于局域网内的微服务如何做Devops呢？腾讯优图业务是结合了腾讯云边缘容器TKE@edge来做服务Devops， 并对服务做了自定义定制， 以支持相应的业务场景。</li> \n </ul> \n <h4 id=\"腾讯wemake工业互联网平台的边缘容器化实践打造更高效的工业互联网\"><a href=\"https://mp.weixin.qq.com/s?__biz=MzkzNDE3MTc4OA==&amp;mid=2247486834&amp;idx=1&amp;sn=b6ea1b347410373d1b387f24617a678a&amp;scene=21#wechat_redirect\" target=\"_blank\" rel=\"noopener\">腾讯WeMake工业互联网平台的边缘容器化实践：打造更高效的工业互联网</a></h4> \n <ul> \n  <li>腾讯WeMake工业互联网平台基于强大的数据、算力、算法与连接能力，并叠加上大量的工业Know-how, 机理模型与OT技术，搭建了一套强大的工业互联网平台架构。</li> \n </ul> \n <h4 id=\"微众银行案例容器化实践在金融行业落地面临的问题和挑战\"><strong><a href=\"http://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247490694&amp;idx=1&amp;sn=bdcd29b1840fd35ba895167787be84df&amp;chksm=c007a75cf7702e4a546cffe74e8dac40c283a64c4f920cc69d8f237394b2b357f1fac03406aa#rd\" target=\"_blank\" rel=\"noopener\">微众银行案例｜容器化实践在金融行业落地面临的问题和挑战</a></strong></h4> \n <ul> \n  <li>本文整理自<strong>微众银行容器负责人陈广镇和李焕</strong> 在 Techo 开发者大会云原生专题的分享内容——微众容器化实践。本文主要和大家介绍微众的容器化实践，具体分为三个部分：<strong>里程碑、实践之路，以及未来的规划</strong>。</li> \n </ul> \n <h4 id=\"让不确定性变得有弹性基于弹性容器的ai评测实践\"><strong><a href=\"http://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247487126&amp;idx=1&amp;sn=ccc0a9f84f9d03173b9957a398ed896a&amp;chksm=c007b54cf7703c5a3ef786ef85d8b689a606d88ebb2d131dccd1c03d44b16fbd109a8ada376c#rd\" target=\"_blank\" rel=\"noopener\">让“不确定性”变得有“弹性”？基于弹性容器的AI评测实践</a></strong></h4> \n <ul> \n  <li>AI的场景丰富多彩，AI的评价方法百花齐放，这对于设计一套更通用的评测框架来说是一个极大的挑战。本文分享了我们在AI评测路上的一些实践经验，重点介绍了我们在解决执行环境的不确定性方面所做的一些尝试。</li> \n </ul> \n <h4 id=\"案例--腾讯广告-ams-的容器化之路\"><a href=\"http://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247509671&amp;idx=1&amp;sn=056034209aebc7ca9fda48075ed0e660&amp;chksm=c0041d7df773946bcfc4f7ba5ae6a74d5fab6422dabc5a8f33a173f8061342d5af52ec0347ec#rd\" target=\"_blank\" rel=\"noopener\">案例 | 腾讯广告 AMS 的容器化之路</a></h4> \n <ul> \n  <li>腾讯广告承载了整个腾讯的广告流量，并且接入了外部联盟的请求，在所有流量日益增大的场景下，流量突增后如何快速调配资源甚至自动调度，都成为了广告团队所需要考虑的问题。</li> \n </ul> \n <h4 id=\"揭秘日活千万腾讯会议全量云原生化上tke技术实践\"><a href=\"http://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247485232&amp;idx=1&amp;sn=7252e5bf54204050e3527934e2c87815&amp;chksm=c007bceaf77035fcaf75f7c3a56715433a6af541cc4e072fc1114fe1ec40139184eb0d47c8e7#rd\" target=\"_blank\" rel=\"noopener\">揭秘日活千万腾讯会议全量云原生化上TKE技术实践</a></h4> \n <ul> \n  <li>腾讯会议，一款联合国都Pick的线上会议解决方案，提供完美会议品质和灵活协作空间，广泛应用在政府、医疗、教育、企业等各个行业。大家从文章<strong>8天扩容100万核，腾讯会议是如何做到的？</strong></li> \n </ul> \n <h4 id=\"云巢揭秘-基于-tke-构建数据库-paas-平台实践分享\"><a href=\"http://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247509536&amp;idx=1&amp;sn=8a735ac857fa864299e7be7847227458&amp;chksm=c0041dfaf77394ec8ac6b7e8a9a18ad5dac0a430cec411e0ec4cbed8788224c19f7087b6ddde#rd\" target=\"_blank\" rel=\"noopener\">云巢揭秘: 基于 TKE 构建数据库 PaaS 平台实践分享</a></h4> \n <ul> \n  <li>在腾讯云发展初期，为了抢占市场获取更多的用户，数据库经历一段时间的烟囱式发展。随着云的发展以及专有云的投入，更多业务团队也开始投入专有云的支持。</li> \n </ul> \n <h2 id=\"腾讯云案例\"><strong>腾讯云案例</strong></h2> \n <h4 id=\"案例--荔枝微课基于-kubernetes-搭建分布式压测系统\"><a href=\"http://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247501790&amp;idx=1&amp;sn=26a28b2c4090e2c13a88e8c8866881b7&amp;chksm=c0047c04f773f51277aab33b36b4209a5ecce25ac4b6f5a7932bf12358130abbfdf6267f15f9#rd\" target=\"_blank\" rel=\"noopener\">案例 | 荔枝微课基于 kubernetes 搭建分布式压测系统</a></h4> \n <ul> \n  <li>荔枝微课作为一个高速发展的平台，面临着业务流量越来越大的冲击，特别是在去年疫情期间遭遇成倍流量增长的情况，是通过什么方式轻松渡过难关的？以我在荔枝微课落地云原生的经历来说，为什么我们要去实践云原生架构呢？只是因为它是业内技术趋势吗？</li> \n </ul> \n <h4 id=\"案例--沃尔玛-x-腾讯云-serverless-应用实践全力保障消费者购物体验\"><a href=\"http://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247515094&amp;idx=1&amp;sn=ac9bd90b4cb496b10108766a43747bde&amp;chksm=c004000cf773891a9465d0b690066309eb1fae7c66c5278a1f20822bb4509e301d481144126d#rd\" target=\"_blank\" rel=\"noopener\">案例 | 沃尔玛 x 腾讯云 Serverless 应用实践，全力保障消费者购物体验</a></h4> \n <ul> \n  <li>位于深圳的山姆会员商店连续 10 余年成为沃尔玛全球销售第一的门店，沃尔玛的管理者认为，<strong>先进的科技在零售市场将有助于沃尔玛赢得竞争</strong> 。腾讯云山姆会员商店项目负责人李逸期在智慧零售深耕多年，从 0 到 1 搭建了山姆会员商店 APP 的技术架构。</li> \n </ul> \n <h4 id=\"技术赋能教育51talk-在线教育的-serverless-及音视频-实践\"><a href=\"http://mp.weixin.qq.com/s?__biz=Mzg5NjA1MjkxNw==&amp;mid=2247513896&amp;idx=2&amp;sn=520bc9fbe07f0702076106d193626c2a&amp;chksm=c0040cf2f77385e4a69f342de4eb6e183c083138f4c5ddc0459a1f3c817f85631e004aa6d097#rd\" target=\"_blank\" rel=\"noopener\">技术赋能教育：51Talk 在线教育的 Serverless 及音视频 实践</a></h4> \n <ul> \n  <li>十年树木，百年树人。教育的初心是育人为本，技术的初心是科技向善。腾讯云 Serverless 与中国教育行业携手同行，秉持初心以技术赋能教育，打造有竞争力的中国教育行业无服务器解决方案。</li> \n </ul> \n <blockquote> \n  <p>【腾讯云原生】云说新品、云研新术、云游新活、云赏资讯，扫码关注同名公众号，及时获取更多干货！！<br> <img src=\"https://img2020.cnblogs.com/other/2041406/202109/2041406-20210908102009122-746999636.png\" alt=\"\" loading=\"lazy\"></p> \n </blockquote> \n</div>"}
